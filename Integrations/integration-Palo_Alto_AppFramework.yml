commonfields:
  id: Palo Alto AppFramework
  version: -1
name: Palo Alto AppFramework
display: Palo Alto Networks Cortex
category: Analytics & SIEM
image: data:image/png;base64,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
description: This framework manages all PA's cloud managed products
detaileddescription: 25$nhXyu4
configuration:
- display: Demisto App Token
  name: token
  defaultvalue: ""
  type: 4
  required: true
- display: Use system proxy settings
  name: proxy
  defaultvalue: "false"
  type: 8
  required: false
- display: Trust any certificate (unsecure)
  name: insecure
  defaultvalue: "false"
  type: 8
  required: false
- display: Severity to filter fetch results by (Informational, Low, Medium, High,
    Critical)
  name: severity
  defaultvalue: ""
  type: 0
  required: false
- display: Fetch incidents
  name: isFetch
  defaultvalue: ""
  type: 8
  required: false
- display: Incident type
  name: incidentType
  defaultvalue: ""
  type: 13
  required: false
script:
  script: |
    ''' IMPORTS '''
    import os
    import datetime
    import requests
    import json
    from time import strftime
    from time import localtime
    import pancloud
    from pancloud.logging import LoggingService
    from pancloud.event import EventService
    # disable insecure warnings
    requests.packages.urllib3.disable_warnings()

    ''' GLOBAL VARS '''

    API_URL=''
    DEMISTO_APP_TOKEN = demisto.params()['token']
    USE_SSL = not demisto.params().get('insecure', False)

    if not demisto.params()['proxy']:
        del os.environ['HTTP_PROXY']
        del os.environ['HTTPS_PROXY']
        del os.environ['http_proxy']
        del os.environ['https_proxy']

    DEFAULT_HEADERS = {
        'Accept': 'application/json',
        'Content-Type': (
            'application/x-www-form-urlencoded;charset=UTF-8'
        )
    }

    THREAT_TABLE_HEADERS = ['id', 'score', 'risk-of-app','type', 'action', 'app', 'pcap_id', 'proto', 'dst', 'reportid', 'rule', 'category-of-threatid', 'characteristic-of-app', 'device_name',
                            'subtype', 'time_received', 'pcap', 'name-of-threatid', 'severity', 'nat', 'natdport', 'natdst', 'natsrc', 'src', 'category-of-app', 'srcloc', 'dstloc', 'category', 'SHA256', 'filetype', 'filename']

    TRAFFIC_TABLE_HEADERS = ['id', 'score', 'aggregations.size', 'action', 'app', 'proto', 'dst', 'rule', 'characteristic-of-app', 'device_name', 'risk-of-app', 'natsport', 'start', 'subcategory-of-app'
                             'time_received', 'nat', 'natdport', 'natdst', 'natsrc', 'src', 'category-of-app', 'srcloc', 'dstloc' ]

    COMMON_HEADERS = ['id', 'score', 'action', 'app', 'proto', 'dst', 'rule', 'characteristic-of-app', 'device_name', 'nat', 'natdport', 'natdst', 'natsrc', 'src', 'category-of-app', 'srcloc', 'dstloc','filetype', 'SHA256', 'filename']

    def epoch_seconds(d=None):
        """
        Return the number of seconds for given date. If no date, return current.

        parameter: (date) d
            The date to convert to seconds

        returns:
            The date in seconds
        """
        if not d:
            d = datetime.datetime.utcnow()
        return int((d - datetime.datetime.utcfromtimestamp(0)).total_seconds())


    def get_access_token():

        global API_URL
        integration_context = demisto.getIntegrationContext()
        access_token = integration_context.get('access_token')
        stored = integration_context.get('stored')
        if access_token and stored:
            if epoch_seconds() - stored < 60 * 60 - 30:
                return access_token
        headers = {
            'Authorization': DEMISTO_APP_TOKEN,
            'Accept': 'application/json'
        }
        token_retrieval_url = 'https://demistobot.demisto.com/panw-token'
        dbot_response = requests.get(token_retrieval_url, headers=headers, params={'token': DEMISTO_APP_TOKEN}, verify=USE_SSL)
        if dbot_response.status_code not in {200, 201}:
            #return_error(dbot_response.content)
            return_error('Error in authentication with the application. Try checking the credentials you entered.')
        try:
            parsed_response = dbot_response.json()
        except ValueError:
            #return_error(dbot_response.content)
            err_msg = 'There was a problem in retrieving an updated access token.\nThe response from the Demistobot server did not contain the expected content.'
            return_error(err_msg)
        access_token = parsed_response.get('access_token')
        API_URL = parsed_response.get('url')
        demisto.setIntegrationContext({
            'access_token': access_token,
            'stored': epoch_seconds(),
        })
        return access_token

    ACCESS_TOKEN = get_access_token()

    # setting the access token as env variable for the pancloud sdk
    os.environ['ACCESS_TOKEN'] = ACCESS_TOKEN;

    ''' HELPER FUNCTIONS '''

    def ack_event_channel(channel_id):
        '''
        Event Service always begins reading from the beginning of the channel whenever it starts up.
        This means that if the service restarts, the app will be reading events that it has already seen
        and, presumably, has already processed. To avoid this, we ack the channel. An ack causes the
        beginning of the channel to move to the current read point. Mechanically, the Event Service simply
        deletes all events from the channel that existed prior to the current read point.
        '''
        event_service = EventService(
            url=API_URL,
            headers={
                'Authorization': 'Bearer {}'.format(ACCESS_TOKEN),
                "Content-Type": "application/json",
                "Accept": "application/json"
            }
        )

        # ack event channel
        event_service.ack(channel_id)

    def query_loggings(query_data):
        '''
        This function handles all the querying of Cortex Logging service
        '''

        logging_service = LoggingService(
            url=API_URL,
            headers={
                'Authorization': 'Bearer {}'.format(ACCESS_TOKEN),
                "Content-Type": "application/json",
                "Accept": "application/json"
            }
        )

        query_result= logging_service.query(query_data).json()

        try:
            query_id = query_result['queryId']  # access 'queryId' from 'query' response
        except Exception, e:
            raise Exception('Received error %s when querying logs. Please check if your authentication token is valid' % e)
        poll_params = {  # Prepare 'poll' params
            "maxWaitTime": 1000 # waiting for resposnse up to 1000ms
        }

        # we poll the logging service until we have a complete response
        full_response = logging_service.poll_all(query_id, 0, poll_params)

        # delete the query from the service
        logging_service.delete(query_id)

        return full_response

    def poll_events(channel_id):
        '''
        This function handles polling events from Cortex Events service
        '''

        event_service = EventService(
            url=API_URL,
            headers={
                'Authorization': 'Bearer {}'.format(ACCESS_TOKEN),
                "Content-Type": "application/json",
                "Accept": "application/json"
            }
        )
        # Poll event channel
        return event_service.poll(channel_id)

    def transform_row_keys(row):
        transformed_row = {}
        for metric, value in row.iteritems():
            if (metric == 'filedigest'):
                transformed_row['SHA256'] = value
            elif (metric == 'misc'):
                transformed_row['filename'] = value
            elif (metric == 'category' and str(value) == '1'):
                transformed_row['category'] = 'malicious'
            else:
                transformed_row[metric] = value
        return transformed_row

    def results_screener(table_name, full_results):
        '''
        This function is used to make sure we include only pre-defined metrics in the human readable
        '''
        screened_results = []

        if(table_name == "traffic"):
            for row in full_results:
                screened_row = {metric:value for metric, value in row.iteritems() if metric in TRAFFIC_TABLE_HEADERS}
                screened_results.append(screened_row)
        elif (table_name == "threat"):
            for row in full_results:
                screened_row = {metric:value for metric, value in row.iteritems() if metric in THREAT_TABLE_HEADERS}
                screened_results.append(screened_row)
        elif (table_name == "common"):
            for row in full_results:
                screened_row = {metric:value for metric, value in row.iteritems() if metric in COMMON_HEADERS}
                screened_results.append(screened_row)
        else:
            return full_results

        return screened_results

    def get_start_time(date_type, time_value):
        current_date = datetime.datetime.now()
        if (date_type == 'minutes'):
            return current_date - datetime.timedelta(minutes=time_value)
        elif (date_type == 'days'):
            return current_date - datetime.timedelta(days=time_value)
        elif (date_type == 'weeks'):
            return current_date - datetime.timedelta(weeks=time_value)

    def convert_log_to_incident(log):
        log_contents = log['_source']
        log_contents['id'] = log['_id']
        log_contents['score'] = log['_score']
        occured = datetime.datetime.utcfromtimestamp(log_contents['time_received']).isoformat() + 'Z'
        # stringifying dictionary values for fetching. (json.dumps() doesn't stringify dictionary values)
        for key, value in log_contents.iteritems():
            log_contents[key] = str(value)
        incident = {
            'name': 'Wildfire file detected ' + str(log_contents.get('filedigest', None)),
            'rawJSON': json.dumps(log_contents, ensure_ascii=False),
            'labels':[
                {
                    'type': 'id',
                    'value': log.get('_id', None)
                },
                {
                    'type': 'score',
                    'value': str(log.get('_score', None))
                },
                {
                    'type': 'srcuser',
                    'value': log_contents.get('srcuser', None)
                },
                {
                    'type': 'threatid',
                    'value': str(log_contents.get('threatid', None))
                },
                {
                    'type': 'sport',
                    'value': str(log_contents.get('sport', None))
                },
                {
                    'type': 'dport',
                    'value': str(log_contents.get('dport', None))
                },
                {
                    'type': 'src',
                    'value': log_contents.get('src', None)
                },
                {
                    'type': 'subtype',
                    'value': log_contents.get('subtype', None)
                },
                {
                    'type': 'reportid',
                    'value': str(log_contents.get('reportid', None))
                },
                {
                    'type': 'SHA256',
                    'value': str(log_contents.get('filedigest', None))
                }
            ],
            'occurred': occured
        }
        return incident

    def severity_name_to_number(severity):
        severity_to_check = severity
        if not severity_to_check:
            return None
        else:
            severity_to_check = severity.lower()

        severity_number_dic = {
            'informational': 1,
            'low': 2,
            'medium': 3,
            'high': 4,
            'critical': 5
        }

        if severity_to_check in severity_number_dic:
            return severity_number_dic[severity_to_check]
        else:
            raise Exception('''Severity parameter of the integration should be one of the
                following: Informational, Low, Medium, High, Critical''')

    def app_to_table(app):
        app_to_check = app
        if not app_to_check:
            return None
        else:
            app_to_check = app.lower()
        app_to_table_dic = {
            'wildfire': 'wildfire'
        }
        if app_to_check in app_to_table_dic:
            return app_to_table_dic[app_to_check]
        else:
            raise Exception('''Application to fetch from parameter of the integration should be one of the
                following: Wildfire''')

    ''' COMMANDS FUNCTIONS '''

    def query_logs_command():
        '''
        Corresponds to 'pan-cortex-query-logs' command. Return the result of querying the Logging service
        '''
        args = demisto.args()
        start_time = args.get('startTime')
        end_time = args.get('endTime')
        time_range = args.get('timeRange')
        time_value = args.get('rangeValue')

        if (time_range):
            if (time_value):
                service_end_date = datetime.datetime.now()
                service_start_date = get_start_time(time_range, int(time_value))
            else:
                raise 'Please enter timeRange and timeValue, or startTime and endTime'
        else:
            # parses user input to datetime object
            service_start_date = datetime.datetime.strptime(start_time, "%Y-%m-%d %H:%M:%S")
            service_end_date = datetime.datetime.strptime(end_time, "%Y-%m-%d %H:%M:%S")

        # transforms datetime object to epoch time
        service_start_date_epoch = int(service_start_date.strftime("%s"))
        service_end_date_epoch = int(service_end_date.strftime("%s"))

        query = args.get('query')

        if ("limit" not in query.lower()):
            query += " LIMIT 100"

        query_data = {
            "query": query,
            "startTime": service_start_date_epoch,
            "endTime": service_end_date_epoch,
        }

        pages = query_loggings(query_data)
        results = []
        table_name = None
        for page in pages:
            current_page = page.json()
            table_name = current_page['result']['esQuery']['table'][0].split('.')[1]
            table_rows = current_page['result']['esResult']['hits']['hits']

            for row in table_rows:
                row_id = row['_id']
                row_contents = row['_source']
                row_contents['id'] = row_id
                row_contents['score'] = row['_score']
                transformed_row = transform_row_keys(row_contents)
                results.append(transformed_row)

        screened_results = results_screener('common', results)

        entry = {
            'Type': entryTypes['note'],
            'Contents': results,
            'ContentsFormat': formats['json'],
            'ReadableContentsFormat': formats['markdown'],
            'HumanReadable': tableToMarkdown('Logs ' + table_name + ' table',  screened_results),
            'EntryContext': {
                  'Cortex.Logging(val.id==obj.id)': results
            }
        }

        return entry

    def poll_events_command():
        '''
        corresponds to 'pan-cortex-poll-events' command. Polls events from Cortex
        '''

        channel_id = 'EventFilter'

        # brings the reading point to date
        ack_event_channel(channel_id)

        # returns the events from the channel
        return poll_events(channel_id).json()

    def get_critical_logs_command():
        '''
        corresponds to 'pan-cortex-get-critical-threat-logs' command. Queries Cortex Logging according to a pre-set query
        '''

        args = demisto.args()

        start_time = args.get('startTime')
        end_time = args.get('endTime')
        value = args.get('logsAmount')
        time_range = args.get('timeRange')
        time_value = args.get('rangeValue')

        if (time_range):
            if (time_value):
                service_end_date = datetime.datetime.now()
                service_start_date = get_start_time(time_range, int(time_value))
            else:
                raise 'Please enter timeRange and timeValue, or startTime and endTime'
        else:
            # parses user input to datetime object
            service_start_date = datetime.datetime.strptime(start_time, "%Y-%m-%d %H:%M:%S")
            service_end_date = datetime.datetime.strptime(end_time, "%Y-%m-%d %H:%M:%S")

        # transforms datetime object to epoch time
        service_start_date_epoch = int(service_start_date.strftime("%s"))
        service_end_date_epoch = int(service_end_date.strftime("%s"))

        api_query = "SELECT * FROM panw.threat WHERE severity = '5' LIMIT " + value

        query_data = {
            "query": api_query,
            "startTime": service_start_date_epoch,
            "endTime": service_end_date_epoch,
        }
        pages = query_loggings(query_data)

        results = []
        table_name = None
        for page in pages:
            current_page = page.json()
            table_name = current_page['result']['esQuery']['table'][0].split('.')[1]
            table_rows = current_page['result']['esResult']['hits']['hits']

            for row in table_rows:
                row_id = row['_id']
                row_contents = row['_source']
                row_contents['id'] = row_id
                row_contents['score'] = row['_score']
                transformed_row = transform_row_keys(row_contents)
                results.append(transformed_row)

        screened_results = results_screener('threat', results)

        entry = {
            'Type': entryTypes['note'],
            'Contents': results,
            'ContentsFormat': formats['json'],
            'ReadableContentsFormat': formats['markdown'],
            'HumanReadable': tableToMarkdown('Logs ' + table_name + ' table',  screened_results),
            'EntryContext': {
                  'Cortex.Logging(val.id==obj.id)': results
            }
        }
        return entry

    def get_social_applications_command():
        ''' corresponds to 'pan-cortex-get-social-applications' command. Queries Cortex Logging according to a pre-set query '''

        args = demisto.args()

        start_time = args.get('startTime')
        end_time = args.get('endTime')
        value = args.get('logsAmount')
        time_range = args.get('timeRange')
        time_value = args.get('rangeValue')

        if (time_range):
            if (time_value):
                service_end_date = datetime.datetime.now()
                service_start_date = get_start_time(time_range, int(time_value))
            else:
                raise 'Please enter timeRange and timeValue, or startTime and endTime'
        else:
            # parses user input to datetime object
            service_start_date = datetime.datetime.strptime(start_time, "%Y-%m-%d %H:%M:%S")
            service_end_date = datetime.datetime.strptime(end_time, "%Y-%m-%d %H:%M:%S")

        # transforms datetime object to epoch time
        service_start_date_epoch = int(service_start_date.strftime("%s"))
        service_end_date_epoch = int(service_end_date.strftime("%s"))

        api_query = "SELECT * FROM panw.traffic WHERE subcategory-of-app = 'social-networking' LIMIT " + value

        query_data = {
            "query": api_query,
            "startTime": service_start_date_epoch,
            "endTime": service_end_date_epoch,
        }

        pages = query_loggings(query_data)

        results = []
        table_name = None
        for page in pages:
            current_page = page.json()
            table_name = current_page['result']['esQuery']['table'][0].split('.')[1]
            table_rows = current_page['result']['esResult']['hits']['hits']

            for row in table_rows:
                row_id = row['_id']
                row_contents = row['_source']
                row_contents['id'] = row_id
                row_contents['score'] = row['_score']
                results.append(row_contents)

        screened_results = results_screener('traffic', results)

        entry = {
            'Type': entryTypes['note'],
            'Contents': results,
            'ContentsFormat': formats['json'],
            'ReadableContentsFormat': formats['markdown'],
            'HumanReadable': tableToMarkdown('Logs ' + table_name + ' table',  screened_results),
            'EntryContext': {
                  'Cortex.Logging(val.id==obj.id)': results
            }
        }
        return entry

    def search_by_file_hash_command():
        '''
        corresponds to 'pan-cortex-search-by-file-hash' command. Queries Cortex Logging according to a pre-set query
        '''

        args = demisto.args()

        start_time = args.get('startTime')
        end_time = args.get('endTime')
        value = args.get('logsAmount')
        time_range = args.get('timeRange')
        time_value = args.get('rangeValue')
        filehash = args.get('SHA256')

        if (time_range):
            if (time_value):
                service_end_date = datetime.datetime.now()
                service_start_date = get_start_time(time_range, int(time_value))
            else:
                raise 'Please enter timeRange and timeValue, or startTime and endTime'
        else:
            # parses user input to datetime object
            service_start_date = datetime.datetime.strptime(start_time, "%Y-%m-%d %H:%M:%S")
            service_end_date = datetime.datetime.strptime(end_time, "%Y-%m-%d %H:%M:%S")

        # transforms datetime object to epoch time
        service_start_date_epoch = int(service_start_date.strftime("%s"))
        service_end_date_epoch = int(service_end_date.strftime("%s"))

        api_query = "SELECT * FROM panw.threat WHERE filedigest='" + filehash + "' LIMIT " + value

        query_data = {
            "query": api_query,
            "startTime": service_start_date_epoch,
            "endTime": service_end_date_epoch,
        }
        pages = query_loggings(query_data)

        results = []
        table_name = None
        for page in pages:
            current_page = page.json()
            table_name = current_page['result']['esQuery']['table'][0].split('.')[1]
            table_rows = current_page['result']['esResult']['hits']['hits']

            for row in table_rows:
                row_id = row['_id']
                row_contents = row['_source']
                row_contents['id'] = row_id
                row_contents['score'] = row['_score']
                transformed_row = transform_row_keys(row_contents)
                results.append(transformed_row)

        screened_results = results_screener('threat', results)

        entry = {
            'Type': entryTypes['note'],
            'Contents': results,
            'ContentsFormat': formats['json'],
            'ReadableContentsFormat': formats['markdown'],
            'HumanReadable': tableToMarkdown('Logs ' + table_name + ' table',  screened_results),
            'EntryContext': {
                  'Cortex.Logging(val.id==obj.id)': results
            }
        }
        return entry

    def fetch_incidents():

        last_run = demisto.getLastRun().get('lastRun', None)
        if (last_run is not None):
            last_run = datetime.datetime.strptime(last_run, "%Y-%m-%dT%H:%M:%S")
        else:
            last_run = datetime.datetime.now() - datetime.timedelta(days=1)
        if not (demisto.params()['application']):
            raise Exception('Please enter the name of application that you want to fetch from')

        table = app_to_table(demisto.params()['application'])
        severity = severity_name_to_number(demisto.params()['severity'])

        query =  "SELECT * FROM panw.threat WHERE subtype='%s'" %table

        if (severity):
            query += " AND severity='%d'" %severity

        LOG('Fetching Palo Alto Cortex incidents with query: %s' %query)

        service_start_date_epoch = int(last_run.strftime("%s"))
        service_end_date_epoch = int(datetime.datetime.now().strftime("%s"))

        query_data = {
            "query": query,
            "startTime": service_start_date_epoch,
            "endTime": service_end_date_epoch,
        }

        pages = query_loggings(query_data)
        incidents = []
        table_name = None

        for page in pages:
            current_page = page.json()
            page_logs = current_page['result']['esResult']['hits']['hits']

            for log in page_logs:
                incident = convert_log_to_incident(log)
                incidents.append(incident)

        demisto.setLastRun({
            'lastRun': last_run.strftime("%Y-%m-%dT%H:%M:%S")
        })
        demisto.incidents(incidents)

    ''' EXECUTION CODE '''
    LOG('command is %s' % (demisto.command(), ))
    try:
        if demisto.command() == 'test-module':
            # This is the call made when pressing the integration test button.
            test_args = {
                "query": "SELECT * FROM panw.threat LIMIT 1",
                "startTime": 0,
                "endTime": 1609459200,
            }
            if query_loggings(test_args):
                demisto.results('ok')
            else:
                demisto.results('test failed')
        elif demisto.command() == 'pan-cortex-query-logs':
            demisto.results(query_logs_command())
        elif demisto.command() == 'pan-cortex-poll-events':
            demisto.results(poll_events_command())
        elif demisto.command() == 'pan-cortex-get-critical-threat-logs':
            demisto.results(get_critical_logs_command())
        elif demisto.command() == 'pan-cortex-get-social-applications':
            demisto.results(get_social_applications_command())
        elif demisto.command() == 'pan-cortex-search-by-file-hash':
            demisto.results(search_by_file_hash_command())
        elif demisto.command() == 'fetch-incidents':
            fetch_incidents()
    except Exception, e:
        LOG(e.message)
        LOG.print_log()
        raise
  type: python
  commands:
  - name: pan-cortex-query-logs
    arguments:
    - name: startTime
      description: Query start time. For example, startTime="2018-04-26 00:00:00"
      defaultValue: 1970-01-01 00:00:00
    - name: endTime
      default: true
      description: Query end time. For example, endTime="2018-04-26 00:00:00"
      defaultValue: 2020-01-01 00:00:00
    - name: query
      description: 'Free text SQL query. For example, query="select * from panw.traffic
        limit 5". There are multiple tables in Loggings, such as: threat, traffic.
        Refer to Cortex Logging service schema reference for the full list.
        Our documentation has more queries samples.'
      defaultValue: select * from panw.traffic limit 5
    - name: timeRange
      auto: PREDEFINED
      predefined:
      - minutes
      - days
      - weeks
      description: Time range for the query, used with rangeValue. For example, timeRange="weeks"
        timeValue="1" would run the query on the last week.
    - name: rangeValue
      description: Time value for the query,  used with timeRange. For example, timeRange="weeks"
        rangeValue="1" would run the query on the last week.
    outputs:
    - contextPath: Cortex.Logging.id
      description: The id of the log
      type: string
    - contextPath: Cortex.Logging.score
      description: The score of the log
      type: number
    - contextPath: Cortex.Logging.action
      description: The action of the log
    - contextPath: Cortex.Logging.app
      description: The app of the log
    - contextPath: Cortex.Logging.proto
      description: The protocol used
      type: string
    - contextPath: Cortex.Logging.dst
      description: Destination ip
      type: string
    - contextPath: Cortex.Logging.rule
      description: Rule used
    - contextPath: Cortex.Logging.src
      description: The source of the action
    - contextPath: Cortex.Logging.category-of-app
      description: Application's category
      type: string
    - contextPath: Cortex.Logging.srcloc
      description: Source location
      type: string
    - contextPath: Cortex.Logging.dstloc
      description: Destination location
      type: string
    - contextPath: Cortex.Logging.characteristic-of-app
      description: Application's characteristics
    - contextPath: Cortex.Logging.device_name
      description: The name of the device
      type: string
    - contextPath: Cortex.Logging.nat
      description: Whether NAT was used or not
      type: number
    - contextPath: Cortex.Logging.natdport
      description: NAT port
    - contextPath: Cortex.Logging.natdst
      description: NAT destination
    - contextPath: Cortex.Logging.natsrc
      description: NAT source
    description: Query Cortex Logging service
  - name: pan-cortex-get-critical-threat-logs
    arguments:
    - name: startTime
      description: Query start time. For example, startTime="2018-04-26 00:00:00"
      defaultValue: 1970-01-01 00:00:00
    - name: endTime
      description: Query end time. For example, endTime="2018-04-26 00:00:00"
      defaultValue: 2020-01-01 00:00:00
    - name: logsAmount
      description: Amount of logs. Default is 10
      defaultValue: "10"
    - name: timeRange
      auto: PREDEFINED
      predefined:
      - minutes
      - days
      - weeks
      description: Time range for the query, used with rangeValue. For example, timeRange="weeks"
        rangeValue="1" would run the query on the last week.
    - name: rangeValue
      description: Time value for the query,  used with timeRange. For example, timeRange="weeks"
        rangeValue="1" would run the query on the last week.
    outputs:
    - contextPath: Cortex.Logging.id
      description: The id of the log
      type: string
    - contextPath: Cortex.Logging.score
      description: The score of the log
      type: number
    - contextPath: Cortex.Logging.action
      description: The action of the log
    - contextPath: Cortex.Logging.app
      description: The app of the log
    - contextPath: Cortex.Logging.proto
      description: The protocol used
      type: string
    - contextPath: Cortex.Logging.dst
      description: Destination ip
      type: string
    - contextPath: Cortex.Logging.rule
      description: Rule used
    - contextPath: Cortex.Logging.src
      description: The source of the action
    - contextPath: Cortex.Logging.category-of-app
      description: Application's category
      type: string
    - contextPath: Cortex.Logging.srcloc
      description: Source location
      type: string
    - contextPath: Cortex.Logging.dstloc
      description: Destination location
      type: string
    - contextPath: Cortex.Logging.characteristic-of-app
      description: Application's characteristics
    - contextPath: Cortex.Logging.device_name
      description: The name of the device
      type: string
    - contextPath: Cortex.Logging.nat
      description: Whether NAT was used or not
      type: number
    - contextPath: Cortex.Logging.natdport
      description: NAT port
    - contextPath: Cortex.Logging.natdst
      description: NAT destination
    - contextPath: Cortex.Logging.natsrc
      description: NAT source
    - contextPath: Cortex.Logging.risk-of-app
      description: Risk of application
    - contextPath: Cortex.Logging.type
      description: Threat type
    - contextPath: Cortex.Logging.pcad_id
      description: Pcap id
    - contextPath: Cortex.Logging.reportid
      description: Report id
      type: number
    - contextPath: Cortex.Logging.category-of-threatid
      description: Category of threat id
    - contextPath: Cortex.Logging.subtype
      description: Threat sub type
    - contextPath: Cortex.Logging.time_received
      description: Time received
    - contextPath: Cortex.Logging.pcap
      description: Pcap
    - contextPath: Cortex.Logging.name-of-threatid
      description: Name of threat id
      type: string
    - contextPath: Cortex.Logging.severity
      description: Threat Severity
    description: Query Cortex Logging service according to pre-set queries
  - name: pan-cortex-get-social-applications
    arguments:
    - name: startTime
      description: Query start time. For example, startTime="2018-04-26 00:00:00"
      defaultValue: 1970-01-01 00:00:00
    - name: endTime
      description: Query end time. For example, endTime="2018-04-26 00:00:00"
      defaultValue: 2020-01-01 00:00:00
    - name: logsAmount
      description: Amount of logs. Default is 10
      defaultValue: "10"
    - name: timeRange
      auto: PREDEFINED
      predefined:
      - minutes
      - days
      - weeks
      description: Time range for the query, used with rangeValue. For example, timeRange="weeks"
        rangeValue="1" would run the query on the last week.
    - name: rangeValue
      description: Time value for the query,  used with timeRange. For example, timeRange="weeks"
        rangeValue="1" would run the query on the last week.
    outputs:
    - contextPath: Cortex.Logging.id
      description: The id of the log
      type: string
    - contextPath: Cortex.Logging.score
      description: The score of the log
      type: number
    - contextPath: Cortex.Logging.action
      description: The action of the log
    - contextPath: Cortex.Logging.app
      description: The app of the log
    - contextPath: Cortex.Logging.proto
      description: The protocol used
      type: string
    - contextPath: Cortex.Logging.dst
      description: Destination ip
      type: string
    - contextPath: Cortex.Logging.rule
      description: Rule used
    - contextPath: Cortex.Logging.src
      description: The source of the action
    - contextPath: Cortex.Logging.category-of-app
      description: Application's category
      type: string
    - contextPath: Cortex.Logging.srcloc
      description: Source location
      type: string
    - contextPath: Cortex.Logging.dstloc
      description: Destination location
      type: string
    - contextPath: Cortex.Logging.characteristic-of-app
      description: Application's characteristics
    - contextPath: Cortex.Logging.device_name
      description: The name of the device
      type: string
    - contextPath: Cortex.Logging.nat
      description: Whether NAT was used or not
      type: number
    - contextPath: Cortex.Logging.natdport
      description: NAT port
    - contextPath: Cortex.Logging.natdst
      description: NAT destination
    - contextPath: Cortex.Logging.natsrc
      description: NAT source
    - contextPath: Cortex.Logging.risk-of-app
      description: Risk of application
    - contextPath: Cortex.Logging.aggregations.size
      description: Aggregations size
    - contextPath: Cortex.Logging.natsport
      description: NAT s port
    - contextPath: Cortex.Logging.start
      description: Traffic start
    - contextPath: Cortex.Logging.subcategory-of-apptime_received
      description: Sub-category of application time
    description: Query Cortex Logging service according to pre-set queries
  - name: pan-cortex-search-by-file-hash
    arguments:
    - name: startTime
      description: Query start time. For example, startTime="2018-04-26 00:00:00"
      defaultValue: 1970-01-01 00:00:00
    - name: endTime
      description: Query end time. For example, endTime="2018-04-26 00:00:00"
      defaultValue: 2020-01-01 00:00:00
    - name: logsAmount
      description: Amount of logs. Default is 10
      defaultValue: "10"
    - name: timeRange
      auto: PREDEFINED
      predefined:
      - minutes
      - days
      - weeks
      description: Time range for the query, used with rangeValue. For example, timeRange="weeks"
        rangeValue="1" would run the query on the last week.
    - name: rangeValue
      description: Time value for the query,  used with timeRange. For example, timeRange="weeks"
        rangeValue="1" would run the query on the last week.
    - name: SHA256
      required: true
      description: File hash for the query. For example, SHA256="503ca1a4fc0d48b18c0336f544ba0f0abf305ae3a3f49b3c2b86b8645d6572dc"
        would return all logs related to this file.
    outputs:
    - contextPath: Cortex.Logging.id
      description: The id of the log
      type: string
    - contextPath: Cortex.Logging.score
      description: The score of the log
      type: number
    - contextPath: Cortex.Logging.action
      description: The action of the log
    - contextPath: Cortex.Logging.app
      description: The app of the log
    - contextPath: Cortex.Logging.proto
      description: The protocol used
      type: string
    - contextPath: Cortex.Logging.dst
      description: Destination ip
      type: string
    - contextPath: Cortex.Logging.rule
      description: Rule used
    - contextPath: Cortex.Logging.src
      description: The source of the action
    - contextPath: Cortex.Logging.category-of-app
      description: Application's category
      type: string
    - contextPath: Cortex.Logging.srcloc
      description: Source location
      type: string
    - contextPath: Cortex.Logging.dstloc
      description: Destination location
      type: string
    - contextPath: Cortex.Logging.characteristic-of-app
      description: Application's characteristics
    - contextPath: Cortex.Logging.device_name
      description: The name of the device
      type: string
    - contextPath: Cortex.Logging.nat
      description: Whether NAT was used or not
      type: number
    - contextPath: Cortex.Logging.natdport
      description: NAT port
    - contextPath: Cortex.Logging.natdst
      description: NAT destination
    - contextPath: Cortex.Logging.natsrc
      description: NAT source
    - contextPath: Cortex.Logging.risk-of-app
      description: Risk of application
    - contextPath: Cortex.Logging.type
      description: Threat type
    - contextPath: Cortex.Logging.pcad_id
      description: Pcap id
    - contextPath: Cortex.Logging.reportid
      description: Report id
      type: number
    - contextPath: Cortex.Logging.category-of-threatid
      description: Category of threat id
    - contextPath: Cortex.Logging.subtype
      description: Threat sub type
    - contextPath: Cortex.Logging.time_received
      description: Time received
    - contextPath: Cortex.Logging.pcap
      description: Pcap
    - contextPath: Cortex.Logging.name-of-threatid
      description: Name of threat id
      type: string
    - contextPath: Cortex.Logging.severity
      description: Threat Severity
    description: Query Cortex Logging service according to pre-set queries
  dockerimage: demisto/python_pancloud:1.0.0.170
  isfetch: true
  runonce: false
tests:
  - No test - OAUTH2
releaseNotes: "Implemented OAUTH2"
