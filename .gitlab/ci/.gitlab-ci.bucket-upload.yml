.bucket-upload-rule:
  rules:
    - if: '$CI_COMMIT_BRANCH =~ /pull\/[0-9]+/'
      when: never
    - if: '$BUCKET_UPLOAD == "true" && $FORCE_BUCKET_UPLOAD == "false"'

.bucket-upload-rule-always:
  rules:
    - if: '$CI_COMMIT_BRANCH =~ /pull\/[0-9]+/'
      when: never
    - if: '$BUCKET_UPLOAD == "true" && $FORCE_BUCKET_UPLOAD == "false"'
      when: always


.check_user_permissions_to_upload_packs: &check_user_permissions_to_upload_packs
  - section_start "Check User Permissions to Upload Packs" # if bucket upload and uploading to marketplace-dist
  - |
    if [[ -n "${BUCKET_UPLOAD}" || -n "${FORCE_BUCKET_UPLOAD}" ]] && [[ "$GCS_MARKET_BUCKET" == "$GCS_PRODUCTION_BUCKET" ]]; then
      CONTENT_LEADERS=$(curl -sS "https://api.github.com/orgs/demisto/teams/content-leaders/members" -H "Authorization: token ${GITHUB_TOKEN}")
      echo "received content leaders"
      LEADER_NAMES=$(echo $CONTENT_LEADERS | jq -r ".[].login")
      LEADER_NAMES=$(echo "${LEADER_NAMES}" "content-bot" "svc -xsoar-gitlab-mirror" "svc-xsoar-gitlab-mirror" "${USERS_ALLOWED_TRIGGER_UPLOAD}" )
      if [[ -z "$GITLAB_USER_NAME" ]] || [[ -z "`echo $LEADER_NAMES | grep -w "$GITLAB_USER_NAME"`" ]]; then
        echo -e "User '$GITLAB_USER_NAME' is not allowed to trigger this build, only one of:\n${LEADER_NAMES}"
        job-done
        exit 1
      else
        echo "User '${GITLAB_USER_NAME}' is allowed to upload packs / force upload packs."
      fi
    fi
  - section_end "Check User Permissions to Upload Packs"

.upload_content_graph: &upload_content_graph
    - |
      if [[ $TEST_UPLOAD == "false" ]]; then
        section_start "Upload content graph GraphML to GCP" --collapsed
        gsutil cp "${ARTIFACTS_FOLDER_SERVER_TYPE}/content_graph/${MARKETPLACE_VERSION}.zip" "gs://$GCS_MARKET_BUCKET_DEV/content_graph/$MARKETPLACE_VERSION.zip"
        # copy the packs.json file to the bucket, used in contribution management
        gsutil cp "${ARTIFACTS_FOLDER_SERVER_TYPE}/packs.json" "gs://${GCS_MARKET_BUCKET_DEV}/content_graph/${MARKETPLACE_VERSION}_packs.json"
        section_end "Upload content graph GraphML to GCP"
      fi

.upload_dependencies_file: &upload_dependencies_file
    - |
      if [[ $TEST_UPLOAD == "false" ]]; then
        section_start "Upload packs_dependencies.json to GCP" --collapsed
        gcloud auth activate-service-account --key-file="$GCS_ARTIFACTS_KEY" >> "${ARTIFACTS_FOLDER}/logs/gcloud_auth.log" 2>&1
        gsutil cp "${ARTIFACTS_FOLDER_SERVER_TYPE}/packs_dependencies.json" "gs://xsoar-ci-artifacts/content-cache-docs/$MARKETPLACE_VERSION/packs_dependencies.json"
        section_end "Upload packs_dependencies.json to GCP"
      fi

run-validations-upload-flow:
  variables:
    DEMISTO_SDK_GRAPH_FORCE_CREATE: "true"
  extends:
    - .run-validations
    - .bucket-upload-rule

run-validations-upload-flow-new-validate-flow:
  variables:
    DEMISTO_SDK_GRAPH_FORCE_CREATE: "true"
  extends:
    - .run-validations-new-validate-flow
    - .bucket-upload-rule
  allow_failure: true

run-unittests-and-lint-upload-flow:
  cache:
    policy: push
  extends:
    - .run-unittests-and-lint
    - .bucket-upload-rule

run-pre-commit-upload-flow:
  cache:
    policy: push
  allow_failure: true
  extends:
    - .run-pre-commit
    - .bucket-upload-rule

jobs-done-check-upload-flow:
  extends:
    - .jobs-done-check
    - .bucket-upload-rule
  needs: ['run-unittests-and-lint-upload-flow', 'run-validations-upload-flow', 'mpv2-prepare-testing-bucket-upload-flow', 'upload-id-set-bucket', 'xpanse-prepare-testing-bucket-upload-flow', 'xsoar-prepare-testing-bucket-upload-flow', 'xsoar-saas-prepare-testing-bucket-upload-flow', 'install-packs-in-server6_9', 'install-packs-in-server6_10', 'install-packs-in-server6_11', 'install-packs-in-server6_12', 'install-packs-in-server-master', 'install-packs-in-xsiam-ga', 'sync-buckets-between-projects', 'upload-packs-to-marketplace', 'upload-packs-to-marketplace-v2', 'upload-packs-to-xpanse-marketplace', 'upload-packs-to-xsoar-saas-marketplace']
  tags:
    - gke
  variables:
    WORKFLOW: 'Upload Packs to Marketplace Storage'



xsoar-prepare-testing-bucket-upload-flow:
  extends:
    - xsoar-prepare-testing-bucket
  variables:
    IFRA_ENV_TYPE: "Bucket-Upload"
    ARTIFACTS_FOLDER: "${ARTIFACTS_FOLDER_XSOAR}"
  rules:
    - if: '$CI_COMMIT_BRANCH =~ /pull\/[0-9]+/'
      when: never
    - if: '$BUCKET_UPLOAD == "true"'
    - if: '$FORCE_BUCKET_UPLOAD == "true"'


xsoar-saas-prepare-testing-bucket-upload-flow:
  extends:
    - xsoar-saas-prepare-testing-bucket
  variables:
    IFRA_ENV_TYPE: "Bucket-Upload"
    ARTIFACTS_FOLDER: "${ARTIFACTS_FOLDER_XSOAR}"
  rules:
    - if: '$CI_COMMIT_BRANCH =~ /pull\/[0-9]+/'
      when: never
    - if: '$BUCKET_UPLOAD == "true"'
    - if: '$FORCE_BUCKET_UPLOAD == "true"'


mpv2-prepare-testing-bucket-upload-flow:
  extends:
      - mpv2-prepare-testing-bucket
  variables:
    IFRA_ENV_TYPE: "Bucket-Upload"
    ARTIFACTS_FOLDER: "${ARTIFACTS_FOLDER_MPV2}"
  rules:
    - if: '$CI_COMMIT_BRANCH =~ /pull\/[0-9]+/'
      when: never
    - if: '$BUCKET_UPLOAD == "true"'
    - if: '$FORCE_BUCKET_UPLOAD == "true"'


xpanse-prepare-testing-bucket-upload-flow:
  extends:
      - xpanse-prepare-testing-bucket
  variables:
    IFRA_ENV_TYPE: "Bucket-Upload"
    ARTIFACTS_FOLDER: "${ARTIFACTS_FOLDER_XPANSE}"
  rules:
    - if: '$CI_COMMIT_BRANCH =~ /pull\/[0-9]+/'
      when: never
    - if: '$BUCKET_UPLOAD == "true"'
    - if: '$FORCE_BUCKET_UPLOAD == "true"'


.install_packs_in_xsoar_server:
  tags:
    - gke
  needs: ["xsoar-prepare-testing-bucket-upload-flow"]
  stage: run-instances
  artifacts:
    expire_in: 48 hrs
    paths:
      - ${CI_PROJECT_DIR}/artifacts/*
      - ${CI_PROJECT_DIR}/pipeline_jobs_folder/*
    when: always
  variables:
    PRODUCT_TYPE: "XSOAR"
    SERVER_TYPE: "XSOAR"
    ARTIFACTS_FOLDER: "${ARTIFACTS_FOLDER_XSOAR}"
    ARTIFACTS_FOLDER_INSTANCE: "${ARTIFACTS_FOLDER_XSOAR}/instance_${INSTANCE_ROLE}"
    ARTIFACTS_FOLDER_SERVER_TYPE: "${ARTIFACTS_FOLDER_XSOAR}/server_type_${SERVER_TYPE}"
    ENV_RESULTS_PATH: "${ARTIFACTS_FOLDER_SERVER_TYPE}/env_results.json"
    INSTANCE_CREATED: "true"
    SSH_TUNNEL_TIMEOUT: 10
    TIME_TO_LIVE: ""
  extends:
    - .bucket-upload-rule
    - .default-job-settings
  script:
    - EXIT_CODE=0
    - !reference [.download-demisto-conf]
    - section_start "Secrets Fetch" --collapsed
    - SECRET_CONF_PATH=$(cat secret_conf_path)
    - python3 ./Tests/scripts/add_secrets_file_to_build.py -sa "$GSM_SERVICE_ACCOUNT" -sf "$SECRET_CONF_PATH" -u "$DEMISTO_USERNAME" -p "$DEMISTO_PASSWORD" --gsm_project_id_dev "$GSM_PROJECT_ID_DEV" --gsm_project_id_prod "$GSM_PROJECT_ID" >> $ARTIFACTS_FOLDER/logs/handle_secrets.log
    - section_end "Secrets Fetch"
    - !reference [.ssh-config-setup]
    - section_start "Check if should run Instance role"
    - export INSTANCES_CREATED_FOR_ROLE=$(cat "${ENV_RESULTS_PATH}" | jq -c "map(select(.Role == \"${INSTANCE_ROLE}\")) | length")
    - |
      echo "Instance role:${INSTANCE_ROLE} Product type:${PRODUCT_TYPE} Instances created for role:${INSTANCES_CREATED_FOR_ROLE}"
      if [[ "${INSTANCES_CREATED_FOR_ROLE}" -eq 0 ]]; then
        echo "Instances with role ${INSTANCE_ROLE} were not created, not running the instance flow."
        rm -f "${ARTIFACTS_FOLDER_INSTANCE}/instance_role.txt" # delete the instance_role.txt file so the job will not be collected by slack notifier.
        job-done
        exit 0
      fi
    - section_end "Check if should run Instance role"
    - section_start "Get Instance Variables"
    - echo INSTANCE_ROLE="$INSTANCE_ROLE"
    - echo INSTANCE_CREATED="$INSTANCE_CREATED"
    - section_end "Get Instance Variables"
    - section_start "Wait Until Server Ready"
    - |
      [ -n "${NIGHTLY}" ] && IS_NIGHTLY=true || IS_NIGHTLY=false
      python3 ./Tests/scripts/wait_until_server_ready.py  -n ${IS_NIGHTLY} --instance-role "${INSTANCE_ROLE}" || EXIT_CODE=$?
    - section_end "Wait Until Server Ready"
    - section_start "Install Packs"
    - ./Tests/Marketplace/install_packs.sh || EXIT_CODE=$?
    - section_end "Install Packs"
    - section_start "Get instance ssh-command"
    - echo "INSTANCE_ROLE -> ${INSTANCE_ROLE}"
    - INSTANCE_NAME=$(jq -r --arg role "$INSTANCE_ROLE" '.[] | select(.Role == $role) | .InstanceName' $ENV_RESULTS_PATH)
    - echo -e "\e[1m gcloud compute ssh --zone \"us-central1-a\" \"${INSTANCE_NAME}\"  --tunnel-through-iap --project "xsoar-content-build" \e[0m"
    - section_end "Get instance ssh-command"
    - job-done
    - exit "${EXIT_CODE}"
  after_script:
    - !reference [.default-after-script]
    - !reference [.install_ssh_keys]
    - !reference [.ssh-config-setup]
    - !reference [.destroy_xsoar_instances]


install-packs-in-server6_9:
  extends: .install_packs_in_xsoar_server
  variables:
    INSTANCE_ROLE: "Server 6.9"

install-packs-in-server6_10:
  extends: .install_packs_in_xsoar_server
  variables:
    INSTANCE_ROLE: "Server 6.10"

install-packs-in-server6_11:
  extends: .install_packs_in_xsoar_server
  variables:
    INSTANCE_ROLE: "Server 6.11"

install-packs-in-server6_12:
  extends: .install_packs_in_xsoar_server
  variables:
    INSTANCE_ROLE: "Server 6.12"

install-packs-in-server-master:
  extends: .install_packs_in_xsoar_server
  variables:
    INSTANCE_ROLE: "Server Master"


.install-mpv2-packs-on-xsiam-instances:
  tags:
    - gke
  needs: ["mpv2-prepare-testing-bucket-upload-flow"]
  stage: run-instances
  artifacts:
    expire_in: 48 hrs
    paths:
      - ${CI_PROJECT_DIR}/artifacts/*
      - ${CI_PROJECT_DIR}/pipeline_jobs_folder/*
    when: always
  rules:
    - if: '$CI_COMMIT_BRANCH =~ /pull\/[0-9]+/'
      when: never
    - if: $TEST_UPLOAD == "true" && $BUCKET_UPLOAD == "true" && $FORCE_BUCKET_UPLOAD == "false"
      when: always
      variables:
        CLOUD_MACHINES_TYPE: "build"
        GCS_LOCKS_PATH: "content-locks/locks-xsiam-ga"
    - if: '$BUCKET_UPLOAD == "true" && $FORCE_BUCKET_UPLOAD == "false"'
  variables:
    PRODUCT_TYPE: "XSIAM"
    SERVER_TYPE: "XSIAM"
    ARTIFACTS_FOLDER: "${ARTIFACTS_FOLDER_MPV2}"
    ARTIFACTS_FOLDER_INSTANCE: "${ARTIFACTS_FOLDER_MPV2}/instance_${INSTANCE_ROLE}"
    ARTIFACTS_FOLDER_SERVER_TYPE: "${ARTIFACTS_FOLDER_MPV2}/server_type_${SERVER_TYPE}"
    ENV_RESULTS_PATH: "${ARTIFACTS_FOLDER_SERVER_TYPE}/env_results.json"
    INSTANCE_CREATED: "true"
    TIME_TO_LIVE: ""
    GCS_LOCKS_PATH: "content-locks/locks-xsiam-ga-upload"
    CLOUD_MACHINES_TYPE: "upload"
    CLOUD_MACHINES_COUNT: 1
  extends:
    - .default-job-settings
  script:
    - EXIT_CODE=0
    - !reference [.download-demisto-conf]
    - section_start "Secrets Fetch" --collapsed
    - SECRET_CONF_PATH=$(cat secret_conf_path)
    - python3 ./Tests/scripts/add_secrets_file_to_build.py -sa "$GSM_SERVICE_ACCOUNT" -sf "$SECRET_CONF_PATH" -u "$DEMISTO_USERNAME" -p "$DEMISTO_PASSWORD" --gsm_project_id_dev "$GSM_PROJECT_ID_DEV" --gsm_project_id_prod "$GSM_PROJECT_ID" >> $ARTIFACTS_FOLDER/logs/handle_secrets.log
    - section_end "Secrets Fetch"
    - section_start "Lock Machine"
    - echo "Authenticating GCP"
    - gcloud auth activate-service-account --key-file="$GCS_ARTIFACTS_KEY" >> "${ARTIFACTS_FOLDER}/logs/gcloud_auth.log" 2>&1
    - echo "Auth done successfully"
    - ./Tests/scripts/wait_in_line_for_cloud_env.sh "$CLOUD_MACHINES_TYPE"
    - source CloudEnvVariables
    - echo "CLOUD Chosen machine ids are:${CLOUD_CHOSEN_MACHINE_IDS}"
    - section_end "Lock Machine"

    - CLOUD_SERVERS_PATH=$(cat $CLOUD_SERVERS_FILE)
    - cat "${CLOUD_API_KEYS}" > "cloud_api_keys.json"
    - !reference [.uninstall-packs-and-reset-bucket-cloud]

    - section_start "Run XSIAM end to end sanity tests"
    - ./Tests/scripts/run_e2e_tests.sh || EXIT_CODE=$?
    - section_end "Run XSIAM end to end sanity tests"

    - section_start "Get Instance Variables"
    - echo INSTANCE_ROLE="$INSTANCE_ROLE"
    - echo INSTANCE_CREATED="$INSTANCE_CREATED"
    - section_end "Get Instance Variables"

    - section_start "Install Packs"
    - ./Tests/Marketplace/install_packs.sh || EXIT_CODE=$?
    - section_end "Install Packs"

    - job-done
    - exit "$EXIT_CODE"
  after_script:
    - source .gitlab/helper_functions.sh
    - !reference [ .unlock-machine ]

install-packs-in-xsiam-ga:
  extends: .install-mpv2-packs-on-xsiam-instances
  variables:
    INSTANCE_ROLE: "XSIAM"
    GCS_QUEUE_FILE: "queue-ga"
    GCS_SOURCE_BUCKET: "$GCS_PRODUCTION_V2_BUCKET"
    GCS_MACHINES_BUCKET: "marketplace-v2-dist-dev/upload-flow/builds-xsiam"
    CLOUD_SERVERS_FILE: "xsiam_servers_path"
    CLOUD_API_KEYS: $XSIAM_API_KEYS
    CLOUD_API_TOKENS: $XSIAM_TOKENS
    NON_REMOVABLE_PACKS: "Base"


upload-packs-to-marketplace:
  tags:
    - gke
  needs: ["run-validations-upload-flow", "install-packs-in-server6_9", "install-packs-in-server6_10", "install-packs-in-server6_11", "install-packs-in-server6_12", "install-packs-in-server-master", "run-unittests-and-lint-upload-flow"]
  stage: upload-to-marketplace
  artifacts:
    expire_in: 48 hrs
    paths:
      - ${CI_PROJECT_DIR}/artifacts/*
      - ${CI_PROJECT_DIR}/pipeline_jobs_folder/*
    when: always
  variables:
    PRODUCT_TYPE: "XSOAR"
    SERVER_TYPE: "XSOAR"
    INSTANCE_ROLE: "Server Master"
    MARKETPLACE_VERSION: "xsoar"
    ARTIFACTS_FOLDER: "${ARTIFACTS_FOLDER_XSOAR}"
    ARTIFACTS_FOLDER_SERVER_TYPE: "${ARTIFACTS_FOLDER_XSOAR}/server_type_${SERVER_TYPE}"
    ENV_RESULTS_PATH: "${ARTIFACTS_FOLDER_SERVER_TYPE}/env_results.json"
    INSTANCE_CREATED: "true"
    SSH_TUNNEL_TIMEOUT: 10
    TIME_TO_LIVE: ""
  extends:
    - .bucket-upload-rule
    - .default-job-settings
  script:
    - !reference [.ssh-config-setup]
    - *check_user_permissions_to_upload_packs
    - section_start "Upload Packs To Marketplace Storage"
    - |
      if [[ "$CI_COMMIT_BRANCH" == "master" ]] || [[ "$GCS_MARKET_BUCKET" != "$GCS_PRODUCTION_BUCKET" ]]; then
        EXTRACT_FOLDER=$(mktemp -d)
        PACK_ARTIFACTS="${ARTIFACTS_FOLDER_SERVER_TYPE}/content_packs.zip"
        PACKS_DEPENDENCIES="${ARTIFACTS_FOLDER_SERVER_TYPE}/packs_dependencies.json"
        CI_COMMIT_BRANCH=${CI_COMMIT_BRANCH:-unknown}
        GCS_BUILD_BUCKET="marketplace-ci-build"
        if [[ $GCS_MARKET_BUCKET == $GCS_PRODUCTION_BUCKET ]] && [[ -z $STORAGE_BASE_PATH ]]; then
          STORAGE_BASE_PATH="content"
        fi

        if [[ $GCS_MARKET_BUCKET != $GCS_PRODUCTION_BUCKET ]] && [[ -z $STORAGE_BASE_PATH ]]; then
         STORAGE_BASE_PATH="upload-flow/builds/$CI_COMMIT_BRANCH/$CI_PIPELINE_ID/content"
        fi

        if [[ -z "${PACKS_TO_UPLOAD}" ]]; then
          PACKS_TO_UPLOAD="All"
        fi
        python3 ./Tests/Marketplace/copy_and_upload_packs.py -a "${PACK_ARTIFACTS}" -e $EXTRACT_FOLDER -pb "$GCS_MARKET_BUCKET" -bb "$GCS_BUILD_BUCKET" -s $GCS_MARKET_KEY -n $CI_PIPELINE_ID -c $CI_COMMIT_BRANCH -p "${PACKS_TO_UPLOAD}" -pbp "$STORAGE_BASE_PATH/packs" --marketplace xsoar
        
        gcloud auth activate-service-account --key-file="$GCS_ARTIFACTS_KEY" >> "${ARTIFACTS_FOLDER}/logs/gcloud_auth.log" 2>&1
        if [[ $TEST_UPLOAD == "false" ]] && [[ -f "${ARTIFACTS_FOLDER_SERVER_TYPE}/packs_results_upload.json" ]]; then
          gsutil cp "${ARTIFACTS_FOLDER_SERVER_TYPE}/packs_results_upload.json" "gs://xsoar-ci-artifacts/content/$CI_COMMIT_SHA/$MARKETPLACE_VERSION/packs_results_upload.json"
          echo "packs_results_upload.json upload successfully"
        fi
        
        core_packs_files_count=$(find "${ARTIFACTS_FOLDER_SERVER_TYPE}" -name "corepacks*.json" | wc -l)
        if [ "${core_packs_files_count}" -eq 0 ]; then
          echo "No core packs files were found, skipping uploading."
        else
          echo "Uploading ${core_packs_files_count} core packs files."
          # Copy core packs files from the artifacts folder to the build bucket:
          find "${ARTIFACTS_FOLDER_SERVER_TYPE}" -name "corepacks*.json" -exec gsutil cp -z json "{}" "gs://$GCS_MARKET_BUCKET/$STORAGE_BASE_PATH/packs" \;
          echo "Successfully uploaded core packs files."
        fi
      fi
    - section_end "Upload Packs To Marketplace Storage"

    - section_start "Download packs from GCP"
    - |
      if [[ $GCS_MARKET_BUCKET == $GCS_PRODUCTION_BUCKET ]] && [[ -z $STORAGE_BASE_PATH ]]; then
        STORAGE_BASE_PATH="content"
      fi
      if [[ $GCS_MARKET_BUCKET != $GCS_PRODUCTION_BUCKET ]] && [[ -z $STORAGE_BASE_PATH ]]; then
        STORAGE_BASE_PATH="upload-flow/builds/$CI_COMMIT_BRANCH/$CI_PIPELINE_ID/content"
      fi

      PACKS_SRC="gs://$GCS_MARKET_BUCKET/$STORAGE_BASE_PATH/packs"
      ZIP_FOLDER=$(mktemp -d)
      gcloud auth activate-service-account --key-file="$GCS_MARKET_KEY" >> "${ARTIFACTS_FOLDER}/logs/gcloud_auth.log" 2>&1
      echo "successfully activated google cloud service account"
      gsutil -m cp -r $PACKS_SRC $ZIP_FOLDER
      echo "successfully downloaded index.zip"
    - section_end "Download packs from GCP"
    - *upload_content_graph
    - *upload_dependencies_file
    - section_start "Revoking GCP Auth"
    - gcloud auth revoke "${GCS_ARTIFACTS_ACCOUNT_NAME}" >> "${ARTIFACTS_FOLDER}/logs/gcloud_auth.log" 2>&1
    - section_end "Revoking GCP Auth"

    - section_start "Zip Content Packs From GCS"
    - python3 ./Tests/Marketplace/zip_packs.py -z $ZIP_FOLDER -a $ARTIFACTS_FOLDER -s $GCS_MARKET_KEY
    - section_end "Zip Content Packs From GCS"

    - job-done

upload-packs-to-marketplace-v2:
  tags:
    - gke
  needs: ["run-validations-upload-flow", "run-unittests-and-lint-upload-flow", "mpv2-prepare-testing-bucket-upload-flow", "install-packs-in-xsiam-ga"] # "install-packs-in-xsiam-dev"
  stage: upload-to-marketplace
  artifacts:
    expire_in: 48 hrs
    paths:
      - ${CI_PROJECT_DIR}/artifacts/*
      - ${CI_PROJECT_DIR}/pipeline_jobs_folder/*
    when: always
  variables:
    MARKETPLACE_VERSION: "marketplacev2"
    INSTANCE_ROLE: "XSIAM"
    PRODUCT_TYPE: "XSIAM"
    SERVER_TYPE: "XSIAM"
    ARTIFACTS_FOLDER: "${ARTIFACTS_FOLDER_MPV2}"
    ARTIFACTS_FOLDER_SERVER_TYPE: "${ARTIFACTS_FOLDER_MPV2}/server_type_${SERVER_TYPE}"
    INSTANCE_CREATED: "true"
    SSH_TUNNEL_TIMEOUT: 10
    TIME_TO_LIVE: ""
  extends:
    - .bucket-upload-rule
    - .default-job-settings
  script:
    - *check_user_permissions_to_upload_packs
    - section_start "Upload Packs To Marketplace Storage"
    - |
      if [[ "$CI_COMMIT_BRANCH" == "master" ]] || [[ "$GCS_MARKET_V2_BUCKET" != "$GCS_PRODUCTION_V2_BUCKET" ]]; then
        EXTRACT_FOLDER=$(mktemp -d)
        PACK_ARTIFACTS="${ARTIFACTS_FOLDER_SERVER_TYPE}/content_packs.zip"
        PACKS_DEPENDENCIES="${ARTIFACTS_FOLDER_SERVER_TYPE}/packs_dependencies.json"
        CI_COMMIT_BRANCH=${CI_COMMIT_BRANCH:-unknown}
        GCS_BUILD_BUCKET="marketplace-ci-build"
        if [[ -z $STORAGE_BASE_PATH ]]; then
          if [[ $GCS_MARKET_V2_BUCKET == $GCS_PRODUCTION_V2_BUCKET ]]; then
            STORAGE_BASE_PATH="content"
          else
            STORAGE_BASE_PATH="upload-flow/builds/$CI_COMMIT_BRANCH/$CI_PIPELINE_ID/content"
          fi
          echo "Set storage base path to $STORAGE_BASE_PATH"
        fi
        if [[ -z "${PACKS_TO_UPLOAD}" ]]; then
          PACKS_TO_UPLOAD="All"
        fi
        python3 ./Tests/Marketplace/copy_and_upload_packs.py -a "${PACK_ARTIFACTS}" -e $EXTRACT_FOLDER -pb "$GCS_MARKET_V2_BUCKET" -bb "$GCS_BUILD_BUCKET" -s $GCS_MARKET_KEY -n $CI_PIPELINE_ID -c $CI_COMMIT_BRANCH -p "${PACKS_TO_UPLOAD}" -pbp "$STORAGE_BASE_PATH/packs" --marketplace marketplacev2
        
        gcloud auth activate-service-account --key-file="$GCS_ARTIFACTS_KEY" >> "${ARTIFACTS_FOLDER}/logs/gcloud_auth.log" 2>&1
      
        if [[ $TEST_UPLOAD == "false" ]] && [[ -f "${ARTIFACTS_FOLDER_SERVER_TYPE}/packs_results_upload.json" ]]; then
          gsutil cp "${ARTIFACTS_FOLDER_SERVER_TYPE}/packs_results_upload.json" "gs://xsoar-ci-artifacts/content/$CI_COMMIT_SHA/$MARKETPLACE_VERSION/packs_results_upload.json"
          echo "packs_results_upload.json upload successfully"
        fi
        
        core_packs_files_count=$(find "${ARTIFACTS_FOLDER_SERVER_TYPE}" -name "corepacks*.json" | wc -l)
        if [ "${core_packs_files_count}" -eq 0 ]; then
          echo "No core packs files were found, skipping uploading."
        else
          echo "Uploading ${core_packs_files_count} core packs files."
          # Copy core packs files from the artifacts folder to the build bucket:
          find "${ARTIFACTS_FOLDER_SERVER_TYPE}" -name "corepacks*.json" -exec gsutil cp -z json "{}" "gs://$GCS_MARKET_V2_BUCKET/$STORAGE_BASE_PATH/packs" \;
          echo "Successfully uploaded core packs files."
        fi
      fi
    - section_end "Upload Packs To Marketplace Storage"

    - section_start "Download packs from GCP"
    - |
      if [[ $GCS_MARKET_V2_BUCKET == $GCS_PRODUCTION_V2_BUCKET ]] && [[ -z $STORAGE_BASE_PATH ]]; then
        STORAGE_BASE_PATH="content"
      fi
      if [[ $GCS_MARKET_V2_BUCKET != $GCS_PRODUCTION_V2_BUCKET ]] && [[ -z $STORAGE_BASE_PATH ]]; then
        STORAGE_BASE_PATH="upload-flow/builds/$CI_COMMIT_BRANCH/$CI_PIPELINE_ID/content"
      fi
      
      PACKS_SRC="gs://$GCS_MARKET_V2_BUCKET/$STORAGE_BASE_PATH/packs"
      ZIP_FOLDER=$(mktemp -d)
      gcloud auth activate-service-account --key-file="$GCS_MARKET_KEY" >> "${ARTIFACTS_FOLDER}/logs/gcloud_auth.log" 2>&1
      echo "successfully activated google cloud service account"
      gsutil -m cp -r $PACKS_SRC $ZIP_FOLDER
      echo "successfully downloaded index.zip"
    - section_end "Download packs from GCP"
    - *upload_content_graph
    - *upload_dependencies_file
    - section_start "Revoking GCP Auth"
    - gcloud auth revoke "${GCS_ARTIFACTS_ACCOUNT_NAME}" >> "${ARTIFACTS_FOLDER}/logs/gcloud_auth.log" 2>&1
    - section_end "Revoking GCP Auth"
    - section_start "Zip Content Packs From GCS"
    - python3 ./Tests/Marketplace/zip_packs.py -z $ZIP_FOLDER -a $ARTIFACTS_FOLDER -s $GCS_MARKET_KEY
    - section_end "Zip Content Packs From GCS"
    - job-done

upload-packs-to-xpanse-marketplace:
  tags:
    - gke
  needs: ["run-validations-upload-flow", "run-unittests-and-lint-upload-flow", "xpanse-prepare-testing-bucket-upload-flow"] # "install-packs-in-xpanse-dev"
  stage: upload-to-marketplace
  artifacts:
    expire_in: 48 hrs
    paths:
      - ${CI_PROJECT_DIR}/artifacts/*
      - ${CI_PROJECT_DIR}/pipeline_jobs_folder/*
    when: always
  variables:
    MARKETPLACE_VERSION: "xpanse"
    INSTANCE_ROLE: "XPANSE"
    PRODUCT_TYPE: "XPANSE"
    SERVER_TYPE: "XPANSE"
    ARTIFACTS_FOLDER: "${ARTIFACTS_FOLDER_XPANSE}"
    ARTIFACTS_FOLDER_SERVER_TYPE: "${ARTIFACTS_FOLDER_XPANSE}/server_type_${SERVER_TYPE}"
    INSTANCE_CREATED: "true"
    SSH_TUNNEL_TIMEOUT: 10
    TIME_TO_LIVE: ""
  extends:
    - .bucket-upload-rule
    - .default-job-settings
  script:
    - *check_user_permissions_to_upload_packs
    - section_start "Upload Packs To Marketplace Storage"
    - |
      if [[ "$CI_COMMIT_BRANCH" == "master" ]] || [[ "$GCS_MARKET_XPANSE_BUCKET" != "$GCS_PRODUCTION_XPANSE_BUCKET" ]]; then
        EXTRACT_FOLDER=$(mktemp -d)
        PACK_ARTIFACTS="${ARTIFACTS_FOLDER_SERVER_TYPE}/content_packs.zip"
        PACKS_DEPENDENCIES="${ARTIFACTS_FOLDER_SERVER_TYPE}/packs_dependencies.json"
        CI_COMMIT_BRANCH=${CI_COMMIT_BRANCH:-unknown}
        GCS_BUILD_BUCKET="marketplace-ci-build"
        if [[ -z $STORAGE_BASE_PATH ]]; then
          if [[ $GCS_MARKET_XPANSE_BUCKET == $GCS_PRODUCTION_XPANSE_BUCKET ]]; then
            STORAGE_BASE_PATH="content"
          else
            STORAGE_BASE_PATH="upload-flow/builds/$CI_COMMIT_BRANCH/$CI_PIPELINE_ID/content"
          fi
          echo "Set storage base path to $STORAGE_BASE_PATH"
        fi
        if [[ -z "${PACKS_TO_UPLOAD}" ]]; then
          PACKS_TO_UPLOAD="All"
        fi
        python3 ./Tests/Marketplace/copy_and_upload_packs.py -a "${PACK_ARTIFACTS}" -e $EXTRACT_FOLDER -pb "$GCS_MARKET_XPANSE_BUCKET" -bb "$GCS_BUILD_BUCKET" -s $GCS_MARKET_KEY -n $CI_PIPELINE_ID -c $CI_COMMIT_BRANCH -p "${PACKS_TO_UPLOAD}" -pbp "$STORAGE_BASE_PATH/packs" --marketplace xpanse
        
        gcloud auth activate-service-account --key-file="$GCS_ARTIFACTS_KEY" >> "${ARTIFACTS_FOLDER}/logs/gcloud_auth.log" 2>&1
        if [[ $TEST_UPLOAD == "false" ]] && [[ -f "${ARTIFACTS_FOLDER_SERVER_TYPE}/packs_results_upload.json" ]]; then
          gsutil cp "${ARTIFACTS_FOLDER_SERVER_TYPE}/packs_results_upload.json" "gs://xsoar-ci-artifacts/content/$CI_COMMIT_SHA/$MARKETPLACE_VERSION/packs_results_upload.json"
          echo "packs_results_upload.json upload successfully"
        fi
      
        core_packs_files_count=$(find "${ARTIFACTS_FOLDER_SERVER_TYPE}" -name "corepacks*.json" | wc -l)
        if [ "${core_packs_files_count}" -eq 0 ]; then
          echo "No core packs files were found, skipping uploading."
        else
          echo "Uploading ${core_packs_files_count} core packs files."
          # Copy core packs files from the artifacts folder to the build bucket:
          find "${ARTIFACTS_FOLDER_SERVER_TYPE}" -name "corepacks*.json" -exec gsutil cp -z json "{}" "gs://$GCS_MARKET_XPANSE_BUCKET/$STORAGE_BASE_PATH/packs" \;
          echo "Successfully uploaded core packs files."
        fi
      fi
    - section_end "Upload Packs To Marketplace Storage"

    - section_start "Download packs from GCP"
    - |
      if [[ $GCS_MARKET_XPANSE_BUCKET == $GCS_PRODUCTION_XPANSE_BUCKET ]] && [[ -z $STORAGE_BASE_PATH ]]; then
        STORAGE_BASE_PATH="content"
      fi
      if [[ $GCS_MARKET_XPANSE_BUCKET != $GCS_PRODUCTION_XPANSE_BUCKET ]] && [[ -z $STORAGE_BASE_PATH ]]; then
        STORAGE_BASE_PATH="upload-flow/builds/$CI_COMMIT_BRANCH/$CI_PIPELINE_ID/content"
      fi
      
      PACKS_SRC="gs://$GCS_MARKET_XPANSE_BUCKET/$STORAGE_BASE_PATH/packs"
      ZIP_FOLDER=$(mktemp -d)
      gcloud auth activate-service-account --key-file="$GCS_MARKET_KEY" >> "${ARTIFACTS_FOLDER}/logs/gcloud_auth.log" 2>&1
      echo "successfully activated google cloud service account"
      gsutil -m cp -r $PACKS_SRC $ZIP_FOLDER
      echo "successfully downloaded index.zip"
    - section_end "Download packs from GCP"
    - *upload_content_graph
    - *upload_dependencies_file
    - section_start "Revoking GCP Auth"
    - gcloud auth revoke "${GCS_ARTIFACTS_ACCOUNT_NAME}" >> "${ARTIFACTS_FOLDER}/logs/gcloud_auth.log" 2>&1
    - section_end "Revoking GCP Auth"

    - section_start "Zip Content Packs From GCS"
    - python3 ./Tests/Marketplace/zip_packs.py -z $ZIP_FOLDER -a $ARTIFACTS_FOLDER -s $GCS_MARKET_KEY
    - section_end "Zip Content Packs From GCS"
    - job-done

upload-packs-to-xsoar-saas-marketplace:
  tags:
    - gke
  needs: ["run-validations-upload-flow", "run-unittests-and-lint-upload-flow", "xsoar-saas-prepare-testing-bucket-upload-flow"] # "install-packs-in-xsoar-saas-dev"
  stage: upload-to-marketplace
  artifacts:
    expire_in: 48 hrs
    paths:
      - ${CI_PROJECT_DIR}/artifacts/*
      - ${CI_PROJECT_DIR}/pipeline_jobs_folder/*
    when: always
  variables:
    MARKETPLACE_VERSION: "xsoar_saas"
    INSTANCE_ROLE: "xsoar_saas"
    PRODUCT_TYPE: "XSOAR"
    SERVER_TYPE: "XSOAR SAAS"
    ARTIFACTS_FOLDER: "${ARTIFACTS_FOLDER_XSOAR}"
    ARTIFACTS_FOLDER_SERVER_TYPE: "${ARTIFACTS_FOLDER_XSOAR}/server_type_${SERVER_TYPE}"
    INSTANCE_CREATED: "true"
    SSH_TUNNEL_TIMEOUT: 10
    TIME_TO_LIVE: ""
  extends:
    - .bucket-upload-rule
    - .default-job-settings
  script:
    - *check_user_permissions_to_upload_packs
    - section_start "Upload Packs To Marketplace Storage"
    - |
      echo "$GCS_MARKET_XSOAR_SAAS_BUCKET"
      echo "$GCS_PRODUCTION_XSOAR_SAAS_BUCKET"
      if [[ "$CI_COMMIT_BRANCH" == "master" ]] ||  [[ "$GCS_MARKET_XSOAR_SAAS_BUCKET" != "$GCS_PRODUCTION_XSOAR_SAAS_BUCKET" ]]; then
        EXTRACT_FOLDER=$(mktemp -d)
        PACK_ARTIFACTS="${ARTIFACTS_FOLDER_SERVER_TYPE}/content_packs.zip"
        PACKS_DEPENDENCIES="${ARTIFACTS_FOLDER_SERVER_TYPE}/packs_dependencies.json"
        CI_COMMIT_BRANCH=${CI_COMMIT_BRANCH:-unknown}
        GCS_BUILD_BUCKET="marketplace-ci-build"
        if [[ -z $STORAGE_BASE_PATH ]]; then
          if [[ "$GCS_MARKET_XSOAR_SAAS_BUCKET" == "$GCS_PRODUCTION_XSOAR_SAAS_BUCKET" ]]; then
            STORAGE_BASE_PATH="content"
          else
            STORAGE_BASE_PATH="upload-flow/builds/$CI_COMMIT_BRANCH/$CI_PIPELINE_ID/content"
          fi
          echo "Set storage base path to $STORAGE_BASE_PATH"
        fi
        python3 ./Tests/Marketplace/copy_and_upload_packs.py -a "${PACK_ARTIFACTS}" -e $EXTRACT_FOLDER -pb "$GCS_MARKET_XSOAR_SAAS_BUCKET" -bb "$GCS_BUILD_BUCKET" -s $GCS_MARKET_KEY -n $CI_PIPELINE_ID -c $CI_COMMIT_BRANCH -pbp "$STORAGE_BASE_PATH/packs" --marketplace xsoar_saas
        
        gcloud auth activate-service-account --key-file="$GCS_ARTIFACTS_KEY" >> "${ARTIFACTS_FOLDER}/logs/gcloud_auth.log" 2>&1
        if [[ $TEST_UPLOAD == "false" ]] && [[ -f "${ARTIFACTS_FOLDER_SERVER_TYPE}/packs_results_upload.json" ]]; then
          gsutil cp "${ARTIFACTS_FOLDER_SERVER_TYPE}/packs_results_upload.json" "gs://xsoar-ci-artifacts/content/$CI_COMMIT_SHA/$MARKETPLACE_VERSION/packs_results_upload.json"
          echo "packs_results_upload.json upload successfully"
        fi
        
        core_packs_files_count=$(find "${ARTIFACTS_FOLDER_SERVER_TYPE}" -name "corepacks*.json" | wc -l)
        if [ "${core_packs_files_count}" -eq 0 ]; then
          echo "No core packs files were found, skipping uploading."
        else
          echo "Uploading ${core_packs_files_count} core packs files."
          # Copy core packs files from the artifacts folder to the build bucket:
          find "${ARTIFACTS_FOLDER_SERVER_TYPE}" -name "corepacks*.json" -exec gsutil cp -z json "{}" "gs://$GCS_MARKET_XSOAR_SAAS_BUCKET/$STORAGE_BASE_PATH/packs" \;
          echo "Successfully uploaded core packs files."
        fi
      fi
    - section_end "Upload Packs To Marketplace Storage"

    - section_start "Download packs from GCP"
    - |
      if [[ $GCS_MARKET_XSOAR_SAAS_BUCKET == $GCS_PRODUCTION_XSOAR_SAAS_BUCKET ]] && [[ -z $STORAGE_BASE_PATH ]]; then
        STORAGE_BASE_PATH="content"
      fi
      if [[ $GCS_MARKET_XSOAR_SAAS_BUCKET != $GCS_PRODUCTION_XSOAR_SAAS_BUCKET ]] && [[ -z $STORAGE_BASE_PATH ]]; then
        STORAGE_BASE_PATH="upload-flow/builds/$CI_COMMIT_BRANCH/$CI_PIPELINE_ID/content"
      fi
      
      PACKS_SRC="gs://$GCS_MARKET_XSOAR_SAAS_BUCKET/$STORAGE_BASE_PATH/packs"
      ZIP_FOLDER=$(mktemp -d)
      gcloud auth activate-service-account --key-file="$GCS_MARKET_KEY" >> "${ARTIFACTS_FOLDER}/logs/gcloud_auth.log" 2>&1
      echo "successfully activated google cloud service account"
      gsutil -m cp -r $PACKS_SRC $ZIP_FOLDER
      echo "successfully downloaded index.zip"
    - section_end "Download packs from GCP"
    - *upload_content_graph
    - *upload_dependencies_file
    - section_start "Revoking GCP Auth"
    - gcloud auth revoke "${GCS_ARTIFACTS_ACCOUNT_NAME}" >> "${ARTIFACTS_FOLDER}/logs/gcloud_auth.log" 2>&1
    - section_end "Revoking GCP Auth"

    - section_start "Zip Content Packs From GCS"
    - python3 ./Tests/Marketplace/zip_packs.py -z $ZIP_FOLDER -a $ARTIFACTS_FOLDER -s $GCS_MARKET_KEY
    - section_end "Zip Content Packs From GCS"
    - job-done

xsoar-force-pack-upload:
  needs: [ "xsoar-prepare-testing-bucket-upload-flow" ]
  variables:
    SERVER_TYPE: "XSOAR"
    ARTIFACTS_FOLDER: "${ARTIFACTS_FOLDER_XSOAR}"
    ARTIFACTS_FOLDER_SERVER_TYPE: "${ARTIFACTS_FOLDER_XSOAR}/server_type_${SERVER_TYPE}"
    GCS_MARKET_BUCKET_TO_UPLOAD: $GCS_MARKET_BUCKET
    MARKETPLACE: "xsoar"
    GCS_CURRENT_PRODUCTION_BUCKET: $GCS_PRODUCTION_BUCKET
  extends: .force-pack-upload
  rules:
    - if: '$FORCE_BUCKET_UPLOAD == "true"'

marketplace-v2-force-pack-upload:
  needs: [ "mpv2-prepare-testing-bucket-upload-flow" ]
  variables:
    SERVER_TYPE: "XSIAM"
    ARTIFACTS_FOLDER: "${ARTIFACTS_FOLDER_MPV2}"
    ARTIFACTS_FOLDER_SERVER_TYPE: "${ARTIFACTS_FOLDER_MPV2}/server_type_${SERVER_TYPE}"
    GCS_MARKET_BUCKET_TO_UPLOAD: $GCS_MARKET_V2_BUCKET
    MARKETPLACE: "marketplacev2"
    GCS_CURRENT_PRODUCTION_BUCKET: $GCS_PRODUCTION_V2_BUCKET
  extends: .force-pack-upload
  rules:
    - if: '$FORCE_BUCKET_UPLOAD == "true"'

xpanse-force-pack-upload:
  needs: [ "xpanse-prepare-testing-bucket-upload-flow" ]
  variables:
    SERVER_TYPE: "XPANSE"
    ARTIFACTS_FOLDER: "${ARTIFACTS_FOLDER_XPANSE}"
    ARTIFACTS_FOLDER_SERVER_TYPE: "${ARTIFACTS_FOLDER_XPANSE}/server_type_${SERVER_TYPE}"
    GCS_MARKET_BUCKET_TO_UPLOAD: $GCS_MARKET_XPANSE_BUCKET
    MARKETPLACE: "xpanse"
    GCS_CURRENT_PRODUCTION_BUCKET: $GCS_PRODUCTION_XPANSE_BUCKET
  extends: .force-pack-upload
  rules:
    - if: '$FORCE_BUCKET_UPLOAD == "true"'

.force-pack-upload:
  tags:
    - gke
  stage: upload-to-marketplace
  extends:
    - .default-job-settings
  script:
    - *check_user_permissions_to_upload_packs
    - EXTRACT_FOLDER=$(mktemp -d)
    - PACK_ARTIFACTS="${ARTIFACTS_FOLDER_SERVER_TYPE}/content_packs.zip"
    - PACKS_DEPENDENCIES="${ARTIFACTS_FOLDER_SERVER_TYPE}/packs_dependencies.json"
    - CI_COMMIT_BRANCH=${CI_COMMIT_BRANCH:-unknown}
    - GCS_BUILD_BUCKET="marketplace-ci-build"
    - |
      if [[ $GCS_MARKET_BUCKET_TO_UPLOAD == $GCS_CURRENT_PRODUCTION_BUCKET ]] && [[ -z $STORAGE_BASE_PATH ]]; then
        STORAGE_BASE_PATH="content"
      fi

      if [[ $GCS_MARKET_BUCKET_TO_UPLOAD != $GCS_CURRENT_PRODUCTION_BUCKET ]] && [[ -z $STORAGE_BASE_PATH ]]; then
       STORAGE_BASE_PATH="upload-flow/builds/$CI_COMMIT_BRANCH/$CI_PIPELINE_ID/content"
      fi

    - python3 ./Tests/Marketplace/copy_and_upload_packs.py -a "${PACK_ARTIFACTS}" -e $EXTRACT_FOLDER -pb "$GCS_MARKET_BUCKET_TO_UPLOAD" -bb "$GCS_BUILD_BUCKET" -s $GCS_MARKET_KEY -n $CI_PIPELINE_ID -c $CI_COMMIT_BRANCH -p "${PACKS_TO_UPLOAD}" -pbp "$STORAGE_BASE_PATH/packs" --marketplace $MARKETPLACE


fan-in-bucket-upload:
  tags:
    - gke
  stage: fan-in
  extends:
    - .bucket-upload-rule-always
  script:
    - echo "fan in"


slack-notify-bucket-upload:
  extends:
    - .trigger-slack-notification
    - .bucket-upload-rule-always
  variables:  # Passes the environment variable from the parent pipeline to the child which can be useful for cases when triggering pipeline with alternate env variable value passed in the API call.
    PIPELINE_TO_QUERY: $CI_PIPELINE_ID
    WORKFLOW: 'Upload Packs to Marketplace Storage'
    JOB_NAME: 'fan-in-bucket-upload'
    SLACK_CHANNEL: $SLACK_CHANNEL
    SLACK_JOB: 'true'
    SLACK_ALLOW_FAILURE: 'false'
    CI_PROJECT_ID: $CI_PROJECT_ID
    CI_SERVER_URL: $CI_SERVER_URL
    JIRA_SERVER_URL: $JIRA_SERVER_URL
    JIRA_VERIFY_SSL: $JIRA_VERIFY_SSL
    JIRA_API_KEY: $JIRA_API_KEY
    JIRA_PROJECT_ID: $JIRA_PROJECT_ID
    JIRA_ISSUE_UNRESOLVED_TRANSITION_NAME: $JIRA_ISSUE_UNRESOLVED_TRANSITION_NAME

upload-id-set-bucket:
  tags:
    - gke
  stage: prepare-testing-bucket
  extends:
    - .bucket-upload-rule
    - .default-job-settings
  variables:
    PRODUCT_TYPE: "XSOAR"
    SERVER_TYPE: "XSOAR"
    INSTANCE_ROLE: "Server Master"
    ARTIFACTS_FOLDER: "${ARTIFACTS_FOLDER_XSOAR}"
    ARTIFACTS_FOLDER_INSTANCE: "${ARTIFACTS_FOLDER}/instance_${INSTANCE_ROLE}"
    ARTIFACTS_FOLDER_SERVER_TYPE: "${ARTIFACTS_FOLDER}/server_type_${SERVER_TYPE}"
  script:
    # This is needed because we still use id_set.json in other repos
    - |
      if [[ $TEST_UPLOAD == "true" ]]; then
        echo "Skipping uploading id-set to the bucket in test upload-flow"
        job-done
        exit 0
      fi

    - !reference [.create-id-set-xsoar]
    - gcloud auth activate-service-account --key-file="$GCS_MARKET_KEY" >> "${ARTIFACTS_FOLDER}/logs/gcloud_auth.log" 2>&1
    - gsutil cp "${ARTIFACTS_FOLDER_SERVER_TYPE}/id_set.json" "gs://$GCS_MARKET_BUCKET/content/id_set.json"
    - job-done

sync-buckets-between-projects:
  # syncs buckets from oproxy-dev project to xdr-xsoar-content-dev-01 project
  tags:
    - gke
  extends:
    - .bucket-upload-rule
    - .default-job-settings
  stage: upload-to-marketplace
  needs: ["upload-packs-to-marketplace", "upload-packs-to-marketplace-v2", "upload-packs-to-xpanse-marketplace", "upload-packs-to-xsoar-saas-marketplace"]
  when: always
  variables:
    MARKETPLACE_XSOAR_PROD: "marketplace-xsoar"
    MARKETPLACE_V2_PROD: "marketplace-xsiam"
    MARKETPLACE_XPANSE_PROD: "marketplace-xpanse"
  script:
    - |
      if [[ $TEST_UPLOAD == "true" ]]; then
        echo "Skipping syncing buckets in test upload-flow"
        exit 0
      fi

    - |
      if [[ -z "$GCS_XSOAR_CONTENT_DEV_KEY" ]] || [[ -z "$GCS_XSOAR_CONTENT_PROD_KEY" ]]; then
        echo "GCS_XSOAR_CONTENT_DEV_KEY or GCS_XSOAR_CONTENT_PROD_KEY not set, cannot perform sync"
        job-done
        exit 1
      else
        gcloud auth activate-service-account --key-file="$GCS_XSOAR_CONTENT_DEV_KEY" >> "${ARTIFACTS_FOLDER}/logs/gcloud_auth.log" 2>&1

        echo "Syncing gs://marketplace-xsoar-dev"
        gsutil -m rsync -r gs://marketplace-saas-dist gs://marketplace-xsoar-dev
        echo "Syncing gs://marketplace-xsiam-dev"
        gsutil -m rsync -r gs://marketplace-v2-dist gs://marketplace-xsiam-dev
        echo "Syncing gs://marketplace-xpanse-dev"
        gsutil -m rsync -r gs://xpanse-dist gs://marketplace-xpanse-dev
      
        ./Tests/scripts/validate_synced_buckets.sh "dev"

        gcloud auth activate-service-account --key-file="$GCS_XSOAR_CONTENT_PROD_KEY" >> "${ARTIFACTS_FOLDER}/logs/gcloud_auth.log" 2>&1

        echo "Syncing gs://marketplace-xsoar-prod-us"
        gsutil -m rsync -r gs://marketplace-saas-dist gs://marketplace-xsoar-prod-us
        echo "Syncing gs://marketplace-xsiam-prod-us"
        gsutil -m rsync -r gs://marketplace-v2-dist gs://marketplace-xsiam-prod-us
        echo "Syncing gs://marketplace-xpanse-prod-us"
        gsutil -m rsync -r gs://xpanse-dist gs://marketplace-xpanse-prod-us
        
        ./Tests/scripts/validate_synced_buckets.sh "prod-us"
      
        echo "Bucket sync completed"
      fi
