.bucket-upload-rule:
  rules:
    - if: '$CI_COMMIT_BRANCH =~ /pull\/[0-9]+/'
      when: never
    - if: '$BUCKET_UPLOAD == "true"'

.bucket-upload-rule-always:
  rules:
    - if: '$CI_COMMIT_BRANCH =~ /pull\/[0-9]+/'
      when: never
    - if: '$BUCKET_UPLOAD == "true"'
      when: always


.check_user_permissions_to_upload_packs: &check_user_permissions_to_upload_packs
  - section_start "Check User Permissions to Upload Packs" # if bucket upload and uploading to marketplace-dist
  - |
    if [[ -n "${BUCKET_UPLOAD}" || -n "${FORCE_BUCKET_UPLOAD}" ]] && [[ "$GCS_MARKET_BUCKET" == "$GCS_PRODUCTION_BUCKET" ]]; then
      CONTENT_LEADERS=$(curl -sS "https://api.github.com/orgs/demisto/teams/content-leaders/members" -H "Authorization: token ${GITHUB_TOKEN}")
      echo "received content leaders"
      LEADER_NAMES=$(echo $CONTENT_LEADERS | jq -r ".[].login")
      LEADER_NAMES=$(echo "${LEADER_NAMES}" "content-bot" "svc -xsoar-gitlab-mirror" "${USERS_ALLOWED_TRIGGER_UPLOAD}" )
      if [[ -z "$GITLAB_USER_NAME" ]] || [[ -z "`echo $LEADER_NAMES | grep -w "$GITLAB_USER_NAME"`" ]]; then
        echo -e "User '$GITLAB_USER_NAME' is not allowed to trigger this build, only one of:\n${LEADER_NAMES}"
        job-done
        exit 1
      else
        echo "User '${GITLAB_USER_NAME}' is allowed to upload packs / force upload packs."
      fi
    fi
  - section_end "Check User Permissions to Upload Packs"

.upload_content_graph: &upload_content_graph
    - |
      if [[ $TEST_UPLOAD == "false" ]]; then
        section_start "Upload content graph GraphML to GCP" --collapsed
        gsutil cp $ARTIFACTS_FOLDER/content_graph/$MARKETPLACE_VERSION.zip "gs://$GCS_MARKET_BUCKET_DEV/content_graph/$MARKETPLACE_VERSION.zip"
        # copy the packs.json file to the bucket, used in contribution management
        gsutil cp $ARTIFACTS_FOLDER/packs.json "gs://$GCS_MARKET_BUCKET_DEV/content_graph/"$MARKETPLACE_VERSION"_packs.json"
        section_end "Upload content graph GraphML to GCP"
      fi

.upload_dependencies_file: &upload_dependencies_file
    - |
      if [[ $TEST_UPLOAD == "false" ]]; then
        section_start "Upload packs_dependencies.json to GCP" --collapsed
        gcloud auth activate-service-account --key-file="$GCS_ARTIFACTS_KEY" > $ARTIFACTS_FOLDER/logs/gauth.out 2>$ARTIFACTS_FOLDER/logs/gauth.err
        gsutil cp $ARTIFACTS_FOLDER/packs_dependencies.json "gs://xsoar-ci-artifacts/content-cache-docs/$MARKETPLACE_VERSION/packs_dependencies.json"
        section_end "Upload packs_dependencies.json to GCP"
      fi

run-validations-upload-flow:
  extends:
    - .run-validations
    - .bucket-upload-rule


run-unittests-and-lint-upload-flow:
  cache:
    policy: push
  extends:
    - .run-unittests-and-lint
    - .bucket-upload-rule

jobs-done-check-upload-flow:
  extends:
    - .jobs-done-check
    - .bucket-upload-rule
  needs: ['run-unittests-and-lint-upload-flow', 'run-validations-upload-flow', 'mpv2-prepare-testing-bucket-upload-flow', 'upload-id-set-bucket', 'xpanse-prepare-testing-bucket-upload-flow', 'xsoar-prepare-testing-bucket-upload-flow', 'xsoar-saas-prepare-testing-bucket-upload-flow', 'install-packs-in-server6_9', 'install-packs-in-server6_10', 'install-packs-in-server6_11', 'install-packs-in-server6_12', 'install-packs-in-server-master', 'install-packs-in-xsiam-ga', 'sync-buckets-between-projects', 'upload-packs-to-marketplace', 'upload-packs-to-marketplace-v2', 'upload-packs-to-xpanse-marketplace', 'upload-packs-to-xsoar-saas-marketplace']
  tags:
    - gke



xsoar-prepare-testing-bucket-upload-flow:
  extends:
    - xsoar-prepare-testing-bucket
  variables:
    IFRA_ENV_TYPE: "Bucket-Upload"
    ARTIFACTS_FOLDER: "${ARTIFACTS_FOLDER_XSOAR}"
  rules:
    - if: '$CI_COMMIT_BRANCH =~ /pull\/[0-9]+/'
      when: never
    - if: '$BUCKET_UPLOAD == "true"'
    - if: '$FORCE_BUCKET_UPLOAD == "true"'


xsoar-saas-prepare-testing-bucket-upload-flow:
  extends:
    - xsoar-saas-prepare-testing-bucket
  variables:
    IFRA_ENV_TYPE: "Bucket-Upload"
    ARTIFACTS_FOLDER: "${ARTIFACTS_FOLDER_XSOAR_SAAS}"
  rules:
    - if: '$CI_COMMIT_BRANCH =~ /pull\/[0-9]+/'
      when: never
    - if: '$BUCKET_UPLOAD == "true"'
    - if: '$FORCE_BUCKET_UPLOAD == "true"'


mpv2-prepare-testing-bucket-upload-flow:
 extends:
   - mpv2-prepare-testing-bucket
 variables:
   IFRA_ENV_TYPE: "Bucket-Upload"
   ARTIFACTS_FOLDER: "${ARTIFACTS_FOLDER_MPV2}"
 rules:
   - if: '$CI_COMMIT_BRANCH =~ /pull\/[0-9]+/'
     when: never
   - if: '$BUCKET_UPLOAD == "true"'
   - if: '$FORCE_BUCKET_UPLOAD == "true"'


xpanse-prepare-testing-bucket-upload-flow:
 extends:
   - xpanse-prepare-testing-bucket
 variables:
   IFRA_ENV_TYPE: "Bucket-Upload"
   ARTIFACTS_FOLDER: "${ARTIFACTS_FOLDER_XPANSE}"
 rules:
   - if: '$CI_COMMIT_BRANCH =~ /pull\/[0-9]+/'
     when: never
   - if: '$BUCKET_UPLOAD == "true"'
   - if: '$FORCE_BUCKET_UPLOAD == "true"'


.install_packs_in_xsoar_server:
  tags:
    - gke
  needs: ["xsoar-prepare-testing-bucket-upload-flow"]
  stage: run-instances
  artifacts:
    expire_in: 48 hrs
    paths:
      - ${CI_PROJECT_DIR}/artifacts/*
      - ${CI_PROJECT_DIR}/pipeline_jobs_folder/*
    when: always
  variables:
    ARTIFACTS_FOLDER: "${ARTIFACTS_FOLDER_XSOAR}"
    ENV_RESULTS_PATH: "${ARTIFACTS_FOLDER_XSOAR}/env_results.json"
    INSTANCE_CREATED: "true"
    SSH_TUNNEL_TIMEOUT: 10
    TIME_TO_LIVE: ""
  extends:
    - .bucket-upload-rule
    - .default-job-settings
  script:
    - EXIT_CODE=0
    - section_start "Download content-test-conf and infra" --collapsed
    - ./Tests/scripts/download_conf_repos.sh 2>&1 | tee --append "${ARTIFACTS_FOLDER}/logs/download_conf_repos.log"
    - section_end "Download content-test-conf and infra"
    - section_start "Secrets Fetch" --collapsed
    - SECRET_CONF_PATH=$(cat secret_conf_path)
    - python3 ./Tests/scripts/add_secrets_file_to_build.py -sa "$GSM_SERVICE_ACCOUNT" -sf "$SECRET_CONF_PATH" -u "$DEMISTO_USERNAME" -p "$DEMISTO_PASSWORD" --gsm_project_id_dev "$GSM_PROJECT_ID_DEV" --gsm_project_id_prod "$GSM_PROJECT_ID" >> $ARTIFACTS_FOLDER/logs/handle_secrets.log
    - section_end "Secrets Fetch"
    - !reference [.ssh-config-setup]
    - section_start "Get Instance Variables"
    - echo INSTANCE_ROLE="$INSTANCE_ROLE"
    - echo INSTANCE_CREATED="$INSTANCE_CREATED"
    - section_end "Get Instance Variables"
    - section_start "Wait Until Server Ready"
    - |
      [ -n "${NIGHTLY}" ] && IS_NIGHTLY=true || IS_NIGHTLY=false
      python3 ./Tests/scripts/wait_until_server_ready.py  -n ${IS_NIGHTLY} --instance-role "${INSTANCE_ROLE}" || EXIT_CODE=$?
    - section_end "Wait Until Server Ready"
    - section_start "Install Packs"
    - ./Tests/Marketplace/install_packs.sh "$INSTANCE_ROLE" || EXIT_CODE=$?
    - section_end "Install Packs"
    - section_start "Destroy instances"
    - python3 ./Tests/scripts/destroy_instances.py --artifacts-dir $ARTIFACTS_FOLDER --env-file $ARTIFACTS_FOLDER/env_results.json --instance-role "$INSTANCE_ROLE" || EXIT_CODE=$?
    - section_end "Destroy instances"
    - job-done
    - exit "$EXIT_CODE"


install-packs-in-server6_9:
  extends: .install_packs_in_xsoar_server
  variables:
    INSTANCE_ROLE: "Server 6.9"

install-packs-in-server6_10:
  extends: .install_packs_in_xsoar_server
  variables:
    INSTANCE_ROLE: "Server 6.10"

install-packs-in-server6_11:
  extends: .install_packs_in_xsoar_server
  variables:
    INSTANCE_ROLE: "Server 6.11"

install-packs-in-server6_12:
  extends: .install_packs_in_xsoar_server
  variables:
    INSTANCE_ROLE: "Server 6.12"

install-packs-in-server-master:
  extends: .install_packs_in_xsoar_server
  variables:
    INSTANCE_ROLE: "Server Master"


.install-mpv2-packs-on-xsiam-instances:
  tags:
    - gke
  needs: ["mpv2-prepare-testing-bucket-upload-flow"]
  stage: run-instances
  artifacts:
    expire_in: 48 hrs
    paths:
      - ${CI_PROJECT_DIR}/artifacts/*
      - ${CI_PROJECT_DIR}/pipeline_jobs_folder/*
    when: always
  variables:
    ARTIFACTS_FOLDER: "${ARTIFACTS_FOLDER_MPV2}"
    ENV_RESULTS_PATH: "${ARTIFACTS_FOLDER_MPV2}/env_results.json"
    INSTANCE_CREATED: "true"
    TIME_TO_LIVE: ""
    GCS_LOCKS_PATH: "content-locks/locks-xsiam-ga-upload"
    CLOUD_MACHINES_TYPE: "upload"
    CLOUD_MACHINES_COUNT: 1
  extends:
    - .bucket-upload-rule
    - .default-job-settings
  script:
    - EXIT_CODE=0
    - section_start "Download content-test-conf and infra" --collapsed
    - ./Tests/scripts/download_conf_repos.sh 2>&1 | tee --append "${ARTIFACTS_FOLDER}/logs/download_conf_repos.log"
    - section_end "Download content-test-conf and infra"
    - section_start "Secrets Fetch" --collapsed
    - SECRET_CONF_PATH=$(cat secret_conf_path)
    - python3 ./Tests/scripts/add_secrets_file_to_build.py -sa "$GSM_SERVICE_ACCOUNT" -sf "$SECRET_CONF_PATH" -u "$DEMISTO_USERNAME" -p "$DEMISTO_PASSWORD" --gsm_project_id_dev "$GSM_PROJECT_ID_DEV" --gsm_project_id_prod "$GSM_PROJECT_ID" >> $ARTIFACTS_FOLDER/logs/handle_secrets.log
    - section_end "Secrets Fetch"
    - section_start "Lock Machine"
    - |
      if [[ $TEST_UPLOAD == "true" ]]; then
        echo "Setting CLOUD_MACHINES_TYPE to build in test upload-flow"
        CLOUD_MACHINES_TYPE="build"
        GCS_LOCKS_PATH="content-locks/locks-xsiam-ga"
      fi
    - echo "Authenticating GCP"
    - gcloud auth activate-service-account --key-file="$GCS_ARTIFACTS_KEY" > $ARTIFACTS_FOLDER/logs/gauth.out 2>$ARTIFACTS_FOLDER/logs/gauth.err
    - echo "Auth done successfully"
    - ./Tests/scripts/wait_in_line_for_cloud_env.sh "$CLOUD_MACHINES_TYPE"
    - source CloudEnvVariables
    - echo "CLOUD Chosen machine ids are:${CLOUD_CHOSEN_MACHINE_IDS}"
    - section_end "Lock Machine"

    - CLOUD_SERVERS_PATH=$(cat $CLOUD_SERVERS_FILE)
    - echo ${CLOUD_API_KEYS} > "cloud_api_keys.json"

    - section_start "Clean Machine"
    - ./Tests/scripts/uninstall_packs_and_reset_bucket_cloud.sh || EXIT_CODE=$?
    - section_end "Clean Machine"

    - section_start "Run end to end sanity tests"
    - ./Tests/scripts/run_end_to_end_tests.sh || EXIT_CODE=$?
    - section_end "Run end to end sanity tests"

    - section_start "Get Instance Variables"
    - echo INSTANCE_ROLE="$INSTANCE_ROLE"
    - echo INSTANCE_CREATED="$INSTANCE_CREATED"
    - section_end "Get Instance Variables"

    - section_start "Install Packs"
    - ./Tests/Marketplace/install_packs.sh "$INSTANCE_ROLE" || EXIT_CODE=$?
    - section_end "Install Packs"

    - job-done
    - exit "$EXIT_CODE"
  after_script:
    - source .gitlab/helper_functions.sh
    - !reference [ .unlock-machine ]

#install-packs-in-xsiam-dev:
#  extends: .install-mpv2-packs-on-xsiam-instances
#  variables:
#    INSTANCE_ROLE: "XSIAM"
#    GCS_QUEUE_FILE: "queue-master"
#    TEST_MACHINES_LIST: "test-machines-master"

install-packs-in-xsiam-ga:
  extends: .install-mpv2-packs-on-xsiam-instances
  variables:
    INSTANCE_ROLE: "XSIAM"
    GCS_QUEUE_FILE: "queue-ga"
    GCS_SOURCE_BUCKET: "$GCS_PRODUCTION_V2_BUCKET"
    GCS_MACHINES_BUCKET: "marketplace-v2-dist-dev/upload-flow/builds-xsiam"
    CLOUD_SERVERS_FILE: "xsiam_servers_path"
    CLOUD_API_KEYS: $XSIAM_API_KEYS
    NON_REMOVABLE_PACKS: "Base"


upload-packs-to-marketplace:
  tags:
    - gke
  needs: ["run-validations-upload-flow", "install-packs-in-server6_9", "install-packs-in-server6_10", "install-packs-in-server6_11", "install-packs-in-server6_12", "install-packs-in-server-master", "run-unittests-and-lint-upload-flow"]
  stage: upload-to-marketplace
  artifacts:
    expire_in: 48 hrs
    paths:
      - ${CI_PROJECT_DIR}/artifacts/*
      - ${CI_PROJECT_DIR}/pipeline_jobs_folder/*
    when: always
  variables:
    MARKETPLACE_VERSION: "xsoar"
    ARTIFACTS_FOLDER: "${ARTIFACTS_FOLDER_XSOAR}"
    ENV_RESULTS_PATH: "${ARTIFACTS_FOLDER_XSOAR}/env_results.json"
    INSTANCE_ROLE: "Server Master"
    INSTANCE_CREATED: "true"
    SSH_TUNNEL_TIMEOUT: 10
    TIME_TO_LIVE: ""
  extends:
    - .bucket-upload-rule
    - .default-job-settings
  script:
    - !reference [.ssh-config-setup]
    - *check_user_permissions_to_upload_packs
    - section_start "Upload Packs To Marketplace Storage"
    - |
      if [[ "$CI_COMMIT_BRANCH" == "master" ]] || [[ "$GCS_MARKET_BUCKET" != "$GCS_PRODUCTION_BUCKET" ]]; then
        EXTRACT_FOLDER=$(mktemp -d)
        PACK_ARTIFACTS=$ARTIFACTS_FOLDER/content_packs.zip
        PACKS_DEPENDENCIES=$ARTIFACTS_FOLDER/packs_dependencies.json
        CI_COMMIT_BRANCH=${CI_COMMIT_BRANCH:-unknown}
        GCS_BUILD_BUCKET="marketplace-ci-build"
        if [[ $GCS_MARKET_BUCKET == $GCS_PRODUCTION_BUCKET ]] && [[ -z $STORAGE_BASE_PATH ]]; then
          STORAGE_BASE_PATH="content"
        fi

        if [[ $GCS_MARKET_BUCKET != $GCS_PRODUCTION_BUCKET ]] && [[ -z $STORAGE_BASE_PATH ]]; then
         STORAGE_BASE_PATH="upload-flow/builds/$CI_COMMIT_BRANCH/$CI_PIPELINE_ID/content"
        fi

        if [[ -z $PACKS_TO_UPLOAD ]]; then
          PACKS_TO_UPLOAD="All"
        fi
        python3 ./Tests/Marketplace/copy_and_upload_packs.py -a $PACK_ARTIFACTS -e $EXTRACT_FOLDER -pb "$GCS_MARKET_BUCKET" -bb "$GCS_BUILD_BUCKET" -s $GCS_MARKET_KEY -n $CI_PIPELINE_ID -c $CI_COMMIT_BRANCH -p "${PACKS_TO_UPLOAD}" -pbp "$STORAGE_BASE_PATH/packs" --marketplace xsoar
      fi
    - section_end "Upload Packs To Marketplace Storage"

    - section_start "Download packs from GCP"
    - |
      if [[ $GCS_MARKET_BUCKET == $GCS_PRODUCTION_BUCKET ]] && [[ -z $STORAGE_BASE_PATH ]]; then
        STORAGE_BASE_PATH="content"
      fi
      if [[ $GCS_MARKET_BUCKET != $GCS_PRODUCTION_BUCKET ]] && [[ -z $STORAGE_BASE_PATH ]]; then
        STORAGE_BASE_PATH="upload-flow/builds/$CI_COMMIT_BRANCH/$CI_PIPELINE_ID/content"
      fi

      PACKS_SRC="gs://$GCS_MARKET_BUCKET/$STORAGE_BASE_PATH/packs"
      ZIP_FOLDER=$(mktemp -d)
      gcloud auth activate-service-account --key-file="$GCS_MARKET_KEY" >> $ARTIFACTS_FOLDER/logs/auth.out
      echo "successfully activated google cloud service account"
      gsutil -m cp -r $PACKS_SRC $ZIP_FOLDER
      echo "successfully downloaded index.zip"
    - section_end "Download packs from GCP"
    - *upload_content_graph
    - *upload_dependencies_file
    - gcloud auth revoke $GCS_ARTIFACTS_ACCOUNT_NAME

    - section_start "Zip Content Packs From GCS"
    - python3 ./Tests/Marketplace/zip_packs.py -z $ZIP_FOLDER -a $ARTIFACTS_FOLDER -s $GCS_MARKET_KEY
    - section_end "Zip Content Packs From GCS"

    - section_start "Validate Premium Packs"
    - |
      if [[ "$CI_COMMIT_BRANCH" == "master" ]] || [[ $GCS_MARKET_BUCKET != $GCS_PRODUCTION_BUCKET ]]; then
        ./Tests/scripts/validate_premium_packs.sh "$INSTANCE_ROLE"
      else
        echo "Skipping Premium Packs Validation"
      fi
    - section_end "Validate Premium Packs"
    - job-done

upload-packs-to-marketplace-v2:
  tags:
    - gke
  needs: ["run-validations-upload-flow", "run-unittests-and-lint-upload-flow", "mpv2-prepare-testing-bucket-upload-flow", "install-packs-in-xsiam-ga"] # "install-packs-in-xsiam-dev"
  stage: upload-to-marketplace
  artifacts:
    expire_in: 48 hrs
    paths:
      - ${CI_PROJECT_DIR}/artifacts/*
      - ${CI_PROJECT_DIR}/pipeline_jobs_folder/*
    when: always
  variables:
    MARKETPLACE_VERSION: "marketplacev2"
    ARTIFACTS_FOLDER: "${ARTIFACTS_FOLDER_MPV2}"
    INSTANCE_ROLE: "Server Master"
    INSTANCE_CREATED: "true"
    SSH_TUNNEL_TIMEOUT: 10
    TIME_TO_LIVE: ""
  extends:
    - .bucket-upload-rule
    - .default-job-settings
  script:
    - *check_user_permissions_to_upload_packs
    - section_start "Upload Packs To Marketplace Storage"
    - |
      if [[ "$CI_COMMIT_BRANCH" == "master" ]] || [[ "$GCS_MARKET_V2_BUCKET" != "$GCS_PRODUCTION_V2_BUCKET" ]]; then
        EXTRACT_FOLDER=$(mktemp -d)
        PACK_ARTIFACTS=$ARTIFACTS_FOLDER/content_packs.zip
        PACKS_DEPENDENCIES=$ARTIFACTS_FOLDER/packs_dependencies.json
        CI_COMMIT_BRANCH=${CI_COMMIT_BRANCH:-unknown}
        GCS_BUILD_BUCKET="marketplace-ci-build"
        if [[ -z $STORAGE_BASE_PATH ]]; then
          if [[ $GCS_MARKET_V2_BUCKET == $GCS_PRODUCTION_V2_BUCKET ]]; then
            STORAGE_BASE_PATH="content"
          else
            STORAGE_BASE_PATH="upload-flow/builds/$CI_COMMIT_BRANCH/$CI_PIPELINE_ID/content"
          fi
          echo "Set storage base path to $STORAGE_BASE_PATH"
        fi
        if [[ -z $PACKS_TO_UPLOAD ]]; then
          PACKS_TO_UPLOAD="All"
        fi
        python3 ./Tests/Marketplace/copy_and_upload_packs.py -a $PACK_ARTIFACTS -e $EXTRACT_FOLDER -pb "$GCS_MARKET_V2_BUCKET" -bb "$GCS_BUILD_BUCKET" -s $GCS_MARKET_KEY -n $CI_PIPELINE_ID -c $CI_COMMIT_BRANCH -p "${PACKS_TO_UPLOAD}" -pbp "$STORAGE_BASE_PATH/packs" --marketplace marketplacev2
      fi
    - section_end "Upload Packs To Marketplace Storage"

    - section_start "Download packs from GCP"
    - |
      if [[ $GCS_MARKET_V2_BUCKET == $GCS_PRODUCTION_V2_BUCKET ]] && [[ -z $STORAGE_BASE_PATH ]]; then
        STORAGE_BASE_PATH="content"
      fi
      if [[ $GCS_MARKET_V2_BUCKET != $GCS_PRODUCTION_V2_BUCKET ]] && [[ -z $STORAGE_BASE_PATH ]]; then
        STORAGE_BASE_PATH="upload-flow/builds/$CI_COMMIT_BRANCH/$CI_PIPELINE_ID/content"
      fi
      
      PACKS_SRC="gs://$GCS_MARKET_V2_BUCKET/$STORAGE_BASE_PATH/packs"
      ZIP_FOLDER=$(mktemp -d)
      gcloud auth activate-service-account --key-file="$GCS_MARKET_KEY" >> $ARTIFACTS_FOLDER/logs/auth.out
      echo "successfully activated google cloud service account"
      gsutil -m cp -r $PACKS_SRC $ZIP_FOLDER
      echo "successfully downloaded index.zip"
    - section_end "Download packs from GCP"
    - *upload_content_graph
    - *upload_dependencies_file
    - gcloud auth revoke $GCS_ARTIFACTS_ACCOUNT_NAME
    - section_start "Zip Content Packs From GCS"
    - python3 ./Tests/Marketplace/zip_packs.py -z $ZIP_FOLDER -a $ARTIFACTS_FOLDER -s $GCS_MARKET_KEY
    - section_end "Zip Content Packs From GCS"
    - job-done

upload-packs-to-xpanse-marketplace:
  tags:
    - gke
  needs: ["run-validations-upload-flow", "run-unittests-and-lint-upload-flow", "xpanse-prepare-testing-bucket-upload-flow"] # "install-packs-in-xpanse-dev"
  stage: upload-to-marketplace
  artifacts:
    expire_in: 48 hrs
    paths:
      - ${CI_PROJECT_DIR}/artifacts/*
      - ${CI_PROJECT_DIR}/pipeline_jobs_folder/*
    when: always
  variables:
    MARKETPLACE_VERSION: "xpanse"
    ARTIFACTS_FOLDER: "${ARTIFACTS_FOLDER_XPANSE}"
    INSTANCE_ROLE: "Server Master"
    INSTANCE_CREATED: "true"
    SSH_TUNNEL_TIMEOUT: 10
    TIME_TO_LIVE: ""
  extends:
    - .bucket-upload-rule
    - .default-job-settings
  script:
    - *check_user_permissions_to_upload_packs
    - section_start "Upload Packs To Marketplace Storage"
    - |
      if [[ "$CI_COMMIT_BRANCH" == "master" ]] || [[ "$GCS_MARKET_XPANSE_BUCKET" != "$GCS_PRODUCTION_XPANSE_BUCKET" ]]; then
        EXTRACT_FOLDER=$(mktemp -d)
        PACK_ARTIFACTS=$ARTIFACTS_FOLDER/content_packs.zip
        PACKS_DEPENDENCIES=$ARTIFACTS_FOLDER/packs_dependencies.json
        CI_COMMIT_BRANCH=${CI_COMMIT_BRANCH:-unknown}
        GCS_BUILD_BUCKET="marketplace-ci-build"
        if [[ -z $STORAGE_BASE_PATH ]]; then
          if [[ $GCS_MARKET_XPANSE_BUCKET == $GCS_PRODUCTION_XPANSE_BUCKET ]]; then
            STORAGE_BASE_PATH="content"
          else
            STORAGE_BASE_PATH="upload-flow/builds/$CI_COMMIT_BRANCH/$CI_PIPELINE_ID/content"
          fi
          echo "Set storage base path to $STORAGE_BASE_PATH"
        fi
        if [[ -z $PACKS_TO_UPLOAD ]]; then
          PACKS_TO_UPLOAD="All"
        fi
        python3 ./Tests/Marketplace/copy_and_upload_packs.py -a $PACK_ARTIFACTS -e $EXTRACT_FOLDER -pb "$GCS_MARKET_XPANSE_BUCKET" -bb "$GCS_BUILD_BUCKET" -s $GCS_MARKET_KEY -n $CI_PIPELINE_ID -c $CI_COMMIT_BRANCH -p "${PACKS_TO_UPLOAD}" -pbp "$STORAGE_BASE_PATH/packs" --marketplace xpanse
      fi
    - section_end "Upload Packs To Marketplace Storage"

    - section_start "Download packs from GCP"
    - |
      if [[ $GCS_MARKET_XPANSE_BUCKET == $GCS_PRODUCTION_XPANSE_BUCKET ]] && [[ -z $STORAGE_BASE_PATH ]]; then
        STORAGE_BASE_PATH="content"
      fi
      if [[ $GCS_MARKET_XPANSE_BUCKET != $GCS_PRODUCTION_XPANSE_BUCKET ]] && [[ -z $STORAGE_BASE_PATH ]]; then
        STORAGE_BASE_PATH="upload-flow/builds/$CI_COMMIT_BRANCH/$CI_PIPELINE_ID/content"
      fi
      
      PACKS_SRC="gs://$GCS_MARKET_XPANSE_BUCKET/$STORAGE_BASE_PATH/packs"
      ZIP_FOLDER=$(mktemp -d)
      gcloud auth activate-service-account --key-file="$GCS_MARKET_KEY" >> $ARTIFACTS_FOLDER/logs/auth.out
      echo "successfully activated google cloud service account"
      gsutil -m cp -r $PACKS_SRC $ZIP_FOLDER
      echo "successfully downloaded index.zip"
    - section_end "Download packs from GCP"
    - *upload_content_graph
    - *upload_dependencies_file
    - gcloud auth revoke $GCS_ARTIFACTS_ACCOUNT_NAME

    - section_start "Zip Content Packs From GCS"
    - python3 ./Tests/Marketplace/zip_packs.py -z $ZIP_FOLDER -a $ARTIFACTS_FOLDER -s $GCS_MARKET_KEY
    - section_end "Zip Content Packs From GCS"
    - job-done

upload-packs-to-xsoar-saas-marketplace:
  tags:
    - gke
  needs: ["run-validations-upload-flow", "run-unittests-and-lint-upload-flow", "xsoar-saas-prepare-testing-bucket-upload-flow"] # "install-packs-in-xsoar-saas-dev"
  stage: upload-to-marketplace
  artifacts:
    expire_in: 48 hrs
    paths:
      - ${CI_PROJECT_DIR}/artifacts/*
      - ${CI_PROJECT_DIR}/pipeline_jobs_folder/*
    when: always
  variables:
    MARKETPLACE_VERSION: "xsoar_saas"
    ARTIFACTS_FOLDER: "${ARTIFACTS_FOLDER_XSOAR_SAAS}"
    INSTANCE_ROLE: "Server Master"
    INSTANCE_CREATED: "true"
    SSH_TUNNEL_TIMEOUT: 10
    TIME_TO_LIVE: ""
  extends:
    - .bucket-upload-rule
    - .default-job-settings
  script:
    - *check_user_permissions_to_upload_packs
    - section_start "Upload Packs To Marketplace Storage"
    - |
      echo "$GCS_MARKET_XSOAR_SAAS_BUCKET"
      echo "$GCS_PRODUCTION_XSOAR_SAAS_BUCKET"
      if [[ "$CI_COMMIT_BRANCH" == "master" ]] ||  [[ "$GCS_MARKET_XSOAR_SAAS_BUCKET" != "$GCS_PRODUCTION_XSOAR_SAAS_BUCKET" ]]; then
        EXTRACT_FOLDER=$(mktemp -d)
        PACK_ARTIFACTS=$ARTIFACTS_FOLDER/content_packs.zip
        PACKS_DEPENDENCIES=$ARTIFACTS_FOLDER/packs_dependencies.json
        CI_COMMIT_BRANCH=${CI_COMMIT_BRANCH:-unknown}
        GCS_BUILD_BUCKET="marketplace-ci-build"
        if [[ -z $STORAGE_BASE_PATH ]]; then
          if [[ "$GCS_MARKET_XSOAR_SAAS_BUCKET" == "$GCS_PRODUCTION_XSOAR_SAAS_BUCKET" ]]; then
            STORAGE_BASE_PATH="content"
          else
            STORAGE_BASE_PATH="upload-flow/builds/$CI_COMMIT_BRANCH/$CI_PIPELINE_ID/content"
          fi
          echo "Set storage base path to $STORAGE_BASE_PATH"
        fi
        python3 ./Tests/Marketplace/copy_and_upload_packs.py -a $PACK_ARTIFACTS -e $EXTRACT_FOLDER -pb "$GCS_MARKET_XSOAR_SAAS_BUCKET" -bb "$GCS_BUILD_BUCKET" -s $GCS_MARKET_KEY -n $CI_PIPELINE_ID -c $CI_COMMIT_BRANCH -pbp "$STORAGE_BASE_PATH/packs" --marketplace xsoar_saas
      fi
    - section_end "Upload Packs To Marketplace Storage"

    - section_start "Download packs from GCP"
    - |
      if [[ $GCS_MARKET_XSOAR_SAAS_BUCKET == $GCS_PRODUCTION_XSOAR_SAAS_BUCKET ]] && [[ -z $STORAGE_BASE_PATH ]]; then
        STORAGE_BASE_PATH="content"
      fi
      if [[ $GCS_MARKET_XSOAR_SAAS_BUCKET != $GCS_PRODUCTION_XSOAR_SAAS_BUCKET ]] && [[ -z $STORAGE_BASE_PATH ]]; then
        STORAGE_BASE_PATH="upload-flow/builds/$CI_COMMIT_BRANCH/$CI_PIPELINE_ID/content"
      fi
      
      PACKS_SRC="gs://$GCS_MARKET_XSOAR_SAAS_BUCKET/$STORAGE_BASE_PATH/packs"
      ZIP_FOLDER=$(mktemp -d)
      gcloud auth activate-service-account --key-file="$GCS_MARKET_KEY" >> $ARTIFACTS_FOLDER/logs/auth.out
      echo "successfully activated google cloud service account"
      gsutil -m cp -r $PACKS_SRC $ZIP_FOLDER
      echo "successfully downloaded index.zip"
    - section_end "Download packs from GCP"
    - *upload_content_graph
    - *upload_dependencies_file
    - gcloud auth revoke $GCS_ARTIFACTS_ACCOUNT_NAME

    - section_start "Zip Content Packs From GCS"
    - python3 ./Tests/Marketplace/zip_packs.py -z $ZIP_FOLDER -a $ARTIFACTS_FOLDER -s $GCS_MARKET_KEY
    - section_end "Zip Content Packs From GCS"
    - job-done

xsoar-force-pack-upload:
  needs: [ "xsoar-prepare-testing-bucket-upload-flow" ]
  variables:
    ARTIFACTS_FOLDER: "${ARTIFACTS_FOLDER_XSOAR}"
    GCS_MARKET_BUCKET_TO_UPLOAD: $GCS_MARKET_BUCKET
    MARKETPLACE: "xsoar"
    GCS_CURRENT_PRODUCTION_BUCKET: $GCS_PRODUCTION_BUCKET
  extends: .force-pack-upload
  rules:
    - if: '$FORCE_BUCKET_UPLOAD'


marketplace-v2-force-pack-upload:
  needs: [ "mpv2-prepare-testing-bucket-upload-flow" ]
  variables:
    ARTIFACTS_FOLDER: "${ARTIFACTS_FOLDER_MPV2}"
    GCS_MARKET_BUCKET_TO_UPLOAD: $GCS_MARKET_V2_BUCKET
    MARKETPLACE: "marketplacev2"
    GCS_CURRENT_PRODUCTION_BUCKET: $GCS_PRODUCTION_V2_BUCKET
  extends: .force-pack-upload
  rules:
    - if: '$FORCE_BUCKET_UPLOAD'

xpanse-force-pack-upload:
  needs: [ "xpanse-prepare-testing-bucket-upload-flow" ]
  variables:
    ARTIFACTS_FOLDER: "${ARTIFACTS_FOLDER_XPANSE}"
    GCS_MARKET_BUCKET_TO_UPLOAD: $GCS_MARKET_XPANSE_BUCKET
    MARKETPLACE: "xpanse"
    GCS_CURRENT_PRODUCTION_BUCKET: $GCS_PRODUCTION_XPANSE_BUCKET
  extends: .force-pack-upload
  rules:
    - if: '$FORCE_BUCKET_UPLOAD'


.force-pack-upload:
  tags:
    - gke
  stage: upload-to-marketplace
  extends:
    - .default-job-settings
  script:
    - *check_user_permissions_to_upload_packs
    - EXTRACT_FOLDER=$(mktemp -d)
    - PACK_ARTIFACTS=$ARTIFACTS_FOLDER/content_packs.zip
    - PACKS_DEPENDENCIES=$ARTIFACTS_FOLDER/packs_dependencies.json
    - CI_COMMIT_BRANCH=${CI_COMMIT_BRANCH:-unknown}
    - GCS_BUILD_BUCKET="marketplace-ci-build"
    - |
      if [[ $GCS_MARKET_BUCKET_TO_UPLOAD == $GCS_CURRENT_PRODUCTION_BUCKET ]] && [[ -z $STORAGE_BASE_PATH ]]; then
        STORAGE_BASE_PATH="content"
      fi

      if [[ $GCS_MARKET_BUCKET_TO_UPLOAD != $GCS_CURRENT_PRODUCTION_BUCKET ]] && [[ -z $STORAGE_BASE_PATH ]]; then
       STORAGE_BASE_PATH="upload-flow/builds/$CI_COMMIT_BRANCH/$CI_PIPELINE_ID/content"
      fi

    - python3 ./Tests/Marketplace/copy_and_upload_packs.py -a $PACK_ARTIFACTS -e $EXTRACT_FOLDER -pb "$GCS_MARKET_BUCKET_TO_UPLOAD" -bb "$GCS_BUILD_BUCKET" -s $GCS_MARKET_KEY -n $CI_PIPELINE_ID -c $CI_COMMIT_BRANCH -p "${PACKS_TO_UPLOAD}" -pbp "$STORAGE_BASE_PATH/packs" --marketplace $MARKETPLACE


fan-in-bucket-upload:
  tags:
    - gke
  stage: fan-in
  extends:
    - .bucket-upload-rule-always
  script:
    - echo "fan in"


slack-notify-bucket-upload:
  variables:
    PIPELINE_TO_QUERY: $CI_PIPELINE_ID
    WORKFLOW: 'Upload Packs to Marketplace Storage'
    JOB_NAME: 'fan-in-bucket-upload'
    # Passes the environment variable from the parent pipeline to the child which can be useful for cases
    # when triggering pipeline with alternate env variable value passed in the API call
    SLACK_CHANNEL: $SLACK_CHANNEL
    SLACK_JOB: 'true'
  extends:
    - .trigger-slack-notification
    - .bucket-upload-rule-always


upload-id-set-bucket:
  tags:
    - gke
  stage: prepare-testing-bucket
  extends:
    - .bucket-upload-rule
    - .default-job-settings
  script:
    # This is needed because we still use id_set.json in other repos
    - |
      if [[ $TEST_UPLOAD == "true" ]]; then
        echo "Skipping uploading id-set to the bucket in test upload-flow"
        job-done
        exit 0
      fi

    - !reference [.create-id-set-xsoar]
    - gcloud auth activate-service-account --key-file="$GCS_MARKET_KEY"
    - gsutil cp $ARTIFACTS_FOLDER/id_set.json "gs://$GCS_MARKET_BUCKET/content/id_set.json"
    - job-done


sync-buckets-between-projects:
  # syncs buckets from oproxy-dev project to xdr-xsoar-content-dev-01 project
  tags:
    - gke
  extends:
    - .bucket-upload-rule
  stage: upload-to-marketplace
  needs: ["upload-packs-to-marketplace", "upload-packs-to-marketplace-v2", "upload-packs-to-xpanse-marketplace"]
  when: always
  variables:
    MARKETPLACE_XSOAR_PROD: "marketplace-xsoar"
    MARKETPLACE_V2_PROD: "marketplace-xsiam"
    MARKETPLACE_XPANSE_PROD: "marketplace-xpanse"
  script:
    - |
      if [[ $TEST_UPLOAD == "true" ]]; then
        echo "Skipping syncing buckets in test upload-flow"
        exit 0
      fi

    - |
      if [[ -z "$GCS_XSOAR_CONTENT_DEV_KEY" ]] || [[ -z "$GCS_XSOAR_CONTENT_PROD_KEY" ]]; then
        echo "GCS_XSOAR_CONTENT_DEV_KEY or GCS_XSOAR_CONTENT_PROD_KEY not set, cannot perform sync"
        job-done
        exit 1
      else
        gcloud auth activate-service-account --key-file="$GCS_XSOAR_CONTENT_DEV_KEY"

        echo "Syncing gs://marketplace-xsoar-dev"
        gsutil -m rsync -r gs://marketplace-dist gs://marketplace-xsoar-dev
        echo "Syncing gs://marketplace-xsiam-dev"
        gsutil -m rsync -r gs://marketplace-v2-dist gs://marketplace-xsiam-dev
        echo "Syncing gs://marketplace-xpanse-dev"
        gsutil -m rsync -r gs://xpanse-dist gs://marketplace-xpanse-dev
      
        ./Tests/scripts/validate_synced_buckets.sh "dev"

        gcloud auth activate-service-account --key-file="$GCS_XSOAR_CONTENT_PROD_KEY"

        echo "Syncing gs://marketplace-xsoar-prod-us"
        gsutil -m rsync -r gs://marketplace-dist gs://marketplace-xsoar-prod-us
        echo "Syncing gs://marketplace-xsiam-prod-us"
        gsutil -m rsync -r gs://marketplace-v2-dist gs://marketplace-xsiam-prod-us
        echo "Syncing gs://marketplace-xpanse-prod-us"
        gsutil -m rsync -r gs://xpanse-dist gs://marketplace-xpanse-prod-us
        
        ./Tests/scripts/validate_synced_buckets.sh "prod-us"
      
        echo "Bucket sync completed"
      fi
