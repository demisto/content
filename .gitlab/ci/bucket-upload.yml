.bucket-upload-rule:
  rules:
    - if: '$GCS_MARKET_BUCKET == "marketplace-dist"' # remove this after testing period
      when: never # remove this after testing period
    - if: '$CI_COMMIT_BRANCH =~ /pull\/[0-9]+/'
      when: never
    - if: '$BUCKET_UPLOAD == "true"'
  variables:
    GCS_PRODUCTION_BUCKET: "marketplace-dist-dev" # remove this after testing period

.bucket-upload-rule-always:
  rules:
    - if: '$GCS_MARKET_BUCKET == "marketplace-dist"' # remove this after testing period
      when: never # remove this after testing period
    - if: '$CI_COMMIT_BRANCH =~ /pull\/[0-9]+/'
      when: never
    - if: '$BUCKET_UPLOAD == "true"'
      when: always
  variables:
    GCS_PRODUCTION_BUCKET: "marketplace-dist-dev" # remove this after testing period


.check_user_permissions_to_upload_packs: &check_user_permissions_to_upload_packs
  - section_start "Check User Permissions to Upload Packs" # if bucket upload and uploading to marketplace-dist
  - |
    if [[ -n "${BUCKET_UPLOAD}" || -n "${FORCE_BUCKET_UPLOAD}" ]] && [[ "$GCS_MARKET_BUCKET" == "$GCS_PRODUCTION_BUCKET" ]]; then
      CONTENT_LEADERS=$(curl -sS "https://api.github.com/orgs/demisto/teams/content-leaders/members" -H "Authorization: token ${GITHUB_TOKEN}")
      echo "recieved content leaders"
      LEADER_NAMES=$(echo $CONTENT_LEADERS | jq -r ".[].login")
      LEADER_NAMES=$(echo "${LEADER_NAMES}" "content-bot" "svc-xsoar-gitlab-mirror" )
      if [[ -z "$GITLAB_USER_NAME" ]] || [[ -z "`echo $LEADER_NAMES | grep -w "$GITLAB_USER_NAME"`" ]]; then
        echo -e "User '$GITLAB_USER_NAME' is not allowed to trigger this build, only one of:\n${LEADER_NAMES}"
        exit 1
      else
        echo "User '${GITLAB_USER_NAME}' is allowed to upload packs / force upload packs."
      fi
    fi
  - section_end "Check User Permissions to Upload Packs"


run-validations-upload-flow:
  extends:
    - .run-validations
    - .bucket-upload-rule


# Uncomment when docker in docker will work
# run-unittests-and-lint-upload-flow:
#   extends:
#     - .run-unittests-and-lint
#     - .bucket-upload-rule


create-instances-upload-flow:
  extends:
    - create-instances
  variables:
    IFRA_ENV_TYPE: "Bucket-Upload"
    GCS_PRODUCTION_BUCKET: "marketplace-dist-dev" # remove this after testing period
  rules:
    - if: '$GCS_MARKET_BUCKET == "marketplace-dist"' # remove this after testing period
      when: never # remove this after testing period
    - if: '$CI_COMMIT_BRANCH =~ /pull\/[0-9]+/'
      when: never
    - if: '$BUCKET_UPLOAD == "true"'
    - if: '$FORCE_BUCKET_UPLOAD == "true"'


.install_packs_in_server:
  needs: ["create-instances-upload-flow"]
  stage: run-instances
  artifacts:
    expire_in: 48 hrs
    paths:
      - /builds/xsoar/content/artifacts/*
    when: always
  variables:
    INSTANCE_CREATED: "true"
    SSH_TUNNEL_TIMEOUT: 10
    TIME_TO_LIVE: ""
  extends:
    - .bucket-upload-rule
    - .default-job-settings
  script:
    - EXIT_CODE=0
    - section_start "Download configuration"
    - ./Tests/scripts/download_demisto_conf.sh  >> $ARTIFACTS_FOLDER/logs/installations.log
    - section_end "Download configuration"
    - !reference [.open-ssh-tunnel]
    - section_start "Get Instance Variables"
    - echo INSTANCE_ROLE="$INSTANCE_ROLE"
    - echo INSTANCE_CREATED="$INSTANCE_CREATED"
    - section_end "Get Instance Variables"
    - section_start "Wait Until Server Ready"
    - python3 ./Tests/scripts/wait_until_server_ready.py "$INSTANCE_ROLE" || EXIT_CODE=$?
    - section_end "Wait Until Server Ready"
    - section_start "Install Packs"
    - ./Tests/Marketplace/install_packs.sh "$INSTANCE_ROLE" || EXIT_CODE=$?
    - section_end "Install Packs"
    - section_start "Destroy instances"
    - python3 ./Tests/scripts/destroy_instances.py $ARTIFACTS_FOLDER $ARTIFACTS_FOLDER/env_results.json "$INSTANCE_ROLE" "$TIME_TO_LIVE" || EXIT_CODE=$?
    - section_end "Destroy instances"
    - exit "$EXIT_CODE"


install-packs-in-server6_0:
  extends: .install_packs_in_server
  variables:
    INSTANCE_ROLE: "Server 6.0"


install-packs-in-server-master:
  extends: .install_packs_in_server
  variables:
    INSTANCE_ROLE: "Server Master"


upload-packs-to-marketplace:
  needs: ["run-validations-upload-flow", "install-packs-in-server6_0", "install-packs-in-server-master"] # add "run-unittests-and-lint-upload-flow" after docker in docker is resolved.
  stage: upload-to-marketplace
  artifacts:
    expire_in: 48 hrs
    paths:
      - /builds/xsoar/content/artifacts/*
    when: always
  variables:
    INSTANCE_ROLE: "Server Master"
    INSTANCE_CREATED: "true"
    SSH_TUNNEL_TIMEOUT: 10
    TIME_TO_LIVE: ""
  extends:
    - .bucket-upload-rule-always
    - .default-job-settings
  script:
    - !reference [.open-ssh-tunnel]
    - *check_user_permissions_to_upload_packs
    - section_start "Upload Packs To Marketplace Storage"
    - |
      if [[ "$CI_COMMIT_BRANCH" == "master" ]] || [[ "$GCS_MARKET_BUCKET" != "$GCS_PRODUCTION_BUCKET" ]]; then
        EXTRACT_FOLDER=$(mktemp -d)
        PACK_ARTIFACTS=$ARTIFACTS_FOLDER/content_packs.zip
        PACKS_DEPENDENCIES=$ARTIFACTS_FOLDER/packs_dependencies.json
        CI_COMMIT_BRANCH=${CI_COMMIT_BRANCH:-unknown}
        GCS_BUILD_BUCKET="marketplace-ci-build"
        if [[ $GCS_MARKET_BUCKET != $GCS_PRODUCTION_BUCKET ]]; then
          STORAGE_BASE_PATH="upload-flow/builds/$CI_COMMIT_BRANCH/$CI_PIPELINE_ID/content/packs"
        fi
        python3 ./Tests/Marketplace/copy_and_upload_packs.py -a $PACK_ARTIFACTS -e $EXTRACT_FOLDER -pb "$GCS_MARKET_BUCKET" -bb "$GCS_BUILD_BUCKET" -s $GCS_MARKET_KEY -n $CI_PIPELINE_ID -c $CI_COMMIT_BRANCH -pbp "$STORAGE_BASE_PATH"
      fi
    - section_end "Upload Packs To Marketplace Storage"
    - section_start "Validate Premium Packs"
    - |
      if [[ "$CI_COMMIT_BRANCH" == "master" ]] || [[ $GCS_MARKET_BUCKET != $GCS_PRODUCTION_BUCKET ]]; then
        ./Tests/scripts/validate_premium_packs.sh "$INSTANCE_ROLE"
      else
        echo "Skipping Premium Packs Validation"
      fi
    - section_end "Validate Premium Packs"


force-pack-upload:
  stage: upload-to-marketplace
  needs: ["create-instances-upload-flow"]
  rules:
    - if: '$GCS_MARKET_BUCKET == "marketplace-dist"' # remove this after testing period
      when: never # remove this after testing period
    - if: '$FORCE_BUCKET_UPLOAD == "true"'
  extends:
    - .default-job-settings
  variables:
    GCS_PRODUCTION_BUCKET: "marketplace-dist-dev" # remove this after testing period
  script:
    - *check_user_permissions_to_upload_packs
    - EXTRACT_FOLDER=$(mktemp -d)
    - PACK_ARTIFACTS=$ARTIFACTS_FOLDER/content_packs.zip
    - PACKS_DEPENDENCIES=$ARTIFACTS_FOLDER/packs_dependencies.json
    - CI_COMMIT_BRANCH=${CI_COMMIT_BRANCH:-unknown}
    - GCS_BUILD_BUCKET="marketplace-ci-build"
    - |
      if [[ $GCS_MARKET_BUCKET != $GCS_PRODUCTION_BUCKET ]]; then
          STORAGE_BASE_PATH="upload-flow/builds/$CI_COMMIT_BRANCH/$CI_PIPELINE_ID/content/packs"
      fi
    - python3 ./Tests/Marketplace/copy_and_upload_packs.py -a $PACK_ARTIFACTS -e $EXTRACT_FOLDER -pb "$GCS_MARKET_BUCKET" -bb "$GCS_BUILD_BUCKET" -s $GCS_MARKET_KEY -n $CI_PIPELINE_ID -c $CI_COMMIT_BRANCH -p "${PACKS_TO_UPLOAD}" -pbp "${STORAGE_BASE_PATH}"


slack-notify-bucket-upload:
  variables:
    PIPELINE_TO_QUERY: $CI_PIPELINE_ID
    WORKFLOW: 'Upload Packs to Marketplace Storage'
    JOB_NAME: 'upload-packs-to-marketplace'
    # Passes the environment variable from the parent pipeline to the child which can be useful for cases
    # when triggering pipeline with alternate env variable value passed in the API call
    SLACK_CHANNEL: $SLACK_CHANNEL
  extends:
    - .trigger-slack-notification
    - .bucket-upload-rule-always
