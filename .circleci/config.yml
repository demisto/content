version: 2.1
orbs:
  python: circleci/python@<< pipeline.parameters.python-orb-version >>
  node: circleci/node@<< pipeline.parameters.node-orb-version >>

commands:
  set-instance-role-env-variable:
    description: "Sets INSTANCE_ROLE env variable into $BASH_ENV file"
    parameters:
      instance_role:
        type: string
      instance_created:
        type: string
        default: ""
    steps:
      - run:
          name: Set INSTANCE_ROLE env variable
          command: |
            echo 'export INSTANCE_ROLE="<< parameters.instance_role >>"' >> $BASH_ENV
            echo 'export INSTANCE_WAS_CREATED="<< parameters.instance_created >>"' >> $BASH_ENV

parameters:
  artifact_build_num:
    type: string
    default: ""
  nightly:
    type: string
    default: ""
  legacy_nightly:
    type: string
    default: ""
  pr_number:
    type: string
    default: ""
  contrib_branch:
    type: string
    default: ""
  contrib_pack_name:
    type: string
    default: ""
  sdk_ref:
    type: string
    default: "master"
  gcs_market_bucket:
    type: string
    default: "marketplace-dist"
  cache-version:
    type: string
    default: v1  # Change this parameter to clear cache.
  python-orb-version:
    type: string
    default: "2.0.3" # disable-secrets-detection
  node-orb-version:
    type: string
    default: "5.0.1" # disable-secrets-detection
  
references:
  environment: &environment
    environment:
      # A flag for the demisto_client to not cache its last response in order to avoid memory leaks.
      DONT_CACHE_LAST_RESPONSE: "true"
      DEMISTO_SDK_LOG_FILE_SIZE: 1073741824  # 1GB
      ARTIFACT_BUILD_NUM: << pipeline.parameters.artifact_build_num >>
      CONTRIB_BRANCH: << pipeline.parameters.contrib_branch >>
      CONTRIB_PACK_NAME: << pipeline.parameters.contrib_pack_name >>
      SDK_REF: << pipeline.parameters.sdk_ref >>
      # Giving different names to the following pipeline parameters to avoid collision, handling such collision case
      # is done in 'Setup Environment' step.
      PULL_REQUEST_NUMBER: << pipeline.parameters.pr_number >>
      NIGHTLY_PARAMETER: << pipeline.parameters.nightly >>
      GCS_MARKET_BUCKET: << pipeline.parameters.gcs_market_bucket >>
  
  install_build_dependencies: &install_build_dependencies
    python/install-packages: 
        pkg-manager: "poetry"
        args: "--with ci"
        cache-version: << pipeline.parameters.cache-version >>
        pre-install-steps:
          - run:
              name: Check if pyproject.toml is consistent with poetry.lock
              command: poetry lock --check

  install_node_ci: &install_node_ci
    node/install-packages:
        cache-version: << pipeline.parameters.cache-version >>


  install_neo4j: &install_neo4j
    run:
      name: Install Neo4j
      command: |
        wget -O - https://debian.neo4j.com/neotechnology.gpg.key | sudo apt-key add -
        echo 'deb https://debian.neo4j.com stable 5' | sudo tee /etc/apt/sources.list.d/neo4j.list
        sudo apt-get update
        apt list -a neo4j
        sudo apt-get install neo4j
        sudo chown -R circleci /var/log/neo4j
        sudo chown -R circleci /var/lib/neo4j
        sudo chown -R circleci /etc/neo4j
        mkdir -p /var/lib/neo4j/plugins
        wget -O /var/lib/neo4j/plugins/apoc-5.5.0-core.jar https://github.com/neo4j/apoc/releases/download/5.5.0/apoc-5.5.0-core.jar
        neo4j_conf_file="/etc/neo4j/neo4j.conf"
        sudo echo "dbms.security.procedures.unrestricted=apoc.*" >> $neo4j_conf_file
        sudo echo "dbms.security.procedures.allowlist=apoc.*" >> $neo4j_conf_file
        apoc_conf_file="/etc/neo4j/apoc.conf"
        sudo echo "apoc.export.file.enabled=true" > $apoc_conf_file
        sudo echo "apoc.import.file.enabled=true" >> $apoc_conf_file
        sudo echo "apoc.import.file.use_neo4j_config=true" >> $apoc_conf_file
        neo4j-admin dbms set-initial-password contentgraph

  container_config: &container_config
    docker:
      - image: devdemisto/content-build:3.0.0.49685  # disable-secrets-detection
        auth:
          username: $DOCKERHUB_USER
          password: $DOCKERHUB_PASSWORD

  workspace_root: &workspace_root
    /home/circleci/

  store_artifacts: &store_artifacts
     store_artifacts:
        path: artifacts
        destination: artifacts
        when: always

  attach_workspace: &attach_workspace
    attach_workspace:
      at: *workspace_root

  prepare_environment: &prepare_environment
    run:
      name: Prepare Environment
      when: always
      command: |
        poetry --version
        # Check if CircleCI's config file and poetry files files are up to date
        # if poetry isn't up-to-date, checkout from origin/master.
        ./Tests/scripts/is_file_up_to_date.sh .circleci/config.yml $CIRCLE_BRANCH
        ./Tests/scripts/is_file_up_to_date.sh poetry.lock $CIRCLE_BRANCH true
        ./Tests/scripts/is_file_up_to_date.sh pyproject.toml $CIRCLE_BRANCH true
        ./Tests/scripts/is_file_up_to_date.sh Tests/Marketplace/core_packs_list.json $CIRCLE_BRANCH true
        ./Tests/scripts/is_file_up_to_date.sh Tests/Marketplace/core_packs_mpv2_list.json $CIRCLE_BRANCH true
        ./Tests/scripts/is_file_up_to_date.sh Tests/Marketplace/core_packs_xpanse_list.json $CIRCLE_BRANCH true

        echo 'export CIRCLE_ARTIFACTS="/home/circleci/project/artifacts"' >> $BASH_ENV
        echo 'export PATH="/home/circleci/.local/bin:${PWD}/node_modules/.bin:${PATH}"' >> $BASH_ENV # disable-secrets-detection
        echo 'export PYTHONPATH="/home/circleci/project:${PYTHONPATH}"' >> $BASH_ENV
        echo 'export DEMISTO_README_VALIDATION=true' >> $BASH_ENV
        echo 'export ENV_RESULTS_PATH=/home/circleci/project/artifacts/env_results.json' >> $BASH_ENV
        echo 'export GCS_PRODUCTION_BUCKET="${TEST_XDR_PREFIX}marketplace-dist"' >> $BASH_ENV
        echo 'source /home/circleci/project/.circleci/content_release_vars.sh' >> $BASH_ENV
        chmod +x .circleci/gitlab-ci-env-variables.sh
        ./.circleci/gitlab-ci-env-variables.sh
        if [ -n "${NIGHTLY_PARAMETER}" ] || [ -n "${LEGACY_NIGHTLY_PARAMETER}" ];
        then
            echo 'export NIGHTLY=true' >> $BASH_ENV
        fi

        echo "=== sourcing $BASH_ENV ==="
        source $BASH_ENV
        sudo mkdir -p -m 777 $CIRCLE_ARTIFACTS/

        # Creating new clean logs folder
        rm -rf $CIRCLE_ARTIFACTS/logs
        mkdir -p $CIRCLE_ARTIFACTS/logs

        chmod +x ./Tests/scripts/*
        chmod +x ./Tests/Marketplace/*

        source ./.venv/bin/activate

        # store in bash env so we load our venv in each step
        echo 'source /home/circleci/project/.venv/bin/activate' >> $BASH_ENV
        git config diff.renameLimit 6000

        echo "========== Build Parameters =========="
        set | grep -E "^NIGHTLY=|^CONTRIB_BRANCH=|^SDK_REF"
        python3 --version | tee -a $CIRCLE_ARTIFACTS/installed_python_libraries.txt
        python3 -m pip list | tee -a $CIRCLE_ARTIFACTS/installed_python_libraries.txt
        node --version
        npm --version
        demisto-sdk --version

  remote_docker: &remote_docker
    setup_remote_docker:
      version: 20.10.17
      docker_layer_caching: true

  persist_to_workspace: &persist_to_workspace
    persist_to_workspace:
      root: /home/circleci/
      paths:
        - project

  secrets: &secrets
    run:
      name: Secrets
      when: always
      no_output_timeout: 5h
      command: |
        demisto-sdk secrets --post-commit --ignore-entropy

  validate_files_and_yaml: &validate_files_and_yaml
    run:
      name: Validate Files and Yaml
      when: always
      no_output_timeout: 1h
      command: |
        [ ! -d ~/.ssh ] && mkdir -p ~/.ssh
        chmod 700 ~/.ssh
        ssh-keyscan github.com >> ~/.ssh/known_hosts
        if [[ "$(echo "$GCS_MARKET_BUCKET" | tr '[:upper:]' '[:lower:]')" != "${TEST_XDR_PREFIX}marketplace-dist" ]]; then
          echo "Skipping the -Validate Files and Yaml- step when uploading to a test bucket."
          exit 0
        fi

        neo4j start
        # poll for neo4j status until available
        while ! curl --fail http://127.0.0.1:7474 &> /dev/null; do sleep 1; done

        ./Tests/scripts/linters_runner.sh
        ./Tests/scripts/validate.sh

  run_unit_testing_and_lint: &run_unit_testing_and_lint
    run:
      parameters:
        dockerimageflag:
          type: string
      name: Run Unit Testing And Lint - Docker Image:<< parameters.dockerimageflag >>
      when: always
      no_output_timeout: 5h
      command: |
        if [[ "$(echo "$GCS_MARKET_BUCKET" | tr '[:upper:]' '[:lower:]')" != "${TEST_XDR_PREFIX}marketplace-dist" ]]; then
          echo "Skipping validations when uploading to a test bucket."
          exit 0
        fi

        echo "demisto-sdk version: $(demisto-sdk --version)"
        echo "mypy version: $(mypy --version)"
        echo "flake8 py3 version: $(python3 -m flake8 --version)"
        echo "bandit py3 version: $(python3 -m bandit --version 2>&1)"
        echo "vulture py3 version: $(python3 -m vulture --version 2>&1)"
        mkdir ./unit-tests

        neo4j start
        # poll for neo4j status until available
        while ! curl --fail http://127.0.0.1:7474 &> /dev/null; do sleep 1; done

        demisto-sdk lint -p 8 -g --test-xml ./unit-tests --log-path ./artifacts --failure-report ./artifacts --coverage-report $ARTIFACTS_FOLDER/coverage_report --docker-image << parameters.dockerimageflag >> --check-dependent-api-module

  generate_coverage_reports: &generate_coverage_reports
    run:
      name: Generate coverage reports
      when: always
      no_output_timeout: 1h
      command: |
        EXIT_CODE=0
        if [[ -f $ARTIFACTS_FOLDER/coverage_report/.coverage ]]; then
          demisto-sdk coverage-analyze -i $ARTIFACTS_FOLDER/coverage_report/.coverage --report-dir $ARTIFACTS_FOLDER/coverage_report --report-type all --previous-coverage-report-url https://storage.googleapis.com/${TEST_XDR_PREFIX}marketplace-dist-dev/code-coverage-reports/coverage-min.json || EXIT_CODE=1
          # Checks if the $XSOAR_BOT_TEST_CONTENT exist. for security reasons only non forked pr's have access to it.
          if [[ -n $XSOAR_BOT_TEST_CONTENT && -e $ARTIFACTS_FOLDER/coverage_report/html/index.html ]]; then
            echo "Adding unit tests coverage comment to the pr"
            python3 ./Tests/scripts/add_pr_comment.py
          fi
          exit $EXIT_CODE
        fi

  infrastructure_testing: &infrastructure_testing
    run:
      name: Infrastructure testing
      when: always
      command: |
        python3 -m pytest ./Tests/scripts/infrastructure_tests/ -v
        python3 -m pytest ./Tests/Marketplace/Tests/ -v
        python3 -m pytest ./Tests/tests -v
        python3 -m pytest ./Tests/private_build/tests -v
        python3 -m pytest Utils -v

        if [ -n "${DEMISTO_SDK_NIGHTLY}" ] ; then
          ./Tests/scripts/sdk_pylint_check.sh
        fi

  get_contribution_pack: &get_contribution_pack
    when:
      condition: << pipeline.parameters.contrib_branch >>
      steps:
        - run:
            name: Get Contributor pack
            when: always
            command: |
                REPO=$(echo $CONTRIB_BRANCH | cut -d ":" -f 1)
                BRANCH=$(echo $CONTRIB_BRANCH | cut -d ":" -f 2)
                python3 ./Utils/update_contribution_pack_in_base_branch.py -p $PULL_REQUEST_NUMBER -b $BRANCH -c $REPO

  comment_on_contrib_pr: &comment_on_contrib_pr
    when:
      condition: << pipeline.parameters.contrib_branch >>
      steps:
        - run:
            name: Comment on the contribution Pull Request
            when: always
            command: |
              SERVER_URL=$(jq -r 'select(.[].Role == "Server Master") | .[].InstanceDNS' $ENV_RESULTS_PATH)
              python3 ./Utils/comment_on_pr.py -p $PULL_REQUEST_NUMBER -c "Instance is ready. Server link: https://$SERVER_URL, Build link: $CIRCLE_BUILD_URL"

  nightly_jobs: &nightly_jobs
    - Setup Environment:
        context: nightly_env
    - Run Unit Testing And Lint:
        context: nightly_env
        requires:
          - Setup Environment
        matrix:
          parameters:
            dockerimageflag: [ "native:ga", "native:maintenance", "native:dev", "from-yml" ]
        name: Run Unit Testing And Lint - Docker Image:<< matrix.dockerimageflag >>
    - Run Validations:
        requires:
          - Setup Environment


jobs:
  Setup Environment:
    <<: *container_config
    resource_class: medium
    <<: *environment
    steps:
      - checkout
      - *install_build_dependencies
      - *install_node_ci
      - *prepare_environment
      - *get_contribution_pack
      - *persist_to_workspace

  Run Unit Testing And Lint:
    <<: *container_config
    resource_class: large
    <<: *environment
    parameters:
      dockerimageflag:
        type: string
    steps:
      - *attach_workspace
      - *remote_docker
      - *install_build_dependencies
      - *install_node_ci
      - *install_neo4j
      - *prepare_environment
      - *infrastructure_testing
      - *run_unit_testing_and_lint
      - *generate_coverage_reports
      - store_test_results:
          path: ./unit-tests
      - *store_artifacts

  Run Validations:
    <<: *container_config
    resource_class: large
    <<: *environment
    steps:
      - *attach_workspace
      - *install_build_dependencies
      - *install_node_ci
      - *install_neo4j
      - *prepare_environment
      - *secrets
      - *validate_files_and_yaml
      - run:
          name: Spell Checks
          command: |
            python3 ./Tests/scripts/circleci_spell_checker.py $CIRCLE_BRANCH
      - run:
          name: Verify Base Branch for Contribution
          when: always
          command: |
            if [[ $CIRCLE_BRANCH =~ pull/[0-9]+ ]] ;
              then
                python3 ./Tests/scripts/verify_base_branch_for_contribution.py $CIRCLE_BRANCH
            fi
      - run:
          name: Validate landingPageSections.json
          when: always
          command: |
            # Download index.zip
            INDEX_PATH=$(mktemp)
            gsutil cp gs://${TEST_XDR_PREFIX}marketplace-dist/content/packs/index.zip $INDEX_PATH
            echo "successfully downloaded index.zip into $INDEX_PATH"

            UNZIP_PATH=$(mktemp -d)
            unzip $INDEX_PATH -d $UNZIP_PATH

            python3 Tests/Marketplace/validate_landing_page_sections.py -i $UNZIP_PATH
      - *store_artifacts
      - store_artifacts:
          path: $ARTIFACTS_FOLDER



workflows:
  version: 2
  commit:
    when:
      matches:
        # matching the environment variable << pipeline.git.branch >> to contributions branch pattern.
        pattern: pull/[0-9]+
        value: << pipeline.git.branch >>
    jobs:
      - Setup Environment
      - Run Unit Testing And Lint:
          requires:
            - Setup Environment
          matrix:
            parameters:
              dockerimageflag: [ "native:ga", "native:maintenance", "native:dev", "native:candidate", "from-yml" ]
          name: Run Unit Testing And Lint - Docker Image:<< matrix.dockerimageflag >>
      - Run Validations:
          requires:
            - Setup Environment

  nightly:
    triggers:
      - schedule:
          # should trigger every day at 12 AM UTC (3 AM Israel Time)
          cron: "0 0 * * *"
          filters:
            branches:
              only:
                - master
    jobs:
      *nightly_jobs

  nightly_trigger:
    # will initiate when using the trigger script.
    when: << pipeline.parameters.nightly >>
    jobs:
      *nightly_jobs