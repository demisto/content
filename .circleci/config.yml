version: 2.1
orbs:
  python: circleci/python@<< pipeline.parameters.python-orb-version >>
  node: circleci/node@<< pipeline.parameters.node-orb-version >>

commands:
  set-instance-role-env-variable:
    description: "Sets INSTANCE_ROLE env variable into $BASH_ENV file"
    parameters:
      instance_role:
        type: string
      instance_created:
        type: string
        default: ""
    steps:
      - run:
          name: Set INSTANCE_ROLE env variable
          command: |
            echo 'export INSTANCE_ROLE="<< parameters.instance_role >>"' >> $BASH_ENV
            echo 'export INSTANCE_WAS_CREATED="<< parameters.instance_created >>"' >> $BASH_ENV

parameters:
  artifact_build_num:
    type: string
    default: ""
  nightly:
    type: string
    default: ""
  legacy_nightly:
    type: string
    default: ""
  pr_number:
    type: string
    default: ""
  contrib_branch:
    type: string
    default: ""
  contrib_pack_name:
    type: string
    default: ""
  sdk_ref:
    type: string
    default: "master"
  gcs_market_bucket:
    type: string
    default: "marketplace-dist"
  cache-version:
    type: string
    default: v1  # Change this parameter to clear cache.
  python-orb-version:
    type: string
    default: "2.0.3" # disable-secrets-detection
  node-orb-version:
    type: string
    default: "5.0.1" # disable-secrets-detection

references:
  environment: &environment
    environment:
      # A flag for the demisto_client to not cache its last response in order to avoid memory leaks.
      DONT_CACHE_LAST_RESPONSE: "true"
      DEMISTO_SDK_LOG_FILE_SIZE: 1073741824  # 1GB
      ARTIFACT_BUILD_NUM: << pipeline.parameters.artifact_build_num >>
      CONTRIB_BRANCH: << pipeline.parameters.contrib_branch >>
      CONTRIB_PACK_NAME: << pipeline.parameters.contrib_pack_name >>
      SDK_REF: << pipeline.parameters.sdk_ref >>
      # Giving different names to the following pipeline parameters to avoid collision, handling such collision case
      # is done in 'Setup Environment' step.
      PULL_REQUEST_NUMBER: << pipeline.parameters.pr_number >>
      NIGHTLY_PARAMETER: << pipeline.parameters.nightly >>
      GCS_MARKET_BUCKET: << pipeline.parameters.gcs_market_bucket >>

  install_build_dependencies: &install_build_dependencies
    python/install-packages:
        pkg-manager: "poetry"
        args: "--with ci"
        cache-version: << pipeline.parameters.cache-version >>
        pre-install-steps:
          - run:
              name: Check if pyproject.toml is consistent with poetry.lock
              command: poetry lock --check

  install_node_ci: &install_node_ci
    node/install-packages:
        cache-version: << pipeline.parameters.cache-version >>


  install_neo4j: &install_neo4j
    run:
        name: Install Neo4j
        command: |
          sudo add-apt-repository -y ppa:openjdk-r/ppa
          sudo apt-get update

          wget -O - https://debian.neo4j.com/neotechnology.gpg.key | sudo apt-key add -
          echo 'deb https://debian.neo4j.com stable 5' | sudo tee /etc/apt/sources.list.d/neo4j.list
          sudo apt-get update
          apt list -a neo4j
          # The neo4j version should be consistent with APOC version below!
          sudo apt-get install neo4j=1:5.13.0
          sudo chown -R circleci /var/log/neo4j
          sudo chown -R circleci /var/lib/neo4j
          sudo chown -R circleci /etc/neo4j
          mkdir -p /var/lib/neo4j/plugins
          wget -O /var/lib/neo4j/plugins/apoc-5.13.0-core.jar https://github.com/neo4j/apoc/releases/download/5.13.0/apoc-5.13.0-core.jar
          neo4j_conf_file="/etc/neo4j/neo4j.conf"
          sudo echo "dbms.security.procedures.unrestricted=apoc.*" >> $neo4j_conf_file
          sudo echo "dbms.security.procedures.allowlist=apoc.*" >> $neo4j_conf_file
          sudo echo "dbms.memory.transaction.total.max=2000m" >> $neo4j_conf_file

          apoc_conf_file="/etc/neo4j/apoc.conf"
          sudo echo "apoc.export.file.enabled=true" > $apoc_conf_file
          sudo echo "apoc.import.file.enabled=true" >> $apoc_conf_file
          sudo echo "apoc.import.file.use_neo4j_config=true" >> $apoc_conf_file
          neo4j-admin dbms set-initial-password contentgraph

  container_config: &container_config
    docker:
      - image: devdemisto/content-build:3.0.0.93625  # disable-secrets-detection
        auth:
          username: $DOCKERHUB_USER
          password: $DOCKERHUB_PASSWORD

  workspace_root: &workspace_root
    /home/circleci/

  store_artifacts: &store_artifacts
     store_artifacts:
        path: artifacts
        destination: artifacts
        when: always

  attach_workspace: &attach_workspace
    attach_workspace:
      at: *workspace_root

  prepare_environment: &prepare_environment
    run:
      name: Prepare Environment
      when: always
      command: |
        # add github to known hosts
        [ ! -d ~/.ssh ] && mkdir -p ~/.ssh
        chmod 700 ~/.ssh
        ssh-keyscan github.com >> ~/.ssh/known_hosts

        poetry --version
        # Check if CircleCI's config file and poetry files files are up to date
        # if poetry isn't up-to-date, checkout from origin/master.
        ./.circleci/is_file_up_to_date.sh .circleci/config.yml $CIRCLE_BRANCH
        ./.circleci/is_file_up_to_date.sh poetry.lock $CIRCLE_BRANCH true
        ./.circleci/is_file_up_to_date.sh pyproject.toml $CIRCLE_BRANCH true

        echo 'export CIRCLE_ARTIFACTS="/home/circleci/project/artifacts"' >> $BASH_ENV
        echo 'export PATH="/home/circleci/.local/bin:${PWD}/node_modules/.bin:${PATH}"' >> $BASH_ENV # disable-secrets-detection
        echo 'export PYTHONPATH="/home/circleci/project:${PYTHONPATH}"' >> $BASH_ENV
        echo 'export DEMISTO_README_VALIDATION=true' >> $BASH_ENV
        echo 'export ENV_RESULTS_PATH=/home/circleci/project/artifacts/env_results.json' >> $BASH_ENV
        echo 'export GCS_PRODUCTION_BUCKET="marketplace-dist"' >> $BASH_ENV
        echo 'source /home/circleci/project/.circleci/content_release_vars.sh' >> $BASH_ENV
        chmod +x .circleci/gitlab-ci-env-variables.sh
        ./.circleci/gitlab-ci-env-variables.sh
        if [ -n "${NIGHTLY_PARAMETER}" ] || [ -n "${LEGACY_NIGHTLY_PARAMETER}" ];
        then
            echo 'export NIGHTLY=true' >> $BASH_ENV
        fi

        echo "=== sourcing $BASH_ENV ==="
        source $BASH_ENV
        sudo mkdir -p -m 777 $CIRCLE_ARTIFACTS/

        # Creating new clean logs folder
        rm -rf $CIRCLE_ARTIFACTS/logs
        mkdir -p $CIRCLE_ARTIFACTS/logs

        chmod +x ./Tests/scripts/*
        chmod +x ./Tests/Marketplace/*
        chmod +x ./Config/*

        source ./.venv/bin/activate

        # store in bash env so we load our venv in each step
        echo 'source /home/circleci/project/.venv/bin/activate' >> $BASH_ENV
        git config diff.renameLimit 6000

        echo "========== Build Parameters =========="
        set | grep -E "^NIGHTLY=|^CONTRIB_BRANCH=|^SDK_REF"
        python3 --version | tee -a $CIRCLE_ARTIFACTS/installed_python_libraries.txt
        python3 -m pip list | tee -a $CIRCLE_ARTIFACTS/installed_python_libraries.txt
        node --version
        npm --version
        demisto-sdk --version

  remote_docker: &remote_docker
    setup_remote_docker:
      version: 20.10.17
      docker_layer_caching: true

  persist_to_workspace: &persist_to_workspace
    persist_to_workspace:
      root: /home/circleci/
      paths:
        - project

  secrets: &secrets
    run:
      name: Secrets
      when: always
      no_output_timeout: 5h
      command: |
        demisto-sdk secrets --post-commit --ignore-entropy

  validate_files_and_yaml: &validate_files_and_yaml
    run:
      name: Validate Files and Yaml
      when: always
      no_output_timeout: 1h
      command: |
        if [[ "$(echo "$GCS_MARKET_BUCKET" | tr '[:upper:]' '[:lower:]')" != "marketplace-dist" ]]; then
          echo "Skipping the -Validate Files and Yaml- step when uploading to a test bucket."
          exit 0
        fi

        neo4j start
        # poll for neo4j status until available
        while ! curl --fail http://127.0.0.1:7474 &> /dev/null; do sleep 1; done

        ./.circleci/analyze_non_packs_files.sh
        ./.circleci/validate.sh

  
  # generate_coverage_reports: &generate_coverage_reports
  #   run:
  #     name: Generate coverage reports
  #     when: always
  #     no_output_timeout: 1h
  #     command: |
  #       EXIT_CODE=0
  #       if [[ -f $ARTIFACTS_FOLDER/coverage_report/.coverage ]]; then
  #         demisto-sdk coverage-analyze -i $ARTIFACTS_FOLDER/coverage_report/.coverage --report-dir $ARTIFACTS_FOLDER/coverage_report --report-type all --previous-coverage-report-url https://storage.googleapis.com/marketplace-dist-dev/code-coverage-reports/coverage-min.json || EXIT_CODE=1
  #         # Checks if the $XSOAR_BOT_TEST_CONTENT exist. for security reasons only non forked pr's have access to it.
  #         if [[ -n $XSOAR_BOT_TEST_CONTENT && -e $ARTIFACTS_FOLDER/coverage_report/html/index.html ]]; then
  #           echo "Adding unit tests coverage comment to the pr"
  #           python3 ./.circleci/add_pr_comment.py
  #         fi
  #         exit $EXIT_CODE
  #       fi

  get_contribution_pack: &get_contribution_pack
    when:
      condition: << pipeline.parameters.contrib_branch >>
      steps:
        - run:
            name: Get Contributor pack
            when: always
            command: |
                USERNAME=$(echo $CONTRIB_BRANCH | cut -d ":" -f 1)
                BRANCH=$(echo $CONTRIB_BRANCH | cut -d ":" -f 2)
                $CONTRIB_REPO="content"
                python3 ./.circleci/update_contribution_pack_in_base_branch.py -p $PULL_REQUEST_NUMBER -b $BRANCH -u $USERNAME -c $CONTRIB_REPO -gt $GITHUB_TOKEN

  comment_on_contrib_pr: &comment_on_contrib_pr
    when:
      condition: << pipeline.parameters.contrib_branch >>
      steps:
        - run:
            name: Comment on the contribution Pull Request
            when: always
            command: |
              SERVER_URL=$(jq -r 'select(.[].Role == "Server Master") | .[].InstanceDNS' $ENV_RESULTS_PATH)
              python3 ./.circleci/comment_on_pr.py -p $PULL_REQUEST_NUMBER -c "Instance is ready. Server link: https://$SERVER_URL, Build link: $CIRCLE_BUILD_URL"

  nightly_jobs: &nightly_jobs
    - Setup Environment:
        context: nightly_env
    - Run Validations:
        requires:
          - Setup Environment


jobs:
  Setup Environment:
    <<: *container_config
    resource_class: medium
    <<: *environment
    steps:
      - checkout
      - *install_build_dependencies
      - *install_node_ci
      - *prepare_environment
      - *get_contribution_pack
      - *persist_to_workspace


  Run Validations:
    <<: *container_config
    resource_class: large
    <<: *environment
    steps:
      - *attach_workspace
      - *install_build_dependencies
      - *install_node_ci
      - *install_neo4j
      - *prepare_environment
      - *secrets
      - *validate_files_and_yaml
      - run:
          name: Spell Checks
          command: |
            python3 ./.circleci/circleci_spell_checker.py $CIRCLE_BRANCH
      - run:
          name: Verify Base Branch for Contribution
          when: always
          command: |
            if [[ $CIRCLE_BRANCH =~ pull/[0-9]+ ]] ;
              then
                python3 ./.circleci/verify_base_branch_for_contribution.py $CIRCLE_BRANCH
            fi
      - run:
          name: Validate landingPageSections.json
          when: always
          command: |
            # Download index.zip
            INDEX_PATH=$(mktemp)
            gsutil cp gs://marketplace-dist/content/packs/index.zip $INDEX_PATH
            echo "successfully downloaded index.zip into $INDEX_PATH"

            UNZIP_PATH=$(mktemp -d)
            unzip $INDEX_PATH -d $UNZIP_PATH

            python3 ./.circleci/validate_landing_page_sections.py -i $UNZIP_PATH
      - *store_artifacts
      - store_artifacts:
          path: $ARTIFACTS_FOLDER



workflows:
  version: 2
  commit:
    when:
      matches:
        # matching the environment variable << pipeline.git.branch >> to contributions branch pattern.
        pattern: pull/[0-9]+
        value: << pipeline.git.branch >>
    jobs:
      - Setup Environment
      - Run Validations:
          requires:
            - Setup Environment

  nightly:
    triggers:
      - schedule:
          # should trigger every day at 12 AM UTC (3 AM Israel Time)
          cron: "0 0 * * *"
          filters:
            branches:
              only:
                - master
    jobs:
      *nightly_jobs

  nightly_trigger:
    # will initiate when using the trigger script.
    when: << pipeline.parameters.nightly >>
    jobs:
      *nightly_jobs