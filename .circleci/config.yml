version: 2.1
commands:
  set-instance-role-env-variable:
    description: "Sets INSTANCE_ROLE env variable into $BASH_ENV file"
    parameters:
      instance_role:
        type: string
      instance_created:
        type: string
        default: ""
    steps:
      - run:
          name: Set INSTANCE_ROLE env variable
          command: |
            echo 'export INSTANCE_ROLE="<< parameters.instance_role >>"' >> $BASH_ENV
            echo 'export INSTANCE_WAS_CREATED="<< parameters.instance_created >>"' >> $BASH_ENV
  start-tunnel:
    description: "Opens an ssh tunnel to the demisto servers and wait until the tunnels are established"
    parameters:
      timeout:
        type: integer
        default: 10
    steps:
      - run:
          name: add ssh configurations
          shell: /bin/bash
          command: |
            if [ -z $INSTANCE_WAS_CREATED ];
              then
                echo "Skipping - instance was not created"
                exit 0
            fi
            # Modifying ssh config file
            echo "Host 10.0.*
              StrictHostKeyChecking no
              LogLevel ERROR
              ProxyJump content-build@content-build-lb.demisto.works  # disable-secrets-detection
             Host content-build-lb.demisto.works
              Port 43567
              UserKnownHostsFile /dev/null
              StrictHostKeyChecking no
              LogLevel ERROR" >> ~/.ssh/config
      - run:
          name: Open SSH Tunnel
          command: |
            if [ -z $INSTANCE_WAS_CREATED ];
              then
                echo "Skipping - instance was not created"
                exit 0
            fi
            ./Tests/scripts/open_ssh_tunnel.sh

parameters:
  artifact_build_num:
    type: string
    default: ""
  nightly:
    type: string
    default: ""
  legacy_nightly:
    type: string
    default: ""
  pr_number:
    type: string
    default: ""
  contrib_branch:
    type: string
    default: ""
  contrib_pack_name:
    type: string
    default: ""
  sdk_ref:
    type: string
    default: "master"
  gcs_market_bucket:
    type: string
    default: "marketplace-dist"

references:
  environment: &environment
    environment:
      # A flag for the demisto_client to not cache it's last response in order to avoid memory leaks
      DONT_CACHE_LAST_RESPONSE: "true"
      ARTIFACT_BUILD_NUM: << pipeline.parameters.artifact_build_num >>
      CONTRIB_BRANCH: << pipeline.parameters.contrib_branch >>
      CONTRIB_PACK_NAME: << pipeline.parameters.contrib_pack_name >>
      SDK_REF: << pipeline.parameters.sdk_ref >>
      # Giving different names to the following pipeline parameters to avoid collision, handling such collision case
      # is done in 'Setup Environment' step.
      PULL_REQUEST_NUMBER: << pipeline.parameters.pr_number >>
      NIGHTLY_PARAMETER: << pipeline.parameters.nightly >>
      GCS_MARKET_BUCKET: << pipeline.parameters.gcs_market_bucket >>


  container_config: &container_config
    docker:
      - image: devdemisto/content-build:3.0.0.27109  # disable-secrets-detection
        auth:
          username: $DOCKERHUB_USER
          password: $DOCKERHUB_PASSWORD

  workspace_root: &workspace_root
    /home/circleci/

  store_artifacts: &store_artifacts
     store_artifacts:
        path: artifacts
        destination: artifacts
        when: always

  attach_workspace: &attach_workspace
    attach_workspace:
      at: *workspace_root

  add_ssh_keys: &add_ssh_keys
    add_ssh_keys:
      fingerprints:
        - "02:df:a5:6a:53:9a:f5:5d:bd:a6:fc:b2:db:9b:c9:47" # disable-secrets-detection
        - "f5:25:6a:e5:ac:4b:84:fb:60:54:14:82:f1:e9:6c:f9" # disable-secrets-detection

  prepare_environment: &prepare_environment
    run:
      name: Prepare Environment
      when: always
      command: |
        echo 'export CIRCLE_ARTIFACTS="/home/circleci/project/artifacts"' >> $BASH_ENV
        echo 'export PATH="/home/circleci/.local/bin:${PWD}/node_modules/.bin:${PATH}"' >> $BASH_ENV # disable-secrets-detection
        echo 'export PYTHONPATH="/home/circleci/project:${PYTHONPATH}"' >> $BASH_ENV
        echo 'export DEMISTO_README_VALIDATION=true' >> $BASH_ENV
        echo 'export ENV_RESULTS_PATH=/home/circleci/project/artifacts/env_results.json' >> $BASH_ENV
        echo 'export GCS_PRODUCTION_BUCKET="marketplace-dist"' >> $BASH_ENV
        echo 'source /home/circleci/project/.circleci/content_release_vars.sh' >> $BASH_ENV
        chmod +x .circleci/gitlab-ci-env-variables.sh
        ./.circleci/gitlab-ci-env-variables.sh
        if [ -n "${NIGHTLY_PARAMETER}" ] || [ -n "${LEGACY_NIGHTLY_PARAMETER}" ];
        then
            echo 'export NIGHTLY=true' >> $BASH_ENV
        fi

        echo "=== sourcing $BASH_ENV ==="
        source $BASH_ENV
        sudo mkdir -p -m 777 $CIRCLE_ARTIFACTS/

        # Creating new clean logs folder
        rm -rf $CIRCLE_ARTIFACTS/logs
        mkdir -p $CIRCLE_ARTIFACTS/logs

        chmod +x ./Tests/scripts/*
        chmod +x ./Tests/Marketplace/*
        if [ ! -e "venv" ]; then
          echo "installing venv"
          NO_HOOKS=1 SETUP_PY2=yes .hooks/bootstrap
          source ./venv/bin/activate
          pip3 install -r .circleci/build-requirements.txt
        else
          echo "venv exists (from cache). activating"
          source ./venv/bin/activate
        fi
        # store in bash env so we load our venv in each step
        echo 'source /home/circleci/project/venv/bin/activate' >> $BASH_ENV
        git config diff.renameLimit 6000

        echo "========== Build Parameters =========="
        set | grep -E "^NIGHTLY=|^CONTRIB_BRANCH=|^SDK_REF"
        python --version
        python3 --version
        node --version
        npm --version
        demisto-sdk --version

  restore_cache: &restore_cache
    restore_cache:
      key: virtualenv-venv-{{ checksum "dev-requirements-py2.txt" }}-{{ checksum "dev-requirements-py3.txt" }}-{{ checksum ".circleci/build-requirements.txt" }}-{{ checksum "package-lock.json" }}

  remote_docker: &remote_docker
    setup_remote_docker:
      version: 20.10.6

  persist_to_workspace: &persist_to_workspace
    persist_to_workspace:
      root: /home/circleci/
      paths:
        - project

  secrets: &secrets
    run:
      name: Secrets
      when: always
      no_output_timeout: 5h
      command: |
        demisto-sdk secrets --post-commit --ignore-entropy

  validate_files_and_yaml: &validate_files_and_yaml
    run:
      name: Validate Files and Yaml
      when: always
      no_output_timeout: 1h
      command: |
        if [[ "$(echo "$GCS_MARKET_BUCKET" | tr '[:upper:]' '[:lower:]')" != "marketplace-dist" ]]; then
          echo "Skipping the -Validate Files and Yaml- step when uploading to a test bucket."
          exit 0
        fi

        ./Tests/scripts/linters_runner.sh
        ./Tests/scripts/validate.sh

  run_unit_testing_and_lint: &run_unit_testing_and_lint
    run:
      name: Run Unit Testing and Lint
      when: always
      no_output_timeout: 5h
      command: |
        if [[ "$(echo "$GCS_MARKET_BUCKET" | tr '[:upper:]' '[:lower:]')" != "marketplace-dist" ]]; then
          echo "Skipping validations when uploading to a test bucket."
          exit 0
        fi

        echo "demisto-sdk version: $(demisto-sdk --version)"
        echo "mypy version: $(mypy --version)"
        echo "flake8 py2 version: $(python2 -m flake8 --version)"
        echo "flake8 py3 version: $(python3 -m flake8 --version)"
        echo "bandit py2 version: $(python2 -m bandit --version 2>&1)"
        echo "bandit py3 version: $(python3 -m bandit --version 2>&1)"
        echo "vulture py2 version: $(python2 -m vulture --version 2>&1)"
        echo "vulture py3 version: $(python3 -m vulture --version 2>&1)"
        mkdir ./unit-tests
        demisto-sdk lint -p 8 -g -v --test-xml ./unit-tests --log-path ./artifacts --failure-report ./artifacts --coverage-report $ARTIFACTS_FOLDER/coverage_report

  generate_coverage_reports: &generate_coverage_reports
    run:
      name: Generate coverage reports
      when: always
      no_output_timeout: 1h
      command: |
        if [[ -f $ARTIFACTS_FOLDER/coverage_report/.coverage ]]; then
          demisto-sdk coverage-analyze -i $ARTIFACTS_FOLDER/coverage_report/.coverage --report-dir $ARTIFACTS_FOLDER/coverage_report --report-type all --previous-coverage-report-url https://storage.googleapis.com/marketplace-dist-dev/code-coverage-reports/coverage-min.json
        fi

  infrastructure_testing: &infrastructure_testing
    run:
      name: Infrastructure testing
      when: always
      command: |
        python3 -m pytest ./Tests/scripts/infrastructure_tests/ -v
        python3 -m pytest ./Tests/Marketplace/Tests/ -v
        python3 -m pytest ./Tests/scripts/utils/tests -v
        python3 -m pytest ./Tests/tests -v
        python3 -m pytest ./Tests/private_build/tests -v
        python3 -m pytest Utils -v

        if [ -n "${DEMISTO_SDK_NIGHTLY}" ] ; then
          ./Tests/scripts/sdk_pylint_check.sh
        fi

  create_id_set: &create_id_set
    run:
      name: Create ID Set
      when: always
      command: |
        demisto-sdk create-id-set -o ./Tests/id_set.json --fail-duplicates
        cp ./Tests/id_set.json $CIRCLE_ARTIFACTS

  merge_public_and_private_id_sets: &merge_public_and_private_id_sets
    run:
      name: Merge public and private ID sets
      when: always
      command: |
        if [[ $CIRCLE_BRANCH =~ pull/[0-9]+ ]]; then
            echo "Skipping, Should not run on contributor's branch."
            exit 0
        fi

        # Download private ID set
        gsutil cp gs://marketplace-dist/content/private_id_set.json $CIRCLE_ARTIFACTS/unified_id_set.json
        echo "successfully downloaded private ID set"

        # Merge public and private ID sets
        demisto-sdk merge-id-sets -i1 ./Tests/id_set.json -i2 $CIRCLE_ARTIFACTS/unified_id_set.json -o $CIRCLE_ARTIFACTS/unified_id_set.json
        echo "successfully merged public and private ID sets"

  get_contribution_pack: &get_contribution_pack
    when:
      condition: << pipeline.parameters.contrib_branch >>
      steps:
        - run:
            name: Get Contributor pack
            when: always
            command: |
                REPO=$(echo $CONTRIB_BRANCH | cut -d ":" -f 1)
                BRANCH=$(echo $CONTRIB_BRANCH | cut -d ":" -f 2)
                python3 ./Utils/update_contribution_pack_in_base_branch.py -p $PULL_REQUEST_NUMBER -b $BRANCH -c $REPO

  comment_on_contrib_pr: &comment_on_contrib_pr
    when:
      condition: << pipeline.parameters.contrib_branch >>
      steps:
        - run:
            name: Comment on the contribution Pull Request
            when: always
            command: |
              SERVER_URL=$(jq -r 'select(.[].Role == "Server Master") | .[].InstanceDNS' $ENV_RESULTS_PATH)
              python3 ./Utils/comment_on_pr.py -p $PULL_REQUEST_NUMBER -c "Instance is ready. Server link: https://$SERVER_URL, Build link: $CIRCLE_BUILD_URL"

  nightly_jobs: &nightly_jobs
    - Setup Environment:
        context: nightly_env
    - Run Unit Testing And Lint:
        context: nightly_env
        requires:
          - Setup Environment
    - Run Validations:
        requires:
          - Setup Environment


jobs:
  Setup Environment:
    <<: *container_config
    resource_class: medium
    <<: *environment
    steps:
      - checkout
      - *restore_cache
      - *prepare_environment
      - save_cache:
          paths:
            - venv
            - node_modules
          key: virtualenv-venv-{{ checksum "dev-requirements-py2.txt" }}-{{ checksum "dev-requirements-py3.txt" }}-{{ checksum ".circleci/build-requirements.txt" }}-{{ checksum "package-lock.json" }}
      - *get_contribution_pack
      - *add_ssh_keys
      - *persist_to_workspace

  Run Unit Testing And Lint:
    <<: *container_config
    resource_class: medium
    <<: *environment
    steps:
      - *attach_workspace
      - *remote_docker
      - *restore_cache
      - *add_ssh_keys
      - *prepare_environment
      - *infrastructure_testing
      - *run_unit_testing_and_lint
      - *generate_coverage_reports
      - store_test_results:
          path: ./unit-tests
      - *store_artifacts

  Run Validations:
    <<: *container_config
    resource_class: medium
    <<: *environment
    steps:
      - *attach_workspace
      - *restore_cache
      - *add_ssh_keys
      - *prepare_environment
      - *secrets
      - *create_id_set
      - *merge_public_and_private_id_sets
      - *validate_files_and_yaml
      - run:
          name: Spell Checks
          command: |
            python3 ./Tests/scripts/circleci_spell_checker.py $CIRCLE_BRANCH
      - run:
          name: Check if CircleCI's config file and requirements.txt files are up to date
          when: always
          command: |
            ./Tests/scripts/is_file_up_to_date.sh .circleci/config.yml $CIRCLE_BRANCH
            ./Tests/scripts/is_file_up_to_date.sh dev-requirements-py2.txt $CIRCLE_BRANCH
            ./Tests/scripts/is_file_up_to_date.sh dev-requirements-py3.txt $CIRCLE_BRANCH
      - run:
          name: Verify Base Branch for Contribution
          when: always
          command: |
            if [[ $CIRCLE_BRANCH =~ pull/[0-9]+ ]] ;
              then
                python3 ./Tests/scripts/verify_base_branch_for_contribution.py $CIRCLE_BRANCH
            fi
      - run:
          name: Validate landingPageSections.json
          when: always
          command: |
            # Download index.zip
            INDEX_PATH=$(mktemp)
            gsutil cp gs://marketplace-dist/content/packs/index.zip $INDEX_PATH
            echo "successfully downloaded index.zip into $INDEX_PATH"

            UNZIP_PATH=$(mktemp -d)
            unzip $INDEX_PATH -d $UNZIP_PATH

            python3 Tests/Marketplace/validate_landing_page_sections.py -i $UNZIP_PATH
      - *store_artifacts



workflows:
  version: 2
  commit:
    when:
      not:
        or:
          - << pipeline.parameters.nightly >>
    jobs:
      - Setup Environment
      - Run Unit Testing And Lint:
          requires:
            - Setup Environment
      - Run Validations:
          requires:
            - Setup Environment

  nightly:
    triggers:
      - schedule:
          # should trigger every day at 12 AM UTC (3 AM Israel Time)
          cron: "0 0 * * *"
          filters:
            branches:
              only:
                - master
    jobs:
      *nightly_jobs

  nightly_trigger:
    # will initiate when using the trigger script.
    when: << pipeline.parameters.nightly >>
    jobs:
      *nightly_jobs

