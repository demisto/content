commonfields:
  id: ParseCSV
  version: -1
name: ParseCSV
script: |+
  import csv
  import socket
  import json
  import re
  import string
  import sys

  reload(sys)
  sys.setdefaultencoding('utf8')
  codec_type = demisto.args().get('codec')

  def remove_non_printable_chars(s):
      """
      removes
      'ZERO WIDTH SPACE' (U+200B)
      'ZERO WIDTH NO-BREAK SPACE' (U+FEFF)
      """
      return s.replace(u'\ufeff', '').replace(u'\u200f', '')


  def unicode_dict_reader(csv_data, **kwargs):
      """
      reads from csv file each row and converts to array of dictionaries.
      in case there are extra fields in a row and they have no column, then we will create NO_NAME_COLUMN_{NUMBER}

      CSV Example:
      aaa,bbb
      1,2
      3,4,5

      ===>

      [
          {
              "aaa": 1,
              "bbb": 2,
              "NO_NAME_COLUMN_3": ""
          },
          {
              "aaa": 3,
              "bbb": 4,
              "NO_NAME_COLUMN_3": 5       <-- extra field/column
          }
      ]
      """
      csv_reader = csv.DictReader((line.replace('\0', '') for line in csv_data), **kwargs)
      arr = []
      no_name_columns_counter = 0
      for row in csv_reader:
          row_dict = {}

          for key, value in row.iteritems():
              if key is None:
                  # if the key is None it means there are fields in the row which has no column name
                  # so we create NO_NAME_COLUMN_{} column
                  if not isinstance(value, list):
                      value = [value]

                  counter = 0
                  for val in value:
                      col_name = 'NO_NAME_COLUMN_{}'.format(counter)
                      row_dict[col_name] = unicode(val, codec_type)
                      counter+=1

                  if no_name_columns_counter < counter:
                      no_name_columns_counter = counter

              elif value is not None:
                  col_name = remove_non_printable_chars(unicode(key, codec_type))
                  row_dict[col_name] = unicode(value, codec_type)
              else:
                  col_name = remove_non_printable_chars(unicode(key, codec_type))
                  row_dict[col_name] = None

          arr.append(row_dict)

      if no_name_columns_counter > 0:
          """
          adding NO_NAME_COLUMN_{} to the first dict in the array
          so that later in tableToMarkdown it will print all the columns
          """
          first_row = arr[0]
          for counter in range(no_name_columns_counter):
              first_row['NO_NAME_COLUMN_{}'.format(counter)] = ""

      return arr

  def get_entry_by_file_name(file):
      entries = demisto.executeCommand('getEntries', {})
      for entry in reversed(entries):
          fn = demisto.get(entry, 'File')

          if type(fn) not in [unicode, str]:
              continue

          if file.lower() == fn.lower():
              return entry
      raise ValueError('Was unable to find "{}" in the war room. Please ensure the file was uploaded.'.format(file))

  csvEntry = None

  iplist = []
  domainlist = []
  hashlist = []

  ipcount = 0
  domaincount = 0
  hashcount = 0

  dArgs = demisto.args()

  entryID = dArgs['entryID'] if 'entryID' in dArgs else None
  file = dArgs['file'] if 'file' in dArgs else None # file arg deprecated
  parseip = int(dArgs['ips']) if 'ips' in dArgs else -1
  parsedomain = int(dArgs['domains']) if 'domains' in dArgs else -1
  parsehash = int(dArgs['hashes']) if 'hashes' in dArgs else -1
  parse_all = True if dArgs['parseAll'] == 'yes' else False

  if parseip == -1 and parsedomain == -1 and parsehash == -1 and not parse_all:
      return_error('Select a field to extract or set parseAll=yes to parse the whole CSV file')

  if file is None and entryID is None:
      return_error('Please provide entryID.')

  if entryID is None:
      # search entry by file name
      try:
          entry = get_entry_by_file_name(file)
          entryID = entry['ID']
      except ValueError as e:
          return_error(e.message)

  res = demisto.getFilePath(entryID)
  if not res:
      return_error("Entry {} not found".format(entryID))

  filePath = res['path']
  fileName = res['name']
  if not fileName.lower().endswith('.csv'):
      return_error('"{}" is not in csv format. Please ensure the file is in correct format and has a ".csv" extention'.format(fileName))

  if parse_all:
      all_csv = []
      with open(filePath, mode='r') as f:
          records = unicode_dict_reader(f)
          for row in records:
              all_csv.append(row)

      output = {
          'ParseCSV.ParsedCSV': all_csv
      }

      human_readable = tableToMarkdown(fileName, all_csv)
      demisto.results({
          "Type" : entryTypes["note"],
          "ContentsFormat" : formats["json"],
          "ReadableContentsFormat" : formats["markdown"],
          "Contents" : all_csv,
          "EntryContext": output,
          "HumanReadable": human_readable
      })
      sys.exit(0)

  if parseip == -1 and parsedomain == -1 and parsehash == -1:
      # stop the script if no need to parse ips,domains or hashes
      sys.exit(0)

  with open(filePath, 'rU') as f:
      has_header = csv.Sniffer().has_header(f.read(1024))
      f.seek(0)

      csvdata = csv.reader(f)

      if has_header:
          next(csvdata)

      md = '### Parsed Data Table\n'+('IPs |' if 'ips' in dArgs else '') + ('Domains |' if 'domains' in dArgs else '') + ('Hashes |' if 'hashes' in dArgs else '') + '\n'
      md += ('- |' if 'ips' in dArgs else '') + ('- |' if 'domains' in dArgs else '') + ('- |' if 'hashes' in dArgs else '') + '\n'
      content = ''

      for row in csvdata:
          content += ','.join(row) + '\n'
          if parseip != -1:
              md += (row[parseip] + '|' if row[parseip] else ' |')
              is_ip = re.search( r'([0-9]{1,3}\.){3}[0-9]{1,3}', row[parseip] )
              is_valid = is_ip_valid(row[parseip])
              if is_ip and is_valid:
                  iplist.append(row[parseip])

          if parsedomain != -1:
              md += (row[parsedomain] + '|' if row[parsedomain] else ' |')
              has_dot = '.' in row[parsedomain]
              no_spaces = ' ' not in row[parsedomain]
              if has_dot and no_spaces:
                  domainlist.append(row[parsedomain])

          if parsehash != -1:
              md += (row[parsehash] + '|' if row[parsehash] else ' |')
              is_hash = re.search( r'[0-9A-Fa-f]{32,128}', row[parsehash] )
              if is_hash:
                  hashlist.append(row[parsehash])
          md += '\n'

  context = {}
  if iplist:
      old_iplist = list(demisto.get( demisto.context(), 'ips')) if demisto.get( demisto.context(), 'ips' ) else []
      iplist = list(set(iplist) - set(old_iplist))
      if len(iplist) > 0:
          context["IP"] = []
          for ip in iplist:
              context["IP"].append({"Address" : ip})

  if domainlist:
      old_domainlist = list(demisto.get( demisto.context(), 'domains')) if demisto.get( demisto.context(), 'domains' ) else []
      domainlist = list(set(domainlist) - set(old_domainlist))
      if len(domainlist) > 0:
          context["Domain"] = []
          for domain in domainlist:
              context["Domain"].append({"Name": domain})

  if hashlist:
      old_hashlist = list(demisto.get( demisto.context(), 'hashes')) if demisto.get( demisto.context(), 'hashes' ) else []
      hashlist = list(set(hashlist) - set(old_hashlist))
      if len(hashlist) > 0:
          context["File"] = []
          for hash in hashlist:
              if len(hash)==32: context["File"].append({"MD5" : hash})
              if len(hash)==64: context["File"].append({"SHA256" : hash})
              if len(hash)==40: context["File"].append({"SHA1" : hash})

  demisto.results({
      "Type" : entryTypes["note"],
      "ContentsFormat" : formats["text"],
      "Contents" : content,
      "HumanReadable" : md,
      "EntryContext": context
  })

type: python
tags:
- file
- csv
- Utility
comment: This script will parse a CSV file and place the unique IPs, Domains and Hashes
  into the context.
enabled: true
args:
- name: entryID
  default: true
  description: The war room entryID of the file.
- name: file
  deprecated: true
  description: The name of the file. The file must be uploaded to the War Room.
- name: ips
  description: The column number that contains IP Addresses. (First column is column
    0)
- name: domains
  description: The column number that contains domains. (First column is column 0)
- name: hashes
  description: The column number that contains file hashes. (First column is column
    0)
- name: parseAll
  auto: PREDEFINED
  predefined:
  - "yes"
  - "no"
  description: parses and converts all the rows in csv into json and puts into context.
  defaultValue: "yes"
- name: codec
  description: The codec type used to parse the file (some character sets are not
    UTF-8 supported)
  defaultValue: utf-8
outputs:
- contextPath: IP.Address
  description: IP address found in parsed file
- contextPath: Domain.Name
  description: Domain found in parsed file
- contextPath: File.MD5
  description: MD5 found in parsed file
- contextPath: File.SHA1
  description: SHA1 found in parsed file
- contextPath: File.SHA256
  description: SHA256 found in parsed file
- contextPath: ParseCSV.ParsedCSV
  description: Parsed csv in form of JSON array
scripttarget: 0
runonce: false
runas: DBotWeakRole
tests:
  - TestParseCSV
