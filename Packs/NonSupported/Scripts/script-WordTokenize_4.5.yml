commonfields:
  id: WordTokenizer
  version: -1
name: WordTokenizer
script: |-
  import nltk, re
  from HTMLParser import HTMLParser
  html_parser = HTMLParser()

  CLEAN_HTML = (demisto.args()['cleanHtml'] == 'yes')
  REMOVE_LINE_BREAKS = (demisto.args()['removeLineBreaks'] == 'yes')
  TOKENIZE_TYPE = demisto.args()['type']
  TEXT_ENCODE = demisto.args()['encoding']
  HASH_SEED = demisto.args().get('hashWordWithSeed')

  REMOVE_HTML_PATTERNS = [
      re.compile(r"(?is)<(script|style).*?>.*?(</\1>)"),
      re.compile(r"(?s)<!--(.*?)-->[\n]?"),
      re.compile(r"(?s)<.*?>"),
      re.compile(r"&nbsp;"),
      re.compile(r" +")
  ]
  def clean_html(text):
      if not CLEAN_HTML:
          return text

      cleaned = text
      for pattern in REMOVE_HTML_PATTERNS:
          cleaned = pattern.sub(" ", cleaned)
      return html_parser.unescape(cleaned).strip()

  def tokenize_text(text):
      if not text:
          return ''
      text = text.lower()
      if TOKENIZE_TYPE == 'word':
          word_tokens = nltk.word_tokenize(text)
      elif TOKENIZE_TYPE == 'punkt':
          word_tokens = nltk.wordpunct_tokenize(text)
      else:
          raise Exception("Unsupported tokenize type: %s" % tokenize_type)
      if HASH_SEED:
          word_tokens = map(str, map(lambda x: hash_djb2(x, int(HASH_SEED)), word_tokens))
      return (' '.join(word_tokens)).encode(TEXT_ENCODE).strip()


  def remove_line_breaks(text):
      if not REMOVE_LINE_BREAKS:
          return text

      return text.replace("\r","").replace("\n","")

  text = demisto.args()['value']

  if type(text) is not list:
      text = [text]
  result = map(remove_line_breaks, map(tokenize_text, map(clean_html, text)))

  if len(result) == 1:
      result = result[0]

  demisto.results({
      'Contents': result,
      'ContentsFormat': formats['json'] if type(result) is list else formats['text'],
      'EntryContext': {
          'WordTokenizeOutput': result
      }
  })
type: python
subtype: python2
tags:
- phishing
- ml
comment: Tokenize the words in a input text.
enabled: true
args:
- name: value
  required: true
  description: The text value
  isArray: true
- name: type
  auto: PREDEFINED
  predefined:
  - word
  - punkt
  description: 'Tokenizer type. you can read more about this here: https://www.nltk.org/api/nltk.tokenize.html'
  defaultValue: word
- name: cleanHtml
  auto: PREDEFINED
  predefined:
  - "yes"
  - "no"
  description: Clean html from text value?
  defaultValue: "yes"
- name: removeLineBreaks
  auto: PREDEFINED
  predefined:
  - "yes"
  - "no"
  description: Remove line breaks?
  defaultValue: "yes"
- name: encoding
  description: Text encoding
  defaultValue: utf-8
- name: hashWordWithSeed
  description: If non-empty hash the words with this seed.
outputs:
- contextPath: WordTokenizeOutput
  description: 'Output text '
  type: string
scripttarget: 0
runonce: true
dockerimage: demisto/nltk:1.0
toversion: 4.5.9
tests:
  - WordTokenizeTest
