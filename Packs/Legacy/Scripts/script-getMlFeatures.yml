commonfields:
  id: getMlFeatures
  version: -1
name: getMlFeatures
script: |+
  #!/usr/bin/env python


  import contextlib as __stickytape_contextlib

  @__stickytape_contextlib.contextmanager
  def __stickytape_temporary_dir():
      import tempfile
      import shutil
      dir_path = tempfile.mkdtemp()
      try:
          yield dir_path
      finally:
          shutil.rmtree(dir_path)

  with __stickytape_temporary_dir() as __stickytape_working_dir:
      def __stickytape_write_module(path, contents):
          import os, os.path, errno

          def make_package(path):
              parts = path.split("/")
              partial_path = __stickytape_working_dir
              for part in parts:
                  partial_path = os.path.join(partial_path, part)
                  if not os.path.exists(partial_path):
                      os.mkdir(partial_path)
                      open(os.path.join(partial_path, "__init__.py"), "w").write("\n")

          make_package(os.path.dirname(path))

          full_path = os.path.join(__stickytape_working_dir, path)
          with open(full_path, "w") as module_file:
              module_file.write(contents)

      import sys as __stickytape_sys
      __stickytape_sys.path.insert(0, __stickytape_working_dir)

      __stickytape_write_module('''duplicate_incidents/consts.py''', '''EDIT_DISTANCE_THRESHOLD = 3\nMAX_STRING_LEN_FOR_EDIT_DISTANCE = 100\n\nMIN_URL_PATH = 2\nIP_SUBNET_BITS = 24\nDOMAIN_LOCAL_SUFFIX_LENGTH = 2\n\nMAX_LEN_FOR_URL = 150\n\nMAX_NEGATIVE_INCIDENTS = 5\n\nEMAIL_RECEIVED_LABEL = \'email/headers/to\'\nEMAIL_SENDER = \'email/from\'\nEMAIL_SUBJECT_LABEL = \'email/subject\'\nEMAIL_DATE_LABEL = \'email/date\'\nEMAIL_TEXT_LABEL = \'email/text\'\nEMAIL_HTML_LABEL = \'email/html\'\nEMAIL_ATTACHMENT_LABEL = \'email/attachments\'\n\nBRAND_LABEL = \'Brand\'\nINSTANCE_LABEL = \'Instance\'\n\nDUPLICATE_COL = "is_duplicate"''')
      __stickytape_write_module('''duplicate_incidents/collect_features/__init__.py''', '''''')
      __stickytape_write_module('''libs/__init__.py''', '''''')
      __stickytape_write_module('''libs/ipaddress.py''', '''# Copyright 2007 Google Inc.\n#  Licensed to PSF under a Contributor Agreement.\n\n"""A fast, lightweight IPv4/IPv6 manipulation library in Python.\n\nThis library is used to create/poke/manipulate IPv4 and IPv6 addresses\nand networks.\n\n"""\n\nfrom __future__ import unicode_literals\n\n\nimport itertools\nimport struct\n\n__version__ = \'1.0.18\'\n\n# Compatibility functions\n_compat_int_types = (int,)\ntry:\n    _compat_int_types = (int, long)\nexcept NameError:\n    pass\ntry:\n    _compat_str = unicode\nexcept NameError:\n    _compat_str = str\n    assert bytes != str\nif b\'\\0\'[0] == 0:  # Python 3 semantics\n    def _compat_bytes_to_byte_vals(byt):\n        return byt\nelse:\n    def _compat_bytes_to_byte_vals(byt):\n        return [struct.unpack(b\'!B\', b)[0] for b in byt]\ntry:\n    _compat_int_from_byte_vals = int.from_bytes\nexcept AttributeError:\n    def _compat_int_from_byte_vals(bytvals, endianess):\n        assert endianess == \'big\'\n        res = 0\n        for bv in bytvals:\n            assert isinstance(bv, _compat_int_types)\n            res = (res << 8) + bv\n        return res\n\n\ndef _compat_to_bytes(intval, length, endianess):\n    assert isinstance(intval, _compat_int_types)\n    assert endianess == \'big\'\n    if length == 4:\n        if intval < 0 or intval >= 2 ** 32:\n            raise struct.error("integer out of range for \'I\' format code")\n        return struct.pack(b\'!I\', intval)\n    elif length == 16:\n        if intval < 0 or intval >= 2 ** 128:\n            raise struct.error("integer out of range for \'QQ\' format code")\n        return struct.pack(b\'!QQ\', intval >> 64, intval & 0xffffffffffffffff)\n    else:\n        raise NotImplementedError()\n\n\nif hasattr(int, \'bit_length\'):\n    # Not int.bit_length , since that won\'t work in 2.7 where long exists\n    def _compat_bit_length(i):\n        return i.bit_length()\nelse:\n    def _compat_bit_length(i):\n        for res in itertools.count():\n            if i >> res == 0:\n                return res\n\n\ndef _compat_range(start, end, step=1):\n    assert step > 0\n    i = start\n    while i < end:\n        yield i\n        i += step\n\n\nclass _TotalOrderingMixin(object):\n    __slots__ = ()\n\n    # Helper that derives the other comparison operations from\n    # __lt__ and __eq__\n    # We avoid functools.total_ordering because it doesn\'t handle\n    # NotImplemented correctly yet (http://bugs.python.org/issue10042)\n    def __eq__(self, other):\n        raise NotImplementedError\n\n    def __ne__(self, other):\n        equal = self.__eq__(other)\n        if equal is NotImplemented:\n            return NotImplemented\n        return not equal\n\n    def __lt__(self, other):\n        raise NotImplementedError\n\n    def __le__(self, other):\n        less = self.__lt__(other)\n        if less is NotImplemented or not less:\n            return self.__eq__(other)\n        return less\n\n    def __gt__(self, other):\n        less = self.__lt__(other)\n        if less is NotImplemented:\n            return NotImplemented\n        equal = self.__eq__(other)\n        if equal is NotImplemented:\n            return NotImplemented\n        return not (less or equal)\n\n    def __ge__(self, other):\n        less = self.__lt__(other)\n        if less is NotImplemented:\n            return NotImplemented\n        return not less\n\n\nIPV4LENGTH = 32\nIPV6LENGTH = 128\n\n\nclass AddressValueError(ValueError):\n    """A Value Error related to the address."""\n\n\nclass NetmaskValueError(ValueError):\n    """A Value Error related to the netmask."""\n\n\ndef ip_address(address):\n    """Take an IP string/int and return an object of the correct type.\n\n    Args:\n        address: A string or integer, the IP address.  Either IPv4 or\n          IPv6 addresses may be supplied; integers less than 2**32 will\n          be considered to be IPv4 by default.\n\n    Returns:\n        An IPv4Address or IPv6Address object.\n\n    Raises:\n        ValueError: if the *address* passed isn\'t either a v4 or a v6\n          address\n\n    """\n    try:\n        return IPv4Address(address)\n    except (AddressValueError, NetmaskValueError):\n        pass\n\n    try:\n        return IPv6Address(address)\n    except (AddressValueError, NetmaskValueError):\n        pass\n\n    if isinstance(address, bytes):\n        raise AddressValueError(\n            \'%r does not appear to be an IPv4 or IPv6 address. \'\n            \'Did you pass in a bytes (str in Python 2) instead of\'\n            \' a unicode object?\' % address)\n\n    raise ValueError(\'%r does not appear to be an IPv4 or IPv6 address\' %\n                     address)\n\n\ndef ip_network(address, strict=True):\n    """Take an IP string/int and return an object of the correct type.\n\n    Args:\n        address: A string or integer, the IP network.  Either IPv4 or\n          IPv6 networks may be supplied; integers less than 2**32 will\n          be considered to be IPv4 by default.\n\n    Returns:\n        An IPv4Network or IPv6Network object.\n\n    Raises:\n        ValueError: if the string passed isn\'t either a v4 or a v6\n          address. Or if the network has host bits set.\n\n    """\n    try:\n        return IPv4Network(address, strict)\n    except (AddressValueError, NetmaskValueError):\n        pass\n\n    try:\n        return IPv6Network(address, strict)\n    except (AddressValueError, NetmaskValueError):\n        pass\n\n    if isinstance(address, bytes):\n        raise AddressValueError(\n            \'%r does not appear to be an IPv4 or IPv6 network. \'\n            \'Did you pass in a bytes (str in Python 2) instead of\'\n            \' a unicode object?\' % address)\n\n    raise ValueError(\'%r does not appear to be an IPv4 or IPv6 network\' %\n                     address)\n\n\ndef ip_interface(address):\n    """Take an IP string/int and return an object of the correct type.\n\n    Args:\n        address: A string or integer, the IP address.  Either IPv4 or\n          IPv6 addresses may be supplied; integers less than 2**32 will\n          be considered to be IPv4 by default.\n\n    Returns:\n        An IPv4Interface or IPv6Interface object.\n\n    Raises:\n        ValueError: if the string passed isn\'t either a v4 or a v6\n          address.\n\n    Notes:\n        The IPv?Interface classes describe an Address on a particular\n        Network, so they\'re basically a combination of both the Address\n        and Network classes.\n\n    """\n    try:\n        return IPv4Interface(address)\n    except (AddressValueError, NetmaskValueError):\n        pass\n\n    try:\n        return IPv6Interface(address)\n    except (AddressValueError, NetmaskValueError):\n        pass\n\n    raise ValueError(\'%r does not appear to be an IPv4 or IPv6 interface\' %\n                     address)\n\n\ndef v4_int_to_packed(address):\n    """Represent an address as 4 packed bytes in network (big-endian) order.\n\n    Args:\n        address: An integer representation of an IPv4 IP address.\n\n    Returns:\n        The integer address packed as 4 bytes in network (big-endian) order.\n\n    Raises:\n        ValueError: If the integer is negative or too large to be an\n          IPv4 IP address.\n\n    """\n    try:\n        return _compat_to_bytes(address, 4, \'big\')\n    except (struct.error, OverflowError):\n        raise ValueError("Address negative or too large for IPv4")\n\n\ndef v6_int_to_packed(address):\n    """Represent an address as 16 packed bytes in network (big-endian) order.\n\n    Args:\n        address: An integer representation of an IPv6 IP address.\n\n    Returns:\n        The integer address packed as 16 bytes in network (big-endian) order.\n\n    """\n    try:\n        return _compat_to_bytes(address, 16, \'big\')\n    except (struct.error, OverflowError):\n        raise ValueError("Address negative or too large for IPv6")\n\n\ndef _split_optional_netmask(address):\n    """Helper to split the netmask and raise AddressValueError if needed"""\n    addr = _compat_str(address).split(\'/\')\n    if len(addr) > 2:\n        raise AddressValueError("Only one \'/\' permitted in %r" % address)\n    return addr\n\n\ndef _find_address_range(addresses):\n    """Find a sequence of sorted deduplicated IPv#Address.\n\n    Args:\n        addresses: a list of IPv#Address objects.\n\n    Yields:\n        A tuple containing the first and last IP addresses in the sequence.\n\n    """\n    it = iter(addresses)\n    first = last = next(it)\n    for ip in it:\n        if ip._ip != last._ip + 1:\n            yield first, last\n            first = ip\n        last = ip\n    yield first, last\n\n\ndef _count_righthand_zero_bits(number, bits):\n    """Count the number of zero bits on the right hand side.\n\n    Args:\n        number: an integer.\n        bits: maximum number of bits to count.\n\n    Returns:\n        The number of zero bits on the right hand side of the number.\n\n    """\n    if number == 0:\n        return bits\n    return min(bits, _compat_bit_length(~number & (number - 1)))\n\n\ndef summarize_address_range(first, last):\n    """Summarize a network range given the first and last IP addresses.\n\n    Example:\n        >>> list(summarize_address_range(IPv4Address(\'192.0.2.0\'),\n        ...                              IPv4Address(\'192.0.2.130\')))\n        ...                                #doctest: +NORMALIZE_WHITESPACE\n        [IPv4Network(\'192.0.2.0/25\'), IPv4Network(\'192.0.2.128/31\'),\n         IPv4Network(\'192.0.2.130/32\')]\n\n    Args:\n        first: the first IPv4Address or IPv6Address in the range.\n        last: the last IPv4Address or IPv6Address in the range.\n\n    Returns:\n        An iterator of the summarized IPv(4|6) network objects.\n\n    Raise:\n        TypeError:\n            If the first and last objects are not IP addresses.\n            If the first and last objects are not the same version.\n        ValueError:\n            If the last object is not greater than the first.\n            If the version of the first address is not 4 or 6.\n\n    """\n    if (not (isinstance(first, _BaseAddress) and\n             isinstance(last, _BaseAddress))):\n        raise TypeError(\'first and last must be IP addresses, not networks\')\n    if first.version != last.version:\n        raise TypeError("%s and %s are not of the same version" % (\n                        first, last))\n    if first > last:\n        raise ValueError(\'last IP address must be greater than first\')\n\n    if first.version == 4:\n        ip = IPv4Network\n    elif first.version == 6:\n        ip = IPv6Network\n    else:\n        raise ValueError(\'unknown IP version\')\n\n    ip_bits = first._max_prefixlen\n    first_int = first._ip\n    last_int = last._ip\n    while first_int <= last_int:\n        nbits = min(_count_righthand_zero_bits(first_int, ip_bits),\n                    _compat_bit_length(last_int - first_int + 1) - 1)\n        net = ip((first_int, ip_bits - nbits))\n        yield net\n        first_int += 1 << nbits\n        if first_int - 1 == ip._ALL_ONES:\n            break\n\n\ndef _collapse_addresses_internal(addresses):\n    """Loops through the addresses, collapsing concurrent netblocks.\n\n    Example:\n\n        ip1 = IPv4Network(\'192.0.2.0/26\')\n        ip2 = IPv4Network(\'192.0.2.64/26\')\n        ip3 = IPv4Network(\'192.0.2.128/26\')\n        ip4 = IPv4Network(\'192.0.2.192/26\')\n\n        _collapse_addresses_internal([ip1, ip2, ip3, ip4]) ->\n          [IPv4Network(\'192.0.2.0/24\')]\n\n        This shouldn\'t be called directly; it is called via\n          collapse_addresses([]).\n\n    Args:\n        addresses: A list of IPv4Network\'s or IPv6Network\'s\n\n    Returns:\n        A list of IPv4Network\'s or IPv6Network\'s depending on what we were\n        passed.\n\n    """\n    # First merge\n    to_merge = list(addresses)\n    subnets = {}\n    while to_merge:\n        net = to_merge.pop()\n        supernet = net.supernet()\n        existing = subnets.get(supernet)\n        if existing is None:\n            subnets[supernet] = net\n        elif existing != net:\n            # Merge consecutive subnets\n            del subnets[supernet]\n            to_merge.append(supernet)\n    # Then iterate over resulting networks, skipping subsumed subnets\n    last = None\n    for net in sorted(subnets.values()):\n        if last is not None:\n            # Since they are sorted,\n            # last.network_address <= net.network_address is a given.\n            if last.broadcast_address >= net.broadcast_address:\n                continue\n        yield net\n        last = net\n\n\ndef collapse_addresses(addresses):\n    """Collapse a list of IP objects.\n\n    Example:\n        collapse_addresses([IPv4Network(\'192.0.2.0/25\'),\n                            IPv4Network(\'192.0.2.128/25\')]) ->\n                           [IPv4Network(\'192.0.2.0/24\')]\n\n    Args:\n        addresses: An iterator of IPv4Network or IPv6Network objects.\n\n    Returns:\n        An iterator of the collapsed IPv(4|6)Network objects.\n\n    Raises:\n        TypeError: If passed a list of mixed version objects.\n\n    """\n    addrs = []\n    ips = []\n    nets = []\n\n    # split IP addresses and networks\n    for ip in addresses:\n        if isinstance(ip, _BaseAddress):\n            if ips and ips[-1]._version != ip._version:\n                raise TypeError("%s and %s are not of the same version" % (\n                                ip, ips[-1]))\n            ips.append(ip)\n        elif ip._prefixlen == ip._max_prefixlen:\n            if ips and ips[-1]._version != ip._version:\n                raise TypeError("%s and %s are not of the same version" % (\n                                ip, ips[-1]))\n            try:\n                ips.append(ip.ip)\n            except AttributeError:\n                ips.append(ip.network_address)\n        else:\n            if nets and nets[-1]._version != ip._version:\n                raise TypeError("%s and %s are not of the same version" % (\n                                ip, nets[-1]))\n            nets.append(ip)\n\n    # sort and dedup\n    ips = sorted(set(ips))\n\n    # find consecutive address ranges in the sorted sequence and summarize them\n    if ips:\n        for first, last in _find_address_range(ips):\n            addrs.extend(summarize_address_range(first, last))\n\n    return _collapse_addresses_internal(addrs + nets)\n\n\ndef get_mixed_type_key(obj):\n    """Return a key suitable for sorting between networks and addresses.\n\n    Address and Network objects are not sortable by default; they\'re\n    fundamentally different so the expression\n\n        IPv4Address(\'192.0.2.0\') <= IPv4Network(\'192.0.2.0/24\')\n\n    doesn\'t make any sense.  There are some times however, where you may wish\n    to have ipaddress sort these for you anyway. If you need to do this, you\n    can use this function as the key= argument to sorted().\n\n    Args:\n      obj: either a Network or Address object.\n    Returns:\n      appropriate key.\n\n    """\n    if isinstance(obj, _BaseNetwork):\n        return obj._get_networks_key()\n    elif isinstance(obj, _BaseAddress):\n        return obj._get_address_key()\n    return NotImplemented\n\n\nclass _IPAddressBase(_TotalOrderingMixin):\n\n    """The mother class."""\n\n    __slots__ = ()\n\n    @property\n    def exploded(self):\n        """Return the longhand version of the IP address as a string."""\n        return self._explode_shorthand_ip_string()\n\n    @property\n    def compressed(self):\n        """Return the shorthand version of the IP address as a string."""\n        return _compat_str(self)\n\n    @property\n    def reverse_pointer(self):\n        """The name of the reverse DNS pointer for the IP address, e.g.:\n            >>> ipaddress.ip_address("127.0.0.1").reverse_pointer\n            \'1.0.0.127.in-addr.arpa\'\n            >>> ipaddress.ip_address("2001:db8::1").reverse_pointer\n            \'1.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.8.b.d.0.1.0.0.2.ip6.arpa\'\n\n        """\n        return self._reverse_pointer()\n\n    @property\n    def version(self):\n        msg = \'%200s has no version specified\' % (type(self),)\n        raise NotImplementedError(msg)\n\n    def _check_int_address(self, address):\n        if address < 0:\n            msg = "%d (< 0) is not permitted as an IPv%d address"\n            raise AddressValueError(msg % (address, self._version))\n        if address > self._ALL_ONES:\n            msg = "%d (>= 2**%d) is not permitted as an IPv%d address"\n            raise AddressValueError(msg % (address, self._max_prefixlen,\n                                           self._version))\n\n    def _check_packed_address(self, address, expected_len):\n        address_len = len(address)\n        if address_len != expected_len:\n            msg = (\n                \'%r (len %d != %d) is not permitted as an IPv%d address. \'\n                \'Did you pass in a bytes (str in Python 2) instead of\'\n                \' a unicode object?\')\n            raise AddressValueError(msg % (address, address_len,\n                                           expected_len, self._version))\n\n    @classmethod\n    def _ip_int_from_prefix(cls, prefixlen):\n        """Turn the prefix length into a bitwise netmask\n\n        Args:\n            prefixlen: An integer, the prefix length.\n\n        Returns:\n            An integer.\n\n        """\n        return cls._ALL_ONES ^ (cls._ALL_ONES >> prefixlen)\n\n    @classmethod\n    def _prefix_from_ip_int(cls, ip_int):\n        """Return prefix length from the bitwise netmask.\n\n        Args:\n            ip_int: An integer, the netmask in expanded bitwise format\n\n        Returns:\n            An integer, the prefix length.\n\n        Raises:\n            ValueError: If the input intermingles zeroes & ones\n        """\n        trailing_zeroes = _count_righthand_zero_bits(ip_int,\n                                                     cls._max_prefixlen)\n        prefixlen = cls._max_prefixlen - trailing_zeroes\n        leading_ones = ip_int >> trailing_zeroes\n        all_ones = (1 << prefixlen) - 1\n        if leading_ones != all_ones:\n            byteslen = cls._max_prefixlen // 8\n            details = _compat_to_bytes(ip_int, byteslen, \'big\')\n            msg = \'Netmask pattern %r mixes zeroes & ones\'\n            raise ValueError(msg % details)\n        return prefixlen\n\n    @classmethod\n    def _report_invalid_netmask(cls, netmask_str):\n        msg = \'%r is not a valid netmask\' % netmask_str\n        raise NetmaskValueError(msg)\n\n    @classmethod\n    def _prefix_from_prefix_string(cls, prefixlen_str):\n        """Return prefix length from a numeric string\n\n        Args:\n            prefixlen_str: The string to be converted\n\n        Returns:\n            An integer, the prefix length.\n\n        Raises:\n            NetmaskValueError: If the input is not a valid netmask\n        """\n        # int allows a leading +/- as well as surrounding whitespace,\n        # so we ensure that isn\'t the case\n        if not _BaseV4._DECIMAL_DIGITS.issuperset(prefixlen_str):\n            cls._report_invalid_netmask(prefixlen_str)\n        try:\n            prefixlen = int(prefixlen_str)\n        except ValueError:\n            cls._report_invalid_netmask(prefixlen_str)\n        if not (0 <= prefixlen <= cls._max_prefixlen):\n            cls._report_invalid_netmask(prefixlen_str)\n        return prefixlen\n\n    @classmethod\n    def _prefix_from_ip_string(cls, ip_str):\n        """Turn a netmask/hostmask string into a prefix length\n\n        Args:\n            ip_str: The netmask/hostmask to be converted\n\n        Returns:\n            An integer, the prefix length.\n\n        Raises:\n            NetmaskValueError: If the input is not a valid netmask/hostmask\n        """\n        # Parse the netmask/hostmask like an IP address.\n        try:\n            ip_int = cls._ip_int_from_string(ip_str)\n        except AddressValueError:\n            cls._report_invalid_netmask(ip_str)\n\n        # Try matching a netmask (this would be /1*0*/ as a bitwise regexp).\n        # Note that the two ambiguous cases (all-ones and all-zeroes) are\n        # treated as netmasks.\n        try:\n            return cls._prefix_from_ip_int(ip_int)\n        except ValueError:\n            pass\n\n        # Invert the bits, and try matching a /0+1+/ hostmask instead.\n        ip_int ^= cls._ALL_ONES\n        try:\n            return cls._prefix_from_ip_int(ip_int)\n        except ValueError:\n            cls._report_invalid_netmask(ip_str)\n\n    def __reduce__(self):\n        return self.__class__, (_compat_str(self),)\n\n\nclass _BaseAddress(_IPAddressBase):\n\n    """A generic IP object.\n\n    This IP class contains the version independent methods which are\n    used by single IP addresses.\n    """\n\n    __slots__ = ()\n\n    def __int__(self):\n        return self._ip\n\n    def __eq__(self, other):\n        try:\n            return (self._ip == other._ip and\n                    self._version == other._version)\n        except AttributeError:\n            return NotImplemented\n\n    def __lt__(self, other):\n        if not isinstance(other, _IPAddressBase):\n            return NotImplemented\n        if not isinstance(other, _BaseAddress):\n            raise TypeError(\'%s and %s are not of the same type\' % (\n                self, other))\n        if self._version != other._version:\n            raise TypeError(\'%s and %s are not of the same version\' % (\n                self, other))\n        if self._ip != other._ip:\n            return self._ip < other._ip\n        return False\n\n    # Shorthand for Integer addition and subtraction. This is not\n    # meant to ever support addition/subtraction of addresses.\n    def __add__(self, other):\n        if not isinstance(other, _compat_int_types):\n            return NotImplemented\n        return self.__class__(int(self) + other)\n\n    def __sub__(self, other):\n        if not isinstance(other, _compat_int_types):\n            return NotImplemented\n        return self.__class__(int(self) - other)\n\n    def __repr__(self):\n        return \'%s(%r)\' % (self.__class__.__name__, _compat_str(self))\n\n    def __str__(self):\n        return _compat_str(self._string_from_ip_int(self._ip))\n\n    def __hash__(self):\n        return hash(hex(int(self._ip)))\n\n    def _get_address_key(self):\n        return (self._version, self)\n\n    def __reduce__(self):\n        return self.__class__, (self._ip,)\n\n\nclass _BaseNetwork(_IPAddressBase):\n\n    """A generic IP network object.\n\n    This IP class contains the version independent methods which are\n    used by networks.\n\n    """\n    def __init__(self, address):\n        self._cache = {}\n\n    def __repr__(self):\n        return \'%s(%r)\' % (self.__class__.__name__, _compat_str(self))\n\n    def __str__(self):\n        return \'%s/%d\' % (self.network_address, self.prefixlen)\n\n    def hosts(self):\n        """Generate Iterator over usable hosts in a network.\n\n        This is like __iter__ except it doesn\'t return the network\n        or broadcast addresses.\n\n        """\n        network = int(self.network_address)\n        broadcast = int(self.broadcast_address)\n        for x in _compat_range(network + 1, broadcast):\n            yield self._address_class(x)\n\n    def __iter__(self):\n        network = int(self.network_address)\n        broadcast = int(self.broadcast_address)\n        for x in _compat_range(network, broadcast + 1):\n            yield self._address_class(x)\n\n    def __getitem__(self, n):\n        network = int(self.network_address)\n        broadcast = int(self.broadcast_address)\n        if n >= 0:\n            if network + n > broadcast:\n                raise IndexError(\'address out of range\')\n            return self._address_class(network + n)\n        else:\n            n += 1\n            if broadcast + n < network:\n                raise IndexError(\'address out of range\')\n            return self._address_class(broadcast + n)\n\n    def __lt__(self, other):\n        if not isinstance(other, _IPAddressBase):\n            return NotImplemented\n        if not isinstance(other, _BaseNetwork):\n            raise TypeError(\'%s and %s are not of the same type\' % (\n                            self, other))\n        if self._version != other._version:\n            raise TypeError(\'%s and %s are not of the same version\' % (\n                            self, other))\n        if self.network_address != other.network_address:\n            return self.network_address < other.network_address\n        if self.netmask != other.netmask:\n            return self.netmask < other.netmask\n        return False\n\n    def __eq__(self, other):\n        try:\n            return (self._version == other._version and\n                    self.network_address == other.network_address and\n                    int(self.netmask) == int(other.netmask))\n        except AttributeError:\n            return NotImplemented\n\n    def __hash__(self):\n        return hash(int(self.network_address) ^ int(self.netmask))\n\n    def __contains__(self, other):\n        # always false if one is v4 and the other is v6.\n        if self._version != other._version:\n            return False\n        # dealing with another network.\n        if isinstance(other, _BaseNetwork):\n            return False\n        # dealing with another address\n        else:\n            # address\n            return (int(self.network_address) <= int(other._ip) <=\n                    int(self.broadcast_address))\n\n    def overlaps(self, other):\n        """Tell if self is partly contained in other."""\n        return self.network_address in other or (\n            self.broadcast_address in other or (\n                other.network_address in self or (\n                    other.broadcast_address in self)))\n\n    @property\n    def broadcast_address(self):\n        x = self._cache.get(\'broadcast_address\')\n        if x is None:\n            x = self._address_class(int(self.network_address) |\n                                    int(self.hostmask))\n            self._cache[\'broadcast_address\'] = x\n        return x\n\n    @property\n    def hostmask(self):\n        x = self._cache.get(\'hostmask\')\n        if x is None:\n            x = self._address_class(int(self.netmask) ^ self._ALL_ONES)\n            self._cache[\'hostmask\'] = x\n        return x\n\n    @property\n    def with_prefixlen(self):\n        return \'%s/%d\' % (self.network_address, self._prefixlen)\n\n    @property\n    def with_netmask(self):\n        return \'%s/%s\' % (self.network_address, self.netmask)\n\n    @property\n    def with_hostmask(self):\n        return \'%s/%s\' % (self.network_address, self.hostmask)\n\n    @property\n    def num_addresses(self):\n        """Number of hosts in the current subnet."""\n        return int(self.broadcast_address) - int(self.network_address) + 1\n\n    @property\n    def _address_class(self):\n        # Returning bare address objects (rather than interfaces) allows for\n        # more consistent behaviour across the network address, broadcast\n        # address and individual host addresses.\n        msg = \'%200s has no associated address class\' % (type(self),)\n        raise NotImplementedError(msg)\n\n    @property\n    def prefixlen(self):\n        return self._prefixlen\n\n    def address_exclude(self, other):\n        """Remove an address from a larger block.\n\n        For example:\n\n            addr1 = ip_network(\'192.0.2.0/28\')\n            addr2 = ip_network(\'192.0.2.1/32\')\n            list(addr1.address_exclude(addr2)) =\n                [IPv4Network(\'192.0.2.0/32\'), IPv4Network(\'192.0.2.2/31\'),\n                 IPv4Network(\'192.0.2.4/30\'), IPv4Network(\'192.0.2.8/29\')]\n\n        or IPv6:\n\n            addr1 = ip_network(\'2001:db8::1/32\')\n            addr2 = ip_network(\'2001:db8::1/128\')\n            list(addr1.address_exclude(addr2)) =\n                [ip_network(\'2001:db8::1/128\'),\n                 ip_network(\'2001:db8::2/127\'),\n                 ip_network(\'2001:db8::4/126\'),\n                 ip_network(\'2001:db8::8/125\'),\n                 ...\n                 ip_network(\'2001:db8:8000::/33\')]\n\n        Args:\n            other: An IPv4Network or IPv6Network object of the same type.\n\n        Returns:\n            An iterator of the IPv(4|6)Network objects which is self\n            minus other.\n\n        Raises:\n            TypeError: If self and other are of differing address\n              versions, or if other is not a network object.\n            ValueError: If other is not completely contained by self.\n\n        """\n        if not self._version == other._version:\n            raise TypeError("%s and %s are not of the same version" % (\n                            self, other))\n\n        if not isinstance(other, _BaseNetwork):\n            raise TypeError("%s is not a network object" % other)\n\n        if not other.subnet_of(self):\n            raise ValueError(\'%s not contained in %s\' % (other, self))\n        if other == self:\n            return\n\n        # Make sure we\'re comparing the network of other.\n        other = other.__class__(\'%s/%s\' % (other.network_address,\n                                           other.prefixlen))\n\n        s1, s2 = self.subnets()\n        while s1 != other and s2 != other:\n            if other.subnet_of(s1):\n                yield s2\n                s1, s2 = s1.subnets()\n            elif other.subnet_of(s2):\n                yield s1\n                s1, s2 = s2.subnets()\n            else:\n                # If we got here, there\'s a bug somewhere.\n                raise AssertionError(\'Error performing exclusion: \'\n                                     \'s1: %s s2: %s other: %s\' %\n                                     (s1, s2, other))\n        if s1 == other:\n            yield s2\n        elif s2 == other:\n            yield s1\n        else:\n            # If we got here, there\'s a bug somewhere.\n            raise AssertionError(\'Error performing exclusion: \'\n                                 \'s1: %s s2: %s other: %s\' %\n                                 (s1, s2, other))\n\n    def compare_networks(self, other):\n        """Compare two IP objects.\n\n        This is only concerned about the comparison of the integer\n        representation of the network addresses.  This means that the\n        host bits aren\'t considered at all in this method.  If you want\n        to compare host bits, you can easily enough do a\n        \'HostA._ip < HostB._ip\'\n\n        Args:\n            other: An IP object.\n\n        Returns:\n            If the IP versions of self and other are the same, returns:\n\n            -1 if self < other:\n              eg: IPv4Network(\'192.0.2.0/25\') < IPv4Network(\'192.0.2.128/25\')\n              IPv6Network(\'2001:db8::1000/124\') <\n                  IPv6Network(\'2001:db8::2000/124\')\n            0 if self == other\n              eg: IPv4Network(\'192.0.2.0/24\') == IPv4Network(\'192.0.2.0/24\')\n              IPv6Network(\'2001:db8::1000/124\') ==\n                  IPv6Network(\'2001:db8::1000/124\')\n            1 if self > other\n              eg: IPv4Network(\'192.0.2.128/25\') > IPv4Network(\'192.0.2.0/25\')\n                  IPv6Network(\'2001:db8::2000/124\') >\n                      IPv6Network(\'2001:db8::1000/124\')\n\n          Raises:\n              TypeError if the IP versions are different.\n\n        """\n        # does this need to raise a ValueError?\n        if self._version != other._version:\n            raise TypeError(\'%s and %s are not of the same type\' % (\n                            self, other))\n        # self._version == other._version below here:\n        if self.network_address < other.network_address:\n            return -1\n        if self.network_address > other.network_address:\n            return 1\n        # self.network_address == other.network_address below here:\n        if self.netmask < other.netmask:\n            return -1\n        if self.netmask > other.netmask:\n            return 1\n        return 0\n\n    def _get_networks_key(self):\n        """Network-only key function.\n\n        Returns an object that identifies this address\' network and\n        netmask. This function is a suitable "key" argument for sorted()\n        and list.sort().\n\n        """\n        return (self._version, self.network_address, self.netmask)\n\n    def subnets(self, prefixlen_diff=1, new_prefix=None):\n        """The subnets which join to make the current subnet.\n\n        In the case that self contains only one IP\n        (self._prefixlen == 32 for IPv4 or self._prefixlen == 128\n        for IPv6), yield an iterator with just ourself.\n\n        Args:\n            prefixlen_diff: An integer, the amount the prefix length\n              should be increased by. This should not be set if\n              new_prefix is also set.\n            new_prefix: The desired new prefix length. This must be a\n              larger number (smaller prefix) than the existing prefix.\n              This should not be set if prefixlen_diff is also set.\n\n        Returns:\n            An iterator of IPv(4|6) objects.\n\n        Raises:\n            ValueError: The prefixlen_diff is too small or too large.\n                OR\n            prefixlen_diff and new_prefix are both set or new_prefix\n              is a smaller number than the current prefix (smaller\n              number means a larger network)\n\n        """\n        if self._prefixlen == self._max_prefixlen:\n            yield self\n            return\n\n        if new_prefix is not None:\n            if new_prefix < self._prefixlen:\n                raise ValueError(\'new prefix must be longer\')\n            if prefixlen_diff != 1:\n                raise ValueError(\'cannot set prefixlen_diff and new_prefix\')\n            prefixlen_diff = new_prefix - self._prefixlen\n\n        if prefixlen_diff < 0:\n            raise ValueError(\'prefix length diff must be > 0\')\n        new_prefixlen = self._prefixlen + prefixlen_diff\n\n        if new_prefixlen > self._max_prefixlen:\n            raise ValueError(\n                \'prefix length diff %d is invalid for netblock %s\' % (\n                    new_prefixlen, self))\n\n        start = int(self.network_address)\n        end = int(self.broadcast_address) + 1\n        step = (int(self.hostmask) + 1) >> prefixlen_diff\n        for new_addr in _compat_range(start, end, step):\n            current = self.__class__((new_addr, new_prefixlen))\n            yield current\n\n    def supernet(self, prefixlen_diff=1, new_prefix=None):\n        """The supernet containing the current network.\n\n        Args:\n            prefixlen_diff: An integer, the amount the prefix length of\n              the network should be decreased by.  For example, given a\n              /24 network and a prefixlen_diff of 3, a supernet with a\n              /21 netmask is returned.\n\n        Returns:\n            An IPv4 network object.\n\n        Raises:\n            ValueError: If self.prefixlen - prefixlen_diff < 0. I.e., you have\n              a negative prefix length.\n                OR\n            If prefixlen_diff and new_prefix are both set or new_prefix is a\n              larger number than the current prefix (larger number means a\n              smaller network)\n\n        """\n        if self._prefixlen == 0:\n            return self\n\n        if new_prefix is not None:\n            if new_prefix > self._prefixlen:\n                raise ValueError(\'new prefix must be shorter\')\n            if prefixlen_diff != 1:\n                raise ValueError(\'cannot set prefixlen_diff and new_prefix\')\n            prefixlen_diff = self._prefixlen - new_prefix\n\n        new_prefixlen = self.prefixlen - prefixlen_diff\n        if new_prefixlen < 0:\n            raise ValueError(\n                \'current prefixlen is %d, cannot have a prefixlen_diff of %d\' %\n                (self.prefixlen, prefixlen_diff))\n        return self.__class__((\n            int(self.network_address) & (int(self.netmask) << prefixlen_diff),\n            new_prefixlen))\n\n    @property\n    def is_multicast(self):\n        """Test if the address is reserved for multicast use.\n\n        Returns:\n            A boolean, True if the address is a multicast address.\n            See RFC 2373 2.7 for details.\n\n        """\n        return (self.network_address.is_multicast and\n                self.broadcast_address.is_multicast)\n\n    def subnet_of(self, other):\n        # always false if one is v4 and the other is v6.\n        if self._version != other._version:\n            return False\n        # dealing with another network.\n        if (hasattr(other, \'network_address\') and\n                hasattr(other, \'broadcast_address\')):\n            return (other.network_address <= self.network_address and\n                    other.broadcast_address >= self.broadcast_address)\n        # dealing with another address\n        else:\n            raise TypeError(\'Unable to test subnet containment with element \'\n                            \'of type %s\' % type(other))\n\n    def supernet_of(self, other):\n        # always false if one is v4 and the other is v6.\n        if self._version != other._version:\n            return False\n        # dealing with another network.\n        if (hasattr(other, \'network_address\') and\n                hasattr(other, \'broadcast_address\')):\n            return (other.network_address >= self.network_address and\n                    other.broadcast_address <= self.broadcast_address)\n        # dealing with another address\n        else:\n            raise TypeError(\'Unable to test subnet containment with element \'\n                            \'of type %s\' % type(other))\n\n    @property\n    def is_reserved(self):\n        """Test if the address is otherwise IETF reserved.\n\n        Returns:\n            A boolean, True if the address is within one of the\n            reserved IPv6 Network ranges.\n\n        """\n        return (self.network_address.is_reserved and\n                self.broadcast_address.is_reserved)\n\n    @property\n    def is_link_local(self):\n        """Test if the address is reserved for link-local.\n\n        Returns:\n            A boolean, True if the address is reserved per RFC 4291.\n\n        """\n        return (self.network_address.is_link_local and\n                self.broadcast_address.is_link_local)\n\n    @property\n    def is_private(self):\n        """Test if this address is allocated for private networks.\n\n        Returns:\n            A boolean, True if the address is reserved per\n            iana-ipv4-special-registry or iana-ipv6-special-registry.\n\n        """\n        return (self.network_address.is_private and\n                self.broadcast_address.is_private)\n\n    @property\n    def is_global(self):\n        """Test if this address is allocated for public networks.\n\n        Returns:\n            A boolean, True if the address is not reserved per\n            iana-ipv4-special-registry or iana-ipv6-special-registry.\n\n        """\n        return not self.is_private\n\n    @property\n    def is_unspecified(self):\n        """Test if the address is unspecified.\n\n        Returns:\n            A boolean, True if this is the unspecified address as defined in\n            RFC 2373 2.5.2.\n\n        """\n        return (self.network_address.is_unspecified and\n                self.broadcast_address.is_unspecified)\n\n    @property\n    def is_loopback(self):\n        """Test if the address is a loopback address.\n\n        Returns:\n            A boolean, True if the address is a loopback address as defined in\n            RFC 2373 2.5.3.\n\n        """\n        return (self.network_address.is_loopback and\n                self.broadcast_address.is_loopback)\n\n\nclass _BaseV4(object):\n\n    """Base IPv4 object.\n\n    The following methods are used by IPv4 objects in both single IP\n    addresses and networks.\n\n    """\n\n    __slots__ = ()\n    _version = 4\n    # Equivalent to 255.255.255.255 or 32 bits of 1\'s.\n    _ALL_ONES = (2 ** IPV4LENGTH) - 1\n    _DECIMAL_DIGITS = frozenset(\'0123456789\')\n\n    # the valid octets for host and netmasks. only useful for IPv4.\n    _valid_mask_octets = frozenset([255, 254, 252, 248, 240, 224, 192, 128, 0])\n\n    _max_prefixlen = IPV4LENGTH\n    # There are only a handful of valid v4 netmasks, so we cache them all\n    # when constructed (see _make_netmask()).\n    _netmask_cache = {}\n\n    def _explode_shorthand_ip_string(self):\n        return _compat_str(self)\n\n    @classmethod\n    def _make_netmask(cls, arg):\n        """Make a (netmask, prefix_len) tuple from the given argument.\n\n        Argument can be:\n        - an integer (the prefix length)\n        - a string representing the prefix length (e.g. "24")\n        - a string representing the prefix netmask (e.g. "255.255.255.0")\n        """\n        if arg not in cls._netmask_cache:\n            if isinstance(arg, _compat_int_types):\n                prefixlen = arg\n            else:\n                try:\n                    # Check for a netmask in prefix length form\n                    prefixlen = cls._prefix_from_prefix_string(arg)\n                except NetmaskValueError:\n                    # Check for a netmask or hostmask in dotted-quad form.\n                    # This may raise NetmaskValueError.\n                    prefixlen = cls._prefix_from_ip_string(arg)\n            netmask = IPv4Address(cls._ip_int_from_prefix(prefixlen))\n            cls._netmask_cache[arg] = netmask, prefixlen\n        return cls._netmask_cache[arg]\n\n    @classmethod\n    def _ip_int_from_string(cls, ip_str):\n        """Turn the given IP string into an integer for comparison.\n\n        Args:\n            ip_str: A string, the IP ip_str.\n\n        Returns:\n            The IP ip_str as an integer.\n\n        Raises:\n            AddressValueError: if ip_str isn\'t a valid IPv4 Address.\n\n        """\n        if not ip_str:\n            raise AddressValueError(\'Address cannot be empty\')\n\n        octets = ip_str.split(\'.\')\n        if len(octets) != 4:\n            raise AddressValueError("Expected 4 octets in %r" % ip_str)\n\n        try:\n            return _compat_int_from_byte_vals(\n                map(cls._parse_octet, octets), \'big\')\n        except ValueError as exc:\n            raise AddressValueError("%s in %r" % (exc, ip_str))\n\n    @classmethod\n    def _parse_octet(cls, octet_str):\n        """Convert a decimal octet into an integer.\n\n        Args:\n            octet_str: A string, the number to parse.\n\n        Returns:\n            The octet as an integer.\n\n        Raises:\n            ValueError: if the octet isn\'t strictly a decimal from [0..255].\n\n        """\n        if not octet_str:\n            raise ValueError("Empty octet not permitted")\n        # Whitelist the characters, since int() allows a lot of bizarre stuff.\n        if not cls._DECIMAL_DIGITS.issuperset(octet_str):\n            msg = "Only decimal digits permitted in %r"\n            raise ValueError(msg % octet_str)\n        # We do the length check second, since the invalid character error\n        # is likely to be more informative for the user\n        if len(octet_str) > 3:\n            msg = "At most 3 characters permitted in %r"\n            raise ValueError(msg % octet_str)\n        # Convert to integer (we know digits are legal)\n        octet_int = int(octet_str, 10)\n        # Any octets that look like they *might* be written in octal,\n        # and which don\'t look exactly the same in both octal and\n        # decimal are rejected as ambiguous\n        if octet_int > 7 and octet_str[0] == \'0\':\n            msg = "Ambiguous (octal/decimal) value in %r not permitted"\n            raise ValueError(msg % octet_str)\n        if octet_int > 255:\n            raise ValueError("Octet %d (> 255) not permitted" % octet_int)\n        return octet_int\n\n    @classmethod\n    def _string_from_ip_int(cls, ip_int):\n        """Turns a 32-bit integer into dotted decimal notation.\n\n        Args:\n            ip_int: An integer, the IP address.\n\n        Returns:\n            The IP address as a string in dotted decimal notation.\n\n        """\n        return \'.\'.join(_compat_str(struct.unpack(b\'!B\', b)[0]\n                                    if isinstance(b, bytes)\n                                    else b)\n                        for b in _compat_to_bytes(ip_int, 4, \'big\'))\n\n    def _is_hostmask(self, ip_str):\n        """Test if the IP string is a hostmask (rather than a netmask).\n\n        Args:\n            ip_str: A string, the potential hostmask.\n\n        Returns:\n            A boolean, True if the IP string is a hostmask.\n\n        """\n        bits = ip_str.split(\'.\')\n        try:\n            parts = [x for x in map(int, bits) if x in self._valid_mask_octets]\n        except ValueError:\n            return False\n        if len(parts) != len(bits):\n            return False\n        if parts[0] < parts[-1]:\n            return True\n        return False\n\n    def _reverse_pointer(self):\n        """Return the reverse DNS pointer name for the IPv4 address.\n\n        This implements the method described in RFC1035 3.5.\n\n        """\n        reverse_octets = _compat_str(self).split(\'.\')[::-1]\n        return \'.\'.join(reverse_octets) + \'.in-addr.arpa\'\n\n    @property\n    def max_prefixlen(self):\n        return self._max_prefixlen\n\n    @property\n    def version(self):\n        return self._version\n\n\nclass IPv4Address(_BaseV4, _BaseAddress):\n\n    """Represent and manipulate single IPv4 Addresses."""\n\n    __slots__ = (\'_ip\', \'__weakref__\')\n\n    def __init__(self, address):\n\n        """\n        Args:\n            address: A string or integer representing the IP\n\n              Additionally, an integer can be passed, so\n              IPv4Address(\'192.0.2.1\') == IPv4Address(3221225985).\n              or, more generally\n              IPv4Address(int(IPv4Address(\'192.0.2.1\'))) ==\n                IPv4Address(\'192.0.2.1\')\n\n        Raises:\n            AddressValueError: If ipaddress isn\'t a valid IPv4 address.\n\n        """\n        # Efficient constructor from integer.\n        if isinstance(address, _compat_int_types):\n            self._check_int_address(address)\n            self._ip = address\n            return\n\n        # Constructing from a packed address\n        if isinstance(address, bytes):\n            self._check_packed_address(address, 4)\n            bvs = _compat_bytes_to_byte_vals(address)\n            self._ip = _compat_int_from_byte_vals(bvs, \'big\')\n            return\n\n        # Assume input argument to be string or any object representation\n        # which converts into a formatted IP string.\n        addr_str = _compat_str(address)\n        if \'/\' in addr_str:\n            raise AddressValueError("Unexpected \'/\' in %r" % address)\n        self._ip = self._ip_int_from_string(addr_str)\n\n    @property\n    def packed(self):\n        """The binary representation of this address."""\n        return v4_int_to_packed(self._ip)\n\n    @property\n    def is_reserved(self):\n        """Test if the address is otherwise IETF reserved.\n\n         Returns:\n             A boolean, True if the address is within the\n             reserved IPv4 Network range.\n\n        """\n        return self in self._constants._reserved_network\n\n    @property\n    def is_private(self):\n        """Test if this address is allocated for private networks.\n\n        Returns:\n            A boolean, True if the address is reserved per\n            iana-ipv4-special-registry.\n\n        """\n        return any(self in net for net in self._constants._private_networks)\n\n    @property\n    def is_global(self):\n        return (\n            self not in self._constants._public_network and\n            not self.is_private)\n\n    @property\n    def is_multicast(self):\n        """Test if the address is reserved for multicast use.\n\n        Returns:\n            A boolean, True if the address is multicast.\n            See RFC 3171 for details.\n\n        """\n        return self in self._constants._multicast_network\n\n    @property\n    def is_unspecified(self):\n        """Test if the address is unspecified.\n\n        Returns:\n            A boolean, True if this is the unspecified address as defined in\n            RFC 5735 3.\n\n        """\n        return self == self._constants._unspecified_address\n\n    @property\n    def is_loopback(self):\n        """Test if the address is a loopback address.\n\n        Returns:\n            A boolean, True if the address is a loopback per RFC 3330.\n\n        """\n        return self in self._constants._loopback_network\n\n    @property\n    def is_link_local(self):\n        """Test if the address is reserved for link-local.\n\n        Returns:\n            A boolean, True if the address is link-local per RFC 3927.\n\n        """\n        return self in self._constants._linklocal_network\n\n\nclass IPv4Interface(IPv4Address):\n\n    def __init__(self, address):\n        if isinstance(address, (bytes, _compat_int_types)):\n            IPv4Address.__init__(self, address)\n            self.network = IPv4Network(self._ip)\n            self._prefixlen = self._max_prefixlen\n            return\n\n        if isinstance(address, tuple):\n            IPv4Address.__init__(self, address[0])\n            if len(address) > 1:\n                self._prefixlen = int(address[1])\n            else:\n                self._prefixlen = self._max_prefixlen\n\n            self.network = IPv4Network(address, strict=False)\n            self.netmask = self.network.netmask\n            self.hostmask = self.network.hostmask\n            return\n\n        addr = _split_optional_netmask(address)\n        IPv4Address.__init__(self, addr[0])\n\n        self.network = IPv4Network(address, strict=False)\n        self._prefixlen = self.network._prefixlen\n\n        self.netmask = self.network.netmask\n        self.hostmask = self.network.hostmask\n\n    def __str__(self):\n        return \'%s/%d\' % (self._string_from_ip_int(self._ip),\n                          self.network.prefixlen)\n\n    def __eq__(self, other):\n        address_equal = IPv4Address.__eq__(self, other)\n        if not address_equal or address_equal is NotImplemented:\n            return address_equal\n        try:\n            return self.network == other.network\n        except AttributeError:\n            # An interface with an associated network is NOT the\n            # same as an unassociated address. That\'s why the hash\n            # takes the extra info into account.\n            return False\n\n    def __lt__(self, other):\n        address_less = IPv4Address.__lt__(self, other)\n        if address_less is NotImplemented:\n            return NotImplemented\n        try:\n            return self.network < other.network\n        except AttributeError:\n            # We *do* allow addresses and interfaces to be sorted. The\n            # unassociated address is considered less than all interfaces.\n            return False\n\n    def __hash__(self):\n        return self._ip ^ self._prefixlen ^ int(self.network.network_address)\n\n    __reduce__ = _IPAddressBase.__reduce__\n\n    @property\n    def ip(self):\n        return IPv4Address(self._ip)\n\n    @property\n    def with_prefixlen(self):\n        return \'%s/%s\' % (self._string_from_ip_int(self._ip),\n                          self._prefixlen)\n\n    @property\n    def with_netmask(self):\n        return \'%s/%s\' % (self._string_from_ip_int(self._ip),\n                          self.netmask)\n\n    @property\n    def with_hostmask(self):\n        return \'%s/%s\' % (self._string_from_ip_int(self._ip),\n                          self.hostmask)\n\n\nclass IPv4Network(_BaseV4, _BaseNetwork):\n\n    """This class represents and manipulates 32-bit IPv4 network + addresses..\n\n    Attributes: [examples for IPv4Network(\'192.0.2.0/27\')]\n        .network_address: IPv4Address(\'192.0.2.0\')\n        .hostmask: IPv4Address(\'0.0.0.31\')\n        .broadcast_address: IPv4Address(\'192.0.2.32\')\n        .netmask: IPv4Address(\'255.255.255.224\')\n        .prefixlen: 27\n\n    """\n    # Class to use when creating address objects\n    _address_class = IPv4Address\n\n    def __init__(self, address, strict=True):\n\n        """Instantiate a new IPv4 network object.\n\n        Args:\n            address: A string or integer representing the IP [& network].\n              \'192.0.2.0/24\'\n              \'192.0.2.0/255.255.255.0\'\n              \'192.0.0.2/0.0.0.255\'\n              are all functionally the same in IPv4. Similarly,\n              \'192.0.2.1\'\n              \'192.0.2.1/255.255.255.255\'\n              \'192.0.2.1/32\'\n              are also functionally equivalent. That is to say, failing to\n              provide a subnetmask will create an object with a mask of /32.\n\n              If the mask (portion after the / in the argument) is given in\n              dotted quad form, it is treated as a netmask if it starts with a\n              non-zero field (e.g. /255.0.0.0 == /8) and as a hostmask if it\n              starts with a zero field (e.g. 0.255.255.255 == /8), with the\n              single exception of an all-zero mask which is treated as a\n              netmask == /0. If no mask is given, a default of /32 is used.\n\n              Additionally, an integer can be passed, so\n              IPv4Network(\'192.0.2.1\') == IPv4Network(3221225985)\n              or, more generally\n              IPv4Interface(int(IPv4Interface(\'192.0.2.1\'))) ==\n                IPv4Interface(\'192.0.2.1\')\n\n        Raises:\n            AddressValueError: If ipaddress isn\'t a valid IPv4 address.\n            NetmaskValueError: If the netmask isn\'t valid for\n              an IPv4 address.\n            ValueError: If strict is True and a network address is not\n              supplied.\n\n        """\n        _BaseNetwork.__init__(self, address)\n\n        # Constructing from a packed address or integer\n        if isinstance(address, (_compat_int_types, bytes)):\n            self.network_address = IPv4Address(address)\n            self.netmask, self._prefixlen = self._make_netmask(\n                self._max_prefixlen)\n            # fixme: address/network test here.\n            return\n\n        if isinstance(address, tuple):\n            if len(address) > 1:\n                arg = address[1]\n            else:\n                # We weren\'t given an address[1]\n                arg = self._max_prefixlen\n            self.network_address = IPv4Address(address[0])\n            self.netmask, self._prefixlen = self._make_netmask(arg)\n            packed = int(self.network_address)\n            if packed & int(self.netmask) != packed:\n                if strict:\n                    raise ValueError(\'%s has host bits set\' % self)\n                else:\n                    self.network_address = IPv4Address(packed &\n                                                       int(self.netmask))\n            return\n\n        # Assume input argument to be string or any object representation\n        # which converts into a formatted IP prefix string.\n        addr = _split_optional_netmask(address)\n        self.network_address = IPv4Address(self._ip_int_from_string(addr[0]))\n\n        if len(addr) == 2:\n            arg = addr[1]\n        else:\n            arg = self._max_prefixlen\n        self.netmask, self._prefixlen = self._make_netmask(arg)\n\n        if strict:\n            if (IPv4Address(int(self.network_address) & int(self.netmask)) !=\n                    self.network_address):\n                raise ValueError(\'%s has host bits set\' % self)\n        self.network_address = IPv4Address(int(self.network_address) &\n                                           int(self.netmask))\n\n        if self._prefixlen == (self._max_prefixlen - 1):\n            self.hosts = self.__iter__\n\n    @property\n    def is_global(self):\n        """Test if this address is allocated for public networks.\n\n        Returns:\n            A boolean, True if the address is not reserved per\n            iana-ipv4-special-registry.\n\n        """\n        return (not (self.network_address in IPv4Network(\'100.64.0.0/10\') and\n                self.broadcast_address in IPv4Network(\'100.64.0.0/10\')) and\n                not self.is_private)\n\n\nclass _IPv4Constants(object):\n\n    _linklocal_network = IPv4Network(\'169.254.0.0/16\')\n\n    _loopback_network = IPv4Network(\'127.0.0.0/8\')\n\n    _multicast_network = IPv4Network(\'224.0.0.0/4\')\n\n    _public_network = IPv4Network(\'100.64.0.0/10\')\n\n    _private_networks = [\n        IPv4Network(\'0.0.0.0/8\'),\n        IPv4Network(\'10.0.0.0/8\'),\n        IPv4Network(\'127.0.0.0/8\'),\n        IPv4Network(\'169.254.0.0/16\'),\n        IPv4Network(\'172.16.0.0/12\'),\n        IPv4Network(\'192.0.0.0/29\'),\n        IPv4Network(\'192.0.0.170/31\'),\n        IPv4Network(\'192.0.2.0/24\'),\n        IPv4Network(\'192.168.0.0/16\'),\n        IPv4Network(\'198.18.0.0/15\'),\n        IPv4Network(\'198.51.100.0/24\'),\n        IPv4Network(\'203.0.113.0/24\'),\n        IPv4Network(\'240.0.0.0/4\'),\n        IPv4Network(\'255.255.255.255/32\'),\n    ]\n\n    _reserved_network = IPv4Network(\'240.0.0.0/4\')\n\n    _unspecified_address = IPv4Address(\'0.0.0.0\')\n\n\nIPv4Address._constants = _IPv4Constants\n\n\nclass _BaseV6(object):\n\n    """Base IPv6 object.\n\n    The following methods are used by IPv6 objects in both single IP\n    addresses and networks.\n\n    """\n\n    __slots__ = ()\n    _version = 6\n    _ALL_ONES = (2 ** IPV6LENGTH) - 1\n    _HEXTET_COUNT = 8\n    _HEX_DIGITS = frozenset(\'0123456789ABCDEFabcdef\')\n    _max_prefixlen = IPV6LENGTH\n\n    # There are only a bunch of valid v6 netmasks, so we cache them all\n    # when constructed (see _make_netmask()).\n    _netmask_cache = {}\n\n    @classmethod\n    def _make_netmask(cls, arg):\n        """Make a (netmask, prefix_len) tuple from the given argument.\n\n        Argument can be:\n        - an integer (the prefix length)\n        - a string representing the prefix length (e.g. "24")\n        - a string representing the prefix netmask (e.g. "255.255.255.0")\n        """\n        if arg not in cls._netmask_cache:\n            if isinstance(arg, _compat_int_types):\n                prefixlen = arg\n            else:\n                prefixlen = cls._prefix_from_prefix_string(arg)\n            netmask = IPv6Address(cls._ip_int_from_prefix(prefixlen))\n            cls._netmask_cache[arg] = netmask, prefixlen\n        return cls._netmask_cache[arg]\n\n    @classmethod\n    def _ip_int_from_string(cls, ip_str):\n        """Turn an IPv6 ip_str into an integer.\n\n        Args:\n            ip_str: A string, the IPv6 ip_str.\n\n        Returns:\n            An int, the IPv6 address\n\n        Raises:\n            AddressValueError: if ip_str isn\'t a valid IPv6 Address.\n\n        """\n        if not ip_str:\n            raise AddressValueError(\'Address cannot be empty\')\n\n        parts = ip_str.split(\':\')\n\n        # An IPv6 address needs at least 2 colons (3 parts).\n        _min_parts = 3\n        if len(parts) < _min_parts:\n            msg = "At least %d parts expected in %r" % (_min_parts, ip_str)\n            raise AddressValueError(msg)\n\n        # If the address has an IPv4-style suffix, convert it to hexadecimal.\n        if \'.\' in parts[-1]:\n            try:\n                ipv4_int = IPv4Address(parts.pop())._ip\n            except AddressValueError as exc:\n                raise AddressValueError("%s in %r" % (exc, ip_str))\n            parts.append(\'%x\' % ((ipv4_int >> 16) & 0xFFFF))\n            parts.append(\'%x\' % (ipv4_int & 0xFFFF))\n\n        # An IPv6 address can\'t have more than 8 colons (9 parts).\n        # The extra colon comes from using the "::" notation for a single\n        # leading or trailing zero part.\n        _max_parts = cls._HEXTET_COUNT + 1\n        if len(parts) > _max_parts:\n            msg = "At most %d colons permitted in %r" % (\n                _max_parts - 1, ip_str)\n            raise AddressValueError(msg)\n\n        # Disregarding the endpoints, find \'::\' with nothing in between.\n        # This indicates that a run of zeroes has been skipped.\n        skip_index = None\n        for i in _compat_range(1, len(parts) - 1):\n            if not parts[i]:\n                if skip_index is not None:\n                    # Can\'t have more than one \'::\'\n                    msg = "At most one \'::\' permitted in %r" % ip_str\n                    raise AddressValueError(msg)\n                skip_index = i\n\n        # parts_hi is the number of parts to copy from above/before the \'::\'\n        # parts_lo is the number of parts to copy from below/after the \'::\'\n        if skip_index is not None:\n            # If we found a \'::\', then check if it also covers the endpoints.\n            parts_hi = skip_index\n            parts_lo = len(parts) - skip_index - 1\n            if not parts[0]:\n                parts_hi -= 1\n                if parts_hi:\n                    msg = "Leading \':\' only permitted as part of \'::\' in %r"\n                    raise AddressValueError(msg % ip_str)  # ^: requires ^::\n            if not parts[-1]:\n                parts_lo -= 1\n                if parts_lo:\n                    msg = "Trailing \':\' only permitted as part of \'::\' in %r"\n                    raise AddressValueError(msg % ip_str)  # :$ requires ::$\n            parts_skipped = cls._HEXTET_COUNT - (parts_hi + parts_lo)\n            if parts_skipped < 1:\n                msg = "Expected at most %d other parts with \'::\' in %r"\n                raise AddressValueError(msg % (cls._HEXTET_COUNT - 1, ip_str))\n        else:\n            # Otherwise, allocate the entire address to parts_hi.  The\n            # endpoints could still be empty, but _parse_hextet() will check\n            # for that.\n            if len(parts) != cls._HEXTET_COUNT:\n                msg = "Exactly %d parts expected without \'::\' in %r"\n                raise AddressValueError(msg % (cls._HEXTET_COUNT, ip_str))\n            if not parts[0]:\n                msg = "Leading \':\' only permitted as part of \'::\' in %r"\n                raise AddressValueError(msg % ip_str)  # ^: requires ^::\n            if not parts[-1]:\n                msg = "Trailing \':\' only permitted as part of \'::\' in %r"\n                raise AddressValueError(msg % ip_str)  # :$ requires ::$\n            parts_hi = len(parts)\n            parts_lo = 0\n            parts_skipped = 0\n\n        try:\n            # Now, parse the hextets into a 128-bit integer.\n            ip_int = 0\n            for i in range(parts_hi):\n                ip_int <<= 16\n                ip_int |= cls._parse_hextet(parts[i])\n            ip_int <<= 16 * parts_skipped\n            for i in range(-parts_lo, 0):\n                ip_int <<= 16\n                ip_int |= cls._parse_hextet(parts[i])\n            return ip_int\n        except ValueError as exc:\n            raise AddressValueError("%s in %r" % (exc, ip_str))\n\n    @classmethod\n    def _parse_hextet(cls, hextet_str):\n        """Convert an IPv6 hextet string into an integer.\n\n        Args:\n            hextet_str: A string, the number to parse.\n\n        Returns:\n            The hextet as an integer.\n\n        Raises:\n            ValueError: if the input isn\'t strictly a hex number from\n              [0..FFFF].\n\n        """\n        # Whitelist the characters, since int() allows a lot of bizarre stuff.\n        if not cls._HEX_DIGITS.issuperset(hextet_str):\n            raise ValueError("Only hex digits permitted in %r" % hextet_str)\n        # We do the length check second, since the invalid character error\n        # is likely to be more informative for the user\n        if len(hextet_str) > 4:\n            msg = "At most 4 characters permitted in %r"\n            raise ValueError(msg % hextet_str)\n        # Length check means we can skip checking the integer value\n        return int(hextet_str, 16)\n\n    @classmethod\n    def _compress_hextets(cls, hextets):\n        """Compresses a list of hextets.\n\n        Compresses a list of strings, replacing the longest continuous\n        sequence of "0" in the list with "" and adding empty strings at\n        the beginning or at the end of the string such that subsequently\n        calling ":".join(hextets) will produce the compressed version of\n        the IPv6 address.\n\n        Args:\n            hextets: A list of strings, the hextets to compress.\n\n        Returns:\n            A list of strings.\n\n        """\n        best_doublecolon_start = -1\n        best_doublecolon_len = 0\n        doublecolon_start = -1\n        doublecolon_len = 0\n        for index, hextet in enumerate(hextets):\n            if hextet == \'0\':\n                doublecolon_len += 1\n                if doublecolon_start == -1:\n                    # Start of a sequence of zeros.\n                    doublecolon_start = index\n                if doublecolon_len > best_doublecolon_len:\n                    # This is the longest sequence of zeros so far.\n                    best_doublecolon_len = doublecolon_len\n                    best_doublecolon_start = doublecolon_start\n            else:\n                doublecolon_len = 0\n                doublecolon_start = -1\n\n        if best_doublecolon_len > 1:\n            best_doublecolon_end = (best_doublecolon_start +\n                                    best_doublecolon_len)\n            # For zeros at the end of the address.\n            if best_doublecolon_end == len(hextets):\n                hextets += [\'\']\n            hextets[best_doublecolon_start:best_doublecolon_end] = [\'\']\n            # For zeros at the beginning of the address.\n            if best_doublecolon_start == 0:\n                hextets = [\'\'] + hextets\n\n        return hextets\n\n    @classmethod\n    def _string_from_ip_int(cls, ip_int=None):\n        """Turns a 128-bit integer into hexadecimal notation.\n\n        Args:\n            ip_int: An integer, the IP address.\n\n        Returns:\n            A string, the hexadecimal representation of the address.\n\n        Raises:\n            ValueError: The address is bigger than 128 bits of all ones.\n\n        """\n        if ip_int is None:\n            ip_int = int(cls._ip)\n\n        if ip_int > cls._ALL_ONES:\n            raise ValueError(\'IPv6 address is too large\')\n\n        hex_str = \'%032x\' % ip_int\n        hextets = [\'%x\' % int(hex_str[x:x + 4], 16) for x in range(0, 32, 4)]\n\n        hextets = cls._compress_hextets(hextets)\n        return \':\'.join(hextets)\n\n    def _explode_shorthand_ip_string(self):\n        """Expand a shortened IPv6 address.\n\n        Args:\n            ip_str: A string, the IPv6 address.\n\n        Returns:\n            A string, the expanded IPv6 address.\n\n        """\n        if isinstance(self, IPv6Network):\n            ip_str = _compat_str(self.network_address)\n        elif isinstance(self, IPv6Interface):\n            ip_str = _compat_str(self.ip)\n        else:\n            ip_str = _compat_str(self)\n\n        ip_int = self._ip_int_from_string(ip_str)\n        hex_str = \'%032x\' % ip_int\n        parts = [hex_str[x:x + 4] for x in range(0, 32, 4)]\n        if isinstance(self, (_BaseNetwork, IPv6Interface)):\n            return \'%s/%d\' % (\':\'.join(parts), self._prefixlen)\n        return \':\'.join(parts)\n\n    def _reverse_pointer(self):\n        """Return the reverse DNS pointer name for the IPv6 address.\n\n        This implements the method described in RFC3596 2.5.\n\n        """\n        reverse_chars = self.exploded[::-1].replace(\':\', \'\')\n        return \'.\'.join(reverse_chars) + \'.ip6.arpa\'\n\n    @property\n    def max_prefixlen(self):\n        return self._max_prefixlen\n\n    @property\n    def version(self):\n        return self._version\n\n\nclass IPv6Address(_BaseV6, _BaseAddress):\n\n    """Represent and manipulate single IPv6 Addresses."""\n\n    __slots__ = (\'_ip\', \'__weakref__\')\n\n    def __init__(self, address):\n        """Instantiate a new IPv6 address object.\n\n        Args:\n            address: A string or integer representing the IP\n\n              Additionally, an integer can be passed, so\n              IPv6Address(\'2001:db8::\') ==\n                IPv6Address(42540766411282592856903984951653826560)\n              or, more generally\n              IPv6Address(int(IPv6Address(\'2001:db8::\'))) ==\n                IPv6Address(\'2001:db8::\')\n\n        Raises:\n            AddressValueError: If address isn\'t a valid IPv6 address.\n\n        """\n        # Efficient constructor from integer.\n        if isinstance(address, _compat_int_types):\n            self._check_int_address(address)\n            self._ip = address\n            return\n\n        # Constructing from a packed address\n        if isinstance(address, bytes):\n            self._check_packed_address(address, 16)\n            bvs = _compat_bytes_to_byte_vals(address)\n            self._ip = _compat_int_from_byte_vals(bvs, \'big\')\n            return\n\n        # Assume input argument to be string or any object representation\n        # which converts into a formatted IP string.\n        addr_str = _compat_str(address)\n        if \'/\' in addr_str:\n            raise AddressValueError("Unexpected \'/\' in %r" % address)\n        self._ip = self._ip_int_from_string(addr_str)\n\n    @property\n    def packed(self):\n        """The binary representation of this address."""\n        return v6_int_to_packed(self._ip)\n\n    @property\n    def is_multicast(self):\n        """Test if the address is reserved for multicast use.\n\n        Returns:\n            A boolean, True if the address is a multicast address.\n            See RFC 2373 2.7 for details.\n\n        """\n        return self in self._constants._multicast_network\n\n    @property\n    def is_reserved(self):\n        """Test if the address is otherwise IETF reserved.\n\n        Returns:\n            A boolean, True if the address is within one of the\n            reserved IPv6 Network ranges.\n\n        """\n        return any(self in x for x in self._constants._reserved_networks)\n\n    @property\n    def is_link_local(self):\n        """Test if the address is reserved for link-local.\n\n        Returns:\n            A boolean, True if the address is reserved per RFC 4291.\n\n        """\n        return self in self._constants._linklocal_network\n\n    @property\n    def is_site_local(self):\n        """Test if the address is reserved for site-local.\n\n        Note that the site-local address space has been deprecated by RFC 3879.\n        Use is_private to test if this address is in the space of unique local\n        addresses as defined by RFC 4193.\n\n        Returns:\n            A boolean, True if the address is reserved per RFC 3513 2.5.6.\n\n        """\n        return self in self._constants._sitelocal_network\n\n    @property\n    def is_private(self):\n        """Test if this address is allocated for private networks.\n\n        Returns:\n            A boolean, True if the address is reserved per\n            iana-ipv6-special-registry.\n\n        """\n        return any(self in net for net in self._constants._private_networks)\n\n    @property\n    def is_global(self):\n        """Test if this address is allocated for public networks.\n\n        Returns:\n            A boolean, true if the address is not reserved per\n            iana-ipv6-special-registry.\n\n        """\n        return not self.is_private\n\n    @property\n    def is_unspecified(self):\n        """Test if the address is unspecified.\n\n        Returns:\n            A boolean, True if this is the unspecified address as defined in\n            RFC 2373 2.5.2.\n\n        """\n        return self._ip == 0\n\n    @property\n    def is_loopback(self):\n        """Test if the address is a loopback address.\n\n        Returns:\n            A boolean, True if the address is a loopback address as defined in\n            RFC 2373 2.5.3.\n\n        """\n        return self._ip == 1\n\n    @property\n    def ipv4_mapped(self):\n        """Return the IPv4 mapped address.\n\n        Returns:\n            If the IPv6 address is a v4 mapped address, return the\n            IPv4 mapped address. Return None otherwise.\n\n        """\n        if (self._ip >> 32) != 0xFFFF:\n            return None\n        return IPv4Address(self._ip & 0xFFFFFFFF)\n\n    @property\n    def teredo(self):\n        """Tuple of embedded teredo IPs.\n\n        Returns:\n            Tuple of the (server, client) IPs or None if the address\n            doesn\'t appear to be a teredo address (doesn\'t start with\n            2001::/32)\n\n        """\n        if (self._ip >> 96) != 0x20010000:\n            return None\n        return (IPv4Address((self._ip >> 64) & 0xFFFFFFFF),\n                IPv4Address(~self._ip & 0xFFFFFFFF))\n\n    @property\n    def sixtofour(self):\n        """Return the IPv4 6to4 embedded address.\n\n        Returns:\n            The IPv4 6to4-embedded address if present or None if the\n            address doesn\'t appear to contain a 6to4 embedded address.\n\n        """\n        if (self._ip >> 112) != 0x2002:\n            return None\n        return IPv4Address((self._ip >> 80) & 0xFFFFFFFF)\n\n\nclass IPv6Interface(IPv6Address):\n\n    def __init__(self, address):\n        if isinstance(address, (bytes, _compat_int_types)):\n            IPv6Address.__init__(self, address)\n            self.network = IPv6Network(self._ip)\n            self._prefixlen = self._max_prefixlen\n            return\n        if isinstance(address, tuple):\n            IPv6Address.__init__(self, address[0])\n            if len(address) > 1:\n                self._prefixlen = int(address[1])\n            else:\n                self._prefixlen = self._max_prefixlen\n            self.network = IPv6Network(address, strict=False)\n            self.netmask = self.network.netmask\n            self.hostmask = self.network.hostmask\n            return\n\n        addr = _split_optional_netmask(address)\n        IPv6Address.__init__(self, addr[0])\n        self.network = IPv6Network(address, strict=False)\n        self.netmask = self.network.netmask\n        self._prefixlen = self.network._prefixlen\n        self.hostmask = self.network.hostmask\n\n    def __str__(self):\n        return \'%s/%d\' % (self._string_from_ip_int(self._ip),\n                          self.network.prefixlen)\n\n    def __eq__(self, other):\n        address_equal = IPv6Address.__eq__(self, other)\n        if not address_equal or address_equal is NotImplemented:\n            return address_equal\n        try:\n            return self.network == other.network\n        except AttributeError:\n            # An interface with an associated network is NOT the\n            # same as an unassociated address. That\'s why the hash\n            # takes the extra info into account.\n            return False\n\n    def __lt__(self, other):\n        address_less = IPv6Address.__lt__(self, other)\n        if address_less is NotImplemented:\n            return NotImplemented\n        try:\n            return self.network < other.network\n        except AttributeError:\n            # We *do* allow addresses and interfaces to be sorted. The\n            # unassociated address is considered less than all interfaces.\n            return False\n\n    def __hash__(self):\n        return self._ip ^ self._prefixlen ^ int(self.network.network_address)\n\n    __reduce__ = _IPAddressBase.__reduce__\n\n    @property\n    def ip(self):\n        return IPv6Address(self._ip)\n\n    @property\n    def with_prefixlen(self):\n        return \'%s/%s\' % (self._string_from_ip_int(self._ip),\n                          self._prefixlen)\n\n    @property\n    def with_netmask(self):\n        return \'%s/%s\' % (self._string_from_ip_int(self._ip),\n                          self.netmask)\n\n    @property\n    def with_hostmask(self):\n        return \'%s/%s\' % (self._string_from_ip_int(self._ip),\n                          self.hostmask)\n\n    @property\n    def is_unspecified(self):\n        return self._ip == 0 and self.network.is_unspecified\n\n    @property\n    def is_loopback(self):\n        return self._ip == 1 and self.network.is_loopback\n\n\nclass IPv6Network(_BaseV6, _BaseNetwork):\n\n    """This class represents and manipulates 128-bit IPv6 networks.\n\n    Attributes: [examples for IPv6(\'2001:db8::1000/124\')]\n        .network_address: IPv6Address(\'2001:db8::1000\')\n        .hostmask: IPv6Address(\'::f\')\n        .broadcast_address: IPv6Address(\'2001:db8::100f\')\n        .netmask: IPv6Address(\'ffff:ffff:ffff:ffff:ffff:ffff:ffff:fff0\')\n        .prefixlen: 124\n\n    """\n\n    # Class to use when creating address objects\n    _address_class = IPv6Address\n\n    def __init__(self, address, strict=True):\n        """Instantiate a new IPv6 Network object.\n\n        Args:\n            address: A string or integer representing the IPv6 network or the\n              IP and prefix/netmask.\n              \'2001:db8::/128\'\n              \'2001:db8:0000:0000:0000:0000:0000:0000/128\'\n              \'2001:db8::\'\n              are all functionally the same in IPv6.  That is to say,\n              failing to provide a subnetmask will create an object with\n              a mask of /128.\n\n              Additionally, an integer can be passed, so\n              IPv6Network(\'2001:db8::\') ==\n                IPv6Network(42540766411282592856903984951653826560)\n              or, more generally\n              IPv6Network(int(IPv6Network(\'2001:db8::\'))) ==\n                IPv6Network(\'2001:db8::\')\n\n            strict: A boolean. If true, ensure that we have been passed\n              A true network address, eg, 2001:db8::1000/124 and not an\n              IP address on a network, eg, 2001:db8::1/124.\n\n        Raises:\n            AddressValueError: If address isn\'t a valid IPv6 address.\n            NetmaskValueError: If the netmask isn\'t valid for\n              an IPv6 address.\n            ValueError: If strict was True and a network address was not\n              supplied.\n\n        """\n        _BaseNetwork.__init__(self, address)\n\n        # Efficient constructor from integer or packed address\n        if isinstance(address, (bytes, _compat_int_types)):\n            self.network_address = IPv6Address(address)\n            self.netmask, self._prefixlen = self._make_netmask(\n                self._max_prefixlen)\n            return\n\n        if isinstance(address, tuple):\n            if len(address) > 1:\n                arg = address[1]\n            else:\n                arg = self._max_prefixlen\n            self.netmask, self._prefixlen = self._make_netmask(arg)\n            self.network_address = IPv6Address(address[0])\n            packed = int(self.network_address)\n            if packed & int(self.netmask) != packed:\n                if strict:\n                    raise ValueError(\'%s has host bits set\' % self)\n                else:\n                    self.network_address = IPv6Address(packed &\n                                                       int(self.netmask))\n            return\n\n        # Assume input argument to be string or any object representation\n        # which converts into a formatted IP prefix string.\n        addr = _split_optional_netmask(address)\n\n        self.network_address = IPv6Address(self._ip_int_from_string(addr[0]))\n\n        if len(addr) == 2:\n            arg = addr[1]\n        else:\n            arg = self._max_prefixlen\n        self.netmask, self._prefixlen = self._make_netmask(arg)\n\n        if strict:\n            if (IPv6Address(int(self.network_address) & int(self.netmask)) !=\n                    self.network_address):\n                raise ValueError(\'%s has host bits set\' % self)\n        self.network_address = IPv6Address(int(self.network_address) &\n                                           int(self.netmask))\n\n        if self._prefixlen == (self._max_prefixlen - 1):\n            self.hosts = self.__iter__\n\n    def hosts(self):\n        """Generate Iterator over usable hosts in a network.\n\n          This is like __iter__ except it doesn\'t return the\n          Subnet-Router anycast address.\n\n        """\n        network = int(self.network_address)\n        broadcast = int(self.broadcast_address)\n        for x in _compat_range(network + 1, broadcast + 1):\n            yield self._address_class(x)\n\n    @property\n    def is_site_local(self):\n        """Test if the address is reserved for site-local.\n\n        Note that the site-local address space has been deprecated by RFC 3879.\n        Use is_private to test if this address is in the space of unique local\n        addresses as defined by RFC 4193.\n\n        Returns:\n            A boolean, True if the address is reserved per RFC 3513 2.5.6.\n\n        """\n        return (self.network_address.is_site_local and\n                self.broadcast_address.is_site_local)\n\n\nclass _IPv6Constants(object):\n\n    _linklocal_network = IPv6Network(\'fe80::/10\')\n\n    _multicast_network = IPv6Network(\'ff00::/8\')\n\n    _private_networks = [\n        IPv6Network(\'::1/128\'),\n        IPv6Network(\'::/128\'),\n        IPv6Network(\'::ffff:0:0/96\'),\n        IPv6Network(\'100::/64\'),\n        IPv6Network(\'2001::/23\'),\n        IPv6Network(\'2001:2::/48\'),\n        IPv6Network(\'2001:db8::/32\'),\n        IPv6Network(\'2001:10::/28\'),\n        IPv6Network(\'fc00::/7\'),\n        IPv6Network(\'fe80::/10\'),\n    ]\n\n    _reserved_networks = [\n        IPv6Network(\'::/8\'), IPv6Network(\'100::/8\'),\n        IPv6Network(\'200::/7\'), IPv6Network(\'400::/6\'),\n        IPv6Network(\'800::/5\'), IPv6Network(\'1000::/4\'),\n        IPv6Network(\'4000::/3\'), IPv6Network(\'6000::/3\'),\n        IPv6Network(\'8000::/3\'), IPv6Network(\'A000::/3\'),\n        IPv6Network(\'C000::/3\'), IPv6Network(\'E000::/4\'),\n        IPv6Network(\'F000::/5\'), IPv6Network(\'F800::/6\'),\n        IPv6Network(\'FE00::/9\'),\n    ]\n\n    _sitelocal_network = IPv6Network(\'fec0::/10\')\n\n\nIPv6Address._constants = _IPv6Constants\n''')
      __stickytape_write_module('''libs/pylev.py''', '''"""\npylev\n=====\n\nA pure Python Levenshtein implementation that\'s not freaking GPL\'d.\n\nBased off the Wikipedia code samples at\nhttp://en.wikipedia.org/wiki/Levenshtein_distance.\n\nUsage\n-----\n\nUsage is fairly straightforward.::\n\n    import pylev\n    distance = pylev.levenshtein(\'kitten\', \'sitting\')\n    assert(distance, 3)\n\n"""\n__author__ = \'Daniel Lindsley\'\n__version__ = (1, 3, 0)\n__license__ = \'New BSD\'\n\n\nimport sys\nPY2 = sys.version_info[0] == 2\n\nif PY2:\n    range = xrange\n\n\ndef classic_levenshtein(string_1, string_2):\n    """\n    Calculates the Levenshtein distance between two strings.\n\n    This version is easier to read, but significantly slower than the version\n    below (up to several orders of magnitude). Useful for learning, less so\n    otherwise.\n\n    Usage::\n\n        >>> classic_levenshtein(\'kitten\', \'sitting\')\n        3\n        >>> classic_levenshtein(\'kitten\', \'kitten\')\n        0\n        >>> classic_levenshtein(\'\', \'\')\n        0\n\n    """\n    len_1 = len(string_1)\n    len_2 = len(string_2)\n    cost = 0\n\n    if len_1 and len_2 and string_1[0] != string_2[0]:\n        cost = 1\n\n    if len_1 == 0:\n        return len_2\n    elif len_2 == 0:\n        return len_1\n    else:\n        return min(\n            classic_levenshtein(string_1[1:], string_2) + 1,\n            classic_levenshtein(string_1, string_2[1:]) + 1,\n            classic_levenshtein(string_1[1:], string_2[1:]) + cost,\n        )\n\n\ndef recursive_levenshtein(string_1, string_2, len_1=None, len_2=None, offset_1=0, offset_2=0, memo=None):\n    """\n    Calculates the Levenshtein distance between two strings.\n\n    Usage::\n\n        >>> recursive_levenshtein(\'kitten\', \'sitting\')\n        3\n        >>> recursive_levenshtein(\'kitten\', \'kitten\')\n        0\n        >>> recursive_levenshtein(\'\', \'\')\n        0\n\n    """\n    if len_1 is None:\n        len_1 = len(string_1)\n\n    if len_2 is None:\n        len_2 = len(string_2)\n\n    if memo is None:\n        memo = {}\n\n    key = \',\'.join([str(offset_1), str(len_1), str(offset_2), str(len_2)])\n\n    if memo.get(key) is not None:\n        return memo[key]\n\n    if len_1 == 0:\n        return len_2\n    elif len_2 == 0:\n        return len_1\n\n    cost = 0\n\n    if string_1[offset_1] != string_2[offset_2]:\n        cost = 1\n\n    dist = min(\n        recursive_levenshtein(string_1, string_2, len_1 - 1, len_2, offset_1 + 1, offset_2, memo) + 1,\n        recursive_levenshtein(string_1, string_2, len_1, len_2 - 1, offset_1, offset_2 + 1, memo) + 1,\n        recursive_levenshtein(string_1, string_2, len_1 - 1, len_2 - 1, offset_1 + 1, offset_2 + 1, memo) + cost,\n    )\n    memo[key] = dist\n    return dist\n\n\ndef wf_levenshtein(string_1, string_2):\n    """\n    Calculates the Levenshtein distance between two strings.\n\n    This version uses the Wagner-Fischer algorithm.\n\n    Usage::\n\n        >>> wf_levenshtein(\'kitten\', \'sitting\')\n        3\n        >>> wf_levenshtein(\'kitten\', \'kitten\')\n        0\n        >>> wf_levenshtein(\'\', \'\')\n        0\n\n    """\n    len_1 = len(string_1) + 1\n    len_2 = len(string_2) + 1\n\n    d = [0] * (len_1 * len_2)\n\n    for i in range(len_1):\n        d[i] = i\n    for j in range(len_2):\n        d[j * len_1] = j\n\n    for j in range(1, len_2):\n        for i in range(1, len_1):\n            if string_1[i - 1] == string_2[j - 1]:\n                d[i + j * len_1] = d[i - 1 + (j - 1) * len_1]\n            else:\n                d[i + j * len_1] = min(\n                   d[i - 1 + j * len_1] + 1,        # deletion\n                   d[i + (j - 1) * len_1] + 1,      # insertion\n                   d[i - 1 + (j - 1) * len_1] + 1,  # substitution\n                )\n\n    return d[-1]\n\n\ndef wfi_levenshtein(string_1, string_2):\n    """\n    Calculates the Levenshtein distance between two strings.\n\n    This version uses an iterative version of the Wagner-Fischer algorithm.\n\n    Usage::\n\n        >>> wfi_levenshtein(\'kitten\', \'sitting\')\n        3\n        >>> wfi_levenshtein(\'kitten\', \'kitten\')\n        0\n        >>> wfi_levenshtein(\'\', \'\')\n        0\n\n    """\n    if string_1 == string_2:\n        return 0\n\n    len_1 = len(string_1)\n    len_2 = len(string_2)\n\n    if len_1 == 0:\n        return len_2\n    if len_2 == 0:\n        return len_1\n\n    if len_1 > len_2:\n        string_2, string_1 = string_1, string_2\n        len_2, len_1 = len_1, len_2\n\n    d0 = [i for i in range(len_2 + 1)]\n    d1 = [j for j in range(len_2 + 1)]\n\n    for i in range(len_1):\n        d1[0] = i + 1\n        for j in range(len_2):\n            cost = d0[j]\n\n            if string_1[i] != string_2[j]:\n                # substitution\n                cost += 1\n\n                # insertion\n                x_cost = d1[j] + 1\n                if x_cost < cost:\n                    cost = x_cost\n\n                # deletion\n                y_cost = d0[j + 1] + 1\n                if y_cost < cost:\n                    cost = y_cost\n\n            d1[j + 1] = cost\n\n        d0, d1 = d1, d0\n\n    return d0[-1]\n\n\ndef damerau_levenshtein(string_1, string_2):\n    """\n    Calculates the Damerau-Levenshtein distance between two strings.\n\n    In addition to insertions, deletions and substitutions,\n    Damerau-Levenshtein considers adjacent transpositions.\n\n    This version is based on an iterative version of the Wagner-Fischer algorithm.\n\n    Usage::\n\n        >>> damerau_levenshtein(\'kitten\', \'sitting\')\n        3\n        >>> damerau_levenshtein(\'kitten\', \'kittne\')\n        1\n        >>> damerau_levenshtein(\'\', \'\')\n        0\n\n    """\n    if string_1 == string_2:\n        return 0\n\n    len_1 = len(string_1)\n    len_2 = len(string_2)\n\n    if len_1 == 0:\n        return len_2\n    if len_2 == 0:\n        return len_1\n\n    if len_1 > len_2:\n        string_2, string_1 = string_1, string_2\n        len_2, len_1 = len_1, len_2\n\n    prev_cost = 0\n    d0 = [i for i in range(len_2 + 1)]\n    d1 = [j for j in range(len_2 + 1)]\n    dprev = d0[:]\n\n    s1 = string_1\n    s2 = string_2\n\n    for i in range(len_1):\n        d1[0] = i + 1\n        for j in range(len_2):\n            cost = d0[j]\n\n            if s1[i] != s2[j]:\n                # substitution\n                cost += 1\n\n                # insertion\n                x_cost = d1[j] + 1\n                if x_cost < cost:\n                    cost = x_cost\n\n                # deletion\n                y_cost = d0[j + 1] + 1\n                if y_cost < cost:\n                    cost = y_cost\n\n                # transposition\n                if i > 0 and j > 0 and s1[i] == s2[j - 1] and s1[i - 1] == s2[j]:\n                    transp_cost = dprev[j - 1] + 1\n                    if transp_cost < cost:\n                        cost = transp_cost\n            d1[j + 1] = cost\n\n        dprev, d0, d1 = d0, d1, dprev\n\n    return d0[-1]\n\n\nlevenshtein = wfi_levenshtein\n\n# Backward-compatibilty because I misspelled.\nclassic_levenschtein = classic_levenshtein\nlevenschtein = levenshtein\n''')
      __stickytape_write_module('''duplicate_incidents/utils.py''', '''import collections\nimport hashlib\nimport re\nfrom rfc822 import parseaddr\nfrom urlparse import urlparse\n\nimport datetime\n\nimport libs.ipaddress as ipaddress\nimport libs.pylev as pylev\nimport libs.tldextract as tldextract\n\nMAX_STRING_LEN_FOR_EDIT_DISTANCE = 150\nEMAIL_PATTERN = re.compile(r"""[a-zA-Z0-9.!#$%&\'*+/=?^_`{|}~-]+@[a-zA-Z0-9](?:[a-zA-Z0-9-]{0,61}[a-zA-Z0-9])?(?:\\.[a-zA-Z0-9](?:[a-zA-Z0-9-]{0,61}[a-zA-Z0-9])?)*""")\n\nfrom consts import EMAIL_DATE_LABEL, EMAIL_SENDER, EMAIL_SUBJECT_LABEL\n\ndef memoize(f):\n    """ Memoization decorator for functions taking one or more arguments. """\n\n    class memodict(dict):\n        def __init__(self, f):\n            self.f = f\n\n        def __call__(self, *args):\n            return self[args]\n\n        def __missing__(self, key):\n            ret = self[key] = self.f(*key)\n            return ret\n\n    return memodict(f)\n\n\ndef get_unique_list(x):\n    return list(set(x))\n\n\ndef get_email_name(email):\n    name = parseaddr(email)[0]\n    if name:\n        return name\n\n\ndef get_email_address(email):\n    addr = parseaddr(email)[1]\n\n    if addr and EMAIL_PATTERN.match(addr):\n        return addr\n\n\ndef string_similarity_check(prefix, s1, s2):\n    result = {}\n    result[prefix + \'_same\'] = s1 == s2\n    result[prefix + \'_same_len\'] = len(s1) == len(s2)\n    # result[prefix + \'_ld\'] = edit_distance_max_len(s1, s2) if not result[prefix + \'_same\'] else 0\n    result[prefix + \'_similarity_max\'] = calculate_similar_pattern([s1], [s2]) if not result[prefix + \'_same\'] else 1\n    result[prefix + \'_words_jaccard\'] = jaccard_similarity(s1.split(), s2.split()) if not result[prefix + \'_same\'] else 1\n    return result\n\ndef complete_email_missing_labels(labels):\n    found_subject = EMAIL_SUBJECT_LABEL in labels\n    found_date = EMAIL_DATE_LABEL in labels\n    found_sender = EMAIL_SENDER in labels\n\n    for label in labels.keys():\n        if not found_subject and \'email\' in label and \'subject\' in label:\n            labels[EMAIL_SUBJECT_LABEL] = labels.pop(label)\n        if not found_date and \'email\' in label and \'date\' in label:\n            labels[EMAIL_DATE_LABEL] = labels.pop(label)\n        if not found_sender and \'email\' in label and (\'from\' in label or \'sender\' in label):\n            labels[EMAIL_SENDER] = labels.pop(label)\n\n    return labels\n\n\ndef get_incident_labels_map(labels, labels_rename={}):\n    if labels is None:\n        return {}\n    labels_map = {}\n    for label in labels:\n        label_type = label[\'type\']\n        if label_type in labels_rename:\n            label_type = labels_rename[label_type]\n        label_type = label_type.lower()\n        if label_type in labels_map:\n            if not type(labels_map[label_type]) == list:\n                labels_map[label_type] = [labels_map[label_type]]\n            labels_map[label_type].append(label[\'value\'])\n        else:\n            labels_map[label_type] = label[\'value\']\n\n    for label, value in labels_map.items():\n        if type(value) == list:\n            value.sort()\n            labels_map[label] = "".join(value)\n    return complete_email_missing_labels(labels_map)\n\n\ndef get_time_diff_seconds(date1, date2):\n    def parse_datetime(datetime_str):\n        datetime_str = datetime_str[:datetime_str.find(".")]\n        return datetime.datetime.strptime(datetime_str, "%Y-%m-%dT%H:%M:%S")\n\n    try:\n        if not date1 or not date2:\n            return None\n        if isinstance(date1, basestring):\n            date1 = parse_datetime(date1)\n        if isinstance(date2, basestring):\n            date2 = parse_datetime(date2)\n        return abs(date1 - date2).total_seconds()\n    except Exception:\n        return None\n\n\ndef intersection_set(x, y):\n    return set.intersection(*[set(x), set(y)])\n\n\ndef intersection_set(x, y):\n    return set.intersection(*[set(x), set(y)])\n\n\ndef union_set(x, y):\n    return set.union(*[set(x), set(y)])\n\n\ndef get_hashable_from_dict(d):\n    return [(k, v) for k, v in d.items() if isinstance(v, collections.Hashable)]\n\n\ndef jaccard_similarity(x, y):\n    if x is None or y is None:\n        return None\n\n    if type(x) == dict:\n        x = get_hashable_from_dict(x)\n    if type(y) == dict:\n        y = get_hashable_from_dict(y)\n\n    x = [v for v in x if isinstance(v, collections.Hashable)]\n    y = [v for v in y if isinstance(v, collections.Hashable)]\n\n    if len(x) == 0 or len(y) == 0:\n        return None\n\n    intersection_cardinality = len(intersection_set(x, y))\n    union_cardinality = len(union_set(x, y))\n    return intersection_cardinality / float(union_cardinality)\n\n\ndef edit_distance_max_len(s1, s2, max_length=MAX_STRING_LEN_FOR_EDIT_DISTANCE):\n    if s1 is None or s2 is None or len(s1) == 0 or len(s2) == 0:\n        return None\n    return pylev.levenshtein(s1[:max_length], s2[:max_length])\n\n\ndef is_similarity_exist(x, y, similarity_function):\n    if x is None or y is None or len(x) == 0 or len(y) == 0:\n        return None\n\n    for value1 in x:\n        for value2 in y:\n            if similarity_function(value1, value2):\n                return True\n    return False\n\n\ndef find_indices(s, lambda_condition):\n    return [i for i, ch in enumerate(s) if lambda_condition(ch)]\n\n\ndef get_minimal_edit_distance(x, y):\n    if x is None or y is None or len(x) == 0 or len(y) == 0:\n        return None\n\n    distances = []\n    for value1 in x:\n        for value2 in y:\n            distances.append(edit_distance_max_len(value1, value2, MAX_STRING_LEN_FOR_EDIT_DISTANCE))\n    distances = [d for d in distances if d is not None]\n    return min(distances)\n\n\ndef canonize_ip_to_network(ip_address, mast_bits):\n    try:\n        return str(ipaddress.IPv4Network(unicode("%s/%d" % (ip_address, mast_bits)), strict=False).broadcast_address)\n    except Exception:\n        return ip_address\n\n\ndef is_ip_private(ip_address):\n    try:\n        return ipaddress.IPv4Address(unicode(ip_address)).is_private\n    except Exception:\n        return False\n\n\ndef extract_email_domain(email):\n    index = email.rfind("@")\n    if index == -1:\n        return None\n    return extract_domain_from_url(email[index + 1:])\n\n\ndef extract_email_username(email):\n    index = email.rfind("@")\n    if index == -1:\n        return None\n    return email[:index]\n\n\ndef get_url_path(url):\n    return urlparse(url).path\n\n\ndef extract_domain_from_url(url):\n    domain = tldextract.extract(url).domain.lower()\n    suffix = tldextract.extract(url).suffix.lower()\n    if len(domain) > 0 and len(suffix) > 0:\n        return ".".join([domain, suffix])\n\n\ndef uri_validator(url):\n    try:\n        result = urlparse(url)\n        if result.scheme and result.netloc and result.path is not None:\n            return True\n    except:\n        return False\n\n\ndef is_groups_cross_empty(group1, group2):\n    return group1 is None or len(group1) == 0 or group2 is None or len(group2) == 0\n\n\ndef get_domains(indicators, labels):\n    domains = []\n    for email in indicators.get(\'Email\', []):\n        domains.append(extract_email_domain(email))\n\n    for url in indicators.get(\'URL\', []):\n        domains.append(extract_domain_from_url(url))\n\n    for label_value in labels.values():\n        if not " " in label_value.strip():\n            if uri_validator(label_value):\n                domains.append(extract_domain_from_url(label_value))\n            for email in EMAIL_PATTERN.findall(label_value):\n                domains.append(extract_email_domain(email))\n\n    domains = [x for x in domains if x is not None]\n\n    return get_unique_list(domains)\n\n\n@memoize\ndef dash_indices(x):\n    return find_indices(x, lambda ch: ch == \'/\')\n\n\n@memoize\ndef dot_indices(x):\n    return find_indices(x, lambda ch: ch == \'.\')\n\n\n@memoize\ndef underscore_indices(x):\n    return find_indices(x, lambda ch: ch == \'_\')\n\n\n@memoize\ndef question_mark_indices(x):\n    return find_indices(x, lambda ch: ch == \'?\')\n\n\n@memoize\ndef ampersand_indices(x):\n    return find_indices(x, lambda ch: ch == \'&\')\n\n\n@memoize\ndef digit_indices(x):\n    return find_indices(x, lambda ch: ch.isdigit())\n\n\n@memoize\ndef lowercase_indices(x):\n    return find_indices(x, lambda ch: \'a\' <= ch <= \'z\')\n\n\n@memoize\ndef uppercase_indices(x):\n    return find_indices(x, lambda ch: \'A\' <= ch <= \'Z\')\n\n\ndef calculate_similar_pattern(group1, group2):\n    feature_functions = {\n        \'dash_indices\': dash_indices,\n        \'dot_indices\': dot_indices,\n        \'underscore_indices\': underscore_indices,\n        \'question_mark_indices\': question_mark_indices,\n        \'ampersand_indices\': ampersand_indices,\n        \'digit_indices\': digit_indices,\n        \'lowercase_indices\': lowercase_indices,\n        \'uppercase_indices\': uppercase_indices\n    }\n\n    if group1 is None or group2 is None or len(group1) == 0 or len(group2) == 0:\n        return None\n\n    match_count_max = len(feature_functions)\n\n    match_counter = {}\n    for function_name, lambda_function in feature_functions.items():\n        def match_function(x, y):\n            return lambda_function(x) == lambda_function(y) and len(lambda_function(x))\n\n        for value1 in group1:\n            for value2 in group2:\n                match_counter_key = (value1, value2)\n                if match_counter_key not in match_counter:\n                    match_counter[match_counter_key] = []\n                if lambda_function(value1) == lambda_function(value2):\n                    bit = lambda_function(value1) == []\n                    match_counter[match_counter_key].append((function_name, bit))\n\n    return max(map(len, match_counter.values())) / float(match_count_max)\n\n\ndef hash_object(str_list_dict, anonymous_data):\n    if not anonymous_data:\n        return str_list_dict\n    if str_list_dict == "" or str_list_dict is None:\n        return str_list_dict\n    if (type(str_list_dict)) == dict:\n        return dict(map(lambda (k, v): (k, hash_object(v, anonymous_data)), str_list_dict.iteritems()))\n    if (type(str_list_dict) == list):\n        return map(lambda x: hash_object(x, anonymous_data), str_list_dict)\n\n    if (type(str_list_dict) in [str, unicode]):\n        str_value = str_list_dict.encode(\'utf-8\')\n    else:\n        str_value = str(str_list_dict)\n    return hashlib.md5(str_value).hexdigest()\n\ndef get_unique_key_for_pair(id1, id2):\n    key_tuple = (id1, id2) if id1 > id2 else (id2, id1)\n    return "%s_%s" % (key_tuple[0], key_tuple[1])\n\ndef create_or_condition(field, terms):\n    return " or ".join(map(lambda x: "%s:%s" % (field, x), terms))\n\n\ndef enrich_incidents_by_indicators(demisto, incident_list, max_number_of_indicators, indicators_for_jaccard=None):\n    query_part1 = create_or_condition("investigationIDs", map(lambda x: x[\'id\'], incident_list))\n    query_part2 = create_or_condition("type", indicators_for_jaccard) if indicators_for_jaccard else None\n    query = "(%s) and (%s)" % (query_part1, query_part2) if query_part2 else query_part1\n    res = demisto.executeCommand("findIndicators", {\'query\': query, \'size\': max_number_of_indicators})\n    indicators = res[0][\'Contents\']\n    incidents = {}\n    for incident in incident_list:\n        incident_id = incident[\'id\']\n        incidents[incident_id] = incident\n        incidents[incident_id][\'indicators\'] = {}\n\n    for indicator in indicators:\n        for incident_id in indicator[\'investigationIDs\']:\n            if incident_id in incidents:\n                indicator_type = indicator.get(\'indicator_type\')\n                indicator_value = indicator.get(\'value\')\n                if indicator_type is None or indicator_value is None:\n                    continue\n                if indicator_type not in incidents[incident_id][\'indicators\']:\n                    incidents[incident_id][\'indicators\'][indicator_type] = []\n                incidents[incident_id][\'indicators\'][indicator_type].append(indicator_value)\n\n    return incidents''')
      __stickytape_write_module('''libs/tldextract.py''', '''# -*- coding: utf-8 -*-\n"""`tldextract` accurately separates the gTLD or ccTLD (generic or country code\ntop-level domain) from the registered domain and subdomains of a URL.\n\n    >>> import tldextract\n\n    >>> tldextract.extract(\'http://forums.news.cnn.com/\')\n    ExtractResult(subdomain=\'forums.news\', domain=\'cnn\', suffix=\'com\')\n\n    >>> tldextract.extract(\'http://forums.bbc.co.uk/\') # United Kingdom\n    ExtractResult(subdomain=\'forums\', domain=\'bbc\', suffix=\'co.uk\')\n\n    >>> tldextract.extract(\'http://www.worldbank.org.kg/\') # Kyrgyzstan\n    ExtractResult(subdomain=\'www\', domain=\'worldbank\', suffix=\'org.kg\')\n\n`ExtractResult` is a namedtuple, so it\'s simple to access the parts you want.\n\n    >>> ext = tldextract.extract(\'http://forums.bbc.co.uk\')\n    >>> (ext.subdomain, ext.domain, ext.suffix)\n    (\'forums\', \'bbc\', \'co.uk\')\n    >>> # rejoin subdomain and domain\n    >>> \'.\'.join(ext[:2])\n    \'forums.bbc\'\n    >>> # a common alias\n    >>> ext.registered_domain\n    \'bbc.co.uk\'\n\nNote subdomain and suffix are _optional_. Not all URL-like inputs have a\nsubdomain or a valid suffix.\n\n    >>> tldextract.extract(\'google.com\')\n    ExtractResult(subdomain=\'\', domain=\'google\', suffix=\'com\')\n\n    >>> tldextract.extract(\'google.notavalidsuffix\')\n    ExtractResult(subdomain=\'google\', domain=\'notavalidsuffix\', suffix=\'\')\n\n    >>> tldextract.extract(\'http://127.0.0.1:8080/deployed/\')\n    ExtractResult(subdomain=\'\', domain=\'127.0.0.1\', suffix=\'\')\n\nIf you want to rejoin the whole namedtuple, regardless of whether a subdomain\nor suffix were found:\n\n    >>> ext = tldextract.extract(\'http://127.0.0.1:8080/deployed/\')\n    >>> # this has unwanted dots\n    >>> \'.\'.join(ext)\n    \'.127.0.0.1.\'\n    >>> # join part only if truthy\n    >>> \'.\'.join(part for part in ext if part)\n    \'127.0.0.1\'\n"""\n\n\nimport collections\nimport socket\nfrom contextlib import closing\nimport errno\nfrom functools import wraps\nimport json\nimport logging\nimport os\nimport re\n\ntry:\n    import pkg_resources\nexcept ImportError:\n    class pkg_resources(object):  # pylint: disable=invalid-name\n\n        """Fake pkg_resources interface which falls back to getting resources\n        inside `tldextract`\'s directory.\n        """\n        @classmethod\n        def resource_stream(cls, _, resource_name):\n            moddir = os.path.dirname(__file__)\n            path = os.path.join(moddir, resource_name)\n            return open(path)\n\nfrom urlparse import scheme_chars\nIP_RE = re.compile(r\'^(([0-9]|[1-9][0-9]|1[0-9]{2}|2[0-4][0-9]|25[0-5])\\.){3}([0-9]|[1-9][0-9]|1[0-9]{2}|2[0-4][0-9]|25[0-5])$\')  # pylint: disable=line-too-long\nSCHEME_RE = re.compile(r\'^([\' + scheme_chars + \']+:)?//\')\n\ndef looks_like_ip(maybe_ip):\n    """Does the given str look like an IP address?"""\n    if not maybe_ip[0].isdigit():\n        return False\n\n    try:\n        socket.inet_aton(maybe_ip)\n        return True\n    except (AttributeError, UnicodeError):\n        if IP_RE.match(maybe_ip):\n            return True\n    except socket.error:\n        return False\n\n# pylint: disable=invalid-name,undefined-variable\ntry:\n    STRING_TYPE = basestring\nexcept NameError:\n    STRING_TYPE = str\n# pylint: enable=invalid-name,undefined-variable\n\n\nLOG = logging.getLogger("tldextract")\n\nCACHE_FILE_DEFAULT = os.path.join(os.path.dirname(__file__), \'.tld_set\')\nCACHE_FILE = os.path.expanduser(os.environ.get("TLDEXTRACT_CACHE", CACHE_FILE_DEFAULT))\nCACHE_TIMEOUT = os.environ.get(\'TLDEXTRACT_CACHE_TIMEOUT\')\n\nPUBLIC_SUFFIX_LIST_URLS = (\n    \'https://publicsuffix.org/list/public_suffix_list.dat\',\n    \'https://raw.githubusercontent.com/publicsuffix/list/master/public_suffix_list.dat\',\n)\n\nPUBLIC_SUFFIX_RE = re.compile(r\'^(?P<suffix>[.*!]*\\w[\\S]*)\', re.UNICODE | re.MULTILINE)\n\n\nclass ExtractResult(collections.namedtuple(\'ExtractResult\', \'subdomain domain suffix\')):\n    \'\'\'namedtuple of a URL\'s subdomain, domain, and suffix.\'\'\'\n\n    # Necessary for __dict__ member to get populated in Python 3+\n    __slots__ = ()\n\n    @property\n    def registered_domain(self):\n        """\n        Joins the domain and suffix fields with a dot, if they\'re both set.\n\n        >>> extract(\'http://forums.bbc.co.uk\').registered_domain\n        \'bbc.co.uk\'\n        >>> extract(\'http://localhost:8080\').registered_domain\n        \'\'\n        """\n        if self.domain and self.suffix:\n            return self.domain + \'.\' + self.suffix\n        return \'\'\n\n    @property\n    def fqdn(self):\n        """\n        Returns a Fully Qualified Domain Name, if there is a proper domain/suffix.\n\n        >>> extract(\'http://forums.bbc.co.uk/path/to/file\').fqdn\n        \'forums.bbc.co.uk\'\n        >>> extract(\'http://localhost:8080\').fqdn\n        \'\'\n        """\n        if self.domain and self.suffix:\n            # self is the namedtuple (subdomain domain suffix)\n            return \'.\'.join(i for i in self if i)\n        return \'\'\n\n    @property\n    def ipv4(self):\n        """\n        Returns the ipv4 if that is what the presented domain/url is\n\n        >>> extract(\'http://127.0.0.1/path/to/file\').ipv4\n        \'127.0.0.1\'\n        >>> extract(\'http://127.0.0.1.1/path/to/file\').ipv4\n        \'\'\n        >>> extract(\'http://256.1.1.1\').ipv4\n        \'\'\n        """\n        if not (self.suffix or self.subdomain) and IP_RE.match(self.domain):\n            return self.domain\n        return \'\'\n\n\nclass TLDExtract(object):\n    \'\'\'A callable for extracting, subdomain, domain, and suffix components from\n    a URL.\'\'\'\n\n    # TODO: Agreed with Pylint: too-many-arguments\n    def __init__(self, cache_file=CACHE_FILE, suffix_list_urls=PUBLIC_SUFFIX_LIST_URLS,  # pylint: disable=too-many-arguments\n                 fallback_to_snapshot=True, include_psl_private_domains=False, extra_suffixes=(),\n                 cache_fetch_timeout=CACHE_TIMEOUT):\n        """\n        Constructs a callable for extracting subdomain, domain, and suffix\n        components from a URL.\n\n        Upon calling it, it first checks for a JSON `cache_file`.\n        By default, the `cache_file` will live in the tldextract directory.\n\n        You can disable the caching functionality of this module  by setting `cache_file` to False.\n\n        If the `cache_file` does not exist (such as on the first run), HTTP request the URLs in\n        `suffix_list_urls` in order, until one returns public suffix list data. To disable HTTP\n        requests, set this to something falsy.\n\n        The default list of URLs point to the latest version of the Mozilla Public Suffix List and\n        its mirror, but any similar document could be specified.\n\n        Local files can be specified by using the `file://` protocol. (See `urllib2` documentation.)\n\n        If there is no `cache_file` loaded and no data is found from the `suffix_list_urls`,\n        the module will fall back to the included TLD set snapshot. If you do not want\n        this behavior, you may set `fallback_to_snapshot` to False, and an exception will be\n        raised instead.\n\n        The Public Suffix List includes a list of "private domains" as TLDs,\n        such as blogspot.com. These do not fit `tldextract`\'s definition of a\n        suffix, so these domains are excluded by default. If you\'d like them\n        included instead, set `include_psl_private_domains` to True.\n\n        You can pass additional suffixes in `extra_suffixes` argument without changing list URL\n\n        cache_fetch_timeout is passed unmodified to the underlying request object\n        per the requests documentation here:\n        http://docs.python-requests.org/en/master/user/advanced/#timeouts\n\n        cache_fetch_timeout can also be set to a single value with the\n        environment variable TLDEXTRACT_CACHE_TIMEOUT, like so:\n\n        TLDEXTRACT_CACHE_TIMEOUT="1.2"\n\n        When set this way, the same timeout value will be used for both connect\n        and read timeouts\n        """\n        suffix_list_urls = suffix_list_urls or ()\n        self.suffix_list_urls = tuple(url.strip() for url in suffix_list_urls if url.strip())\n\n        self.cache_file = os.path.expanduser(cache_file or \'\')\n        self.fallback_to_snapshot = fallback_to_snapshot\n        if not (self.suffix_list_urls or self.cache_file or self.fallback_to_snapshot):\n            raise ValueError("The arguments you have provided disable all ways for tldextract "\n                             "to obtain data. Please provide a suffix list data, a cache_file, "\n                             "or set `fallback_to_snapshot` to `True`.")\n\n        self.include_psl_private_domains = include_psl_private_domains\n        self.extra_suffixes = extra_suffixes\n        self._extractor = None\n\n        self.cache_fetch_timeout = cache_fetch_timeout\n        if isinstance(self.cache_fetch_timeout, STRING_TYPE):\n            self.cache_fetch_timeout = float(self.cache_fetch_timeout)\n\n    def __call__(self, url):\n        """\n        Takes a string URL and splits it into its subdomain, domain, and\n        suffix (effective TLD, gTLD, ccTLD, etc.) component.\n\n        >>> extract = TLDExtract()\n        >>> extract(\'http://forums.news.cnn.com/\')\n        ExtractResult(subdomain=\'forums.news\', domain=\'cnn\', suffix=\'com\')\n        >>> extract(\'http://forums.bbc.co.uk/\')\n        ExtractResult(subdomain=\'forums\', domain=\'bbc\', suffix=\'co.uk\')\n        """\n        netloc = SCHEME_RE.sub("", url) \\\n            .partition("/")[0] \\\n            .partition("?")[0] \\\n            .partition("#")[0] \\\n            .split("@")[-1] \\\n            .partition(":")[0] \\\n            .strip() \\\n            .rstrip(".")\n\n        labels = netloc.split(".")\n\n        def decode_punycode(label):\n            return label\n\n        translations = [decode_punycode(label).lower() for label in labels]\n        suffix_index = self._get_tld_extractor().suffix_index(translations)\n\n        registered_domain = ".".join(labels[:suffix_index])\n        suffix = ".".join(labels[suffix_index:])\n\n        if not suffix and netloc and looks_like_ip(netloc):\n            return ExtractResult(\'\', netloc, \'\')\n\n        subdomain, _, domain = registered_domain.rpartition(\'.\')\n        return ExtractResult(subdomain, domain, suffix)\n\n    def update(self, fetch_now=False):\n        if os.path.exists(self.cache_file):\n            os.unlink(self.cache_file)\n        self._extractor = None\n        if fetch_now:\n            self._get_tld_extractor()\n\n    @property\n    def tlds(self):\n        return self._get_tld_extractor().tlds\n\n    def _get_tld_extractor(self):\n        \'\'\'Get or compute this object\'s TLDExtractor. Looks up the TLDExtractor\n        in roughly the following order, based on the settings passed to\n        __init__:\n\n        1. Memoized on `self`\n        2. Local system cache file\n        3. Remote PSL, over HTTP\n        4. Bundled PSL snapshot file\'\'\'\n        if self._extractor:\n            return self._extractor\n\n        tlds = ["ac", "com.ac", "edu.ac", "gov.ac", "net.ac", "mil.ac", "org.ac", "ad", "nom.ad", "ae", "co.ae", "net.ae", "org.ae", "sch.ae", "ac.ae", "gov.ae", "mil.ae", "aero", "accident-investigation.aero", "accident-prevention.aero", "aerobatic.aero", "aeroclub.aero", "aerodrome.aero", "agents.aero", "aircraft.aero", "airline.aero", "airport.aero", "air-surveillance.aero", "airtraffic.aero", "air-traffic-control.aero", "ambulance.aero", "amusement.aero", "association.aero", "author.aero", "ballooning.aero", "broker.aero", "caa.aero", "cargo.aero", "catering.aero", "certification.aero", "championship.aero", "charter.aero", "civilaviation.aero", "club.aero", "conference.aero", "consultant.aero", "consulting.aero", "control.aero", "council.aero", "crew.aero", "design.aero", "dgca.aero", "educator.aero", "emergency.aero", "engine.aero", "engineer.aero", "entertainment.aero", "equipment.aero", "exchange.aero", "express.aero", "federation.aero", "flight.aero", "freight.aero", "fuel.aero", "gliding.aero", "government.aero", "groundhandling.aero", "group.aero", "hanggliding.aero", "homebuilt.aero", "insurance.aero", "journal.aero", "journalist.aero", "leasing.aero", "logistics.aero", "magazine.aero", "maintenance.aero", "media.aero", "microlight.aero", "modelling.aero", "navigation.aero", "parachuting.aero", "paragliding.aero", "passenger-association.aero", "pilot.aero", "press.aero", "production.aero", "recreation.aero", "repbody.aero", "res.aero", "research.aero", "rotorcraft.aero", "safety.aero", "scientist.aero", "services.aero", "show.aero", "skydiving.aero", "software.aero", "student.aero", "trader.aero", "trading.aero", "trainer.aero", "union.aero", "workinggroup.aero", "works.aero", "af", "gov.af", "com.af", "org.af", "net.af", "edu.af", "ag", "com.ag", "org.ag", "net.ag", "co.ag", "nom.ag", "ai", "off.ai", "com.ai", "net.ai", "org.ai", "al", "com.al", "edu.al", "gov.al", "mil.al", "net.al", "org.al", "am", "ao", "ed.ao", "gv.ao", "og.ao", "co.ao", "pb.ao", "it.ao", "aq", "ar", "com.ar", "edu.ar", "gob.ar", "gov.ar", "int.ar", "mil.ar", "musica.ar", "net.ar", "org.ar", "tur.ar", "arpa", "e164.arpa", "in-addr.arpa", "ip6.arpa", "iris.arpa", "uri.arpa", "urn.arpa", "as", "gov.as", "asia", "at", "ac.at", "co.at", "gv.at", "or.at", "au", "com.au", "net.au", "org.au", "edu.au", "gov.au", "asn.au", "id.au", "info.au", "conf.au", "oz.au", "act.au", "nsw.au", "nt.au", "qld.au", "sa.au", "tas.au", "vic.au", "wa.au", "act.edu.au", "nsw.edu.au", "nt.edu.au", "qld.edu.au", "sa.edu.au", "tas.edu.au", "vic.edu.au", "wa.edu.au", "qld.gov.au", "sa.gov.au", "tas.gov.au", "vic.gov.au", "wa.gov.au", "aw", "com.aw", "ax", "az", "com.az", "net.az", "int.az", "gov.az", "org.az", "edu.az", "info.az", "pp.az", "mil.az", "name.az", "pro.az", "biz.az", "ba", "com.ba", "edu.ba", "gov.ba", "mil.ba", "net.ba", "org.ba", "bb", "biz.bb", "co.bb", "com.bb", "edu.bb", "gov.bb", "info.bb", "net.bb", "org.bb", "store.bb", "tv.bb", "*.bd", "be", "ac.be", "bf", "gov.bf", "bg", "a.bg", "b.bg", "c.bg", "d.bg", "e.bg", "f.bg", "g.bg", "h.bg", "i.bg", "j.bg", "k.bg", "l.bg", "m.bg", "n.bg", "o.bg", "p.bg", "q.bg", "r.bg", "s.bg", "t.bg", "u.bg", "v.bg", "w.bg", "x.bg", "y.bg", "z.bg", "0.bg", "1.bg", "2.bg", "3.bg", "4.bg", "5.bg", "6.bg", "7.bg", "8.bg", "9.bg", "bh", "com.bh", "edu.bh", "net.bh", "org.bh", "gov.bh", "bi", "co.bi", "com.bi", "edu.bi", "or.bi", "org.bi", "biz", "bj", "asso.bj", "barreau.bj", "gouv.bj", "bm", "com.bm", "edu.bm", "gov.bm", "net.bm", "org.bm", "*.bn", "bo", "com.bo", "edu.bo", "gov.bo", "gob.bo", "int.bo", "org.bo", "net.bo", "mil.bo", "tv.bo", "br", "abc.br", "adm.br", "adv.br", "agr.br", "aju.br", "am.br", "aparecida.br", "arq.br", "art.br", "ato.br", "b.br", "belem.br", "bhz.br", "bio.br", "blog.br", "bmd.br", "boavista.br", "bsb.br", "campinas.br", "caxias.br", "cim.br", "cng.br", "cnt.br", "com.br", "contagem.br", "coop.br", "cri.br", "cuiaba.br", "def.br", "ecn.br", "eco.br", "edu.br", "emp.br", "eng.br", "esp.br", "etc.br", "eti.br", "far.br", "feira.br", "flog.br", "floripa.br", "fm.br", "fnd.br", "fortal.br", "fot.br", "fst.br", "g12.br", "ggf.br", "goiania.br", "gov.br", "ac.gov.br", "al.gov.br", "am.gov.br", "ap.gov.br", "ba.gov.br", "ce.gov.br", "df.gov.br", "es.gov.br", "go.gov.br", "ma.gov.br", "mg.gov.br", "ms.gov.br", "mt.gov.br", "pa.gov.br", "pb.gov.br", "pe.gov.br", "pi.gov.br", "pr.gov.br", "rj.gov.br", "rn.gov.br", "ro.gov.br", "rr.gov.br", "rs.gov.br", "sc.gov.br", "se.gov.br", "sp.gov.br", "to.gov.br", "gru.br", "imb.br", "ind.br", "inf.br", "jab.br", "jampa.br", "jdf.br", "joinville.br", "jor.br", "jus.br", "leg.br", "lel.br", "londrina.br", "macapa.br", "maceio.br", "mat.br", "med.br", "mil.br", "morena.br", "mp.br", "mus.br", "natal.br", "net.br", "niteroi.br", "*.nom.br", "not.br", "ntr.br", "odo.br", "org.br", "osasco.br", "palmas.br", "poa.br", "ppg.br", "pro.br", "psc.br", "psi.br", "pvh.br", "qsl.br", "radio.br", "rec.br", "recife.br", "ribeirao.br", "rio.br", "riobranco.br", "salvador.br", "sampa.br", "sjc.br", "slg.br", "slz.br", "sorocaba.br", "srv.br", "taxi.br", "teo.br", "the.br", "tmp.br", "trd.br", "tur.br", "tv.br", "udi.br", "vet.br", "vix.br", "vlog.br", "wiki.br", "zlg.br", "bs", "com.bs", "net.bs", "org.bs", "edu.bs", "gov.bs", "bt", "com.bt", "edu.bt", "gov.bt", "net.bt", "org.bt", "bv", "bw", "co.bw", "org.bw", "by", "gov.by", "mil.by", "com.by", "of.by", "bz", "com.bz", "net.bz", "org.bz", "edu.bz", "gov.bz", "ca", "ab.ca", "bc.ca", "mb.ca", "nb.ca", "nf.ca", "nl.ca", "ns.ca", "nt.ca", "nu.ca", "on.ca", "pe.ca", "qc.ca", "sk.ca", "yk.ca", "gc.ca", "cat", "cc", "cd", "gov.cd", "cf", "cg", "ch", "ci", "org.ci", "or.ci", "com.ci", "co.ci", "edu.ci", "ed.ci", "ac.ci", "net.ci", "go.ci", "asso.ci", "a\\\\u00e9roport.ci", "int.ci", "presse.ci", "md.ci", "gouv.ci", "*.ck", "!www.ck", "cl", "gov.cl", "gob.cl", "co.cl", "mil.cl", "cm", "co.cm", "com.cm", "gov.cm", "net.cm", "cn", "ac.cn", "com.cn", "edu.cn", "gov.cn", "net.cn", "org.cn", "mil.cn", "\\\\u516c\\\\u53f8.cn", "\\\\u7f51\\\\u7edc.cn", "\\\\u7db2\\\\u7d61.cn", "ah.cn", "bj.cn", "cq.cn", "fj.cn", "gd.cn", "gs.cn", "gz.cn", "gx.cn", "ha.cn", "hb.cn", "he.cn", "hi.cn", "hl.cn", "hn.cn", "jl.cn", "js.cn", "jx.cn", "ln.cn", "nm.cn", "nx.cn", "qh.cn", "sc.cn", "sd.cn", "sh.cn", "sn.cn", "sx.cn", "tj.cn", "xj.cn", "xz.cn", "yn.cn", "zj.cn", "hk.cn", "mo.cn", "tw.cn", "co", "arts.co", "com.co", "edu.co", "firm.co", "gov.co", "info.co", "int.co", "mil.co", "net.co", "nom.co", "org.co", "rec.co", "web.co", "com", "coop", "cr", "ac.cr", "co.cr", "ed.cr", "fi.cr", "go.cr", "or.cr", "sa.cr", "cu", "com.cu", "edu.cu", "org.cu", "net.cu", "gov.cu", "inf.cu", "cv", "cw", "com.cw", "edu.cw", "net.cw", "org.cw", "cx", "gov.cx", "cy", "ac.cy", "biz.cy", "com.cy", "ekloges.cy", "gov.cy", "ltd.cy", "name.cy", "net.cy", "org.cy", "parliament.cy", "press.cy", "pro.cy", "tm.cy", "cz", "de", "dj", "dk", "dm", "com.dm", "net.dm", "org.dm", "edu.dm", "gov.dm", "do", "art.do", "com.do", "edu.do", "gob.do", "gov.do", "mil.do", "net.do", "org.do", "sld.do", "web.do", "dz", "com.dz", "org.dz", "net.dz", "gov.dz", "edu.dz", "asso.dz", "pol.dz", "art.dz", "ec", "com.ec", "info.ec", "net.ec", "fin.ec", "k12.ec", "med.ec", "pro.ec", "org.ec", "edu.ec", "gov.ec", "gob.ec", "mil.ec", "edu", "ee", "edu.ee", "gov.ee", "riik.ee", "lib.ee", "med.ee", "com.ee", "pri.ee", "aip.ee", "org.ee", "fie.ee", "eg", "com.eg", "edu.eg", "eun.eg", "gov.eg", "mil.eg", "name.eg", "net.eg", "org.eg", "sci.eg", "*.er", "es", "com.es", "nom.es", "org.es", "gob.es", "edu.es", "et", "com.et", "gov.et", "org.et", "edu.et", "biz.et", "name.et", "info.et", "net.et", "eu", "fi", "aland.fi", "*.fj", "*.fk", "fm", "fo", "fr", "com.fr", "asso.fr", "nom.fr", "prd.fr", "presse.fr", "tm.fr", "aeroport.fr", "assedic.fr", "avocat.fr", "avoues.fr", "cci.fr", "chambagri.fr", "chirurgiens-dentistes.fr", "experts-comptables.fr", "geometre-expert.fr", "gouv.fr", "greta.fr", "huissier-justice.fr", "medecin.fr", "notaires.fr", "pharmacien.fr", "port.fr", "veterinaire.fr", "ga", "gb", "gd", "ge", "com.ge", "edu.ge", "gov.ge", "org.ge", "mil.ge", "net.ge", "pvt.ge", "gf", "gg", "co.gg", "net.gg", "org.gg", "gh", "com.gh", "edu.gh", "gov.gh", "org.gh", "mil.gh", "gi", "com.gi", "ltd.gi", "gov.gi", "mod.gi", "edu.gi", "org.gi", "gl", "co.gl", "com.gl", "edu.gl", "net.gl", "org.gl", "gm", "gn", "ac.gn", "com.gn", "edu.gn", "gov.gn", "org.gn", "net.gn", "gov", "gp", "com.gp", "net.gp", "mobi.gp", "edu.gp", "org.gp", "asso.gp", "gq", "gr", "com.gr", "edu.gr", "net.gr", "org.gr", "gov.gr", "gs", "gt", "com.gt", "edu.gt", "gob.gt", "ind.gt", "mil.gt", "net.gt", "org.gt", "*.gu", "gw", "gy", "co.gy", "com.gy", "edu.gy", "gov.gy", "net.gy", "org.gy", "hk", "com.hk", "edu.hk", "gov.hk", "idv.hk", "net.hk", "org.hk", "\\\\u516c\\\\u53f8.hk", "\\\\u6559\\\\u80b2.hk", "\\\\u654e\\\\u80b2.hk", "\\\\u653f\\\\u5e9c.hk", "\\\\u500b\\\\u4eba.hk", "\\\\u4e2a\\\\u4eba.hk", "\\\\u7b87\\\\u4eba.hk", "\\\\u7db2\\\\u7edc.hk", "\\\\u7f51\\\\u7edc.hk", "\\\\u7ec4\\\\u7e54.hk", "\\\\u7db2\\\\u7d61.hk", "\\\\u7f51\\\\u7d61.hk", "\\\\u7ec4\\\\u7ec7.hk", "\\\\u7d44\\\\u7e54.hk", "\\\\u7d44\\\\u7ec7.hk", "hm", "hn", "com.hn", "edu.hn", "org.hn", "net.hn", "mil.hn", "gob.hn", "hr", "iz.hr", "from.hr", "name.hr", "com.hr", "ht", "com.ht", "shop.ht", "firm.ht", "info.ht", "adult.ht", "net.ht", "pro.ht", "org.ht", "med.ht", "art.ht", "coop.ht", "pol.ht", "asso.ht", "edu.ht", "rel.ht", "gouv.ht", "perso.ht", "hu", "co.hu", "info.hu", "org.hu", "priv.hu", "sport.hu", "tm.hu", "2000.hu", "agrar.hu", "bolt.hu", "casino.hu", "city.hu", "erotica.hu", "erotika.hu", "film.hu", "forum.hu", "games.hu", "hotel.hu", "ingatlan.hu", "jogasz.hu", "konyvelo.hu", "lakas.hu", "media.hu", "news.hu", "reklam.hu", "sex.hu", "shop.hu", "suli.hu", "szex.hu", "tozsde.hu", "utazas.hu", "video.hu", "id", "ac.id", "biz.id", "co.id", "desa.id", "go.id", "mil.id", "my.id", "net.id", "or.id", "sch.id", "web.id", "ie", "gov.ie", "il", "ac.il", "co.il", "gov.il", "idf.il", "k12.il", "muni.il", "net.il", "org.il", "im", "ac.im", "co.im", "com.im", "ltd.co.im", "net.im", "org.im", "plc.co.im", "tt.im", "tv.im", "in", "co.in", "firm.in", "net.in", "org.in", "gen.in", "ind.in", "nic.in", "ac.in", "edu.in", "res.in", "gov.in", "mil.in", "info", "int", "eu.int", "io", "com.io", "iq", "gov.iq", "edu.iq", "mil.iq", "com.iq", "org.iq", "net.iq", "ir", "ac.ir", "co.ir", "gov.ir", "id.ir", "net.ir", "org.ir", "sch.ir", "\\\\u0627\\\\u06cc\\\\u0631\\\\u0627\\\\u0646.ir", "\\\\u0627\\\\u064a\\\\u0631\\\\u0627\\\\u0646.ir", "is", "net.is", "com.is", "edu.is", "gov.is", "org.is", "int.is", "it", "gov.it", "edu.it", "abr.it", "abruzzo.it", "aosta-valley.it", "aostavalley.it", "bas.it", "basilicata.it", "cal.it", "calabria.it", "cam.it", "campania.it", "emilia-romagna.it", "emiliaromagna.it", "emr.it", "friuli-v-giulia.it", "friuli-ve-giulia.it", "friuli-vegiulia.it", "friuli-venezia-giulia.it", "friuli-veneziagiulia.it", "friuli-vgiulia.it", "friuliv-giulia.it", "friulive-giulia.it", "friulivegiulia.it", "friulivenezia-giulia.it", "friuliveneziagiulia.it", "friulivgiulia.it", "fvg.it", "laz.it", "lazio.it", "lig.it", "liguria.it", "lom.it", "lombardia.it", "lombardy.it", "lucania.it", "mar.it", "marche.it", "mol.it", "molise.it", "piedmont.it", "piemonte.it", "pmn.it", "pug.it", "puglia.it", "sar.it", "sardegna.it", "sardinia.it", "sic.it", "sicilia.it", "sicily.it", "taa.it", "tos.it", "toscana.it", "trentino-a-adige.it", "trentino-aadige.it", "trentino-alto-adige.it", "trentino-altoadige.it", "trentino-s-tirol.it", "trentino-stirol.it", "trentino-sud-tirol.it", "trentino-sudtirol.it", "trentino-sued-tirol.it", "trentino-suedtirol.it", "trentinoa-adige.it", "trentinoaadige.it", "trentinoalto-adige.it", "trentinoaltoadige.it", "trentinos-tirol.it", "trentinostirol.it", "trentinosud-tirol.it", "trentinosudtirol.it", "trentinosued-tirol.it", "trentinosuedtirol.it", "tuscany.it", "umb.it", "umbria.it", "val-d-aosta.it", "val-daosta.it", "vald-aosta.it", "valdaosta.it", "valle-aosta.it", "valle-d-aosta.it", "valle-daosta.it", "valleaosta.it", "valled-aosta.it", "valledaosta.it", "vallee-aoste.it", "valleeaoste.it", "vao.it", "vda.it", "ven.it", "veneto.it", "ag.it", "agrigento.it", "al.it", "alessandria.it", "alto-adige.it", "altoadige.it", "an.it", "ancona.it", "andria-barletta-trani.it", "andria-trani-barletta.it", "andriabarlettatrani.it", "andriatranibarletta.it", "ao.it", "aosta.it", "aoste.it", "ap.it", "aq.it", "aquila.it", "ar.it", "arezzo.it", "ascoli-piceno.it", "ascolipiceno.it", "asti.it", "at.it", "av.it", "avellino.it", "ba.it", "balsan.it", "bari.it", "barletta-trani-andria.it", "barlettatraniandria.it", "belluno.it", "benevento.it", "bergamo.it", "bg.it", "bi.it", "biella.it", "bl.it", "bn.it", "bo.it", "bologna.it", "bolzano.it", "bozen.it", "br.it", "brescia.it", "brindisi.it", "bs.it", "bt.it", "bz.it", "ca.it", "cagliari.it", "caltanissetta.it", "campidano-medio.it", "campidanomedio.it", "campobasso.it", "carbonia-iglesias.it", "carboniaiglesias.it", "carrara-massa.it", "carraramassa.it", "caserta.it", "catania.it", "catanzaro.it", "cb.it", "ce.it", "cesena-forli.it", "cesenaforli.it", "ch.it", "chieti.it", "ci.it", "cl.it", "cn.it", "co.it", "como.it", "cosenza.it", "cr.it", "cremona.it", "crotone.it", "cs.it", "ct.it", "cuneo.it", "cz.it", "dell-ogliastra.it", "dellogliastra.it", "en.it", "enna.it", "fc.it", "fe.it", "fermo.it", "ferrara.it", "fg.it", "fi.it", "firenze.it", "florence.it", "fm.it", "foggia.it", "forli-cesena.it", "forlicesena.it", "fr.it", "frosinone.it", "ge.it", "genoa.it", "genova.it", "go.it", "gorizia.it", "gr.it", "grosseto.it", "iglesias-carbonia.it", "iglesiascarbonia.it", "im.it", "imperia.it", "is.it", "isernia.it", "kr.it", "la-spezia.it", "laquila.it", "laspezia.it", "latina.it", "lc.it", "le.it", "lecce.it", "lecco.it", "li.it", "livorno.it", "lo.it", "lodi.it", "lt.it", "lu.it", "lucca.it", "macerata.it", "mantova.it", "massa-carrara.it", "massacarrara.it", "matera.it", "mb.it", "mc.it", "me.it", "medio-campidano.it", "mediocampidano.it", "messina.it", "mi.it", "milan.it", "milano.it", "mn.it", "mo.it", "modena.it", "monza-brianza.it", "monza-e-della-brianza.it", "monza.it", "monzabrianza.it", "monzaebrianza.it", "monzaedellabrianza.it", "ms.it", "mt.it", "na.it", "naples.it", "napoli.it", "no.it", "novara.it", "nu.it", "nuoro.it", "og.it", "ogliastra.it", "olbia-tempio.it", "olbiatempio.it", "or.it", "oristano.it", "ot.it", "pa.it", "padova.it", "padua.it", "palermo.it", "parma.it", "pavia.it", "pc.it", "pd.it", "pe.it", "perugia.it", "pesaro-urbino.it", "pesarourbino.it", "pescara.it", "pg.it", "pi.it", "piacenza.it", "pisa.it", "pistoia.it", "pn.it", "po.it", "pordenone.it", "potenza.it", "pr.it", "prato.it", "pt.it", "pu.it", "pv.it", "pz.it", "ra.it", "ragusa.it", "ravenna.it", "rc.it", "re.it", "reggio-calabria.it", "reggio-emilia.it", "reggiocalabria.it", "reggioemilia.it", "rg.it", "ri.it", "rieti.it", "rimini.it", "rm.it", "rn.it", "ro.it", "roma.it", "rome.it", "rovigo.it", "sa.it", "salerno.it", "sassari.it", "savona.it", "si.it", "siena.it", "siracusa.it", "so.it", "sondrio.it", "sp.it", "sr.it", "ss.it", "suedtirol.it", "sv.it", "ta.it", "taranto.it", "te.it", "tempio-olbia.it", "tempioolbia.it", "teramo.it", "terni.it", "tn.it", "to.it", "torino.it", "tp.it", "tr.it", "trani-andria-barletta.it", "trani-barletta-andria.it", "traniandriabarletta.it", "tranibarlettaandria.it", "trapani.it", "trentino.it", "trento.it", "treviso.it", "trieste.it", "ts.it", "turin.it", "tv.it", "ud.it", "udine.it", "urbino-pesaro.it", "urbinopesaro.it", "va.it", "varese.it", "vb.it", "vc.it", "ve.it", "venezia.it", "venice.it", "verbania.it", "vercelli.it", "verona.it", "vi.it", "vibo-valentia.it", "vibovalentia.it", "vicenza.it", "viterbo.it", "vr.it", "vs.it", "vt.it", "vv.it", "je", "co.je", "net.je", "org.je", "*.jm", "jo", "com.jo", "org.jo", "net.jo", "edu.jo", "sch.jo", "gov.jo", "mil.jo", "name.jo", "jobs", "jp", "ac.jp", "ad.jp", "co.jp", "ed.jp", "go.jp", "gr.jp", "lg.jp", "ne.jp", "or.jp", "aichi.jp", "akita.jp", "aomori.jp", "chiba.jp", "ehime.jp", "fukui.jp", "fukuoka.jp", "fukushima.jp", "gifu.jp", "gunma.jp", "hiroshima.jp", "hokkaido.jp", "hyogo.jp", "ibaraki.jp", "ishikawa.jp", "iwate.jp", "kagawa.jp", "kagoshima.jp", "kanagawa.jp", "kochi.jp", "kumamoto.jp", "kyoto.jp", "mie.jp", "miyagi.jp", "miyazaki.jp", "nagano.jp", "nagasaki.jp", "nara.jp", "niigata.jp", "oita.jp", "okayama.jp", "okinawa.jp", "osaka.jp", "saga.jp", "saitama.jp", "shiga.jp", "shimane.jp", "shizuoka.jp", "tochigi.jp", "tokushima.jp", "tokyo.jp", "tottori.jp", "toyama.jp", "wakayama.jp", "yamagata.jp", "yamaguchi.jp", "yamanashi.jp", "\\\\u6803\\\\u6728.jp", "\\\\u611b\\\\u77e5.jp", "\\\\u611b\\\\u5a9b.jp", "\\\\u5175\\\\u5eab.jp", "\\\\u718a\\\\u672c.jp", "\\\\u8328\\\\u57ce.jp", "\\\\u5317\\\\u6d77\\\\u9053.jp", "\\\\u5343\\\\u8449.jp", "\\\\u548c\\\\u6b4c\\\\u5c71.jp", "\\\\u9577\\\\u5d0e.jp", "\\\\u9577\\\\u91ce.jp", "\\\\u65b0\\\\u6f5f.jp", "\\\\u9752\\\\u68ee.jp", "\\\\u9759\\\\u5ca1.jp", "\\\\u6771\\\\u4eac.jp", "\\\\u77f3\\\\u5ddd.jp", "\\\\u57fc\\\\u7389.jp", "\\\\u4e09\\\\u91cd.jp", "\\\\u4eac\\\\u90fd.jp", "\\\\u4f50\\\\u8cc0.jp", "\\\\u5927\\\\u5206.jp", "\\\\u5927\\\\u962a.jp", "\\\\u5948\\\\u826f.jp", "\\\\u5bae\\\\u57ce.jp", "\\\\u5bae\\\\u5d0e.jp", "\\\\u5bcc\\\\u5c71.jp", "\\\\u5c71\\\\u53e3.jp", "\\\\u5c71\\\\u5f62.jp", "\\\\u5c71\\\\u68a8.jp", "\\\\u5ca9\\\\u624b.jp", "\\\\u5c90\\\\u961c.jp", "\\\\u5ca1\\\\u5c71.jp", "\\\\u5cf6\\\\u6839.jp", "\\\\u5e83\\\\u5cf6.jp", "\\\\u5fb3\\\\u5cf6.jp", "\\\\u6c96\\\\u7e04.jp", "\\\\u6ecb\\\\u8cc0.jp", "\\\\u795e\\\\u5948\\\\u5ddd.jp", "\\\\u798f\\\\u4e95.jp", "\\\\u798f\\\\u5ca1.jp", "\\\\u798f\\\\u5cf6.jp", "\\\\u79cb\\\\u7530.jp", "\\\\u7fa4\\\\u99ac.jp", "\\\\u9999\\\\u5ddd.jp", "\\\\u9ad8\\\\u77e5.jp", "\\\\u9ce5\\\\u53d6.jp", "\\\\u9e7f\\\\u5150\\\\u5cf6.jp", "*.kawasaki.jp", "*.kitakyushu.jp", "*.kobe.jp", "*.nagoya.jp", "*.sapporo.jp", "*.sendai.jp", "*.yokohama.jp", "!city.kawasaki.jp", "!city.kitakyushu.jp", "!city.kobe.jp", "!city.nagoya.jp", "!city.sapporo.jp", "!city.sendai.jp", "!city.yokohama.jp", "aisai.aichi.jp", "ama.aichi.jp", "anjo.aichi.jp", "asuke.aichi.jp", "chiryu.aichi.jp", "chita.aichi.jp", "fuso.aichi.jp", "gamagori.aichi.jp", "handa.aichi.jp", "hazu.aichi.jp", "hekinan.aichi.jp", "higashiura.aichi.jp", "ichinomiya.aichi.jp", "inazawa.aichi.jp", "inuyama.aichi.jp", "isshiki.aichi.jp", "iwakura.aichi.jp", "kanie.aichi.jp", "kariya.aichi.jp", "kasugai.aichi.jp", "kira.aichi.jp", "kiyosu.aichi.jp", "komaki.aichi.jp", "konan.aichi.jp", "kota.aichi.jp", "mihama.aichi.jp", "miyoshi.aichi.jp", "nishio.aichi.jp", "nisshin.aichi.jp", "obu.aichi.jp", "oguchi.aichi.jp", "oharu.aichi.jp", "okazaki.aichi.jp", "owariasahi.aichi.jp", "seto.aichi.jp", "shikatsu.aichi.jp", "shinshiro.aichi.jp", "shitara.aichi.jp", "tahara.aichi.jp", "takahama.aichi.jp", "tobishima.aichi.jp", "toei.aichi.jp", "togo.aichi.jp", "tokai.aichi.jp", "tokoname.aichi.jp", "toyoake.aichi.jp", "toyohashi.aichi.jp", "toyokawa.aichi.jp", "toyone.aichi.jp", "toyota.aichi.jp", "tsushima.aichi.jp", "yatomi.aichi.jp", "akita.akita.jp", "daisen.akita.jp", "fujisato.akita.jp", "gojome.akita.jp", "hachirogata.akita.jp", "happou.akita.jp", "higashinaruse.akita.jp", "honjo.akita.jp", "honjyo.akita.jp", "ikawa.akita.jp", "kamikoani.akita.jp", "kamioka.akita.jp", "katagami.akita.jp", "kazuno.akita.jp", "kitaakita.akita.jp", "kosaka.akita.jp", "kyowa.akita.jp", "misato.akita.jp", "mitane.akita.jp", "moriyoshi.akita.jp", "nikaho.akita.jp", "noshiro.akita.jp", "odate.akita.jp", "oga.akita.jp", "ogata.akita.jp", "semboku.akita.jp", "yokote.akita.jp", "yurihonjo.akita.jp", "aomori.aomori.jp", "gonohe.aomori.jp", "hachinohe.aomori.jp", "hashikami.aomori.jp", "hiranai.aomori.jp", "hirosaki.aomori.jp", "itayanagi.aomori.jp", "kuroishi.aomori.jp", "misawa.aomori.jp", "mutsu.aomori.jp", "nakadomari.aomori.jp", "noheji.aomori.jp", "oirase.aomori.jp", "owani.aomori.jp", "rokunohe.aomori.jp", "sannohe.aomori.jp", "shichinohe.aomori.jp", "shingo.aomori.jp", "takko.aomori.jp", "towada.aomori.jp", "tsugaru.aomori.jp", "tsuruta.aomori.jp", "abiko.chiba.jp", "asahi.chiba.jp", "chonan.chiba.jp", "chosei.chiba.jp", "choshi.chiba.jp", "chuo.chiba.jp", "funabashi.chiba.jp", "futtsu.chiba.jp", "hanamigawa.chiba.jp", "ichihara.chiba.jp", "ichikawa.chiba.jp", "ichinomiya.chiba.jp", "inzai.chiba.jp", "isumi.chiba.jp", "kamagaya.chiba.jp", "kamogawa.chiba.jp", "kashiwa.chiba.jp", "katori.chiba.jp", "katsuura.chiba.jp", "kimitsu.chiba.jp", "kisarazu.chiba.jp", "kozaki.chiba.jp", "kujukuri.chiba.jp", "kyonan.chiba.jp", "matsudo.chiba.jp", "midori.chiba.jp", "mihama.chiba.jp", "minamiboso.chiba.jp", "mobara.chiba.jp", "mutsuzawa.chiba.jp", "nagara.chiba.jp", "nagareyama.chiba.jp", "narashino.chiba.jp", "narita.chiba.jp", "noda.chiba.jp", "oamishirasato.chiba.jp", "omigawa.chiba.jp", "onjuku.chiba.jp", "otaki.chiba.jp", "sakae.chiba.jp", "sakura.chiba.jp", "shimofusa.chiba.jp", "shirako.chiba.jp", "shiroi.chiba.jp", "shisui.chiba.jp", "sodegaura.chiba.jp", "sosa.chiba.jp", "tako.chiba.jp", "tateyama.chiba.jp", "togane.chiba.jp", "tohnosho.chiba.jp", "tomisato.chiba.jp", "urayasu.chiba.jp", "yachimata.chiba.jp", "yachiyo.chiba.jp", "yokaichiba.chiba.jp", "yokoshibahikari.chiba.jp", "yotsukaido.chiba.jp", "ainan.ehime.jp", "honai.ehime.jp", "ikata.ehime.jp", "imabari.ehime.jp", "iyo.ehime.jp", "kamijima.ehime.jp", "kihoku.ehime.jp", "kumakogen.ehime.jp", "masaki.ehime.jp", "matsuno.ehime.jp", "matsuyama.ehime.jp", "namikata.ehime.jp", "niihama.ehime.jp", "ozu.ehime.jp", "saijo.ehime.jp", "seiyo.ehime.jp", "shikokuchuo.ehime.jp", "tobe.ehime.jp", "toon.ehime.jp", "uchiko.ehime.jp", "uwajima.ehime.jp", "yawatahama.ehime.jp", "echizen.fukui.jp", "eiheiji.fukui.jp", "fukui.fukui.jp", "ikeda.fukui.jp", "katsuyama.fukui.jp", "mihama.fukui.jp", "minamiechizen.fukui.jp", "obama.fukui.jp", "ohi.fukui.jp", "ono.fukui.jp", "sabae.fukui.jp", "sakai.fukui.jp", "takahama.fukui.jp", "tsuruga.fukui.jp", "wakasa.fukui.jp", "ashiya.fukuoka.jp", "buzen.fukuoka.jp", "chikugo.fukuoka.jp", "chikuho.fukuoka.jp", "chikujo.fukuoka.jp", "chikushino.fukuoka.jp", "chikuzen.fukuoka.jp", "chuo.fukuoka.jp", "dazaifu.fukuoka.jp", "fukuchi.fukuoka.jp", "hakata.fukuoka.jp", "higashi.fukuoka.jp", "hirokawa.fukuoka.jp", "hisayama.fukuoka.jp", "iizuka.fukuoka.jp", "inatsuki.fukuoka.jp", "kaho.fukuoka.jp", "kasuga.fukuoka.jp", "kasuya.fukuoka.jp", "kawara.fukuoka.jp", "keisen.fukuoka.jp", "koga.fukuoka.jp", "kurate.fukuoka.jp", "kurogi.fukuoka.jp", "kurume.fukuoka.jp", "minami.fukuoka.jp", "miyako.fukuoka.jp", "miyama.fukuoka.jp", "miyawaka.fukuoka.jp", "mizumaki.fukuoka.jp", "munakata.fukuoka.jp", "nakagawa.fukuoka.jp", "nakama.fukuoka.jp", "nishi.fukuoka.jp", "nogata.fukuoka.jp", "ogori.fukuoka.jp", "okagaki.fukuoka.jp", "okawa.fukuoka.jp", "oki.fukuoka.jp", "omuta.fukuoka.jp", "onga.fukuoka.jp", "onojo.fukuoka.jp", "oto.fukuoka.jp", "saigawa.fukuoka.jp", "sasaguri.fukuoka.jp", "shingu.fukuoka.jp", "shinyoshitomi.fukuoka.jp", "shonai.fukuoka.jp", "soeda.fukuoka.jp", "sue.fukuoka.jp", "tachiarai.fukuoka.jp", "tagawa.fukuoka.jp", "takata.fukuoka.jp", "toho.fukuoka.jp", "toyotsu.fukuoka.jp", "tsuiki.fukuoka.jp", "ukiha.fukuoka.jp", "umi.fukuoka.jp", "usui.fukuoka.jp", "yamada.fukuoka.jp", "yame.fukuoka.jp", "yanagawa.fukuoka.jp", "yukuhashi.fukuoka.jp", "aizubange.fukushima.jp", "aizumisato.fukushima.jp", "aizuwakamatsu.fukushima.jp", "asakawa.fukushima.jp", "bandai.fukushima.jp", "date.fukushima.jp", "fukushima.fukushima.jp", "furudono.fukushima.jp", "futaba.fukushima.jp", "hanawa.fukushima.jp", "higashi.fukushima.jp", "hirata.fukushima.jp", "hirono.fukushima.jp", "iitate.fukushima.jp", "inawashiro.fukushima.jp", "ishikawa.fukushima.jp", "iwaki.fukushima.jp", "izumizaki.fukushima.jp", "kagamiishi.fukushima.jp", "kaneyama.fukushima.jp", "kawamata.fukushima.jp", "kitakata.fukushima.jp", "kitashiobara.fukushima.jp", "koori.fukushima.jp", "koriyama.fukushima.jp", "kunimi.fukushima.jp", "miharu.fukushima.jp", "mishima.fukushima.jp", "namie.fukushima.jp", "nango.fukushima.jp", "nishiaizu.fukushima.jp", "nishigo.fukushima.jp", "okuma.fukushima.jp", "omotego.fukushima.jp", "ono.fukushima.jp", "otama.fukushima.jp", "samegawa.fukushima.jp", "shimogo.fukushima.jp", "shirakawa.fukushima.jp", "showa.fukushima.jp", "soma.fukushima.jp", "sukagawa.fukushima.jp", "taishin.fukushima.jp", "tamakawa.fukushima.jp", "tanagura.fukushima.jp", "tenei.fukushima.jp", "yabuki.fukushima.jp", "yamato.fukushima.jp", "yamatsuri.fukushima.jp", "yanaizu.fukushima.jp", "yugawa.fukushima.jp", "anpachi.gifu.jp", "ena.gifu.jp", "gifu.gifu.jp", "ginan.gifu.jp", "godo.gifu.jp", "gujo.gifu.jp", "hashima.gifu.jp", "hichiso.gifu.jp", "hida.gifu.jp", "higashishirakawa.gifu.jp", "ibigawa.gifu.jp", "ikeda.gifu.jp", "kakamigahara.gifu.jp", "kani.gifu.jp", "kasahara.gifu.jp", "kasamatsu.gifu.jp", "kawaue.gifu.jp", "kitagata.gifu.jp", "mino.gifu.jp", "minokamo.gifu.jp", "mitake.gifu.jp", "mizunami.gifu.jp", "motosu.gifu.jp", "nakatsugawa.gifu.jp", "ogaki.gifu.jp", "sakahogi.gifu.jp", "seki.gifu.jp", "sekigahara.gifu.jp", "shirakawa.gifu.jp", "tajimi.gifu.jp", "takayama.gifu.jp", "tarui.gifu.jp", "toki.gifu.jp", "tomika.gifu.jp", "wanouchi.gifu.jp", "yamagata.gifu.jp", "yaotsu.gifu.jp", "yoro.gifu.jp", "annaka.gunma.jp", "chiyoda.gunma.jp", "fujioka.gunma.jp", "higashiagatsuma.gunma.jp", "isesaki.gunma.jp", "itakura.gunma.jp", "kanna.gunma.jp", "kanra.gunma.jp", "katashina.gunma.jp", "kawaba.gunma.jp", "kiryu.gunma.jp", "kusatsu.gunma.jp", "maebashi.gunma.jp", "meiwa.gunma.jp", "midori.gunma.jp", "minakami.gunma.jp", "naganohara.gunma.jp", "nakanojo.gunma.jp", "nanmoku.gunma.jp", "numata.gunma.jp", "oizumi.gunma.jp", "ora.gunma.jp", "ota.gunma.jp", "shibukawa.gunma.jp", "shimonita.gunma.jp", "shinto.gunma.jp", "showa.gunma.jp", "takasaki.gunma.jp", "takayama.gunma.jp", "tamamura.gunma.jp", "tatebayashi.gunma.jp", "tomioka.gunma.jp", "tsukiyono.gunma.jp", "tsumagoi.gunma.jp", "ueno.gunma.jp", "yoshioka.gunma.jp", "asaminami.hiroshima.jp", "daiwa.hiroshima.jp", "etajima.hiroshima.jp", "fuchu.hiroshima.jp", "fukuyama.hiroshima.jp", "hatsukaichi.hiroshima.jp", "higashihiroshima.hiroshima.jp", "hongo.hiroshima.jp", "jinsekikogen.hiroshima.jp", "kaita.hiroshima.jp", "kui.hiroshima.jp", "kumano.hiroshima.jp", "kure.hiroshima.jp", "mihara.hiroshima.jp", "miyoshi.hiroshima.jp", "naka.hiroshima.jp", "onomichi.hiroshima.jp", "osakikamijima.hiroshima.jp", "otake.hiroshima.jp", "saka.hiroshima.jp", "sera.hiroshima.jp", "seranishi.hiroshima.jp", "shinichi.hiroshima.jp", "shobara.hiroshima.jp", "takehara.hiroshima.jp", "abashiri.hokkaido.jp", "abira.hokkaido.jp", "aibetsu.hokkaido.jp", "akabira.hokkaido.jp", "akkeshi.hokkaido.jp", "asahikawa.hokkaido.jp", "ashibetsu.hokkaido.jp", "ashoro.hokkaido.jp", "assabu.hokkaido.jp", "atsuma.hokkaido.jp", "bibai.hokkaido.jp", "biei.hokkaido.jp", "bifuka.hokkaido.jp", "bihoro.hokkaido.jp", "biratori.hokkaido.jp", "chippubetsu.hokkaido.jp", "chitose.hokkaido.jp", "date.hokkaido.jp", "ebetsu.hokkaido.jp", "embetsu.hokkaido.jp", "eniwa.hokkaido.jp", "erimo.hokkaido.jp", "esan.hokkaido.jp", "esashi.hokkaido.jp", "fukagawa.hokkaido.jp", "fukushima.hokkaido.jp", "furano.hokkaido.jp", "furubira.hokkaido.jp", "haboro.hokkaido.jp", "hakodate.hokkaido.jp", "hamatonbetsu.hokkaido.jp", "hidaka.hokkaido.jp", "higashikagura.hokkaido.jp", "higashikawa.hokkaido.jp", "hiroo.hokkaido.jp", "hokuryu.hokkaido.jp", "hokuto.hokkaido.jp", "honbetsu.hokkaido.jp", "horokanai.hokkaido.jp", "horonobe.hokkaido.jp", "ikeda.hokkaido.jp", "imakane.hokkaido.jp", "ishikari.hokkaido.jp", "iwamizawa.hokkaido.jp", "iwanai.hokkaido.jp", "kamifurano.hokkaido.jp", "kamikawa.hokkaido.jp", "kamishihoro.hokkaido.jp", "kamisunagawa.hokkaido.jp", "kamoenai.hokkaido.jp", "kayabe.hokkaido.jp", "kembuchi.hokkaido.jp", "kikonai.hokkaido.jp", "kimobetsu.hokkaido.jp", "kitahiroshima.hokkaido.jp", "kitami.hokkaido.jp", "kiyosato.hokkaido.jp", "koshimizu.hokkaido.jp", "kunneppu.hokkaido.jp", "kuriyama.hokkaido.jp", "kuromatsunai.hokkaido.jp", "kushiro.hokkaido.jp", "kutchan.hokkaido.jp", "kyowa.hokkaido.jp", "mashike.hokkaido.jp", "matsumae.hokkaido.jp", "mikasa.hokkaido.jp", "minamifurano.hokkaido.jp", "mombetsu.hokkaido.jp", "moseushi.hokkaido.jp", "mukawa.hokkaido.jp", "muroran.hokkaido.jp", "naie.hokkaido.jp", "nakagawa.hokkaido.jp", "nakasatsunai.hokkaido.jp", "nakatombetsu.hokkaido.jp", "nanae.hokkaido.jp", "nanporo.hokkaido.jp", "nayoro.hokkaido.jp", "nemuro.hokkaido.jp", "niikappu.hokkaido.jp", "niki.hokkaido.jp", "nishiokoppe.hokkaido.jp", "noboribetsu.hokkaido.jp", "numata.hokkaido.jp", "obihiro.hokkaido.jp", "obira.hokkaido.jp", "oketo.hokkaido.jp", "okoppe.hokkaido.jp", "otaru.hokkaido.jp", "otobe.hokkaido.jp", "otofuke.hokkaido.jp", "otoineppu.hokkaido.jp", "oumu.hokkaido.jp", "ozora.hokkaido.jp", "pippu.hokkaido.jp", "rankoshi.hokkaido.jp", "rebun.hokkaido.jp", "rikubetsu.hokkaido.jp", "rishiri.hokkaido.jp", "rishirifuji.hokkaido.jp", "saroma.hokkaido.jp", "sarufutsu.hokkaido.jp", "shakotan.hokkaido.jp", "shari.hokkaido.jp", "shibecha.hokkaido.jp", "shibetsu.hokkaido.jp", "shikabe.hokkaido.jp", "shikaoi.hokkaido.jp", "shimamaki.hokkaido.jp", "shimizu.hokkaido.jp", "shimokawa.hokkaido.jp", "shinshinotsu.hokkaido.jp", "shintoku.hokkaido.jp", "shiranuka.hokkaido.jp", "shiraoi.hokkaido.jp", "shiriuchi.hokkaido.jp", "sobetsu.hokkaido.jp", "sunagawa.hokkaido.jp", "taiki.hokkaido.jp", "takasu.hokkaido.jp", "takikawa.hokkaido.jp", "takinoue.hokkaido.jp", "teshikaga.hokkaido.jp", "tobetsu.hokkaido.jp", "tohma.hokkaido.jp", "tomakomai.hokkaido.jp", "tomari.hokkaido.jp", "toya.hokkaido.jp", "toyako.hokkaido.jp", "toyotomi.hokkaido.jp", "toyoura.hokkaido.jp", "tsubetsu.hokkaido.jp", "tsukigata.hokkaido.jp", "urakawa.hokkaido.jp", "urausu.hokkaido.jp", "uryu.hokkaido.jp", "utashinai.hokkaido.jp", "wakkanai.hokkaido.jp", "wassamu.hokkaido.jp", "yakumo.hokkaido.jp", "yoichi.hokkaido.jp", "aioi.hyogo.jp", "akashi.hyogo.jp", "ako.hyogo.jp", "amagasaki.hyogo.jp", "aogaki.hyogo.jp", "asago.hyogo.jp", "ashiya.hyogo.jp", "awaji.hyogo.jp", "fukusaki.hyogo.jp", "goshiki.hyogo.jp", "harima.hyogo.jp", "himeji.hyogo.jp", "ichikawa.hyogo.jp", "inagawa.hyogo.jp", "itami.hyogo.jp", "kakogawa.hyogo.jp", "kamigori.hyogo.jp", "kamikawa.hyogo.jp", "kasai.hyogo.jp", "kasuga.hyogo.jp", "kawanishi.hyogo.jp", "miki.hyogo.jp", "minamiawaji.hyogo.jp", "nishinomiya.hyogo.jp", "nishiwaki.hyogo.jp", "ono.hyogo.jp", "sanda.hyogo.jp", "sannan.hyogo.jp", "sasayama.hyogo.jp", "sayo.hyogo.jp", "shingu.hyogo.jp", "shinonsen.hyogo.jp", "shiso.hyogo.jp", "sumoto.hyogo.jp", "taishi.hyogo.jp", "taka.hyogo.jp", "takarazuka.hyogo.jp", "takasago.hyogo.jp", "takino.hyogo.jp", "tamba.hyogo.jp", "tatsuno.hyogo.jp", "toyooka.hyogo.jp", "yabu.hyogo.jp", "yashiro.hyogo.jp", "yoka.hyogo.jp", "yokawa.hyogo.jp", "ami.ibaraki.jp", "asahi.ibaraki.jp", "bando.ibaraki.jp", "chikusei.ibaraki.jp", "daigo.ibaraki.jp", "fujishiro.ibaraki.jp", "hitachi.ibaraki.jp", "hitachinaka.ibaraki.jp", "hitachiomiya.ibaraki.jp", "hitachiota.ibaraki.jp", "ibaraki.ibaraki.jp", "ina.ibaraki.jp", "inashiki.ibaraki.jp", "itako.ibaraki.jp", "iwama.ibaraki.jp", "joso.ibaraki.jp", "kamisu.ibaraki.jp", "kasama.ibaraki.jp", "kashima.ibaraki.jp", "kasumigaura.ibaraki.jp", "koga.ibaraki.jp", "miho.ibaraki.jp", "mito.ibaraki.jp", "moriya.ibaraki.jp", "naka.ibaraki.jp", "namegata.ibaraki.jp", "oarai.ibaraki.jp", "ogawa.ibaraki.jp", "omitama.ibaraki.jp", "ryugasaki.ibaraki.jp", "sakai.ibaraki.jp", "sakuragawa.ibaraki.jp", "shimodate.ibaraki.jp", "shimotsuma.ibaraki.jp", "shirosato.ibaraki.jp", "sowa.ibaraki.jp", "suifu.ibaraki.jp", "takahagi.ibaraki.jp", "tamatsukuri.ibaraki.jp", "tokai.ibaraki.jp", "tomobe.ibaraki.jp", "tone.ibaraki.jp", "toride.ibaraki.jp", "tsuchiura.ibaraki.jp", "tsukuba.ibaraki.jp", "uchihara.ibaraki.jp", "ushiku.ibaraki.jp", "yachiyo.ibaraki.jp", "yamagata.ibaraki.jp", "yawara.ibaraki.jp", "yuki.ibaraki.jp", "anamizu.ishikawa.jp", "hakui.ishikawa.jp", "hakusan.ishikawa.jp", "kaga.ishikawa.jp", "kahoku.ishikawa.jp", "kanazawa.ishikawa.jp", "kawakita.ishikawa.jp", "komatsu.ishikawa.jp", "nakanoto.ishikawa.jp", "nanao.ishikawa.jp", "nomi.ishikawa.jp", "nonoichi.ishikawa.jp", "noto.ishikawa.jp", "shika.ishikawa.jp", "suzu.ishikawa.jp", "tsubata.ishikawa.jp", "tsurugi.ishikawa.jp", "uchinada.ishikawa.jp", "wajima.ishikawa.jp", "fudai.iwate.jp", "fujisawa.iwate.jp", "hanamaki.iwate.jp", "hiraizumi.iwate.jp", "hirono.iwate.jp", "ichinohe.iwate.jp", "ichinoseki.iwate.jp", "iwaizumi.iwate.jp", "iwate.iwate.jp", "joboji.iwate.jp", "kamaishi.iwate.jp", "kanegasaki.iwate.jp", "karumai.iwate.jp", "kawai.iwate.jp", "kitakami.iwate.jp", "kuji.iwate.jp", "kunohe.iwate.jp", "kuzumaki.iwate.jp", "miyako.iwate.jp", "mizusawa.iwate.jp", "morioka.iwate.jp", "ninohe.iwate.jp", "noda.iwate.jp", "ofunato.iwate.jp", "oshu.iwate.jp", "otsuchi.iwate.jp", "rikuzentakata.iwate.jp", "shiwa.iwate.jp", "shizukuishi.iwate.jp", "sumita.iwate.jp", "tanohata.iwate.jp", "tono.iwate.jp", "yahaba.iwate.jp", "yamada.iwate.jp", "ayagawa.kagawa.jp", "higashikagawa.kagawa.jp", "kanonji.kagawa.jp", "kotohira.kagawa.jp", "manno.kagawa.jp", "marugame.kagawa.jp", "mitoyo.kagawa.jp", "naoshima.kagawa.jp", "sanuki.kagawa.jp", "tadotsu.kagawa.jp", "takamatsu.kagawa.jp", "tonosho.kagawa.jp", "uchinomi.kagawa.jp", "utazu.kagawa.jp", "zentsuji.kagawa.jp", "akune.kagoshima.jp", "amami.kagoshima.jp", "hioki.kagoshima.jp", "isa.kagoshima.jp", "isen.kagoshima.jp", "izumi.kagoshima.jp", "kagoshima.kagoshima.jp", "kanoya.kagoshima.jp", "kawanabe.kagoshima.jp", "kinko.kagoshima.jp", "kouyama.kagoshima.jp", "makurazaki.kagoshima.jp", "matsumoto.kagoshima.jp", "minamitane.kagoshima.jp", "nakatane.kagoshima.jp", "nishinoomote.kagoshima.jp", "satsumasendai.kagoshima.jp", "soo.kagoshima.jp", "tarumizu.kagoshima.jp", "yusui.kagoshima.jp", "aikawa.kanagawa.jp", "atsugi.kanagawa.jp", "ayase.kanagawa.jp", "chigasaki.kanagawa.jp", "ebina.kanagawa.jp", "fujisawa.kanagawa.jp", "hadano.kanagawa.jp", "hakone.kanagawa.jp", "hiratsuka.kanagawa.jp", "isehara.kanagawa.jp", "kaisei.kanagawa.jp", "kamakura.kanagawa.jp", "kiyokawa.kanagawa.jp", "matsuda.kanagawa.jp", "minamiashigara.kanagawa.jp", "miura.kanagawa.jp", "nakai.kanagawa.jp", "ninomiya.kanagawa.jp", "odawara.kanagawa.jp", "oi.kanagawa.jp", "oiso.kanagawa.jp", "sagamihara.kanagawa.jp", "samukawa.kanagawa.jp", "tsukui.kanagawa.jp", "yamakita.kanagawa.jp", "yamato.kanagawa.jp", "yokosuka.kanagawa.jp", "yugawara.kanagawa.jp", "zama.kanagawa.jp", "zushi.kanagawa.jp", "aki.kochi.jp", "geisei.kochi.jp", "hidaka.kochi.jp", "higashitsuno.kochi.jp", "ino.kochi.jp", "kagami.kochi.jp", "kami.kochi.jp", "kitagawa.kochi.jp", "kochi.kochi.jp", "mihara.kochi.jp", "motoyama.kochi.jp", "muroto.kochi.jp", "nahari.kochi.jp", "nakamura.kochi.jp", "nankoku.kochi.jp", "nishitosa.kochi.jp", "niyodogawa.kochi.jp", "ochi.kochi.jp", "okawa.kochi.jp", "otoyo.kochi.jp", "otsuki.kochi.jp", "sakawa.kochi.jp", "sukumo.kochi.jp", "susaki.kochi.jp", "tosa.kochi.jp", "tosashimizu.kochi.jp", "toyo.kochi.jp", "tsuno.kochi.jp", "umaji.kochi.jp", "yasuda.kochi.jp", "yusuhara.kochi.jp", "amakusa.kumamoto.jp", "arao.kumamoto.jp", "aso.kumamoto.jp", "choyo.kumamoto.jp", "gyokuto.kumamoto.jp", "kamiamakusa.kumamoto.jp", "kikuchi.kumamoto.jp", "kumamoto.kumamoto.jp", "mashiki.kumamoto.jp", "mifune.kumamoto.jp", "minamata.kumamoto.jp", "minamioguni.kumamoto.jp", "nagasu.kumamoto.jp", "nishihara.kumamoto.jp", "oguni.kumamoto.jp", "ozu.kumamoto.jp", "sumoto.kumamoto.jp", "takamori.kumamoto.jp", "uki.kumamoto.jp", "uto.kumamoto.jp", "yamaga.kumamoto.jp", "yamato.kumamoto.jp", "yatsushiro.kumamoto.jp", "ayabe.kyoto.jp", "fukuchiyama.kyoto.jp", "higashiyama.kyoto.jp", "ide.kyoto.jp", "ine.kyoto.jp", "joyo.kyoto.jp", "kameoka.kyoto.jp", "kamo.kyoto.jp", "kita.kyoto.jp", "kizu.kyoto.jp", "kumiyama.kyoto.jp", "kyotamba.kyoto.jp", "kyotanabe.kyoto.jp", "kyotango.kyoto.jp", "maizuru.kyoto.jp", "minami.kyoto.jp", "minamiyamashiro.kyoto.jp", "miyazu.kyoto.jp", "muko.kyoto.jp", "nagaokakyo.kyoto.jp", "nakagyo.kyoto.jp", "nantan.kyoto.jp", "oyamazaki.kyoto.jp", "sakyo.kyoto.jp", "seika.kyoto.jp", "tanabe.kyoto.jp", "uji.kyoto.jp", "ujitawara.kyoto.jp", "wazuka.kyoto.jp", "yamashina.kyoto.jp", "yawata.kyoto.jp", "asahi.mie.jp", "inabe.mie.jp", "ise.mie.jp", "kameyama.mie.jp", "kawagoe.mie.jp", "kiho.mie.jp", "kisosaki.mie.jp", "kiwa.mie.jp", "komono.mie.jp", "kumano.mie.jp", "kuwana.mie.jp", "matsusaka.mie.jp", "meiwa.mie.jp", "mihama.mie.jp", "minamiise.mie.jp", "misugi.mie.jp", "miyama.mie.jp", "nabari.mie.jp", "shima.mie.jp", "suzuka.mie.jp", "tado.mie.jp", "taiki.mie.jp", "taki.mie.jp", "tamaki.mie.jp", "toba.mie.jp", "tsu.mie.jp", "udono.mie.jp", "ureshino.mie.jp", "watarai.mie.jp", "yokkaichi.mie.jp", "furukawa.miyagi.jp", "higashimatsushima.miyagi.jp", "ishinomaki.miyagi.jp", "iwanuma.miyagi.jp", "kakuda.miyagi.jp", "kami.miyagi.jp", "kawasaki.miyagi.jp", "marumori.miyagi.jp", "matsushima.miyagi.jp", "minamisanriku.miyagi.jp", "misato.miyagi.jp", "murata.miyagi.jp", "natori.miyagi.jp", "ogawara.miyagi.jp", "ohira.miyagi.jp", "onagawa.miyagi.jp", "osaki.miyagi.jp", "rifu.miyagi.jp", "semine.miyagi.jp", "shibata.miyagi.jp", "shichikashuku.miyagi.jp", "shikama.miyagi.jp", "shiogama.miyagi.jp", "shiroishi.miyagi.jp", "tagajo.miyagi.jp", "taiwa.miyagi.jp", "tome.miyagi.jp", "tomiya.miyagi.jp", "wakuya.miyagi.jp", "watari.miyagi.jp", "yamamoto.miyagi.jp", "zao.miyagi.jp", "aya.miyazaki.jp", "ebino.miyazaki.jp", "gokase.miyazaki.jp", "hyuga.miyazaki.jp", "kadogawa.miyazaki.jp", "kawaminami.miyazaki.jp", "kijo.miyazaki.jp", "kitagawa.miyazaki.jp", "kitakata.miyazaki.jp", "kitaura.miyazaki.jp", "kobayashi.miyazaki.jp", "kunitomi.miyazaki.jp", "kushima.miyazaki.jp", "mimata.miyazaki.jp", "miyakonojo.miyazaki.jp", "miyazaki.miyazaki.jp", "morotsuka.miyazaki.jp", "nichinan.miyazaki.jp", "nishimera.miyazaki.jp", "nobeoka.miyazaki.jp", "saito.miyazaki.jp", "shiiba.miyazaki.jp", "shintomi.miyazaki.jp", "takaharu.miyazaki.jp", "takanabe.miyazaki.jp", "takazaki.miyazaki.jp", "tsuno.miyazaki.jp", "achi.nagano.jp", "agematsu.nagano.jp", "anan.nagano.jp", "aoki.nagano.jp", "asahi.nagano.jp", "azumino.nagano.jp", "chikuhoku.nagano.jp", "chikuma.nagano.jp", "chino.nagano.jp", "fujimi.nagano.jp", "hakuba.nagano.jp", "hara.nagano.jp", "hiraya.nagano.jp", "iida.nagano.jp", "iijima.nagano.jp", "iiyama.nagano.jp", "iizuna.nagano.jp", "ikeda.nagano.jp", "ikusaka.nagano.jp", "ina.nagano.jp", "karuizawa.nagano.jp", "kawakami.nagano.jp", "kiso.nagano.jp", "kisofukushima.nagano.jp", "kitaaiki.nagano.jp", "komagane.nagano.jp", "komoro.nagano.jp", "matsukawa.nagano.jp", "matsumoto.nagano.jp", "miasa.nagano.jp", "minamiaiki.nagano.jp", "minamimaki.nagano.jp", "minamiminowa.nagano.jp", "minowa.nagano.jp", "miyada.nagano.jp", "miyota.nagano.jp", "mochizuki.nagano.jp", "nagano.nagano.jp", "nagawa.nagano.jp", "nagiso.nagano.jp", "nakagawa.nagano.jp", "nakano.nagano.jp", "nozawaonsen.nagano.jp", "obuse.nagano.jp", "ogawa.nagano.jp", "okaya.nagano.jp", "omachi.nagano.jp", "omi.nagano.jp", "ookuwa.nagano.jp", "ooshika.nagano.jp", "otaki.nagano.jp", "otari.nagano.jp", "sakae.nagano.jp", "sakaki.nagano.jp", "saku.nagano.jp", "sakuho.nagano.jp", "shimosuwa.nagano.jp", "shinanomachi.nagano.jp", "shiojiri.nagano.jp", "suwa.nagano.jp", "suzaka.nagano.jp", "takagi.nagano.jp", "takamori.nagano.jp", "takayama.nagano.jp", "tateshina.nagano.jp", "tatsuno.nagano.jp", "togakushi.nagano.jp", "togura.nagano.jp", "tomi.nagano.jp", "ueda.nagano.jp", "wada.nagano.jp", "yamagata.nagano.jp", "yamanouchi.nagano.jp", "yasaka.nagano.jp", "yasuoka.nagano.jp", "chijiwa.nagasaki.jp", "futsu.nagasaki.jp", "goto.nagasaki.jp", "hasami.nagasaki.jp", "hirado.nagasaki.jp", "iki.nagasaki.jp", "isahaya.nagasaki.jp", "kawatana.nagasaki.jp", "kuchinotsu.nagasaki.jp", "matsuura.nagasaki.jp", "nagasaki.nagasaki.jp", "obama.nagasaki.jp", "omura.nagasaki.jp", "oseto.nagasaki.jp", "saikai.nagasaki.jp", "sasebo.nagasaki.jp", "seihi.nagasaki.jp", "shimabara.nagasaki.jp", "shinkamigoto.nagasaki.jp", "togitsu.nagasaki.jp", "tsushima.nagasaki.jp", "unzen.nagasaki.jp", "ando.nara.jp", "gose.nara.jp", "heguri.nara.jp", "higashiyoshino.nara.jp", "ikaruga.nara.jp", "ikoma.nara.jp", "kamikitayama.nara.jp", "kanmaki.nara.jp", "kashiba.nara.jp", "kashihara.nara.jp", "katsuragi.nara.jp", "kawai.nara.jp", "kawakami.nara.jp", "kawanishi.nara.jp", "koryo.nara.jp", "kurotaki.nara.jp", "mitsue.nara.jp", "miyake.nara.jp", "nara.nara.jp", "nosegawa.nara.jp", "oji.nara.jp", "ouda.nara.jp", "oyodo.nara.jp", "sakurai.nara.jp", "sango.nara.jp", "shimoichi.nara.jp", "shimokitayama.nara.jp", "shinjo.nara.jp", "soni.nara.jp", "takatori.nara.jp", "tawaramoto.nara.jp", "tenkawa.nara.jp", "tenri.nara.jp", "uda.nara.jp", "yamatokoriyama.nara.jp", "yamatotakada.nara.jp", "yamazoe.nara.jp", "yoshino.nara.jp", "aga.niigata.jp", "agano.niigata.jp", "gosen.niigata.jp", "itoigawa.niigata.jp", "izumozaki.niigata.jp", "joetsu.niigata.jp", "kamo.niigata.jp", "kariwa.niigata.jp", "kashiwazaki.niigata.jp", "minamiuonuma.niigata.jp", "mitsuke.niigata.jp", "muika.niigata.jp", "murakami.niigata.jp", "myoko.niigata.jp", "nagaoka.niigata.jp", "niigata.niigata.jp", "ojiya.niigata.jp", "omi.niigata.jp", "sado.niigata.jp", "sanjo.niigata.jp", "seiro.niigata.jp", "seirou.niigata.jp", "sekikawa.niigata.jp", "shibata.niigata.jp", "tagami.niigata.jp", "tainai.niigata.jp", "tochio.niigata.jp", "tokamachi.niigata.jp", "tsubame.niigata.jp", "tsunan.niigata.jp", "uonuma.niigata.jp", "yahiko.niigata.jp", "yoita.niigata.jp", "yuzawa.niigata.jp", "beppu.oita.jp", "bungoono.oita.jp", "bungotakada.oita.jp", "hasama.oita.jp", "hiji.oita.jp", "himeshima.oita.jp", "hita.oita.jp", "kamitsue.oita.jp", "kokonoe.oita.jp", "kuju.oita.jp", "kunisaki.oita.jp", "kusu.oita.jp", "oita.oita.jp", "saiki.oita.jp", "taketa.oita.jp", "tsukumi.oita.jp", "usa.oita.jp", "usuki.oita.jp", "yufu.oita.jp", "akaiwa.okayama.jp", "asakuchi.okayama.jp", "bizen.okayama.jp", "hayashima.okayama.jp", "ibara.okayama.jp", "kagamino.okayama.jp", "kasaoka.okayama.jp", "kibichuo.okayama.jp", "kumenan.okayama.jp", "kurashiki.okayama.jp", "maniwa.okayama.jp", "misaki.okayama.jp", "nagi.okayama.jp", "niimi.okayama.jp", "nishiawakura.okayama.jp", "okayama.okayama.jp", "satosho.okayama.jp", "setouchi.okayama.jp", "shinjo.okayama.jp", "shoo.okayama.jp", "soja.okayama.jp", "takahashi.okayama.jp", "tamano.okayama.jp", "tsuyama.okayama.jp", "wake.okayama.jp", "yakage.okayama.jp", "aguni.okinawa.jp", "ginowan.okinawa.jp", "ginoza.okinawa.jp", "gushikami.okinawa.jp", "haebaru.okinawa.jp", "higashi.okinawa.jp", "hirara.okinawa.jp", "iheya.okinawa.jp", "ishigaki.okinawa.jp", "ishikawa.okinawa.jp", "itoman.okinawa.jp", "izena.okinawa.jp", "kadena.okinawa.jp", "kin.okinawa.jp", "kitadaito.okinawa.jp", "kitanakagusuku.okinawa.jp", "kumejima.okinawa.jp", "kunigami.okinawa.jp", "minamidaito.okinawa.jp", "motobu.okinawa.jp", "nago.okinawa.jp", "naha.okinawa.jp", "nakagusuku.okinawa.jp", "nakijin.okinawa.jp", "nanjo.okinawa.jp", "nishihara.okinawa.jp", "ogimi.okinawa.jp", "okinawa.okinawa.jp", "onna.okinawa.jp", "shimoji.okinawa.jp", "taketomi.okinawa.jp", "tarama.okinawa.jp", "tokashiki.okinawa.jp", "tomigusuku.okinawa.jp", "tonaki.okinawa.jp", "urasoe.okinawa.jp", "uruma.okinawa.jp", "yaese.okinawa.jp", "yomitan.okinawa.jp", "yonabaru.okinawa.jp", "yonaguni.okinawa.jp", "zamami.okinawa.jp", "abeno.osaka.jp", "chihayaakasaka.osaka.jp", "chuo.osaka.jp", "daito.osaka.jp", "fujiidera.osaka.jp", "habikino.osaka.jp", "hannan.osaka.jp", "higashiosaka.osaka.jp", "higashisumiyoshi.osaka.jp", "higashiyodogawa.osaka.jp", "hirakata.osaka.jp", "ibaraki.osaka.jp", "ikeda.osaka.jp", "izumi.osaka.jp", "izumiotsu.osaka.jp", "izumisano.osaka.jp", "kadoma.osaka.jp", "kaizuka.osaka.jp", "kanan.osaka.jp", "kashiwara.osaka.jp", "katano.osaka.jp", "kawachinagano.osaka.jp", "kishiwada.osaka.jp", "kita.osaka.jp", "kumatori.osaka.jp", "matsubara.osaka.jp", "minato.osaka.jp", "minoh.osaka.jp", "misaki.osaka.jp", "moriguchi.osaka.jp", "neyagawa.osaka.jp", "nishi.osaka.jp", "nose.osaka.jp", "osakasayama.osaka.jp", "sakai.osaka.jp", "sayama.osaka.jp", "sennan.osaka.jp", "settsu.osaka.jp", "shijonawate.osaka.jp", "shimamoto.osaka.jp", "suita.osaka.jp", "tadaoka.osaka.jp", "taishi.osaka.jp", "tajiri.osaka.jp", "takaishi.osaka.jp", "takatsuki.osaka.jp", "tondabayashi.osaka.jp", "toyonaka.osaka.jp", "toyono.osaka.jp", "yao.osaka.jp", "ariake.saga.jp", "arita.saga.jp", "fukudomi.saga.jp", "genkai.saga.jp", "hamatama.saga.jp", "hizen.saga.jp", "imari.saga.jp", "kamimine.saga.jp", "kanzaki.saga.jp", "karatsu.saga.jp", "kashima.saga.jp", "kitagata.saga.jp", "kitahata.saga.jp", "kiyama.saga.jp", "kouhoku.saga.jp", "kyuragi.saga.jp", "nishiarita.saga.jp", "ogi.saga.jp", "omachi.saga.jp", "ouchi.saga.jp", "saga.saga.jp", "shiroishi.saga.jp", "taku.saga.jp", "tara.saga.jp", "tosu.saga.jp", "yoshinogari.saga.jp", "arakawa.saitama.jp", "asaka.saitama.jp", "chichibu.saitama.jp", "fujimi.saitama.jp", "fujimino.saitama.jp", "fukaya.saitama.jp", "hanno.saitama.jp", "hanyu.saitama.jp", "hasuda.saitama.jp", "hatogaya.saitama.jp", "hatoyama.saitama.jp", "hidaka.saitama.jp", "higashichichibu.saitama.jp", "higashimatsuyama.saitama.jp", "honjo.saitama.jp", "ina.saitama.jp", "iruma.saitama.jp", "iwatsuki.saitama.jp", "kamiizumi.saitama.jp", "kamikawa.saitama.jp", "kamisato.saitama.jp", "kasukabe.saitama.jp", "kawagoe.saitama.jp", "kawaguchi.saitama.jp", "kawajima.saitama.jp", "kazo.saitama.jp", "kitamoto.saitama.jp", "koshigaya.saitama.jp", "kounosu.saitama.jp", "kuki.saitama.jp", "kumagaya.saitama.jp", "matsubushi.saitama.jp", "minano.saitama.jp", "misato.saitama.jp", "miyashiro.saitama.jp", "miyoshi.saitama.jp", "moroyama.saitama.jp", "nagatoro.saitama.jp", "namegawa.saitama.jp", "niiza.saitama.jp", "ogano.saitama.jp", "ogawa.saitama.jp", "ogose.saitama.jp", "okegawa.saitama.jp", "omiya.saitama.jp", "otaki.saitama.jp", "ranzan.saitama.jp", "ryokami.saitama.jp", "saitama.saitama.jp", "sakado.saitama.jp", "satte.saitama.jp", "sayama.saitama.jp", "shiki.saitama.jp", "shiraoka.saitama.jp", "soka.saitama.jp", "sugito.saitama.jp", "toda.saitama.jp", "tokigawa.saitama.jp", "tokorozawa.saitama.jp", "tsurugashima.saitama.jp", "urawa.saitama.jp", "warabi.saitama.jp", "yashio.saitama.jp", "yokoze.saitama.jp", "yono.saitama.jp", "yorii.saitama.jp", "yoshida.saitama.jp", "yoshikawa.saitama.jp", "yoshimi.saitama.jp", "aisho.shiga.jp", "gamo.shiga.jp", "higashiomi.shiga.jp", "hikone.shiga.jp", "koka.shiga.jp", "konan.shiga.jp", "kosei.shiga.jp", "koto.shiga.jp", "kusatsu.shiga.jp", "maibara.shiga.jp", "moriyama.shiga.jp", "nagahama.shiga.jp", "nishiazai.shiga.jp", "notogawa.shiga.jp", "omihachiman.shiga.jp", "otsu.shiga.jp", "ritto.shiga.jp", "ryuoh.shiga.jp", "takashima.shiga.jp", "takatsuki.shiga.jp", "torahime.shiga.jp", "toyosato.shiga.jp", "yasu.shiga.jp", "akagi.shimane.jp", "ama.shimane.jp", "gotsu.shimane.jp", "hamada.shimane.jp", "higashiizumo.shimane.jp", "hikawa.shimane.jp", "hikimi.shimane.jp", "izumo.shimane.jp", "kakinoki.shimane.jp", "masuda.shimane.jp", "matsue.shimane.jp", "misato.shimane.jp", "nishinoshima.shimane.jp", "ohda.shimane.jp", "okinoshima.shimane.jp", "okuizumo.shimane.jp", "shimane.shimane.jp", "tamayu.shimane.jp", "tsuwano.shimane.jp", "unnan.shimane.jp", "yakumo.shimane.jp", "yasugi.shimane.jp", "yatsuka.shimane.jp", "arai.shizuoka.jp", "atami.shizuoka.jp", "fuji.shizuoka.jp", "fujieda.shizuoka.jp", "fujikawa.shizuoka.jp", "fujinomiya.shizuoka.jp", "fukuroi.shizuoka.jp", "gotemba.shizuoka.jp", "haibara.shizuoka.jp", "hamamatsu.shizuoka.jp", "higashiizu.shizuoka.jp", "ito.shizuoka.jp", "iwata.shizuoka.jp", "izu.shizuoka.jp", "izunokuni.shizuoka.jp", "kakegawa.shizuoka.jp", "kannami.shizuoka.jp", "kawanehon.shizuoka.jp", "kawazu.shizuoka.jp", "kikugawa.shizuoka.jp", "kosai.shizuoka.jp", "makinohara.shizuoka.jp", "matsuzaki.shizuoka.jp", "minamiizu.shizuoka.jp", "mishima.shizuoka.jp", "morimachi.shizuoka.jp", "nishiizu.shizuoka.jp", "numazu.shizuoka.jp", "omaezaki.shizuoka.jp", "shimada.shizuoka.jp", "shimizu.shizuoka.jp", "shimoda.shizuoka.jp", "shizuoka.shizuoka.jp", "susono.shizuoka.jp", "yaizu.shizuoka.jp", "yoshida.shizuoka.jp", "ashikaga.tochigi.jp", "bato.tochigi.jp", "haga.tochigi.jp", "ichikai.tochigi.jp", "iwafune.tochigi.jp", "kaminokawa.tochigi.jp", "kanuma.tochigi.jp", "karasuyama.tochigi.jp", "kuroiso.tochigi.jp", "mashiko.tochigi.jp", "mibu.tochigi.jp", "moka.tochigi.jp", "motegi.tochigi.jp", "nasu.tochigi.jp", "nasushiobara.tochigi.jp", "nikko.tochigi.jp", "nishikata.tochigi.jp", "nogi.tochigi.jp", "ohira.tochigi.jp", "ohtawara.tochigi.jp", "oyama.tochigi.jp", "sakura.tochigi.jp", "sano.tochigi.jp", "shimotsuke.tochigi.jp", "shioya.tochigi.jp", "takanezawa.tochigi.jp", "tochigi.tochigi.jp", "tsuga.tochigi.jp", "ujiie.tochigi.jp", "utsunomiya.tochigi.jp", "yaita.tochigi.jp", "aizumi.tokushima.jp", "anan.tokushima.jp", "ichiba.tokushima.jp", "itano.tokushima.jp", "kainan.tokushima.jp", "komatsushima.tokushima.jp", "matsushige.tokushima.jp", "mima.tokushima.jp", "minami.tokushima.jp", "miyoshi.tokushima.jp", "mugi.tokushima.jp", "nakagawa.tokushima.jp", "naruto.tokushima.jp", "sanagochi.tokushima.jp", "shishikui.tokushima.jp", "tokushima.tokushima.jp", "wajiki.tokushima.jp", "adachi.tokyo.jp", "akiruno.tokyo.jp", "akishima.tokyo.jp", "aogashima.tokyo.jp", "arakawa.tokyo.jp", "bunkyo.tokyo.jp", "chiyoda.tokyo.jp", "chofu.tokyo.jp", "chuo.tokyo.jp", "edogawa.tokyo.jp", "fuchu.tokyo.jp", "fussa.tokyo.jp", "hachijo.tokyo.jp", "hachioji.tokyo.jp", "hamura.tokyo.jp", "higashikurume.tokyo.jp", "higashimurayama.tokyo.jp", "higashiyamato.tokyo.jp", "hino.tokyo.jp", "hinode.tokyo.jp", "hinohara.tokyo.jp", "inagi.tokyo.jp", "itabashi.tokyo.jp", "katsushika.tokyo.jp", "kita.tokyo.jp", "kiyose.tokyo.jp", "kodaira.tokyo.jp", "koganei.tokyo.jp", "kokubunji.tokyo.jp", "komae.tokyo.jp", "koto.tokyo.jp", "kouzushima.tokyo.jp", "kunitachi.tokyo.jp", "machida.tokyo.jp", "meguro.tokyo.jp", "minato.tokyo.jp", "mitaka.tokyo.jp", "mizuho.tokyo.jp", "musashimurayama.tokyo.jp", "musashino.tokyo.jp", "nakano.tokyo.jp", "nerima.tokyo.jp", "ogasawara.tokyo.jp", "okutama.tokyo.jp", "ome.tokyo.jp", "oshima.tokyo.jp", "ota.tokyo.jp", "setagaya.tokyo.jp", "shibuya.tokyo.jp", "shinagawa.tokyo.jp", "shinjuku.tokyo.jp", "suginami.tokyo.jp", "sumida.tokyo.jp", "tachikawa.tokyo.jp", "taito.tokyo.jp", "tama.tokyo.jp", "toshima.tokyo.jp", "chizu.tottori.jp", "hino.tottori.jp", "kawahara.tottori.jp", "koge.tottori.jp", "kotoura.tottori.jp", "misasa.tottori.jp", "nanbu.tottori.jp", "nichinan.tottori.jp", "sakaiminato.tottori.jp", "tottori.tottori.jp", "wakasa.tottori.jp", "yazu.tottori.jp", "yonago.tottori.jp", "asahi.toyama.jp", "fuchu.toyama.jp", "fukumitsu.toyama.jp", "funahashi.toyama.jp", "himi.toyama.jp", "imizu.toyama.jp", "inami.toyama.jp", "johana.toyama.jp", "kamiichi.toyama.jp", "kurobe.toyama.jp", "nakaniikawa.toyama.jp", "namerikawa.toyama.jp", "nanto.toyama.jp", "nyuzen.toyama.jp", "oyabe.toyama.jp", "taira.toyama.jp", "takaoka.toyama.jp", "tateyama.toyama.jp", "toga.toyama.jp", "tonami.toyama.jp", "toyama.toyama.jp", "unazuki.toyama.jp", "uozu.toyama.jp", "yamada.toyama.jp", "arida.wakayama.jp", "aridagawa.wakayama.jp", "gobo.wakayama.jp", "hashimoto.wakayama.jp", "hidaka.wakayama.jp", "hirogawa.wakayama.jp", "inami.wakayama.jp", "iwade.wakayama.jp", "kainan.wakayama.jp", "kamitonda.wakayama.jp", "katsuragi.wakayama.jp", "kimino.wakayama.jp", "kinokawa.wakayama.jp", "kitayama.wakayama.jp", "koya.wakayama.jp", "koza.wakayama.jp", "kozagawa.wakayama.jp", "kudoyama.wakayama.jp", "kushimoto.wakayama.jp", "mihama.wakayama.jp", "misato.wakayama.jp", "nachikatsuura.wakayama.jp", "shingu.wakayama.jp", "shirahama.wakayama.jp", "taiji.wakayama.jp", "tanabe.wakayama.jp", "wakayama.wakayama.jp", "yuasa.wakayama.jp", "yura.wakayama.jp", "asahi.yamagata.jp", "funagata.yamagata.jp", "higashine.yamagata.jp", "iide.yamagata.jp", "kahoku.yamagata.jp", "kaminoyama.yamagata.jp", "kaneyama.yamagata.jp", "kawanishi.yamagata.jp", "mamurogawa.yamagata.jp", "mikawa.yamagata.jp", "murayama.yamagata.jp", "nagai.yamagata.jp", "nakayama.yamagata.jp", "nanyo.yamagata.jp", "nishikawa.yamagata.jp", "obanazawa.yamagata.jp", "oe.yamagata.jp", "oguni.yamagata.jp", "ohkura.yamagata.jp", "oishida.yamagata.jp", "sagae.yamagata.jp", "sakata.yamagata.jp", "sakegawa.yamagata.jp", "shinjo.yamagata.jp", "shirataka.yamagata.jp", "shonai.yamagata.jp", "takahata.yamagata.jp", "tendo.yamagata.jp", "tozawa.yamagata.jp", "tsuruoka.yamagata.jp", "yamagata.yamagata.jp", "yamanobe.yamagata.jp", "yonezawa.yamagata.jp", "yuza.yamagata.jp", "abu.yamaguchi.jp", "hagi.yamaguchi.jp", "hikari.yamaguchi.jp", "hofu.yamaguchi.jp", "iwakuni.yamaguchi.jp", "kudamatsu.yamaguchi.jp", "mitou.yamaguchi.jp", "nagato.yamaguchi.jp", "oshima.yamaguchi.jp", "shimonoseki.yamaguchi.jp", "shunan.yamaguchi.jp", "tabuse.yamaguchi.jp", "tokuyama.yamaguchi.jp", "toyota.yamaguchi.jp", "ube.yamaguchi.jp", "yuu.yamaguchi.jp", "chuo.yamanashi.jp", "doshi.yamanashi.jp", "fuefuki.yamanashi.jp", "fujikawa.yamanashi.jp", "fujikawaguchiko.yamanashi.jp", "fujiyoshida.yamanashi.jp", "hayakawa.yamanashi.jp", "hokuto.yamanashi.jp", "ichikawamisato.yamanashi.jp", "kai.yamanashi.jp", "kofu.yamanashi.jp", "koshu.yamanashi.jp", "kosuge.yamanashi.jp", "minami-alps.yamanashi.jp", "minobu.yamanashi.jp", "nakamichi.yamanashi.jp", "nanbu.yamanashi.jp", "narusawa.yamanashi.jp", "nirasaki.yamanashi.jp", "nishikatsura.yamanashi.jp", "oshino.yamanashi.jp", "otsuki.yamanashi.jp", "showa.yamanashi.jp", "tabayama.yamanashi.jp", "tsuru.yamanashi.jp", "uenohara.yamanashi.jp", "yamanakako.yamanashi.jp", "yamanashi.yamanashi.jp", "*.ke", "kg", "org.kg", "net.kg", "com.kg", "edu.kg", "gov.kg", "mil.kg", "*.kh", "ki", "edu.ki", "biz.ki", "net.ki", "org.ki", "gov.ki", "info.ki", "com.ki", "km", "org.km", "nom.km", "gov.km", "prd.km", "tm.km", "edu.km", "mil.km", "ass.km", "com.km", "coop.km", "asso.km", "presse.km", "medecin.km", "notaires.km", "pharmaciens.km", "veterinaire.km", "gouv.km", "kn", "net.kn", "org.kn", "edu.kn", "gov.kn", "kp", "com.kp", "edu.kp", "gov.kp", "org.kp", "rep.kp", "tra.kp", "kr", "ac.kr", "co.kr", "es.kr", "go.kr", "hs.kr", "kg.kr", "mil.kr", "ms.kr", "ne.kr", "or.kr", "pe.kr", "re.kr", "sc.kr", "busan.kr", "chungbuk.kr", "chungnam.kr", "daegu.kr", "daejeon.kr", "gangwon.kr", "gwangju.kr", "gyeongbuk.kr", "gyeonggi.kr", "gyeongnam.kr", "incheon.kr", "jeju.kr", "jeonbuk.kr", "jeonnam.kr", "seoul.kr", "ulsan.kr", "*.kw", "ky", "edu.ky", "gov.ky", "com.ky", "org.ky", "net.ky", "kz", "org.kz", "edu.kz", "net.kz", "gov.kz", "mil.kz", "com.kz", "la", "int.la", "net.la", "info.la", "edu.la", "gov.la", "per.la", "com.la", "org.la", "lb", "com.lb", "edu.lb", "gov.lb", "net.lb", "org.lb", "lc", "com.lc", "net.lc", "co.lc", "org.lc", "edu.lc", "gov.lc", "li", "lk", "gov.lk", "sch.lk", "net.lk", "int.lk", "com.lk", "org.lk", "edu.lk", "ngo.lk", "soc.lk", "web.lk", "ltd.lk", "assn.lk", "grp.lk", "hotel.lk", "ac.lk", "lr", "com.lr", "edu.lr", "gov.lr", "org.lr", "net.lr", "ls", "co.ls", "org.ls", "lt", "gov.lt", "lu", "lv", "com.lv", "edu.lv", "gov.lv", "org.lv", "mil.lv", "id.lv", "net.lv", "asn.lv", "conf.lv", "ly", "com.ly", "net.ly", "gov.ly", "plc.ly", "edu.ly", "sch.ly", "med.ly", "org.ly", "id.ly", "ma", "co.ma", "net.ma", "gov.ma", "org.ma", "ac.ma", "press.ma", "mc", "tm.mc", "asso.mc", "md", "me", "co.me", "net.me", "org.me", "edu.me", "ac.me", "gov.me", "its.me", "priv.me", "mg", "org.mg", "nom.mg", "gov.mg", "prd.mg", "tm.mg", "edu.mg", "mil.mg", "com.mg", "co.mg", "mh", "mil", "mk", "com.mk", "org.mk", "net.mk", "edu.mk", "gov.mk", "inf.mk", "name.mk", "ml", "com.ml", "edu.ml", "gouv.ml", "gov.ml", "net.ml", "org.ml", "presse.ml", "*.mm", "mn", "gov.mn", "edu.mn", "org.mn", "mo", "com.mo", "net.mo", "org.mo", "edu.mo", "gov.mo", "mobi", "mp", "mq", "mr", "gov.mr", "ms", "com.ms", "edu.ms", "gov.ms", "net.ms", "org.ms", "mt", "com.mt", "edu.mt", "net.mt", "org.mt", "mu", "com.mu", "net.mu", "org.mu", "gov.mu", "ac.mu", "co.mu", "or.mu", "museum", "academy.museum", "agriculture.museum", "air.museum", "airguard.museum", "alabama.museum", "alaska.museum", "amber.museum", "ambulance.museum", "american.museum", "americana.museum", "americanantiques.museum", "americanart.museum", "amsterdam.museum", "and.museum", "annefrank.museum", "anthro.museum", "anthropology.museum", "antiques.museum", "aquarium.museum", "arboretum.museum", "archaeological.museum", "archaeology.museum", "architecture.museum", "art.museum", "artanddesign.museum", "artcenter.museum", "artdeco.museum", "arteducation.museum", "artgallery.museum", "arts.museum", "artsandcrafts.museum", "asmatart.museum", "assassination.museum", "assisi.museum", "association.museum", "astronomy.museum", "atlanta.museum", "austin.museum", "australia.museum", "automotive.museum", "aviation.museum", "axis.museum", "badajoz.museum", "baghdad.museum", "bahn.museum", "bale.museum", "baltimore.museum", "barcelona.museum", "baseball.museum", "basel.museum", "baths.museum", "bauern.museum", "beauxarts.museum", "beeldengeluid.museum", "bellevue.museum", "bergbau.museum", "berkeley.museum", "berlin.museum", "bern.museum", "bible.museum", "bilbao.museum", "bill.museum", "birdart.museum", "birthplace.museum", "bonn.museum", "boston.museum", "botanical.museum", "botanicalgarden.museum", "botanicgarden.museum", "botany.museum", "brandywinevalley.museum", "brasil.museum", "bristol.museum", "british.museum", "britishcolumbia.museum", "broadcast.museum", "brunel.museum", "brussel.museum", "brussels.museum", "bruxelles.museum", "building.museum", "burghof.museum", "bus.museum", "bushey.museum", "cadaques.museum", "california.museum", "cambridge.museum", "can.museum", "canada.museum", "capebreton.museum", "carrier.museum", "cartoonart.museum", "casadelamoneda.museum", "castle.museum", "castres.museum", "celtic.museum", "center.museum", "chattanooga.museum", "cheltenham.museum", "chesapeakebay.museum", "chicago.museum", "children.museum", "childrens.museum", "childrensgarden.museum", "chiropractic.museum", "chocolate.museum", "christiansburg.museum", "cincinnati.museum", "cinema.museum", "circus.museum", "civilisation.museum", "civilization.museum", "civilwar.museum", "clinton.museum", "clock.museum", "coal.museum", "coastaldefence.museum", "cody.museum", "coldwar.museum", "collection.museum", "colonialwilliamsburg.museum", "coloradoplateau.museum", "columbia.museum", "columbus.museum", "communication.museum", "communications.museum", "community.museum", "computer.museum", "computerhistory.museum", "comunica\\\\u00e7\\\\u00f5es.museum", "contemporary.museum", "contemporaryart.museum", "convent.museum", "copenhagen.museum", "corporation.museum", "correios-e-telecomunica\\\\u00e7\\\\u00f5es.museum", "corvette.museum", "costume.museum", "countryestate.museum", "county.museum", "crafts.museum", "cranbrook.museum", "creation.museum", "cultural.museum", "culturalcenter.museum", "culture.museum", "cyber.museum", "cymru.museum", "dali.museum", "dallas.museum", "database.museum", "ddr.museum", "decorativearts.museum", "delaware.museum", "delmenhorst.museum", "denmark.museum", "depot.museum", "design.museum", "detroit.museum", "dinosaur.museum", "discovery.museum", "dolls.museum", "donostia.museum", "durham.museum", "eastafrica.museum", "eastcoast.museum", "education.museum", "educational.museum", "egyptian.museum", "eisenbahn.museum", "elburg.museum", "elvendrell.museum", "embroidery.museum", "encyclopedic.museum", "england.museum", "entomology.museum", "environment.museum", "environmentalconservation.museum", "epilepsy.museum", "essex.museum", "estate.museum", "ethnology.museum", "exeter.museum", "exhibition.museum", "family.museum", "farm.museum", "farmequipment.museum", "farmers.museum", "farmstead.museum", "field.museum", "figueres.museum", "filatelia.museum", "film.museum", "fineart.museum", "finearts.museum", "finland.museum", "flanders.museum", "florida.museum", "force.museum", "fortmissoula.museum", "fortworth.museum", "foundation.museum", "francaise.museum", "frankfurt.museum", "franziskaner.museum", "freemasonry.museum", "freiburg.museum", "fribourg.museum", "frog.museum", "fundacio.museum", "furniture.museum", "gallery.museum", "garden.museum", "gateway.museum", "geelvinck.museum", "gemological.museum", "geology.museum", "georgia.museum", "giessen.museum", "glas.museum", "glass.museum", "gorge.museum", "grandrapids.museum", "graz.museum", "guernsey.museum", "halloffame.museum", "hamburg.museum", "handson.museum", "harvestcelebration.museum", "hawaii.museum", "health.museum", "heimatunduhren.museum", "hellas.museum", "helsinki.museum", "hembygdsforbund.museum", "heritage.museum", "histoire.museum", "historical.museum", "historicalsociety.museum", "historichouses.museum", "historisch.museum", "historisches.museum", "history.museum", "historyofscience.museum", "horology.museum", "house.museum", "humanities.museum", "illustration.museum", "imageandsound.museum", "indian.museum", "indiana.museum", "indianapolis.museum", "indianmarket.museum", "intelligence.museum", "interactive.museum", "iraq.museum", "iron.museum", "isleofman.museum", "jamison.museum", "jefferson.museum", "jerusalem.museum", "jewelry.museum", "jewish.museum", "jewishart.museum", "jfk.museum", "journalism.museum", "judaica.museum", "judygarland.museum", "juedisches.museum", "juif.museum", "karate.museum", "karikatur.museum", "kids.museum", "koebenhavn.museum", "koeln.museum", "kunst.museum", "kunstsammlung.museum", "kunstunddesign.museum", "labor.museum", "labour.museum", "lajolla.museum", "lancashire.museum", "landes.museum", "lans.museum", "l\\\\u00e4ns.museum", "larsson.museum", "lewismiller.museum", "lincoln.museum", "linz.museum", "living.museum", "livinghistory.museum", "localhistory.museum", "london.museum", "losangeles.museum", "louvre.museum", "loyalist.museum", "lucerne.museum", "luxembourg.museum", "luzern.museum", "mad.museum", "madrid.museum", "mallorca.museum", "manchester.museum", "mansion.museum", "mansions.museum", "manx.museum", "marburg.museum", "maritime.museum", "maritimo.museum", "maryland.museum", "marylhurst.museum", "media.museum", "medical.museum", "medizinhistorisches.museum", "meeres.museum", "memorial.museum", "mesaverde.museum", "michigan.museum", "midatlantic.museum", "military.museum", "mill.museum", "miners.museum", "mining.museum", "minnesota.museum", "missile.museum", "missoula.museum", "modern.museum", "moma.museum", "money.museum", "monmouth.museum", "monticello.museum", "montreal.museum", "moscow.museum", "motorcycle.museum", "muenchen.museum", "muenster.museum", "mulhouse.museum", "muncie.museum", "museet.museum", "museumcenter.museum", "museumvereniging.museum", "music.museum", "national.museum", "nationalfirearms.museum", "nationalheritage.museum", "nativeamerican.museum", "naturalhistory.museum", "naturalhistorymuseum.museum", "naturalsciences.museum", "nature.museum", "naturhistorisches.museum", "natuurwetenschappen.museum", "naumburg.museum", "naval.museum", "nebraska.museum", "neues.museum", "newhampshire.museum", "newjersey.museum", "newmexico.museum", "newport.museum", "newspaper.museum", "newyork.museum", "niepce.museum", "norfolk.museum", "north.museum", "nrw.museum", "nuernberg.museum", "nuremberg.museum", "nyc.museum", "nyny.museum", "oceanographic.museum", "oceanographique.museum", "omaha.museum", "online.museum", "ontario.museum", "openair.museum", "oregon.museum", "oregontrail.museum", "otago.museum", "oxford.museum", "pacific.museum", "paderborn.museum", "palace.museum", "paleo.museum", "palmsprings.museum", "panama.museum", "paris.museum", "pasadena.museum", "pharmacy.museum", "philadelphia.museum", "philadelphiaarea.museum", "philately.museum", "phoenix.museum", "photography.museum", "pilots.museum", "pittsburgh.museum", "planetarium.museum", "plantation.museum", "plants.museum", "plaza.museum", "portal.museum", "portland.museum", "portlligat.museum", "posts-and-telecommunications.museum", "preservation.museum", "presidio.museum", "press.museum", "project.museum", "public.museum", "pubol.museum", "quebec.museum", "railroad.museum", "railway.museum", "research.museum", "resistance.museum", "riodejaneiro.museum", "rochester.museum", "rockart.museum", "roma.museum", "russia.museum", "saintlouis.museum", "salem.museum", "salvadordali.museum", "salzburg.museum", "sandiego.museum", "sanfrancisco.museum", "santabarbara.museum", "santacruz.museum", "santafe.museum", "saskatchewan.museum", "satx.museum", "savannahga.museum", "schlesisches.museum", "schoenbrunn.museum", "schokoladen.museum", "school.museum", "schweiz.museum", "science.museum", "scienceandhistory.museum", "scienceandindustry.museum", "sciencecenter.museum", "sciencecenters.museum", "science-fiction.museum", "sciencehistory.museum", "sciences.museum", "sciencesnaturelles.museum", "scotland.museum", "seaport.museum", "settlement.museum", "settlers.museum", "shell.museum", "sherbrooke.museum", "sibenik.museum", "silk.museum", "ski.museum", "skole.museum", "society.museum", "sologne.museum", "soundandvision.museum", "southcarolina.museum", "southwest.museum", "space.museum", "spy.museum", "square.museum", "stadt.museum", "stalbans.museum", "starnberg.museum", "state.museum", "stateofdelaware.museum", "station.museum", "steam.museum", "steiermark.museum", "stjohn.museum", "stockholm.museum", "stpetersburg.museum", "stuttgart.museum", "suisse.museum", "surgeonshall.museum", "surrey.museum", "svizzera.museum", "sweden.museum", "sydney.museum", "tank.museum", "tcm.museum", "technology.museum", "telekommunikation.museum", "television.museum", "texas.museum", "textile.museum", "theater.museum", "time.museum", "timekeeping.museum", "topology.museum", "torino.museum", "touch.museum", "town.museum", "transport.museum", "tree.museum", "trolley.museum", "trust.museum", "trustee.museum", "uhren.museum", "ulm.museum", "undersea.museum", "university.museum", "usa.museum", "usantiques.museum", "usarts.museum", "uscountryestate.museum", "usculture.museum", "usdecorativearts.museum", "usgarden.museum", "ushistory.museum", "ushuaia.museum", "uslivinghistory.museum", "utah.museum", "uvic.museum", "valley.museum", "vantaa.museum", "versailles.museum", "viking.museum", "village.museum", "virginia.museum", "virtual.museum", "virtuel.museum", "vlaanderen.museum", "volkenkunde.museum", "wales.museum", "wallonie.museum", "war.museum", "washingtondc.museum", "watchandclock.museum", "watch-and-clock.museum", "western.museum", "westfalen.museum", "whaling.museum", "wildlife.museum", "williamsburg.museum", "windmill.museum", "workshop.museum", "york.museum", "yorkshire.museum", "yosemite.museum", "youth.museum", "zoological.museum", "zoology.museum", "\\\\u05d9\\\\u05e8\\\\u05d5\\\\u05e9\\\\u05dc\\\\u05d9\\\\u05dd.museum", "\\\\u0438\\\\u043a\\\\u043e\\\\u043c.museum", "mv", "aero.mv", "biz.mv", "com.mv", "coop.mv", "edu.mv", "gov.mv", "info.mv", "int.mv", "mil.mv", "museum.mv", "name.mv", "net.mv", "org.mv", "pro.mv", "mw", "ac.mw", "biz.mw", "co.mw", "com.mw", "coop.mw", "edu.mw", "gov.mw", "int.mw", "museum.mw", "net.mw", "org.mw", "mx", "com.mx", "org.mx", "gob.mx", "edu.mx", "net.mx", "my", "com.my", "net.my", "org.my", "gov.my", "edu.my", "mil.my", "name.my", "mz", "ac.mz", "adv.mz", "co.mz", "edu.mz", "gov.mz", "mil.mz", "net.mz", "org.mz", "na", "info.na", "pro.na", "name.na", "school.na", "or.na", "dr.na", "us.na", "mx.na", "ca.na", "in.na", "cc.na", "tv.na", "ws.na", "mobi.na", "co.na", "com.na", "org.na", "name", "nc", "asso.nc", "nom.nc", "ne", "net", "nf", "com.nf", "net.nf", "per.nf", "rec.nf", "web.nf", "arts.nf", "firm.nf", "info.nf", "other.nf", "store.nf", "ng", "com.ng", "edu.ng", "gov.ng", "i.ng", "mil.ng", "mobi.ng", "name.ng", "net.ng", "org.ng", "sch.ng", "ni", "ac.ni", "biz.ni", "co.ni", "com.ni", "edu.ni", "gob.ni", "in.ni", "info.ni", "int.ni", "mil.ni", "net.ni", "nom.ni", "org.ni", "web.ni", "nl", "bv.nl", "no", "fhs.no", "vgs.no", "fylkesbibl.no", "folkebibl.no", "museum.no", "idrett.no", "priv.no", "mil.no", "stat.no", "dep.no", "kommune.no", "herad.no", "aa.no", "ah.no", "bu.no", "fm.no", "hl.no", "hm.no", "jan-mayen.no", "mr.no", "nl.no", "nt.no", "of.no", "ol.no", "oslo.no", "rl.no", "sf.no", "st.no", "svalbard.no", "tm.no", "tr.no", "va.no", "vf.no", "gs.aa.no", "gs.ah.no", "gs.bu.no", "gs.fm.no", "gs.hl.no", "gs.hm.no", "gs.jan-mayen.no", "gs.mr.no", "gs.nl.no", "gs.nt.no", "gs.of.no", "gs.ol.no", "gs.oslo.no", "gs.rl.no", "gs.sf.no", "gs.st.no", "gs.svalbard.no", "gs.tm.no", "gs.tr.no", "gs.va.no", "gs.vf.no", "akrehamn.no", "\\\\u00e5krehamn.no", "algard.no", "\\\\u00e5lg\\\\u00e5rd.no", "arna.no", "brumunddal.no", "bryne.no", "bronnoysund.no", "br\\\\u00f8nn\\\\u00f8ysund.no", "drobak.no", "dr\\\\u00f8bak.no", "egersund.no", "fetsund.no", "floro.no", "flor\\\\u00f8.no", "fredrikstad.no", "hokksund.no", "honefoss.no", "h\\\\u00f8nefoss.no", "jessheim.no", "jorpeland.no", "j\\\\u00f8rpeland.no", "kirkenes.no", "kopervik.no", "krokstadelva.no", "langevag.no", "langev\\\\u00e5g.no", "leirvik.no", "mjondalen.no", "mj\\\\u00f8ndalen.no", "mo-i-rana.no", "mosjoen.no", "mosj\\\\u00f8en.no", "nesoddtangen.no", "orkanger.no", "osoyro.no", "os\\\\u00f8yro.no", "raholt.no", "r\\\\u00e5holt.no", "sandnessjoen.no", "sandnessj\\\\u00f8en.no", "skedsmokorset.no", "slattum.no", "spjelkavik.no", "stathelle.no", "stavern.no", "stjordalshalsen.no", "stj\\\\u00f8rdalshalsen.no", "tananger.no", "tranby.no", "vossevangen.no", "afjord.no", "\\\\u00e5fjord.no", "agdenes.no", "al.no", "\\\\u00e5l.no", "alesund.no", "\\\\u00e5lesund.no", "alstahaug.no", "alta.no", "\\\\u00e1lt\\\\u00e1.no", "alaheadju.no", "\\\\u00e1laheadju.no", "alvdal.no", "amli.no", "\\\\u00e5mli.no", "amot.no", "\\\\u00e5mot.no", "andebu.no", "andoy.no", "and\\\\u00f8y.no", "andasuolo.no", "ardal.no", "\\\\u00e5rdal.no", "aremark.no", "arendal.no", "\\\\u00e5s.no", "aseral.no", "\\\\u00e5seral.no", "asker.no", "askim.no", "askvoll.no", "askoy.no", "ask\\\\u00f8y.no", "asnes.no", "\\\\u00e5snes.no", "audnedaln.no", "aukra.no", "aure.no", "aurland.no", "aurskog-holand.no", "aurskog-h\\\\u00f8land.no", "austevoll.no", "austrheim.no", "averoy.no", "aver\\\\u00f8y.no", "balestrand.no", "ballangen.no", "balat.no", "b\\\\u00e1l\\\\u00e1t.no", "balsfjord.no", "bahccavuotna.no", "b\\\\u00e1hccavuotna.no", "bamble.no", "bardu.no", "beardu.no", "beiarn.no", "bajddar.no", "b\\\\u00e1jddar.no", "baidar.no", "b\\\\u00e1id\\\\u00e1r.no", "berg.no", "bergen.no", "berlevag.no", "berlev\\\\u00e5g.no", "bearalvahki.no", "bearalv\\\\u00e1hki.no", "bindal.no", "birkenes.no", "bjarkoy.no", "bjark\\\\u00f8y.no", "bjerkreim.no", "bjugn.no", "bodo.no", "bod\\\\u00f8.no", "badaddja.no", "b\\\\u00e5d\\\\u00e5ddj\\\\u00e5.no", "budejju.no", "bokn.no", "bremanger.no", "bronnoy.no", "br\\\\u00f8nn\\\\u00f8y.no", "bygland.no", "bykle.no", "barum.no", "b\\\\u00e6rum.no", "bo.telemark.no", "b\\\\u00f8.telemark.no", "bo.nordland.no", "b\\\\u00f8.nordland.no", "bievat.no", "biev\\\\u00e1t.no", "bomlo.no", "b\\\\u00f8mlo.no", "batsfjord.no", "b\\\\u00e5tsfjord.no", "bahcavuotna.no", "b\\\\u00e1hcavuotna.no", "dovre.no", "drammen.no", "drangedal.no", "dyroy.no", "dyr\\\\u00f8y.no", "donna.no", "d\\\\u00f8nna.no", "eid.no", "eidfjord.no", "eidsberg.no", "eidskog.no", "eidsvoll.no", "eigersund.no", "elverum.no", "enebakk.no", "engerdal.no", "etne.no", "etnedal.no", "evenes.no", "evenassi.no", "even\\\\u00e1\\\\u0161\\\\u0161i.no", "evje-og-hornnes.no", "farsund.no", "fauske.no", "fuossko.no", "fuoisku.no", "fedje.no", "fet.no", "finnoy.no", "finn\\\\u00f8y.no", "fitjar.no", "fjaler.no", "fjell.no", "flakstad.no", "flatanger.no", "flekkefjord.no", "flesberg.no", "flora.no", "fla.no", "fl\\\\u00e5.no", "folldal.no", "forsand.no", "fosnes.no", "frei.no", "frogn.no", "froland.no", "frosta.no", "frana.no", "fr\\\\u00e6na.no", "froya.no", "fr\\\\u00f8ya.no", "fusa.no", "fyresdal.no", "forde.no", "f\\\\u00f8rde.no", "gamvik.no", "gangaviika.no", "g\\\\u00e1\\\\u014bgaviika.no", "gaular.no", "gausdal.no", "gildeskal.no", "gildesk\\\\u00e5l.no", "giske.no", "gjemnes.no", "gjerdrum.no", "gjerstad.no", "gjesdal.no", "gjovik.no", "gj\\\\u00f8vik.no", "gloppen.no", "gol.no", "gran.no", "grane.no", "granvin.no", "gratangen.no", "grimstad.no", "grong.no", "kraanghke.no", "kr\\\\u00e5anghke.no", "grue.no", "gulen.no", "hadsel.no", "halden.no", "halsa.no", "hamar.no", "hamaroy.no", "habmer.no", "h\\\\u00e1bmer.no", "hapmir.no", "h\\\\u00e1pmir.no", "hammerfest.no", "hammarfeasta.no", "h\\\\u00e1mm\\\\u00e1rfeasta.no", "haram.no", "hareid.no", "harstad.no", "hasvik.no", "aknoluokta.no", "\\\\u00e1k\\\\u014boluokta.no", "hattfjelldal.no", "aarborte.no", "haugesund.no", "hemne.no", "hemnes.no", "hemsedal.no", "heroy.more-og-romsdal.no", "her\\\\u00f8y.m\\\\u00f8re-og-romsdal.no", "heroy.nordland.no", "her\\\\u00f8y.nordland.no", "hitra.no", "hjartdal.no", "hjelmeland.no", "hobol.no", "hob\\\\u00f8l.no", "hof.no", "hol.no", "hole.no", "holmestrand.no", "holtalen.no", "holt\\\\u00e5len.no", "hornindal.no", "horten.no", "hurdal.no", "hurum.no", "hvaler.no", "hyllestad.no", "hagebostad.no", "h\\\\u00e6gebostad.no", "hoyanger.no", "h\\\\u00f8yanger.no", "hoylandet.no", "h\\\\u00f8ylandet.no", "ha.no", "h\\\\u00e5.no", "ibestad.no", "inderoy.no", "inder\\\\u00f8y.no", "iveland.no", "jevnaker.no", "jondal.no", "jolster.no", "j\\\\u00f8lster.no", "karasjok.no", "karasjohka.no", "k\\\\u00e1r\\\\u00e1\\\\u0161johka.no", "karlsoy.no", "galsa.no", "g\\\\u00e1ls\\\\u00e1.no", "karmoy.no", "karm\\\\u00f8y.no", "kautokeino.no", "guovdageaidnu.no", "klepp.no", "klabu.no", "kl\\\\u00e6bu.no", "kongsberg.no", "kongsvinger.no", "kragero.no", "krager\\\\u00f8.no", "kristiansand.no", "kristiansund.no", "krodsherad.no", "kr\\\\u00f8dsherad.no", "kvalsund.no", "rahkkeravju.no", "r\\\\u00e1hkker\\\\u00e1vju.no", "kvam.no", "kvinesdal.no", "kvinnherad.no", "kviteseid.no", "kvitsoy.no", "kvits\\\\u00f8y.no", "kvafjord.no", "kv\\\\u00e6fjord.no", "giehtavuoatna.no", "kvanangen.no", "kv\\\\u00e6nangen.no", "navuotna.no", "n\\\\u00e1vuotna.no", "kafjord.no", "k\\\\u00e5fjord.no", "gaivuotna.no", "g\\\\u00e1ivuotna.no", "larvik.no", "lavangen.no", "lavagis.no", "loabat.no", "loab\\\\u00e1t.no", "lebesby.no", "davvesiida.no", "leikanger.no", "leirfjord.no", "leka.no", "leksvik.no", "lenvik.no", "leangaviika.no", "lea\\\\u014bgaviika.no", "lesja.no", "levanger.no", "lier.no", "lierne.no", "lillehammer.no", "lillesand.no", "lindesnes.no", "lindas.no", "lind\\\\u00e5s.no", "lom.no", "loppa.no", "lahppi.no", "l\\\\u00e1hppi.no", "lund.no", "lunner.no", "luroy.no", "lur\\\\u00f8y.no", "luster.no", "lyngdal.no", "lyngen.no", "ivgu.no", "lardal.no", "lerdal.no", "l\\\\u00e6rdal.no", "lodingen.no", "l\\\\u00f8dingen.no", "lorenskog.no", "l\\\\u00f8renskog.no", "loten.no", "l\\\\u00f8ten.no", "malvik.no", "masoy.no", "m\\\\u00e5s\\\\u00f8y.no", "muosat.no", "muos\\\\u00e1t.no", "mandal.no", "marker.no", "marnardal.no", "masfjorden.no", "meland.no", "meldal.no", "melhus.no", "meloy.no", "mel\\\\u00f8y.no", "meraker.no", "mer\\\\u00e5ker.no", "moareke.no", "mo\\\\u00e5reke.no", "midsund.no", "midtre-gauldal.no", "modalen.no", "modum.no", "molde.no", "moskenes.no", "moss.no", "mosvik.no", "malselv.no", "m\\\\u00e5lselv.no", "malatvuopmi.no", "m\\\\u00e1latvuopmi.no", "namdalseid.no", "aejrie.no", "namsos.no", "namsskogan.no", "naamesjevuemie.no", "n\\\\u00e5\\\\u00e5mesjevuemie.no", "laakesvuemie.no", "nannestad.no", "narvik.no", "narviika.no", "naustdal.no", "nedre-eiker.no", "nes.akershus.no", "nes.buskerud.no", "nesna.no", "nesodden.no", "nesseby.no", "unjarga.no", "unj\\\\u00e1rga.no", "nesset.no", "nissedal.no", "nittedal.no", "nord-aurdal.no", "nord-fron.no", "nord-odal.no", "norddal.no", "nordkapp.no", "davvenjarga.no", "davvenj\\\\u00e1rga.no", "nordre-land.no", "nordreisa.no", "raisa.no", "r\\\\u00e1isa.no", "nore-og-uvdal.no", "notodden.no", "naroy.no", "n\\\\u00e6r\\\\u00f8y.no", "notteroy.no", "n\\\\u00f8tter\\\\u00f8y.no", "odda.no", "oksnes.no", "\\\\u00f8ksnes.no", "oppdal.no", "oppegard.no", "oppeg\\\\u00e5rd.no", "orkdal.no", "orland.no", "\\\\u00f8rland.no", "orskog.no", "\\\\u00f8rskog.no", "orsta.no", "\\\\u00f8rsta.no", "os.hedmark.no", "os.hordaland.no", "osen.no", "osteroy.no", "oster\\\\u00f8y.no", "ostre-toten.no", "\\\\u00f8stre-toten.no", "overhalla.no", "ovre-eiker.no", "\\\\u00f8vre-eiker.no", "oyer.no", "\\\\u00f8yer.no", "oygarden.no", "\\\\u00f8ygarden.no", "oystre-slidre.no", "\\\\u00f8ystre-slidre.no", "porsanger.no", "porsangu.no", "pors\\\\u00e1\\\\u014bgu.no", "porsgrunn.no", "radoy.no", "rad\\\\u00f8y.no", "rakkestad.no", "rana.no", "ruovat.no", "randaberg.no", "rauma.no", "rendalen.no", "rennebu.no", "rennesoy.no", "rennes\\\\u00f8y.no", "rindal.no", "ringebu.no", "ringerike.no", "ringsaker.no", "rissa.no", "risor.no", "ris\\\\u00f8r.no", "roan.no", "rollag.no", "rygge.no", "ralingen.no", "r\\\\u00e6lingen.no", "rodoy.no", "r\\\\u00f8d\\\\u00f8y.no", "romskog.no", "r\\\\u00f8mskog.no", "roros.no", "r\\\\u00f8ros.no", "rost.no", "r\\\\u00f8st.no", "royken.no", "r\\\\u00f8yken.no", "royrvik.no", "r\\\\u00f8yrvik.no", "rade.no", "r\\\\u00e5de.no", "salangen.no", "siellak.no", "saltdal.no", "salat.no", "s\\\\u00e1l\\\\u00e1t.no", "s\\\\u00e1lat.no", "samnanger.no", "sande.more-og-romsdal.no", "sande.m\\\\u00f8re-og-romsdal.no", "sande.vestfold.no", "sandefjord.no", "sandnes.no", "sandoy.no", "sand\\\\u00f8y.no", "sarpsborg.no", "sauda.no", "sauherad.no", "sel.no", "selbu.no", "selje.no", "seljord.no", "sigdal.no", "siljan.no", "sirdal.no", "skaun.no", "skedsmo.no", "ski.no", "skien.no", "skiptvet.no", "skjervoy.no", "skjerv\\\\u00f8y.no", "skierva.no", "skierv\\\\u00e1.no", "skjak.no", "skj\\\\u00e5k.no", "skodje.no", "skanland.no", "sk\\\\u00e5nland.no", "skanit.no", "sk\\\\u00e1nit.no", "smola.no", "sm\\\\u00f8la.no", "snillfjord.no", "snasa.no", "sn\\\\u00e5sa.no", "snoasa.no", "snaase.no", "sn\\\\u00e5ase.no", "sogndal.no", "sokndal.no", "sola.no", "solund.no", "songdalen.no", "sortland.no", "spydeberg.no", "stange.no", "stavanger.no", "steigen.no", "steinkjer.no", "stjordal.no", "stj\\\\u00f8rdal.no", "stokke.no", "stor-elvdal.no", "stord.no", "stordal.no", "storfjord.no", "omasvuotna.no", "strand.no", "stranda.no", "stryn.no", "sula.no", "suldal.no", "sund.no", "sunndal.no", "surnadal.no", "sveio.no", "svelvik.no", "sykkylven.no", "sogne.no", "s\\\\u00f8gne.no", "somna.no", "s\\\\u00f8mna.no", "sondre-land.no", "s\\\\u00f8ndre-land.no", "sor-aurdal.no", "s\\\\u00f8r-aurdal.no", "sor-fron.no", "s\\\\u00f8r-fron.no", "sor-odal.no", "s\\\\u00f8r-odal.no", "sor-varanger.no", "s\\\\u00f8r-varanger.no", "matta-varjjat.no", "m\\\\u00e1tta-v\\\\u00e1rjjat.no", "sorfold.no", "s\\\\u00f8rfold.no", "sorreisa.no", "s\\\\u00f8rreisa.no", "sorum.no", "s\\\\u00f8rum.no", "tana.no", "deatnu.no", "time.no", "tingvoll.no", "tinn.no", "tjeldsund.no", "dielddanuorri.no", "tjome.no", "tj\\\\u00f8me.no", "tokke.no", "tolga.no", "torsken.no", "tranoy.no", "tran\\\\u00f8y.no", "tromso.no", "troms\\\\u00f8.no", "tromsa.no", "romsa.no", "trondheim.no", "troandin.no", "trysil.no", "trana.no", "tr\\\\u00e6na.no", "trogstad.no", "tr\\\\u00f8gstad.no", "tvedestrand.no", "tydal.no", "tynset.no", "tysfjord.no", "divtasvuodna.no", "divttasvuotna.no", "tysnes.no", "tysvar.no", "tysv\\\\u00e6r.no", "tonsberg.no", "t\\\\u00f8nsberg.no", "ullensaker.no", "ullensvang.no", "ulvik.no", "utsira.no", "vadso.no", "vads\\\\u00f8.no", "cahcesuolo.no", "\\\\u010d\\\\u00e1hcesuolo.no", "vaksdal.no", "valle.no", "vang.no", "vanylven.no", "vardo.no", "vard\\\\u00f8.no", "varggat.no", "v\\\\u00e1rgg\\\\u00e1t.no", "vefsn.no", "vaapste.no", "vega.no", "vegarshei.no", "veg\\\\u00e5rshei.no", "vennesla.no", "verdal.no", "verran.no", "vestby.no", "vestnes.no", "vestre-slidre.no", "vestre-toten.no", "vestvagoy.no", "vestv\\\\u00e5g\\\\u00f8y.no", "vevelstad.no", "vik.no", "vikna.no", "vindafjord.no", "volda.no", "voss.no", "varoy.no", "v\\\\u00e6r\\\\u00f8y.no", "vagan.no", "v\\\\u00e5gan.no", "voagat.no", "vagsoy.no", "v\\\\u00e5gs\\\\u00f8y.no", "vaga.no", "v\\\\u00e5g\\\\u00e5.no", "valer.ostfold.no", "v\\\\u00e5ler.\\\\u00f8stfold.no", "valer.hedmark.no", "v\\\\u00e5ler.hedmark.no", "*.np", "nr", "biz.nr", "info.nr", "gov.nr", "edu.nr", "org.nr", "net.nr", "com.nr", "nu", "nz", "ac.nz", "co.nz", "cri.nz", "geek.nz", "gen.nz", "govt.nz", "health.nz", "iwi.nz", "kiwi.nz", "maori.nz", "mil.nz", "m\\\\u0101ori.nz", "net.nz", "org.nz", "parliament.nz", "school.nz", "om", "co.om", "com.om", "edu.om", "gov.om", "med.om", "museum.om", "net.om", "org.om", "pro.om", "onion", "org", "pa", "ac.pa", "gob.pa", "com.pa", "org.pa", "sld.pa", "edu.pa", "net.pa", "ing.pa", "abo.pa", "med.pa", "nom.pa", "pe", "edu.pe", "gob.pe", "nom.pe", "mil.pe", "org.pe", "com.pe", "net.pe", "pf", "com.pf", "org.pf", "edu.pf", "*.pg", "ph", "com.ph", "net.ph", "org.ph", "gov.ph", "edu.ph", "ngo.ph", "mil.ph", "i.ph", "pk", "com.pk", "net.pk", "edu.pk", "org.pk", "fam.pk", "biz.pk", "web.pk", "gov.pk", "gob.pk", "gok.pk", "gon.pk", "gop.pk", "gos.pk", "info.pk", "pl", "com.pl", "net.pl", "org.pl", "aid.pl", "agro.pl", "atm.pl", "auto.pl", "biz.pl", "edu.pl", "gmina.pl", "gsm.pl", "info.pl", "mail.pl", "miasta.pl", "media.pl", "mil.pl", "nieruchomosci.pl", "nom.pl", "pc.pl", "powiat.pl", "priv.pl", "realestate.pl", "rel.pl", "sex.pl", "shop.pl", "sklep.pl", "sos.pl", "szkola.pl", "targi.pl", "tm.pl", "tourism.pl", "travel.pl", "turystyka.pl", "gov.pl", "ap.gov.pl", "ic.gov.pl", "is.gov.pl", "us.gov.pl", "kmpsp.gov.pl", "kppsp.gov.pl", "kwpsp.gov.pl", "psp.gov.pl", "wskr.gov.pl", "kwp.gov.pl", "mw.gov.pl", "ug.gov.pl", "um.gov.pl", "umig.gov.pl", "ugim.gov.pl", "upow.gov.pl", "uw.gov.pl", "starostwo.gov.pl", "pa.gov.pl", "po.gov.pl", "psse.gov.pl", "pup.gov.pl", "rzgw.gov.pl", "sa.gov.pl", "so.gov.pl", "sr.gov.pl", "wsa.gov.pl", "sko.gov.pl", "uzs.gov.pl", "wiih.gov.pl", "winb.gov.pl", "pinb.gov.pl", "wios.gov.pl", "witd.gov.pl", "wzmiuw.gov.pl", "piw.gov.pl", "wiw.gov.pl", "griw.gov.pl", "wif.gov.pl", "oum.gov.pl", "sdn.gov.pl", "zp.gov.pl", "uppo.gov.pl", "mup.gov.pl", "wuoz.gov.pl", "konsulat.gov.pl", "oirm.gov.pl", "augustow.pl", "babia-gora.pl", "bedzin.pl", "beskidy.pl", "bialowieza.pl", "bialystok.pl", "bielawa.pl", "bieszczady.pl", "boleslawiec.pl", "bydgoszcz.pl", "bytom.pl", "cieszyn.pl", "czeladz.pl", "czest.pl", "dlugoleka.pl", "elblag.pl", "elk.pl", "glogow.pl", "gniezno.pl", "gorlice.pl", "grajewo.pl", "ilawa.pl", "jaworzno.pl", "jelenia-gora.pl", "jgora.pl", "kalisz.pl", "kazimierz-dolny.pl", "karpacz.pl", "kartuzy.pl", "kaszuby.pl", "katowice.pl", "kepno.pl", "ketrzyn.pl", "klodzko.pl", "kobierzyce.pl", "kolobrzeg.pl", "konin.pl", "konskowola.pl", "kutno.pl", "lapy.pl", "lebork.pl", "legnica.pl", "lezajsk.pl", "limanowa.pl", "lomza.pl", "lowicz.pl", "lubin.pl", "lukow.pl", "malbork.pl", "malopolska.pl", "mazowsze.pl", "mazury.pl", "mielec.pl", "mielno.pl", "mragowo.pl", "naklo.pl", "nowaruda.pl", "nysa.pl", "olawa.pl", "olecko.pl", "olkusz.pl", "olsztyn.pl", "opoczno.pl", "opole.pl", "ostroda.pl", "ostroleka.pl", "ostrowiec.pl", "ostrowwlkp.pl", "pila.pl", "pisz.pl", "podhale.pl", "podlasie.pl", "polkowice.pl", "pomorze.pl", "pomorskie.pl", "prochowice.pl", "pruszkow.pl", "przeworsk.pl", "pulawy.pl", "radom.pl", "rawa-maz.pl", "rybnik.pl", "rzeszow.pl", "sanok.pl", "sejny.pl", "slask.pl", "slupsk.pl", "sosnowiec.pl", "stalowa-wola.pl", "skoczow.pl", "starachowice.pl", "stargard.pl", "suwalki.pl", "swidnica.pl", "swiebodzin.pl", "swinoujscie.pl", "szczecin.pl", "szczytno.pl", "tarnobrzeg.pl", "tgory.pl", "turek.pl", "tychy.pl", "ustka.pl", "walbrzych.pl", "warmia.pl", "warszawa.pl", "waw.pl", "wegrow.pl", "wielun.pl", "wlocl.pl", "wloclawek.pl", "wodzislaw.pl", "wolomin.pl", "wroclaw.pl", "zachpomor.pl", "zagan.pl", "zarow.pl", "zgora.pl", "zgorzelec.pl", "pm", "pn", "gov.pn", "co.pn", "org.pn", "edu.pn", "net.pn", "post", "pr", "com.pr", "net.pr", "org.pr", "gov.pr", "edu.pr", "isla.pr", "pro.pr", "biz.pr", "info.pr", "name.pr", "est.pr", "prof.pr", "ac.pr", "pro", "aaa.pro", "aca.pro", "acct.pro", "avocat.pro", "bar.pro", "cpa.pro", "eng.pro", "jur.pro", "law.pro", "med.pro", "recht.pro", "ps", "edu.ps", "gov.ps", "sec.ps", "plo.ps", "com.ps", "org.ps", "net.ps", "pt", "net.pt", "gov.pt", "org.pt", "edu.pt", "int.pt", "publ.pt", "com.pt", "nome.pt", "pw", "co.pw", "ne.pw", "or.pw", "ed.pw", "go.pw", "belau.pw", "py", "com.py", "coop.py", "edu.py", "gov.py", "mil.py", "net.py", "org.py", "qa", "com.qa", "edu.qa", "gov.qa", "mil.qa", "name.qa", "net.qa", "org.qa", "sch.qa", "re", "asso.re", "com.re", "nom.re", "ro", "arts.ro", "com.ro", "firm.ro", "info.ro", "nom.ro", "nt.ro", "org.ro", "rec.ro", "store.ro", "tm.ro", "www.ro", "rs", "ac.rs", "co.rs", "edu.rs", "gov.rs", "in.rs", "org.rs", "ru", "ac.ru", "edu.ru", "gov.ru", "int.ru", "mil.ru", "test.ru", "rw", "gov.rw", "net.rw", "edu.rw", "ac.rw", "com.rw", "co.rw", "int.rw", "mil.rw", "gouv.rw", "sa", "com.sa", "net.sa", "org.sa", "gov.sa", "med.sa", "pub.sa", "edu.sa", "sch.sa", "sb", "com.sb", "edu.sb", "gov.sb", "net.sb", "org.sb", "sc", "com.sc", "gov.sc", "net.sc", "org.sc", "edu.sc", "sd", "com.sd", "net.sd", "org.sd", "edu.sd", "med.sd", "tv.sd", "gov.sd", "info.sd", "se", "a.se", "ac.se", "b.se", "bd.se", "brand.se", "c.se", "d.se", "e.se", "f.se", "fh.se", "fhsk.se", "fhv.se", "g.se", "h.se", "i.se", "k.se", "komforb.se", "kommunalforbund.se", "komvux.se", "l.se", "lanbib.se", "m.se", "n.se", "naturbruksgymn.se", "o.se", "org.se", "p.se", "parti.se", "pp.se", "press.se", "r.se", "s.se", "t.se", "tm.se", "u.se", "w.se", "x.se", "y.se", "z.se", "sg", "com.sg", "net.sg", "org.sg", "gov.sg", "edu.sg", "per.sg", "sh", "com.sh", "net.sh", "gov.sh", "org.sh", "mil.sh", "si", "sj", "sk", "sl", "com.sl", "net.sl", "edu.sl", "gov.sl", "org.sl", "sm", "sn", "art.sn", "com.sn", "edu.sn", "gouv.sn", "org.sn", "perso.sn", "univ.sn", "so", "com.so", "net.so", "org.so", "sr", "st", "co.st", "com.st", "consulado.st", "edu.st", "embaixada.st", "gov.st", "mil.st", "net.st", "org.st", "principe.st", "saotome.st", "store.st", "su", "sv", "com.sv", "edu.sv", "gob.sv", "org.sv", "red.sv", "sx", "gov.sx", "sy", "edu.sy", "gov.sy", "net.sy", "mil.sy", "com.sy", "org.sy", "sz", "co.sz", "ac.sz", "org.sz", "tc", "td", "tel", "tf", "tg", "th", "ac.th", "co.th", "go.th", "in.th", "mi.th", "net.th", "or.th", "tj", "ac.tj", "biz.tj", "co.tj", "com.tj", "edu.tj", "go.tj", "gov.tj", "int.tj", "mil.tj", "name.tj", "net.tj", "nic.tj", "org.tj", "test.tj", "web.tj", "tk", "tl", "gov.tl", "tm", "com.tm", "co.tm", "org.tm", "net.tm", "nom.tm", "gov.tm", "mil.tm", "edu.tm", "tn", "com.tn", "ens.tn", "fin.tn", "gov.tn", "ind.tn", "intl.tn", "nat.tn", "net.tn", "org.tn", "info.tn", "perso.tn", "tourism.tn", "edunet.tn", "rnrt.tn", "rns.tn", "rnu.tn", "mincom.tn", "agrinet.tn", "defense.tn", "turen.tn", "to", "com.to", "gov.to", "net.to", "org.to", "edu.to", "mil.to", "tr", "com.tr", "info.tr", "biz.tr", "net.tr", "org.tr", "web.tr", "gen.tr", "tv.tr", "av.tr", "dr.tr", "bbs.tr", "name.tr", "tel.tr", "gov.tr", "bel.tr", "pol.tr", "mil.tr", "k12.tr", "edu.tr", "kep.tr", "nc.tr", "gov.nc.tr", "travel", "tt", "co.tt", "com.tt", "org.tt", "net.tt", "biz.tt", "info.tt", "pro.tt", "int.tt", "coop.tt", "jobs.tt", "mobi.tt", "travel.tt", "museum.tt", "aero.tt", "name.tt", "gov.tt", "edu.tt", "tv", "tw", "edu.tw", "gov.tw", "mil.tw", "com.tw", "net.tw", "org.tw", "idv.tw", "game.tw", "ebiz.tw", "club.tw", "\\\\u7db2\\\\u8def.tw", "\\\\u7d44\\\\u7e54.tw", "\\\\u5546\\\\u696d.tw", "tz", "ac.tz", "co.tz", "go.tz", "hotel.tz", "info.tz", "me.tz", "mil.tz", "mobi.tz", "ne.tz", "or.tz", "sc.tz", "tv.tz", "ua", "com.ua", "edu.ua", "gov.ua", "in.ua", "net.ua", "org.ua", "cherkassy.ua", "cherkasy.ua", "chernigov.ua", "chernihiv.ua", "chernivtsi.ua", "chernovtsy.ua", "ck.ua", "cn.ua", "cr.ua", "crimea.ua", "cv.ua", "dn.ua", "dnepropetrovsk.ua", "dnipropetrovsk.ua", "dominic.ua", "donetsk.ua", "dp.ua", "if.ua", "ivano-frankivsk.ua", "kh.ua", "kharkiv.ua", "kharkov.ua", "kherson.ua", "khmelnitskiy.ua", "khmelnytskyi.ua", "kiev.ua", "kirovograd.ua", "km.ua", "kr.ua", "krym.ua", "ks.ua", "kv.ua", "kyiv.ua", "lg.ua", "lt.ua", "lugansk.ua", "lutsk.ua", "lv.ua", "lviv.ua", "mk.ua", "mykolaiv.ua", "nikolaev.ua", "od.ua", "odesa.ua", "odessa.ua", "pl.ua", "poltava.ua", "rivne.ua", "rovno.ua", "rv.ua", "sb.ua", "sebastopol.ua", "sevastopol.ua", "sm.ua", "sumy.ua", "te.ua", "ternopil.ua", "uz.ua", "uzhgorod.ua", "vinnica.ua", "vinnytsia.ua", "vn.ua", "volyn.ua", "yalta.ua", "zaporizhzhe.ua", "zaporizhzhia.ua", "zhitomir.ua", "zhytomyr.ua", "zp.ua", "zt.ua", "ug", "co.ug", "or.ug", "ac.ug", "sc.ug", "go.ug", "ne.ug", "com.ug", "org.ug", "uk", "ac.uk", "co.uk", "gov.uk", "ltd.uk", "me.uk", "net.uk", "nhs.uk", "org.uk", "plc.uk", "police.uk", "*.sch.uk", "us", "dni.us", "fed.us", "isa.us", "kids.us", "nsn.us", "ak.us", "al.us", "ar.us", "as.us", "az.us", "ca.us", "co.us", "ct.us", "dc.us", "de.us", "fl.us", "ga.us", "gu.us", "hi.us", "ia.us", "id.us", "il.us", "in.us", "ks.us", "ky.us", "la.us", "ma.us", "md.us", "me.us", "mi.us", "mn.us", "mo.us", "ms.us", "mt.us", "nc.us", "nd.us", "ne.us", "nh.us", "nj.us", "nm.us", "nv.us", "ny.us", "oh.us", "ok.us", "or.us", "pa.us", "pr.us", "ri.us", "sc.us", "sd.us", "tn.us", "tx.us", "ut.us", "vi.us", "vt.us", "va.us", "wa.us", "wi.us", "wv.us", "wy.us", "k12.ak.us", "k12.al.us", "k12.ar.us", "k12.as.us", "k12.az.us", "k12.ca.us", "k12.co.us", "k12.ct.us", "k12.dc.us", "k12.de.us", "k12.fl.us", "k12.ga.us", "k12.gu.us", "k12.ia.us", "k12.id.us", "k12.il.us", "k12.in.us", "k12.ks.us", "k12.ky.us", "k12.la.us", "k12.ma.us", "k12.md.us", "k12.me.us", "k12.mi.us", "k12.mn.us", "k12.mo.us", "k12.ms.us", "k12.mt.us", "k12.nc.us", "k12.ne.us", "k12.nh.us", "k12.nj.us", "k12.nm.us", "k12.nv.us", "k12.ny.us", "k12.oh.us", "k12.ok.us", "k12.or.us", "k12.pa.us", "k12.pr.us", "k12.ri.us", "k12.sc.us", "k12.tn.us", "k12.tx.us", "k12.ut.us", "k12.vi.us", "k12.vt.us", "k12.va.us", "k12.wa.us", "k12.wi.us", "k12.wy.us", "cc.ak.us", "cc.al.us", "cc.ar.us", "cc.as.us", "cc.az.us", "cc.ca.us", "cc.co.us", "cc.ct.us", "cc.dc.us", "cc.de.us", "cc.fl.us", "cc.ga.us", "cc.gu.us", "cc.hi.us", "cc.ia.us", "cc.id.us", "cc.il.us", "cc.in.us", "cc.ks.us", "cc.ky.us", "cc.la.us", "cc.ma.us", "cc.md.us", "cc.me.us", "cc.mi.us", "cc.mn.us", "cc.mo.us", "cc.ms.us", "cc.mt.us", "cc.nc.us", "cc.nd.us", "cc.ne.us", "cc.nh.us", "cc.nj.us", "cc.nm.us", "cc.nv.us", "cc.ny.us", "cc.oh.us", "cc.ok.us", "cc.or.us", "cc.pa.us", "cc.pr.us", "cc.ri.us", "cc.sc.us", "cc.sd.us", "cc.tn.us", "cc.tx.us", "cc.ut.us", "cc.vi.us", "cc.vt.us", "cc.va.us", "cc.wa.us", "cc.wi.us", "cc.wv.us", "cc.wy.us", "lib.ak.us", "lib.al.us", "lib.ar.us", "lib.as.us", "lib.az.us", "lib.ca.us", "lib.co.us", "lib.ct.us", "lib.dc.us", "lib.fl.us", "lib.ga.us", "lib.gu.us", "lib.hi.us", "lib.ia.us", "lib.id.us", "lib.il.us", "lib.in.us", "lib.ks.us", "lib.ky.us", "lib.la.us", "lib.ma.us", "lib.md.us", "lib.me.us", "lib.mi.us", "lib.mn.us", "lib.mo.us", "lib.ms.us", "lib.mt.us", "lib.nc.us", "lib.nd.us", "lib.ne.us", "lib.nh.us", "lib.nj.us", "lib.nm.us", "lib.nv.us", "lib.ny.us", "lib.oh.us", "lib.ok.us", "lib.or.us", "lib.pa.us", "lib.pr.us", "lib.ri.us", "lib.sc.us", "lib.sd.us", "lib.tn.us", "lib.tx.us", "lib.ut.us", "lib.vi.us", "lib.vt.us", "lib.va.us", "lib.wa.us", "lib.wi.us", "lib.wy.us", "pvt.k12.ma.us", "chtr.k12.ma.us", "paroch.k12.ma.us", "ann-arbor.mi.us", "cog.mi.us", "dst.mi.us", "eaton.mi.us", "gen.mi.us", "mus.mi.us", "tec.mi.us", "washtenaw.mi.us", "uy", "com.uy", "edu.uy", "gub.uy", "mil.uy", "net.uy", "org.uy", "uz", "co.uz", "com.uz", "net.uz", "org.uz", "va", "vc", "com.vc", "net.vc", "org.vc", "gov.vc", "mil.vc", "edu.vc", "ve", "arts.ve", "co.ve", "com.ve", "e12.ve", "edu.ve", "firm.ve", "gob.ve", "gov.ve", "info.ve", "int.ve", "mil.ve", "net.ve", "org.ve", "rec.ve", "store.ve", "tec.ve", "web.ve", "vg", "vi", "co.vi", "com.vi", "k12.vi", "net.vi", "org.vi", "vn", "com.vn", "net.vn", "org.vn", "edu.vn", "gov.vn", "int.vn", "ac.vn", "biz.vn", "info.vn", "name.vn", "pro.vn", "health.vn", "vu", "com.vu", "edu.vu", "net.vu", "org.vu", "wf", "ws", "com.ws", "net.ws", "org.ws", "gov.ws", "edu.ws", "yt", "\\\\u0627\\\\u0645\\\\u0627\\\\u0631\\\\u0627\\\\u062a", "\\\\u0570\\\\u0561\\\\u0575", "\\\\u09ac\\\\u09be\\\\u0982\\\\u09b2\\\\u09be", "\\\\u0431\\\\u0433", "\\\\u0431\\\\u0435\\\\u043b", "\\\\u4e2d\\\\u56fd", "\\\\u4e2d\\\\u570b", "\\\\u0627\\\\u0644\\\\u062c\\\\u0632\\\\u0627\\\\u0626\\\\u0631", "\\\\u0645\\\\u0635\\\\u0631", "\\\\u0435\\\\u044e", "\\\\u10d2\\\\u10d4", "\\\\u03b5\\\\u03bb", "\\\\u9999\\\\u6e2f", "\\\\u0cad\\\\u0cbe\\\\u0cb0\\\\u0ca4", "\\\\u0b2d\\\\u0b3e\\\\u0b30\\\\u0b24", "\\\\u09ad\\\\u09be\\\\u09f0\\\\u09a4", "\\\\u092d\\\\u093e\\\\u0930\\\\u0924\\\\u092e\\\\u094d", "\\\\u092d\\\\u093e\\\\u0930\\\\u094b\\\\u0924", "\\\\u0680\\\\u0627\\\\u0631\\\\u062a", "\\\\u0d2d\\\\u0d3e\\\\u0d30\\\\u0d24\\\\u0d02", "\\\\u092d\\\\u093e\\\\u0930\\\\u0924", "\\\\u0628\\\\u06be\\\\u0627\\\\u0631\\\\u062a", "\\\\u0c2d\\\\u0c3e\\\\u0c30\\\\u0c24\\\\u0c4d", "\\\\u0aad\\\\u0abe\\\\u0ab0\\\\u0aa4", "\\\\u0a2d\\\\u0a3e\\\\u0a30\\\\u0a24", "\\\\u09ad\\\\u09be\\\\u09b0\\\\u09a4", "\\\\u0b87\\\\u0ba8\\\\u0bcd\\\\u0ba4\\\\u0bbf\\\\u0baf\\\\u0bbe", "\\\\u0627\\\\u06cc\\\\u0631\\\\u0627\\\\u0646", "\\\\u0627\\\\u064a\\\\u0631\\\\u0627\\\\u0646", "\\\\u0639\\\\u0631\\\\u0627\\\\u0642", "\\\\u0627\\\\u0644\\\\u0627\\\\u0631\\\\u062f\\\\u0646", "\\\\ud55c\\\\uad6d", "\\\\u049b\\\\u0430\\\\u0437", "\\\\u0dbd\\\\u0d82\\\\u0d9a\\\\u0dcf", "\\\\u0b87\\\\u0bb2\\\\u0b99\\\\u0bcd\\\\u0b95\\\\u0bc8", "\\\\u0627\\\\u0644\\\\u0645\\\\u063a\\\\u0631\\\\u0628", "\\\\u043c\\\\u043a\\\\u0434", "\\\\u043c\\\\u043e\\\\u043d", "\\\\u6fb3\\\\u9580", "\\\\u6fb3\\\\u95e8", "\\\\u0645\\\\u0644\\\\u064a\\\\u0633\\\\u064a\\\\u0627", "\\\\u0639\\\\u0645\\\\u0627\\\\u0646", "\\\\u067e\\\\u0627\\\\u06a9\\\\u0633\\\\u062a\\\\u0627\\\\u0646", "\\\\u067e\\\\u0627\\\\u0643\\\\u0633\\\\u062a\\\\u0627\\\\u0646", "\\\\u0641\\\\u0644\\\\u0633\\\\u0637\\\\u064a\\\\u0646", "\\\\u0441\\\\u0440\\\\u0431", "\\\\u043f\\\\u0440.\\\\u0441\\\\u0440\\\\u0431", "\\\\u043e\\\\u0440\\\\u0433.\\\\u0441\\\\u0440\\\\u0431", "\\\\u043e\\\\u0431\\\\u0440.\\\\u0441\\\\u0440\\\\u0431", "\\\\u043e\\\\u0434.\\\\u0441\\\\u0440\\\\u0431", "\\\\u0443\\\\u043f\\\\u0440.\\\\u0441\\\\u0440\\\\u0431", "\\\\u0430\\\\u043a.\\\\u0441\\\\u0440\\\\u0431", "\\\\u0440\\\\u0444", "\\\\u0642\\\\u0637\\\\u0631", "\\\\u0627\\\\u0644\\\\u0633\\\\u0639\\\\u0648\\\\u062f\\\\u064a\\\\u0629", "\\\\u0627\\\\u0644\\\\u0633\\\\u0639\\\\u0648\\\\u062f\\\\u06cc\\\\u0629", "\\\\u0627\\\\u0644\\\\u0633\\\\u0639\\\\u0648\\\\u062f\\\\u06cc\\\\u06c3", "\\\\u0627\\\\u0644\\\\u0633\\\\u0639\\\\u0648\\\\u062f\\\\u064a\\\\u0647", "\\\\u0633\\\\u0648\\\\u062f\\\\u0627\\\\u0646", "\\\\u65b0\\\\u52a0\\\\u5761", "\\\\u0b9a\\\\u0bbf\\\\u0b99\\\\u0bcd\\\\u0b95\\\\u0baa\\\\u0bcd\\\\u0baa\\\\u0bc2\\\\u0bb0\\\\u0bcd", "\\\\u0633\\\\u0648\\\\u0631\\\\u064a\\\\u0629", "\\\\u0633\\\\u0648\\\\u0631\\\\u064a\\\\u0627", "\\\\u0e44\\\\u0e17\\\\u0e22", "\\\\u0e28\\\\u0e36\\\\u0e01\\\\u0e29\\\\u0e32.\\\\u0e44\\\\u0e17\\\\u0e22", "\\\\u0e18\\\\u0e38\\\\u0e23\\\\u0e01\\\\u0e34\\\\u0e08.\\\\u0e44\\\\u0e17\\\\u0e22", "\\\\u0e23\\\\u0e31\\\\u0e10\\\\u0e1a\\\\u0e32\\\\u0e25.\\\\u0e44\\\\u0e17\\\\u0e22", "\\\\u0e17\\\\u0e2b\\\\u0e32\\\\u0e23.\\\\u0e44\\\\u0e17\\\\u0e22", "\\\\u0e40\\\\u0e19\\\\u0e47\\\\u0e15.\\\\u0e44\\\\u0e17\\\\u0e22", "\\\\u0e2d\\\\u0e07\\\\u0e04\\\\u0e4c\\\\u0e01\\\\u0e23.\\\\u0e44\\\\u0e17\\\\u0e22", "\\\\u062a\\\\u0648\\\\u0646\\\\u0633", "\\\\u53f0\\\\u7063", "\\\\u53f0\\\\u6e7e", "\\\\u81fa\\\\u7063", "\\\\u0443\\\\u043a\\\\u0440", "\\\\u0627\\\\u0644\\\\u064a\\\\u0645\\\\u0646", "xxx", "*.ye", "ac.za", "agric.za", "alt.za", "co.za", "edu.za", "gov.za", "grondar.za", "law.za", "mil.za", "net.za", "ngo.za", "nis.za", "nom.za", "org.za", "school.za", "tm.za", "web.za", "zm", "ac.zm", "biz.zm", "co.zm", "com.zm", "edu.zm", "gov.zm", "info.zm", "mil.zm", "net.zm", "org.zm", "sch.zm", "zw", "ac.zw", "co.zw", "gov.zw", "mil.zw", "org.zw", "aaa", "aarp", "abarth", "abb", "abbott", "abbvie", "abc", "able", "abogado", "abudhabi", "academy", "accenture", "accountant", "accountants", "aco", "active", "actor", "adac", "ads", "adult", "aeg", "aetna", "afamilycompany", "afl", "africa", "agakhan", "agency", "aig", "aigo", "airbus", "airforce", "airtel", "akdn", "alfaromeo", "alibaba", "alipay", "allfinanz", "allstate", "ally", "alsace", "alstom", "americanexpress", "americanfamily", "amex", "amfam", "amica", "amsterdam", "analytics", "android", "anquan", "anz", "aol", "apartments", "app", "apple", "aquarelle", "arab", "aramco", "archi", "army", "art", "arte", "asda", "associates", "athleta", "attorney", "auction", "audi", "audible", "audio", "auspost", "author", "auto", "autos", "avianca", "aws", "axa", "azure", "baby", "baidu", "banamex", "bananarepublic", "band", "bank", "bar", "barcelona", "barclaycard", "barclays", "barefoot", "bargains", "baseball", "basketball", "bauhaus", "bayern", "bbc", "bbt", "bbva", "bcg", "bcn", "beats", "beauty", "beer", "bentley", "berlin", "best", "bestbuy", "bet", "bharti", "bible", "bid", "bike", "bing", "bingo", "bio", "black", "blackfriday", "blanco", "blockbuster", "blog", "bloomberg", "blue", "bms", "bmw", "bnl", "bnpparibas", "boats", "boehringer", "bofa", "bom", "bond", "boo", "book", "booking", "boots", "bosch", "bostik", "boston", "bot", "boutique", "box", "bradesco", "bridgestone", "broadway", "broker", "brother", "brussels", "budapest", "bugatti", "build", "builders", "business", "buy", "buzz", "bzh", "cab", "cafe", "cal", "call", "calvinklein", "cam", "camera", "camp", "cancerresearch", "canon", "capetown", "capital", "capitalone", "car", "caravan", "cards", "care", "career", "careers", "cars", "cartier", "casa", "case", "caseih", "cash", "casino", "catering", "catholic", "cba", "cbn", "cbre", "cbs", "ceb", "center", "ceo", "cern", "cfa", "cfd", "chanel", "channel", "chase", "chat", "cheap", "chintai", "christmas", "chrome", "chrysler", "church", "cipriani", "circle", "cisco", "citadel", "citi", "citic", "city", "cityeats", "claims", "cleaning", "click", "clinic", "clinique", "clothing", "cloud", "club", "clubmed", "coach", "codes", "coffee", "college", "cologne", "comcast", "commbank", "community", "company", "compare", "computer", "comsec", "condos", "construction", "consulting", "contact", "contractors", "cooking", "cookingchannel", "cool", "corsica", "country", "coupon", "coupons", "courses", "credit", "creditcard", "creditunion", "cricket", "crown", "crs", "cruise", "cruises", "csc", "cuisinella", "cymru", "cyou", "dabur", "dad", "dance", "data", "date", "dating", "datsun", "day", "dclk", "dds", "deal", "dealer", "deals", "degree", "delivery", "dell", "deloitte", "delta", "democrat", "dental", "dentist", "desi", "design", "dev", "dhl", "diamonds", "diet", "digital", "direct", "directory", "discount", "discover", "dish", "diy", "dnp", "docs", "doctor", "dodge", "dog", "doha", "domains", "dot", "download", "drive", "dtv", "dubai", "duck", "dunlop", "duns", "dupont", "durban", "dvag", "dvr", "earth", "eat", "eco", "edeka", "education", "email", "emerck", "energy", "engineer", "engineering", "enterprises", "epost", "epson", "equipment", "ericsson", "erni", "esq", "estate", "esurance", "etisalat", "eurovision", "eus", "events", "everbank", "exchange", "expert", "exposed", "express", "extraspace", "fage", "fail", "fairwinds", "faith", "family", "fan", "fans", "farm", "farmers", "fashion", "fast", "fedex", "feedback", "ferrari", "ferrero", "fiat", "fidelity", "fido", "film", "final", "finance", "financial", "fire", "firestone", "firmdale", "fish", "fishing", "fit", "fitness", "flickr", "flights", "flir", "florist", "flowers", "fly", "foo", "food", "foodnetwork", "football", "ford", "forex", "forsale", "forum", "foundation", "fox", "free", "fresenius", "frl", "frogans", "frontdoor", "frontier", "ftr", "fujitsu", "fujixerox", "fun", "fund", "furniture", "futbol", "fyi", "gal", "gallery", "gallo", "gallup", "game", "games", "gap", "garden", "gbiz", "gdn", "gea", "gent", "genting", "george", "ggee", "gift", "gifts", "gives", "giving", "glade", "glass", "gle", "global", "globo", "gmail", "gmbh", "gmo", "gmx", "godaddy", "gold", "goldpoint", "golf", "goo", "goodhands", "goodyear", "goog", "google", "gop", "got", "grainger", "graphics", "gratis", "green", "gripe", "grocery", "group", "guardian", "gucci", "guge", "guide", "guitars", "guru", "hair", "hamburg", "hangout", "haus", "hbo", "hdfc", "hdfcbank", "health", "healthcare", "help", "helsinki", "here", "hermes", "hgtv", "hiphop", "hisamitsu", "hitachi", "hiv", "hkt", "hockey", "holdings", "holiday", "homedepot", "homegoods", "homes", "homesense", "honda", "honeywell", "horse", "hospital", "host", "hosting", "hot", "hoteles", "hotels", "hotmail", "house", "how", "hsbc", "hughes", "hyatt", "hyundai", "ibm", "icbc", "ice", "icu", "ieee", "ifm", "ikano", "imamat", "imdb", "immo", "immobilien", "industries", "infiniti", "ing", "ink", "institute", "insurance", "insure", "intel", "international", "intuit", "investments", "ipiranga", "irish", "iselect", "ismaili", "ist", "istanbul", "itau", "itv", "iveco", "iwc", "jaguar", "java", "jcb", "jcp", "jeep", "jetzt", "jewelry", "jio", "jlc", "jll", "jmp", "jnj", "joburg", "jot", "joy", "jpmorgan", "jprs", "juegos", "juniper", "kaufen", "kddi", "kerryhotels", "kerrylogistics", "kerryproperties", "kfh", "kia", "kim", "kinder", "kindle", "kitchen", "kiwi", "koeln", "komatsu", "kosher", "kpmg", "kpn", "krd", "kred", "kuokgroup", "kyoto", "lacaixa", "ladbrokes", "lamborghini", "lamer", "lancaster", "lancia", "lancome", "land", "landrover", "lanxess", "lasalle", "lat", "latino", "latrobe", "law", "lawyer", "lds", "lease", "leclerc", "lefrak", "legal", "lego", "lexus", "lgbt", "liaison", "lidl", "life", "lifeinsurance", "lifestyle", "lighting", "like", "lilly", "limited", "limo", "lincoln", "linde", "link", "lipsy", "live", "living", "lixil", "loan", "loans", "locker", "locus", "loft", "lol", "london", "lotte", "lotto", "love", "lpl", "lplfinancial", "ltd", "ltda", "lundbeck", "lupin", "luxe", "luxury", "macys", "madrid", "maif", "maison", "makeup", "man", "management", "mango", "map", "market", "marketing", "markets", "marriott", "marshalls", "maserati", "mattel", "mba", "mckinsey", "med", "media", "meet", "melbourne", "meme", "memorial", "men", "menu", "meo", "merckmsd", "metlife", "miami", "microsoft", "mini", "mint", "mit", "mitsubishi", "mlb", "mls", "mma", "mobile", "mobily", "moda", "moe", "moi", "mom", "monash", "money", "monster", "mopar", "mormon", "mortgage", "moscow", "moto", "motorcycles", "mov", "movie", "movistar", "msd", "mtn", "mtpc", "mtr", "mutual", "nab", "nadex", "nagoya", "nationwide", "natura", "navy", "nba", "nec", "netbank", "netflix", "network", "neustar", "new", "newholland", "news", "next", "nextdirect", "nexus", "nfl", "ngo", "nhk", "nico", "nike", "nikon", "ninja", "nissan", "nissay", "nokia", "northwesternmutual", "norton", "now", "nowruz", "nowtv", "nra", "nrw", "ntt", "nyc", "obi", "observer", "off", "office", "okinawa", "olayan", "olayangroup", "oldnavy", "ollo", "omega", "one", "ong", "onl", "online", "onyourside", "ooo", "open", "oracle", "orange", "organic", "origins", "osaka", "otsuka", "ott", "ovh", "page", "panasonic", "panerai", "paris", "pars", "partners", "parts", "party", "passagens", "pay", "pccw", "pet", "pfizer", "pharmacy", "phd", "philips", "phone", "photo", "photography", "photos", "physio", "piaget", "pics", "pictet", "pictures", "pid", "pin", "ping", "pink", "pioneer", "pizza", "place", "play", "playstation", "plumbing", "plus", "pnc", "pohl", "poker", "politie", "porn", "pramerica", "praxi", "press", "prime", "prod", "productions", "prof", "progressive", "promo", "properties", "property", "protection", "pru", "prudential", "pub", "pwc", "qpon", "quebec", "quest", "qvc", "racing", "radio", "raid", "read", "realestate", "realtor", "realty", "recipes", "red", "redstone", "redumbrella", "rehab", "reise", "reisen", "reit", "reliance", "ren", "rent", "rentals", "repair", "report", "republican", "rest", "restaurant", "review", "reviews", "rexroth", "rich", "richardli", "ricoh", "rightathome", "ril", "rio", "rip", "rmit", "rocher", "rocks", "rodeo", "rogers", "room", "rsvp", "rugby", "ruhr", "run", "rwe", "ryukyu", "saarland", "safe", "safety", "sakura", "sale", "salon", "samsclub", "samsung", "sandvik", "sandvikcoromant", "sanofi", "sap", "sapo", "sarl", "sas", "save", "saxo", "sbi", "sbs", "sca", "scb", "schaeffler", "schmidt", "scholarships", "school", "schule", "schwarz", "science", "scjohnson", "scor", "scot", "search", "seat", "secure", "security", "seek", "select", "sener", "services", "ses", "seven", "sew", "sex", "sexy", "sfr", "shangrila", "sharp", "shaw", "shell", "shia", "shiksha", "shoes", "shop", "shopping", "shouji", "show", "showtime", "shriram", "silk", "sina", "singles", "site", "ski", "skin", "sky", "skype", "sling", "smart", "smile", "sncf", "soccer", "social", "softbank", "software", "sohu", "solar", "solutions", "song", "sony", "soy", "space", "spiegel", "spot", "spreadbetting", "srl", "srt", "stada", "staples", "star", "starhub", "statebank", "statefarm", "statoil", "stc", "stcgroup", "stockholm", "storage", "store", "stream", "studio", "study", "style", "sucks", "supplies", "supply", "support", "surf", "surgery", "suzuki", "swatch", "swiftcover", "swiss", "sydney", "symantec", "systems", "tab", "taipei", "talk", "taobao", "target", "tatamotors", "tatar", "tattoo", "tax", "taxi", "tci", "tdk", "team", "tech", "technology", "telecity", "telefonica", "temasek", "tennis", "teva", "thd", "theater", "theatre", "tiaa", "tickets", "tienda", "tiffany", "tips", "tires", "tirol", "tjmaxx", "tjx", "tkmaxx", "tmall", "today", "tokyo", "tools", "top", "toray", "toshiba", "total", "tours", "town", "toyota", "toys", "trade", "trading", "training", "travelchannel", "travelers", "travelersinsurance", "trust", "trv", "tube", "tui", "tunes", "tushu", "tvs", "ubank", "ubs", "uconnect", "unicom", "university", "uno", "uol", "ups", "vacations", "vana", "vanguard", "vegas", "ventures", "verisign", "versicherung", "vet", "viajes", "video", "vig", "viking", "villas", "vin", "vip", "virgin", "visa", "vision", "vista", "vistaprint", "viva", "vivo", "vlaanderen", "vodka", "volkswagen", "volvo", "vote", "voting", "voto", "voyage", "vuelos", "wales", "walmart", "walter", "wang", "wanggou", "warman", "watch", "watches", "weather", "weatherchannel", "webcam", "weber", "website", "wed", "wedding", "weibo", "weir", "whoswho", "wien", "wiki", "williamhill", "win", "windows", "wine", "winners", "wme", "wolterskluwer", "woodside", "work", "works", "world", "wow", "wtc", "wtf", "xbox", "xerox", "xfinity", "xihuan", "xin", "\\\\u0915\\\\u0949\\\\u092e", "\\\\u30bb\\\\u30fc\\\\u30eb", "\\\\u4f5b\\\\u5c71", "\\\\u6148\\\\u5584", "\\\\u96c6\\\\u56e2", "\\\\u5728\\\\u7ebf", "\\\\u5927\\\\u4f17\\\\u6c7d\\\\u8f66", "\\\\u70b9\\\\u770b", "\\\\u0e04\\\\u0e2d\\\\u0e21", "\\\\u516b\\\\u5366", "\\\\u0645\\\\u0648\\\\u0642\\\\u0639", "\\\\u516c\\\\u76ca", "\\\\u516c\\\\u53f8", "\\\\u9999\\\\u683c\\\\u91cc\\\\u62c9", "\\\\u7f51\\\\u7ad9", "\\\\u79fb\\\\u52a8", "\\\\u6211\\\\u7231\\\\u4f60", "\\\\u043c\\\\u043e\\\\u0441\\\\u043a\\\\u0432\\\\u0430", "\\\\u043a\\\\u0430\\\\u0442\\\\u043e\\\\u043b\\\\u0438\\\\u043a", "\\\\u043e\\\\u043d\\\\u043b\\\\u0430\\\\u0439\\\\u043d", "\\\\u0441\\\\u0430\\\\u0439\\\\u0442", "\\\\u8054\\\\u901a", "\\\\u05e7\\\\u05d5\\\\u05dd", "\\\\u65f6\\\\u5c1a", "\\\\u5fae\\\\u535a", "\\\\u6de1\\\\u9a6c\\\\u9521", "\\\\u30d5\\\\u30a1\\\\u30c3\\\\u30b7\\\\u30e7\\\\u30f3", "\\\\u043e\\\\u0440\\\\u0433", "\\\\u0928\\\\u0947\\\\u091f", "\\\\u30b9\\\\u30c8\\\\u30a2", "\\\\uc0bc\\\\uc131", "\\\\u5546\\\\u6807", "\\\\u5546\\\\u5e97", "\\\\u5546\\\\u57ce", "\\\\u0434\\\\u0435\\\\u0442\\\\u0438", "\\\\u30dd\\\\u30a4\\\\u30f3\\\\u30c8", "\\\\u65b0\\\\u95fb", "\\\\u5de5\\\\u884c", "\\\\u5bb6\\\\u96fb", "\\\\u0643\\\\u0648\\\\u0645", "\\\\u4e2d\\\\u6587\\\\u7f51", "\\\\u4e2d\\\\u4fe1", "\\\\u5a31\\\\u4e50", "\\\\u8c37\\\\u6b4c", "\\\\u96fb\\\\u8a0a\\\\u76c8\\\\u79d1", "\\\\u8d2d\\\\u7269", "\\\\u30af\\\\u30e9\\\\u30a6\\\\u30c9", "\\\\u901a\\\\u8ca9", "\\\\u7f51\\\\u5e97", "\\\\u0938\\\\u0902\\\\u0917\\\\u0920\\\\u0928", "\\\\u9910\\\\u5385", "\\\\u7f51\\\\u7edc", "\\\\u043a\\\\u043e\\\\u043c", "\\\\u8bfa\\\\u57fa\\\\u4e9a", "\\\\u98df\\\\u54c1", "\\\\u98de\\\\u5229\\\\u6d66", "\\\\u624b\\\\u8868", "\\\\u624b\\\\u673a", "\\\\u0627\\\\u0631\\\\u0627\\\\u0645\\\\u0643\\\\u0648", "\\\\u0627\\\\u0644\\\\u0639\\\\u0644\\\\u064a\\\\u0627\\\\u0646", "\\\\u0627\\\\u062a\\\\u0635\\\\u0627\\\\u0644\\\\u0627\\\\u062a", "\\\\u0628\\\\u0627\\\\u0632\\\\u0627\\\\u0631", "\\\\u0645\\\\u0648\\\\u0628\\\\u0627\\\\u064a\\\\u0644\\\\u064a", "\\\\u0627\\\\u0628\\\\u0648\\\\u0638\\\\u0628\\\\u064a", "\\\\u0643\\\\u0627\\\\u062b\\\\u0648\\\\u0644\\\\u064a\\\\u0643", "\\\\u0647\\\\u0645\\\\u0631\\\\u0627\\\\u0647", "\\\\ub2f7\\\\ucef4", "\\\\u653f\\\\u5e9c", "\\\\u0634\\\\u0628\\\\u0643\\\\u0629", "\\\\u0628\\\\u064a\\\\u062a\\\\u0643", "\\\\u0639\\\\u0631\\\\u0628", "\\\\u673a\\\\u6784", "\\\\u7ec4\\\\u7ec7\\\\u673a\\\\u6784", "\\\\u5065\\\\u5eb7", "\\\\u0440\\\\u0443\\\\u0441", "\\\\u73e0\\\\u5b9d", "\\\\u5927\\\\u62ff", "\\\\u307f\\\\u3093\\\\u306a", "\\\\u30b0\\\\u30fc\\\\u30b0\\\\u30eb", "\\\\u4e16\\\\u754c", "\\\\u66f8\\\\u7c4d", "\\\\u7f51\\\\u5740", "\\\\ub2f7\\\\ub137", "\\\\u30b3\\\\u30e0", "\\\\u5929\\\\u4e3b\\\\u6559", "\\\\u6e38\\\\u620f", "verm\\\\u00f6gensberater", "verm\\\\u00f6gensberatung", "\\\\u4f01\\\\u4e1a", "\\\\u4fe1\\\\u606f", "\\\\u5609\\\\u91cc\\\\u5927\\\\u9152\\\\u5e97", "\\\\u5609\\\\u91cc", "\\\\u5e7f\\\\u4e1c", "\\\\u653f\\\\u52a1", "xperia", "xyz", "yachts", "yahoo", "yamaxun", "yandex", "yodobashi", "yoga", "yokohama", "you", "youtube", "yun", "zappos", "zara", "zero", "zip", "zippo", "zone", "zuerich"]\n        if tlds:\n            tlds.extend(self.extra_suffixes)\n            self._extractor = _PublicSuffixListTLDExtractor(tlds)\n            return self._extractor\n\n        if not tlds and self.fallback_to_snapshot:\n            tlds = self._get_snapshot_tld_extractor()\n            tlds.extend(self.extra_suffixes)\n            self._extractor = _PublicSuffixListTLDExtractor(tlds)\n            return self._extractor\n        elif not tlds:\n            raise Exception("tlds is empty, but fallback_to_snapshot is set"\n                            " to false. Cannot proceed without tlds.")\n\n        self._cache_tlds(tlds)\n\n        tlds.extend(self.extra_suffixes)\n        self._extractor = _PublicSuffixListTLDExtractor(tlds)\n        return self._extractor\n\n    def _get_cached_tlds(self):\n        \'\'\'Read the local TLD cache file. Returns None on IOError or other\n        error, or if this object is not set to use the cache\n        file.\'\'\'\n        if not self.cache_file:\n            return\n\n        try:\n            with open(self.cache_file) as cache_file:\n                try:\n                    return json.loads(cache_file.read())\n                except (IOError, ValueError) as exc:\n                    LOG.error(\n                        "error reading TLD cache file %s: %s",\n                        self.cache_file,\n                        exc\n                    )\n        except IOError as ioe:\n            file_not_found = ioe.errno == errno.ENOENT\n            if not file_not_found:\n                LOG.error("error reading TLD cache file %s: %s", self.cache_file, ioe)\n\n    @staticmethod\n    def _get_snapshot_tld_extractor():\n        snapshot_stream = pkg_resources.resource_stream(__name__, \'.tld_set_snapshot\')\n        with closing(snapshot_stream) as snapshot_file:\n            return json.loads(snapshot_file.read().decode(\'utf-8\'))\n\n    def _cache_tlds(self, tlds):\n        \'\'\'Logs a diff of the new TLDs and caches them on disk, according to\n        settings passed to __init__.\'\'\'\n        if LOG.isEnabledFor(logging.DEBUG):\n            import difflib\n            snapshot_stream = pkg_resources.resource_stream(__name__, \'.tld_set_snapshot\')\n            with closing(snapshot_stream) as snapshot_file:\n                snapshot = sorted(\n                    json.loads(snapshot_file.read().decode(\'utf-8\'))\n                )\n            new = sorted(tlds)\n            LOG.debug(\'computed TLD diff:\\n\' + \'\\n\'.join(difflib.unified_diff(\n                snapshot,\n                new,\n                fromfile=".tld_set_snapshot",\n                tofile=self.cache_file\n            )))\n\n        if self.cache_file:\n            try:\n                with open(self.cache_file, \'w\') as cache_file:\n                    json.dump(tlds, cache_file)\n            except IOError as ioe:\n                LOG.warning("unable to cache TLDs in file %s: %s", self.cache_file, ioe)\n\n\nTLD_EXTRACTOR = TLDExtract()\n\n\n@wraps(TLD_EXTRACTOR.__call__)\ndef extract(url):\n    return TLD_EXTRACTOR(url)\n\n\n@wraps(TLD_EXTRACTOR.update)\ndef update(*args, **kwargs):\n    return TLD_EXTRACTOR.update(*args, **kwargs)\n\n\ndef get_tlds_from_raw_suffix_list_data(suffix_list_source, include_psl_private_domains=False):\n    if include_psl_private_domains:\n        text = suffix_list_source\n    else:\n        text, _, _ = suffix_list_source.partition(\'// ===BEGIN PRIVATE DOMAINS===\')\n\n    tlds = [m.group(\'suffix\') for m in PUBLIC_SUFFIX_RE.finditer(text)]\n    return tlds\n\n\nclass _PublicSuffixListTLDExtractor(object):\n\n    def __init__(self, tlds):\n        self.tlds = frozenset(tlds)\n\n    def suffix_index(self, lower_spl):\n        """Returns the index of the first suffix label.\n        Returns len(spl) if no suffix is found\n        """\n        for i in range(len(lower_spl)):\n            maybe_tld = \'.\'.join(lower_spl[i:])\n            exception_tld = \'!\' + maybe_tld\n            if exception_tld in self.tlds:\n                return i + 1\n\n            if maybe_tld in self.tlds:\n                return i\n\n            wildcard_tld = \'*.\' + \'.\'.join(lower_spl[i + 1:])\n            if wildcard_tld in self.tlds:\n                return i\n\n        return len(lower_spl)\n''')
      __stickytape_write_module('''duplicate_incidents/collect_features/get_duplicate_features.py''', '''import libs.tldextract as tldextract\nimport duplicate_incidents.utils\nfrom duplicate_incidents.consts import *\n\nLABELS_BLACKLIST = [BRAND_LABEL, INSTANCE_LABEL, EMAIL_SENDER,\n                    EMAIL_SUBJECT_LABEL, EMAIL_RECEIVED_LABEL, EMAIL_ATTACHMENT_LABEL, EMAIL_DATE_LABEL,\n                    EMAIL_TEXT_LABEL, EMAIL_HTML_LABEL]\n\nINCIDENT_HASH_VALUES = [\'name\', \'owner\', \'closingUserId\', \'closeNotes\',\n                        \'reason\', \'closeReason\', \'CustomFields\', \'indicators\']\n\nINCIDENT_SAFE_FIELDS = [\'status\', \'autime\', \'isPlayground\', \'activated\', \'id\', \'category\',\n                        \'linkedIncidents\', \'dueDate\', \'version\', \'openDuration\', \'closed\', \'reminder\',\n                        \'type\', \'parent\', \'runStatus\', \'occurred\', \'phase\', \'severity\', \'account\',\n                        \'created\', \'modified\', \'investigationId\', \'playbookId\', \'sla\']\n\n\nclass IncidentFeatures():\n    def __init__(self, incident1, incident2):\n\n        self.incident1 = incident1\n        self.incident2 = incident2\n\n        self.indicators1 = incident1[\'indicators\']\n        self.indicators2 = incident2[\'indicators\']\n\n        self.labels_map1 = duplicate_incidents.utils.get_incident_labels_map(self.incident1[\'labels\'])\n        self.labels_map2 = duplicate_incidents.utils.get_incident_labels_map(self.incident2[\'labels\'])\n\n        self.enrich_domain_indicator()\n        if \'IP\' in self.indicators1 and \'IP\' in self.indicators2:\n            self.enrich_ip_network_indicator(24)\n            self.enrich_ip_private_indicator()\n\n    def enrich_domain_indicator(self):\n        domains1 = duplicate_incidents.utils.get_unique_list(\n            self.indicators1.get(\'Domain\', []) + duplicate_incidents.utils.get_domains(self.indicators1, self.labels_map2))\n        domains2 = duplicate_incidents.utils.get_unique_list(\n            self.indicators2.get(\'Domain\', []) + duplicate_incidents.utils.get_domains(self.indicators2, self.labels_map2))\n\n        if len(domains1) > 0:\n            self.indicators1[\'Domain\'] = domains1\n        if len(domains2) > 0:\n            self.indicators2[\'Domain\'] = domains2\n\n    def enrich_ip_network_indicator(self, bit_mask):\n        self.indicators1[\'IP_%d\' % bit_mask] = map(lambda ip: duplicate_incidents.utils.canonize_ip_to_network(ip, bit_mask),\n                                                   self.indicators1[\'IP\'])\n        self.indicators2[\'IP_%d\' % bit_mask] = map(lambda ip: duplicate_incidents.utils.canonize_ip_to_network(ip, bit_mask),\n                                                   self.indicators2[\'IP\'])\n\n    def enrich_ip_private_indicator(self):\n        def insert_ips(indicators):\n            indicators[\'IP_private\'] = []\n            indicators[\'IP_public\'] = []\n            for ip in indicators[\'IP\']:\n                if duplicate_incidents.utils.is_ip_private(ip):\n                    indicators[\'IP_private\'].append(ip)\n                else:\n                    indicators[\'IP_public\'].append(ip)\n\n        insert_ips(self.indicators1)\n        insert_ips(self.indicators2)\n\n    def get_domains_features(self):\n        def get_domain_suffix(domain):\n            return tldextract.extract(domain).suffix\n\n        domains1, domains2 = self.indicators1.get(\'Domain\', []), self.indicators2.get(\'Domain\', [])\n        if duplicate_incidents.utils.is_groups_cross_empty(domains1, domains2):\n            return {}\n\n        features = {}\n\n        suffix1 = [x for x in duplicate_incidents.utils.get_unique_list(map(get_domain_suffix, domains1)) if x != "com"\n                   and len(x) > DOMAIN_LOCAL_SUFFIX_LENGTH]\n        suffix2 = [x for x in duplicate_incidents.utils.get_unique_list(map(get_domain_suffix, domains2)) if x != "com"\n                   and len(x) > DOMAIN_LOCAL_SUFFIX_LENGTH]\n\n        if len(suffix1) > 0 and len(suffix2) > 0:\n            features[\'domains_suffix_jaccard\'] = duplicate_incidents.utils.jaccard_similarity(suffix1, suffix2)\n\n        features[\'domain_same_length_exist\'] = duplicate_incidents.utils.is_similarity_exist(domains1, domains2,\n                                                                                             lambda v1, v2: len(v1) == len(v2))\n        features[\'domain_similarity_max\'] = duplicate_incidents.utils.calculate_similar_pattern(domains1, domains2)\n\n        return features\n\n    def get_url_features(self):\n        urls1, urls2 = self.indicators1.get(\'URL\', []), self.indicators2.get(\'URL\', [])\n        urls1 = [x for x in urls1 if len(x) <= MAX_LEN_FOR_URL]\n        urls2 = [x for x in urls2 if len(x) <= MAX_LEN_FOR_URL]\n        if duplicate_incidents.utils.is_groups_cross_empty(urls1, urls2):\n            return {}\n\n        features = {}\n\n        def url_path_similarity(x, y):\n            return duplicate_incidents.utils.get_url_path(x) == duplicate_incidents.utils.get_url_path(y) and duplicate_incidents.utils.get_url_path(x) > MIN_URL_PATH\n\n        features[\'url_same_path_exist\'] = duplicate_incidents.utils.is_similarity_exist(urls1, urls2, url_path_similarity)\n        features[\'url_similarity_max\'] = duplicate_incidents.utils.calculate_similar_pattern(urls1, urls2)\n        if len(duplicate_incidents.utils.intersection_set(urls1, urls2)) > 0:\n            features[\'url_min_ld\'] = 0\n        else:\n            features[\'url_min_ld\'] = duplicate_incidents.utils.get_minimal_edit_distance(urls1, urls2)\n        return features\n\n    def get_email_features(self):\n        emails1, emails2 = self.indicators1.get(\'Email\', []), self.indicators2.get(\'Email\', [])\n        if duplicate_incidents.utils.is_groups_cross_empty(emails1, emails2):\n            return {}\n\n        email_user_names1 = map(duplicate_incidents.utils.extract_email_username, emails1)\n        email_user_names2 = map(duplicate_incidents.utils.extract_email_username, emails2)\n\n        features = {}\n        features[\'email_username_similarity_max\'] = duplicate_incidents.utils.calculate_similar_pattern(email_user_names1,\n                                                                                                        email_user_names2)\n        features[\'email_min_ld\'] = duplicate_incidents.utils.get_minimal_edit_distance(email_user_names1, email_user_names2)\n\n        return features\n\n    def get_email_labels_features(self):\n        features = {}\n        labels1 = self.labels_map1\n        labels2 = self.labels_map2\n\n        if EMAIL_SENDER in labels1 and EMAIL_SENDER in labels2:\n            sender_name1 = duplicate_incidents.utils.get_email_name(labels1[EMAIL_SENDER])\n            sender_name2 = duplicate_incidents.utils.get_email_name(labels2[EMAIL_SENDER])\n            if sender_name1 and sender_name2:\n                prefix = EMAIL_SENDER + "_name"\n                features.update(duplicate_incidents.utils.string_similarity_check(prefix, sender_name1, sender_name2))\n\n            sender_email1 = duplicate_incidents.utils.get_email_address(labels1[EMAIL_SENDER])\n            sender_email2 = duplicate_incidents.utils.get_email_address(labels2[EMAIL_SENDER])\n            if sender_email1 and sender_email2:\n                prefix = EMAIL_SENDER + "_address"\n                features.update(duplicate_incidents.utils.string_similarity_check(prefix, sender_email1, sender_email2))\n                same_domain = duplicate_incidents.utils.extract_email_domain(sender_email1) == duplicate_incidents.utils.extract_email_domain(sender_email2)\n                features[prefix + "_same_domain"] = same_domain\n\n        for label in [EMAIL_SUBJECT_LABEL, EMAIL_ATTACHMENT_LABEL]:\n            if label in labels1 and label in labels2:\n                s1 = labels1[label]\n                s2 = labels2[label]\n                features.update(duplicate_incidents.utils.string_similarity_check(label, s1, s2))\n\n        for label in [EMAIL_TEXT_LABEL, EMAIL_HTML_LABEL]:\n            if label in labels1 and label in labels2:\n                s1 = labels1[label]\n                s2 = labels2[label]\n                features[label + \'_words_jaccard\'] = duplicate_incidents.utils.jaccard_similarity(s1.split(), s2.split())\n\n        return features\n\n    def get_incident_features(self):\n        features = {}\n        incident_time_diff = duplicate_incidents.utils.get_time_diff_seconds(self.incident1[\'occurred\'], self.incident2[\'occurred\'])\n        features[\'incident_time_diff\'] = incident_time_diff\n        features[\'same_type\'] = self.incident1[\'type\'] == self.incident2[\'type\']\n        features[\'same_severity\'] = self.incident1[\'severity\'] == self.incident2[\'severity\']\n        features[\'custom_fields_jaccard\'] = duplicate_incidents.utils.jaccard_similarity(self.incident1.get(\'CustomFields\', []),\n                                                                                         self.incident2.get(\'CustomFields\', []))\n        features[\'same_incident_name\'] = self.incident1[\'name\'] == self.incident2[\'name\']\n        if not features[\'same_incident_name\']:\n            features.update(duplicate_incidents.utils.string_similarity_check("incident_name", self.incident1[\'name\'], self.incident2[\'name\']))\n            # features[\'incident_name_ld\'] = duplicate_incidents.utils.edit_distance_max_len(self.incident1[\'name\'], self.incident2[\'name\'])\n        else:\n            features[\'incident_name_ld\'] = 0\n        features[\'labels_jaccard\'] = duplicate_incidents.utils.jaccard_similarity(\n            [(k, v) for (k, v) in self.labels_map1.items() if k not in LABELS_BLACKLIST],\n            [(k, v) for (k, v) in self.labels_map2.items() if k not in LABELS_BLACKLIST]\n        )\n\n        if INSTANCE_LABEL in self.labels_map1 and INSTANCE_LABEL in self.labels_map2:\n            features[\'same_instance\'] = self.labels_map1[INSTANCE_LABEL] == self.labels_map2[INSTANCE_LABEL]\n\n        for indicator_type in duplicate_incidents.utils.intersection_set(self.indicators1.keys(), self.indicators2.keys()):\n            features[\'indicator_%s_jaccard\' % indicator_type] = duplicate_incidents.utils.jaccard_similarity(\n                self.indicators1[indicator_type],\n                self.indicators2[indicator_type])\n\n        return features\n\n    def calculate_features(self):\n        features = {}\n        features.update(self.get_incident_features())\n        features.update(self.get_email_labels_features())\n        features.update(self.get_domains_features())\n        features.update(self.get_url_features())\n        features.update(self.get_email_features())\n\n        features = dict((k, v) for (k, v) in features.items() if v is not None)\n\n        return features\n\n\ndef parse_incident(incident, anonymous_data):\n    incident_info = {key: incident[key] for key in set(INCIDENT_SAFE_FIELDS).intersection(set(incident.keys()))}\n    for field in incident_info:\n        incident_info[field] = duplicate_incidents.utils.hash_object(incident[field], anonymous_data)\n\n    if incident[\'labels\'] is not None:\n        incident_info[\'labels\'] = []\n        for label in incident[\'labels\']:\n            incident_info[\'labels\'].append({\'type\': label[\'type\'],\n                                            \'value\': duplicate_incidents.utils.hash_object(label[\'value\'], anonymous_data)})\n    else:\n        incident_info[\'labels\'] = None\n\n    if incident.get(\'attachment\'):\n        incident_info[\'attachment\'] = []\n        for attachment in incident_info[\'attachment\']:\n            incident_info[\'attachment\'].append({\'type\': attachment[\'type\'],\n                                                \'name\': duplicate_incidents.utils.hash_object(attachment[\'name\'], anonymous_data)})\n    else:\n        incident_info[\'attachment\'] = None\n\n    return incident_info\n\n\ndef run_main(incidents, anonymous_data, recursive_related=False):\n    related_features = {}\n    for incident in incidents.values():\n        related_incidents = incident[\'linkedIncidents\']\n        if recursive_related:\n            for related_incident_id in related_incidents:\n                if related_incident_id in incidents:\n                    related_incidents += list(\n                        set(incidents[related_incident_id][\'linkedIncidents\']).difference(related_incidents))\n        for related_incident_id in related_incidents:\n            key = duplicate_incidents.utils.get_unique_key_for_pair(incident[\'id\'], related_incident_id)\n            if incident[\'id\'] == related_incident_id or key in related_features or related_incident_id not in incidents:\n                continue\n            related_incident = incidents[related_incident_id]\n            related_features[key] = IncidentFeatures(incident, related_incident).calculate_features()\n            related_features[key][\'duplicate\'] =  \'duplicat\' in incident[\'closeReason\'].lower() \\\n                                                  or \'duplicat\' in related_incident[\'closeReason\'].lower()\n\n    non_related_features = {}\n    for incident in incidents.values():\n        related_incidents = incident[\'linkedIncidents\']\n        other_incidents = set(incidents.keys()).difference(set(related_incidents)).difference(set([incident[\'id\']]))\n        for other_incident_id in list(other_incidents)[:MAX_NEGATIVE_INCIDENTS]:\n            key = duplicate_incidents.utils.get_unique_key_for_pair(incident[\'id\'], other_incident_id)\n            if key in non_related_features:\n                continue\n            non_related_features[key] = IncidentFeatures(incident, incidents[other_incident_id]).calculate_features()\n\n    incidents_map_hashed = {}\n    for incident_id, incident in incidents.items():\n        incidents_map_hashed[incident_id] = parse_incident(incident, anonymous_data)\n\n    return {\'related_features\': related_features,\n            \'non_related_features\': non_related_features,\n            \'incidents\': incidents_map_hashed}\n''')
      __stickytape_write_module('''duplicate_incidents/__init__.py''', '''''')
      import json

      from duplicate_incidents.utils import enrich_incidents_by_indicators

      try:
          import boto3
      except:
          pass

      import datetime

      from duplicate_incidents.collect_features import get_duplicate_features


      def get_duplicate_incident_features(query):
          incidents_list = get_incidents_by_query(query, MAX_NUMBER_INCIDENTS)
          incidents = enrich_incidents_by_indicators(demisto, incidents_list, MAX_NUMBER_INDICATORS)
          res = get_duplicate_features.run_main(incidents, ANONYMOUS_DATA, RECURSIVE_RELATED)
          handle_results(res)


      def handle_results(obj):
          if UPLOAD_TO_S3:
              upload_to_s3(json.dumps(obj))
              demisto.results("upload to s3 successfully")
              return
          elif hasattr(demisto, 'results'):
              demisto.results(fileResult('results.json', json.dumps(obj)))
              return

      def upload_to_s3(bytes):
          client = boto3.client(
              's3',
              aws_access_key_id=AWS_ACCESS_KEY,
              aws_secret_access_key=AWS_SECRET_KEY
          )
          now = datetime.datetime.now().isoformat()
          client.put_object(Bucket=AWS_BUCKET, Key='%s/%s.json' % (AWS_CLIENT_ID, now), Body=bytes)


      def get_incidents_by_query(query, max_number_of_results):
          res = demisto.executeCommand("getIncidents", {'query': query, 'size': max_number_of_results})
          return res[0]['Contents']['data']


      ########################################################################################################################


      UPLOAD_TO_S3 = (demisto.args()['uploadToS3'] == 'yes')
      ANONYMOUS_DATA = (demisto.args()['anonymousData'] == 'yes')
      MAX_NUMBER_INCIDENTS = int(demisto.args()['maxNumberOfIncidents'])
      INCIDENT_QUERY = demisto.args()['incidentsQuery']
      RECURSIVE_RELATED = (demisto.args()['recursive_related'] == 'yes')
      MAX_NUMBER_INDICATORS = MAX_NUMBER_INCIDENTS * 100

      AWS_ACCESS_KEY = ''
      AWS_SECRET_KEY = ''
      AWS_BUCKET = ''
      AWS_CLIENT_ID = ''

      AWS_INFO = demisto.args().get('awsInfo')
      if AWS_INFO:
          AWS_ACCESS_KEY, AWS_SECRET_KEY, AWS_BUCKET, AWS_CLIENT_ID = AWS_INFO.split(',')


      get_duplicate_incident_features(INCIDENT_QUERY)



type: python
subtype: python2
tags:
- ml
comment: Calculate features for machine learning
enabled: true
args:
- name: maxNumberOfIncidents
  description: Max number of incidents to check
  defaultValue: "200"
- name: anonymousData
  auto: PREDEFINED
  predefined:
  - "yes"
  - "no"
  description: Incident data should be anonymous?
  defaultValue: "yes"
- name: uploadToS3
  auto: PREDEFINED
  predefined:
  - "yes"
  - "no"
  description: Upload data to s3
  defaultValue: "no"
- name: awsInfo
  description: 'Comma separated values of: AWS_ACCESS_KEY,AWS_SECRET_KEY,AWS_BUCKET,AWS_CLIENT_ID'
- name: incidentsQuery
  description: The query to fetch incidents from the database
  defaultValue: linkedIncidents:*
- name: recursive_related
  auto: PREDEFINED
  predefined:
  - "yes"
  - "no"
  description: Check for second degree related incidents
  defaultValue: "no"
scripttarget: 0
timeout: 400ns
runonce: false
dockerimage: demisto/ml-telemetry
fromversion: "3.5.0"