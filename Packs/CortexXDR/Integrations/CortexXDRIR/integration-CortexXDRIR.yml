category: Endpoint
sectionorder:
- Connect
- Collect
commonfields:
  id: Cortex XDR - IR - Candidate
  version: -1
configuration:
- display: Fetch incidents
  name: isFetch
  defaultvalue: 'true'
  type: 8
  section: Collect
  required: false
- display: Incident type
  name: incidentType
  type: 13
  section: Connect
  required: false
  defaultvalue: Cortex XDR - Lite
- name: url
  type: 0
  display: Server URL (copy URL from XDR)
  section: Connect
  required: true
- displaypassword: API Key ID
  name: apikey_id_creds
  type: 9
  hiddenusername: true
  display: ''
  section: Connect
  required: false
- display: ''
  name: apikey_creds
  type: 9
  section: Connect
  required: false
  displaypassword: API Key
  hiddenusername: true
- defaultvalue: 'false'
  display: Remove legacy incident fields
  name: dont_format_sublists
  type: 8
  section: Collect
  required: false
  additionalinfo: Not selected for backwards compatibility. Recommended to select. This will remove duplicated incident fields under file_artifacts, network_artifacts, and alerts (like client_id, clientid.)
- display: Incident Mirroring Direction
  name: mirror_direction
  required: false
  type: 15
  section: Collect
  defaultvalue: None
  options:
  - None
  - Incoming
  - Outgoing
  - Both
- defaultvalue: '1'
  display: XDR mirroring delay in minutes
  name: xdr_delay
  type: 0
  section: Collect
  required: false
  advanced: true
  additionalinfo: In the event of a delay in mirroring incoming changes from XDR, use the xdr_delay parameter to extend the look-back period. However, be aware that this may result in increased latency when updating incidents.
- display: Custom close-reason mapping (XSOAR -> XDR mirrored incident. Overwrites default close-reason mapping defined by Cortex XSOAR)
  section: Collect
  advanced: true
  additionalinfo: 'Define how to close the mirrored incidents from Cortex XSOAR into Cortex XDR with a custom close reason mapping. Enter a comma-separated list of close reasons (acceptable format {Cortex XSOAR close reason}={Cortex XDR close reason}) to override the default close reason mapping defined by Cortex XSOAR. Note that the mapping must be configured accordingly with the existing close reasons in Cortex XSOAR and Cortex XDR. Not following this format will result in closing the incident with a default close reason. Example: "Resolved=Other,Duplicate=Other". Refer to ../README.md for possible close-reasons - `XDR Incident Mirroring`.'
  name: custom_xsoar_to_xdr_close_reason_mapping
  defaultvalue: ''
  type: 0
  required: false
- display: Custom close-reason mapping (XDR -> XSOAR mirrored incident. Overwrites default close-reason mapping defined by Cortex XSOAR)
  section: Collect
  advanced: true
  additionalinfo: 'Define how to close the mirrored incidents from Cortex XDR into Cortex XSOAR with a custom close reason mapping. Enter a comma-separated list of close reasons (acceptable format {Cortex XDR close reason}={Cortex XSOAR close reason}) to override the default close reason mapping defined by Cortex XSOAR. Note that the mapping must be configured accordingly with the existing close reasons in Cortex XSOAR and Cortex XDR. Not following this format will result in closing the incident with a default close reason. Example: “Known Issue=Resolved, Duplicate Incident=Other". Refer to ../README.md for possible close-reasons - `XDR Incident Mirroring`.'
  name: custom_xdr_to_xsoar_close_reason_mapping
  defaultvalue: ''
  type: 0
  required: false
- display: API Key ID
  name: apikey_id
  type: 4
  hidden: true
  section: Connect
  required: false
- display: API Key
  name: apikey
  type: 4
  section: Connect
  required: false
  hidden: true
- additionalinfo: The timeout of the HTTP requests sent to Cortex XDR API (in seconds).
  defaultvalue: '120'
  display: HTTP Timeout
  name: timeout
  type: 0
  section: Connect
  required: false
  advanced: true
- display: Maximum number of incidents per fetch
  name: max_fetch
  type: 0
  section: Collect
  required: false
  additionalinfo: The maximum number of incidents per fetch. Cannot exceed 100.
  defaultvalue: '10'
- display: Only fetch starred incidents
  name: starred
  type: 8
  section: Collect
  advanced: true
  required: false
- defaultvalue: 3 days
  display: Starred incidents fetch window
  name: starred_incidents_fetch_window
  type: 0
  section: Collect
  required: false
  additionalinfo: Starred fetch window timestamp (<number> <time unit>, e.g., 12 hours, 7 days). Fetches only starred incidents within the specified time range.
  advanced: true
- display: First fetch timestamp (<number> <time unit>, e.g., 12 hours, 7 days)
  name: fetch_time
  type: 0
  section: Collect
  required: false
  defaultvalue: 3 days
- display: Sync Incident Owners
  name: sync_owners
  type: 8
  section: Collect
  advanced: true
  required: false
  additionalinfo: For Cortex XSOAR version 6.0.0 and above. If selected, for every incident fetched from Cortex XDR to Cortex XSOAR, the incident owners will be synced. Note that once this value is changed and synchronized between the systems, additional changes will not be reflected. For example, if you change the owner in Cortex XSOAR, the new owner will also be changed in Cortex XDR. However, if you now change the owner back in Cortex XDR, this additional change will not be reflected in Cortex XSOAR. In addition, for this change to be reflected, the owners must exist in both Cortex XSOAR and Cortex XDR.
- display: Trust any certificate (not secure)
  name: insecure
  type: 8
  section: Connect
  advanced: true
  required: false
- display: Use system proxy settings
  name: proxy
  type: 8
  section: Connect
  advanced: true
  required: false
- additionalinfo: Whether the XDR tenant mode is prevent only
  display: Prevent Only Mode
  name: prevent_only
  type: 8
  section: Connect
  advanced: true
  required: false
- additionalinfo: 'The statuses of the incidents that will be fetched. If no status is provided then incidents of all the statuses will be fetched. Note: An incident whose status was changed to a filtered status after its creation time will not be fetched.'
  display: Incident Statuses to Fetch
  name: status
  options:
  - new
  - under_investigation
  - resolved_known_issue
  - resolved_false_positive
  - resolved_true_positive
  - resolved_security_testing
  - resolved_other
  - resolved_auto
  type: 16
  section: Collect
  advanced: true
  required: false
- additionalinfo: Whether to fetch only the essential incident's fields - without Network Artifacts and File Artifacts to minimize the incident's information.
  display: Minimize Incident Information
  name: exclude_fields
  required: false
  type: 8
  section: Collect
  defaultvalue: 'true'
  advanced: true
- display: Close all related alerts in XDR
  name: close_alerts_in_xdr
  required: false
  additionalinfo: Close all related alerts in Cortex XDR once an incident has been closed in Cortex XSOAR.
  advanced: true
  type: 8
  section: Collect
description: Cortex XDR is the world's first detection and response app that natively integrates network, endpoint, and cloud data to stop sophisticated attacks.
display: Palo Alto Networks Cortex XDR - Investigation and Response - Candidate
name: Cortex XDR - IR - Candidate
script:
  commands:
  - arguments:
    - description: A date in the format 2019-12-31T23:59:00 in UTC. Only incidents that were created on or before the specified date/time will be retrieved.
      name: lte_creation_time
    - description: A date in the format 2019-12-31T23:59:00 in UTC. Only incidents that were created on or after the specified date/time will be retrieved.
      name: gte_creation_time
    - description: Filters returned incidents that were modified on or before the specified date/time, in the format 2019-12-31T23:59:00.
      name: lte_modification_time
    - description: Filters returned incidents that were modified on or after the specified date/time, in the format 2019-12-31T23:59:00.
      name: gte_modification_time
    - description: An array or CSV string of incident IDs.
      isArray: true
      name: incident_id_list
    - description: Filters returned incidents that were created on or after the specified date/time range, for example, 1 month, 2 days, 1 hour, and so on.
      name: since_creation_time
    - description: Filters returned incidents that were modified on or after the specified date/time range, for example, 1 month, 2 days, 1 hour, and so on.
      name: since_modification_time
    - auto: PREDEFINED
      description: Sorts returned incidents by the date/time that the incident was last modified ("asc" - ascending, "desc" - descending).
      name: sort_by_modification_time
      predefined:
      - asc
      - desc
    - auto: PREDEFINED
      description: Sorts returned incidents by the date/time that the incident was created ("asc" - ascending, "desc" - descending).
      name: sort_by_creation_time
      predefined:
      - asc
      - desc
    - defaultValue: '0'
      description: Page number (for pagination). 0 is the first page.
      name: page
    - defaultValue: '100'
      description: Maximum number of incidents to return per page. The default and maximum is 100.
      name: limit
    - description: 'Filters only incidents in the specified status. The options are: new, under_investigation, resolved_known_issue, resolved_false_positive, resolved_true_positive resolved_security_testing, resolved_other, resolved_auto.'
      name: status
    - auto: PREDEFINED
      description: Whether the incident is starred.
      name: starred
      predefined:
      - 'true'
      - 'false'
    - description: Deprecated. Use gte_creation_time instead.
      defaultValue: 3 days
      name: starred_incidents_fetch_window
      deprecated: true
    description: "Returns a list of incidents, which you can filter by a list of incident IDs (max. 100), the time the incident was last modified, and the time the incident was created.\nIf you pass multiple filtering arguments, they will be concatenated using the AND condition. The OR condition is not supported."
    name: xdr-get-incidents
    outputs:
    - contextPath: PaloAltoNetworksXDR.Incident.incident_id
      description: Unique ID assigned to each returned incident.
      type: String
    - contextPath: PaloAltoNetworksXDR.Incident.manual_severity
      description: Incident severity assigned by the user. This does not affect the calculated severity. Can be "low", "medium", "high".
      type: String
    - contextPath: PaloAltoNetworksXDR.Incident.manual_description
      description: Incident description provided by the user.
      type: String
    - contextPath: PaloAltoNetworksXDR.Incident.assigned_user_mail
      description: Email address of the assigned user.
      type: String
    - contextPath: PaloAltoNetworksXDR.Incident.high_severity_alert_count
      description: Number of alerts with the severity HIGH.
      type: String
    - contextPath: PaloAltoNetworksXDR.Incident.host_count
      description: Number of hosts involved in the incident.
      type: number
    - contextPath: PaloAltoNetworksXDR.Incident.xdr_url
      description: A link to the incident view on Cortex XDR.
      type: String
    - contextPath: PaloAltoNetworksXDR.Incident.assigned_user_pretty_name
      description: Full name of the user assigned to the incident.
      type: String
    - contextPath: PaloAltoNetworksXDR.Incident.alert_count
      description: Total number of alerts in the incident.
      type: number
    - contextPath: PaloAltoNetworksXDR.Incident.med_severity_alert_count
      description: Number of alerts with the severity MEDIUM.
      type: number
    - contextPath: PaloAltoNetworksXDR.Incident.user_count
      description: Number of users involved in the incident.
      type: number
    - contextPath: PaloAltoNetworksXDR.Incident.severity
      description: "Calculated severity of the incident. Valid values are: \"low\",\"medium\",\"high\".\n"
      type: String
    - contextPath: PaloAltoNetworksXDR.Incident.low_severity_alert_count
      description: Number of alerts with the severity LOW.
      type: String
    - contextPath: PaloAltoNetworksXDR.Incident.status
      description: "Current status of the incident. Valid values are: \"new\",\"under_investigation\",\"resolved_known_issue\",\"resolved_duplicate_incident\",\"resolved_false_positive\",\"resolved_true_positive\",\"resolved_security_testing\" or \"resolved_other\".\n"
      type: String
    - contextPath: PaloAltoNetworksXDR.Incident.description
      description: Description of the incident.
      type: String
    - contextPath: PaloAltoNetworksXDR.Incident.resolve_comment
      description: Comments entered by the user when the incident was resolved.
      type: String
    - contextPath: PaloAltoNetworksXDR.Incident.notes
      description: Comments entered by the user regarding the incident.
      type: String
    - contextPath: PaloAltoNetworksXDR.Incident.creation_time
      description: Date and time the incident was created on Cortex XDR.
      type: date
    - contextPath: PaloAltoNetworksXDR.Incident.detection_time
      description: Date and time that the first alert occurred in the incident.
      type: date
    - contextPath: PaloAltoNetworksXDR.Incident.modification_time
      description: Date and time that the incident was last modified.
      type: date
  - arguments:
    - description: The ID of the incident for which to get additional data.
      name: incident_id
      required: true
    - defaultValue: '1000'
      description: Maximum number of alerts to return.
      name: alerts_limit
    - defaultValue: 'False'
      description: Return data only if the incident was changed since the last time it was mirrored into Cortex XSOAR.  This flag should be used only from within a Cortex XDR incident.
      name: return_only_updated_incident
    - defaultValue: 'False'
      description: Whether to exclude Network Artifacts and File Artifacts from incident data.
      name: excluding_artifacts
    description: Returns additional data for the specified incident, for example, related alerts, file artifacts, network artifacts, and so on.
    name: xdr-get-incident-extra-data
    outputs:
    - contextPath: PaloAltoNetworksXDR.Incident.incident_id
      description: Unique ID assigned to each returned incident.
      type: String
    - contextPath: PaloAltoNetworksXDR.Incident.creation_time
      description: Date and time the incident was created on Cortex XDR.
      type: Date
    - contextPath: PaloAltoNetworksXDR.Incident.modification_time
      description: Date and time that the incident was last modified.
      type: Date
    - contextPath: PaloAltoNetworksXDR.Incident.detection_time
      description: Date and time that the first alert occurred in the incident.
      type: Date
    - contextPath: PaloAltoNetworksXDR.Incident.status
      description: "Current status of the incident. Valid values are:\n\"new\",\"under_investigation\",\"resolved_known_issue\",\"resolved_duplicate\",\"resolved_false_positive\",\"resolved_true_positive\",\"resolved_security_testing\",\"resolved_other\"."
      type: String
    - contextPath: PaloAltoNetworksXDR.Incident.severity
      description: 'Calculated severity of the incident. Valid values are: "low","medium","high".'
      type: String
    - contextPath: PaloAltoNetworksXDR.Incident.description
      description: Description of the incident.
      type: String
    - contextPath: PaloAltoNetworksXDR.Incident.assigned_user_mail
      description: Email address of the assigned user.
      type: String
    - contextPath: PaloAltoNetworksXDR.Incident.assigned_user_pretty_name
      description: Full name of the user assigned to the incident.
      type: String
    - contextPath: PaloAltoNetworksXDR.Incident.alert_count
      description: Total number of alerts in the incident.
      type: Number
    - contextPath: PaloAltoNetworksXDR.Incident.low_severity_alert_count
      description: Number of alerts with the severity LOW.
      type: Number
    - contextPath: PaloAltoNetworksXDR.Incident.med_severity_alert_count
      description: Number of alerts with the severity MEDIUM.
      type: Number
    - contextPath: PaloAltoNetworksXDR.Incident.high_severity_alert_count
      description: Number of alerts with the severity HIGH.
      type: Number
    - contextPath: PaloAltoNetworksXDR.Incident.user_count
      description: Number of users involved in the incident.
      type: Number
    - contextPath: PaloAltoNetworksXDR.Incident.host_count
      description: Number of hosts involved in the incident.
      type: Number
    - contextPath: PaloAltoNetworksXDR.Incident.notes
      description: Comments entered by the user regarding the incident.
      type: Unknown
    - contextPath: PaloAltoNetworksXDR.Incident.resolve_comment
      description: Comments entered by the user when the incident was resolved.
      type: String
    - contextPath: PaloAltoNetworksXDR.Incident.manual_severity
      description: Incident severity assigned by the user. This does not affect the calculated severity. Can be "low", "medium", "high".
      type: String
    - contextPath: PaloAltoNetworksXDR.Incident.manual_description
      description: Incident description provided by the user.
      type: String
    - contextPath: PaloAltoNetworksXDR.Incident.xdr_url
      description: A link to the incident view on Cortex XDR.
      type: String
    - contextPath: PaloAltoNetworksXDR.Incident.starred
      description: Whether the incident is starred.
      type: Boolean
    - contextPath: PaloAltoNetworksXDR.Incident.wildfire_hits.mitre_techniques_ids_and_names
      description: Incident MITRE techniques IDs and names.
      type: String
    - contextPath: PaloAltoNetworksXDR.Incident.wildfire_hits.mitre_tactics_ids_and_names
      description: Incident MITRE tactics IDs and names.
      type: String
    - contextPath: PaloAltoNetworksXDR.Incident.alerts.alert_id
      description: Unique ID for each alert.
      type: String
    - contextPath: PaloAltoNetworksXDR.Incident.alerts.detection_timestamp
      description: Date and time the alert occurred.
      type: Date
    - contextPath: PaloAltoNetworksXDR.Incident.alerts.source
      description: The product/vendor from which this alert came.
      type: String
    - contextPath: PaloAltoNetworksXDR.Incident.alerts.severity
      description: 'Severity of the alert. Valid values are: "low","medium","high".'
      type: String
    - contextPath: PaloAltoNetworksXDR.Incident.alerts.name
      description: Calculated name of the alert.
      type: String
    - contextPath: PaloAltoNetworksXDR.Incident.alerts.category
      description: Category of the alert, for example, Spyware Detected via Anti-Spyware profile.
      type: String
    - contextPath: PaloAltoNetworksXDR.Incident.alerts.description
      description: Description of the alert.
      type: String
    - contextPath: PaloAltoNetworksXDR.Incident.alerts.host_ip_list
      description: Host IP address involved in the alert.
      type: Unknown
    - contextPath: PaloAltoNetworksXDR.Incident.alerts.host_name
      description: Hostname involved in the alert.
      type: String
    - contextPath: PaloAltoNetworksXDR.Incident.alerts.user_name
      description: User name involved with the alert.
      type: String
    - contextPath: PaloAltoNetworksXDR.Incident.alerts.event_type
      description: 'Event type. Valid values are: "Process Execution","Network Event","File Event","Registry Event","Injection Event","Load Image Event","Windows Event Log".'
      type: String
    - contextPath: PaloAltoNetworksXDR.Incident.alerts.action
      description: 'The action that triggered the alert. Valid values are: "REPORTED", "BLOCKED", "POST_DETECTED", "SCANNED", "DOWNLOAD", "PROMPT_ALLOW", "PROMPT_BLOCK", "DETECTED", "BLOCKED_1", "BLOCKED_2", "BLOCKED_3", "BLOCKED_5", "BLOCKED_6", "BLOCKED_7", "BLOCKED_8", "BLOCKED_9", "BLOCKED_10", "BLOCKED_11", "BLOCKED_13", "BLOCKED_14", "BLOCKED_15", "BLOCKED_16", "BLOCKED_17", "BLOCKED_24", "BLOCKED_25", "DETECTED_0", "DETECTED_4", "DETECTED_18", "DETECTED_19", "DETECTED_20", "DETECTED_21", "DETECTED_22", "DETECTED_23".'
      type: String
    - contextPath: PaloAltoNetworksXDR.Incident.alerts.action_pretty
      description: 'The action that triggered the alert. Valid values are: "Detected (Reported)" "Prevented (Blocked)" "Detected (Post Detected)" "Detected (Scanned)" "Detected (Download)" "Detected (Prompt Allow)" "Prevented (Prompt Block)" "Detected" "Prevented (Denied The Session)" "Prevented (Dropped The Session)" "Prevented (Dropped The Session And Sent a TCP Reset)" "Prevented (Blocked The URL)" "Prevented (Blocked The IP)" "Prevented (Dropped The Packet)" "Prevented (Dropped All Packets)" "Prevented (Terminated The Session And Sent a TCP Reset To Both Sides Of The Connection)" "Prevented (Terminated The Session And Sent a TCP Reset To The Client)" "Prevented (Terminated The Session And Sent a TCP Reset To The Server)" "Prevented (Continue)" "Prevented (Block-Override)" "Prevented (Override-Lockout)" "Prevented (Override)" "Prevented (Random-Drop)" "Prevented (Silently Dropped The Session With An ICMP Unreachable Message To The Host Or Application)" "Prevented (Block)" "Detected (Allowed The Session)" "Detected (Raised An Alert)" "Detected (Syncookie Sent)" "Detected (Forward)" "Detected (Wildfire Upload Success)" "Detected (Wildfire Upload Failure)" "Detected (Wildfire Upload Skip)" "Detected (Sinkhole)".'
      type: String
    - contextPath: PaloAltoNetworksXDR.Incident.alerts.actor_process_image_name
      description: Image name.
      type: String
    - contextPath: PaloAltoNetworksXDR.Incident.alerts.actor_process_command_line
      description: Command line.
      type: String
    - contextPath: PaloAltoNetworksXDR.Incident.alerts.actor_process_signature_status
      description: 'Signature status. Valid values are: "Signed" "Invalid Signature" "Unsigned" "Revoked" "Signature Fail" "N/A" "Weak Hash".'
      type: String
    - contextPath: PaloAltoNetworksXDR.Incident.alerts.actor_process_signature_vendor
      description: Signature vendor name.
      type: String
    - contextPath: PaloAltoNetworksXDR.Incident.alerts.causality_actor_process_image_name
      description: Image name.
      type: String
    - contextPath: PaloAltoNetworksXDR.Incident.alerts.causality_actor_process_command_line
      description: Command line.
      type: String
    - contextPath: PaloAltoNetworksXDR.Incident.alerts.causality_actor_process_signature_status
      description: 'Signature status. Valid values are: "Signed" "Invalid Signature" "Unsigned" "Revoked" "Signature Fail" "N/A" "Weak Hash".'
      type: String
    - contextPath: PaloAltoNetworksXDR.Incident.alerts.causality_actor_process_signature_vendor
      description: Signature vendor.
      type: String
    - contextPath: PaloAltoNetworksXDR.Incident.alerts.causality_actor_causality_id
      description: Causality ID.
      type: Unknown
    - contextPath: PaloAltoNetworksXDR.Incident.alerts.action_process_image_name
      description: Image name.
      type: String
    - contextPath: PaloAltoNetworksXDR.Incident.alerts.action_process_image_command_line
      description: Command line.
      type: String
    - contextPath: PaloAltoNetworksXDR.Incident.alerts.action_process_image_sha256
      description: Image SHA256 hash.
      type: String
    - contextPath: PaloAltoNetworksXDR.Incident.alerts.action_process_signature_status
      description: 'Signature status. Valid values are: "Signed" "Invalid Signature" "Unsigned" "Revoked" "Signature Fail" "N/A" "Weak Hash".'
      type: String
    - contextPath: PaloAltoNetworksXDR.Incident.alerts.action_process_signature_vendor
      description: Signature vendor name.
      type: String
    - contextPath: PaloAltoNetworksXDR.Incident.alerts.action_file_path
      description: File path.
      type: String
    - contextPath: PaloAltoNetworksXDR.Incident.alerts.action_file_md5
      description: MD5 hash of the file.
      type: String
    - contextPath: PaloAltoNetworksXDR.Incident.alerts.action_file_sha256
      description: SHA256 hash of the file.
      type: String
    - contextPath: PaloAltoNetworksXDR.Incident.alerts.action_registry_data
      description: Registry data.
      type: String
    - contextPath: PaloAltoNetworksXDR.Incident.alerts.action_registry_full_key
      description: Registry full key.
      type: String
    - contextPath: PaloAltoNetworksXDR.Incident.alerts.action_local_ip
      description: Local IP address.
      type: String
    - contextPath: PaloAltoNetworksXDR.Incident.alerts.action_local_port
      description: Local port.
      type: Number
    - contextPath: PaloAltoNetworksXDR.Incident.alerts.action_remote_ip
      description: Remote IP address.
      type: String
    - contextPath: PaloAltoNetworksXDR.Incident.alerts.action_remote_port
      description: Remote port.
      type: Number
    - contextPath: PaloAltoNetworksXDR.Incident.alerts.action_external_hostname
      description: External hostname.
      type: String
    - contextPath: PaloAltoNetworksXDR.Incident.alerts.fw_app_id
      description: Firewall app ID.
      type: Unknown
    - contextPath: PaloAltoNetworksXDR.Incident.alerts.is_whitelisted
      description: 'Whether the alert is on the allow list. Valid values are: "Yes" "No".'
      type: String
    - contextPath: PaloAltoNetworksXDR.Incident.alerts.starred
      description: Whether the alert is starred.
      type: Boolean
    - contextPath: PaloAltoNetworksXDR.Incident.network_artifacts.type
      description: Network artifact type.
      type: String
    - contextPath: PaloAltoNetworksXDR.Incident.network_artifacts.network_remote_port
      description: The remote port related to the artifact.
      type: number
    - contextPath: PaloAltoNetworksXDR.Incident.network_artifacts.alert_count
      description: Number of alerts related to the artifact.
      type: number
    - contextPath: PaloAltoNetworksXDR.Incident.network_artifacts.network_remote_ip
      description: The remote IP address related to the artifact.
      type: String
    - contextPath: PaloAltoNetworksXDR.Incident.network_artifacts.is_manual
      description: Whether the artifact was created by the user (manually).
      type: boolean
    - contextPath: PaloAltoNetworksXDR.Incident.network_artifacts.network_domain
      description: The domain related to the artifact.
      type: String
    - contextPath: PaloAltoNetworksXDR.Incident.network_artifacts.type
      description: 'The artifact type. Valid values are: "META", "GID", "CID", "HASH", "IP", "DOMAIN", "REGISTRY", "HOSTNAME".'
      type: String
    - contextPath: PaloAltoNetworksXDR.Incident.network_artifacts.network_country
      description: The country related to the artifact.
      type: String
    - contextPath: PaloAltoNetworksXDR.Incident.file_artifacts.file_signature_status
      description: 'Digital signature status of the file. Valid values are: "SIGNATURE_UNAVAILABLE" "SIGNATURE_SIGNED" "SIGNATURE_INVALID" "SIGNATURE_UNSIGNED" "SIGNATURE_WEAK_HASH".'
      type: String
    - contextPath: PaloAltoNetworksXDR.Incident.file_artifacts.is_process
      description: Whether the file artifact is related to a process execution.
      type: boolean
    - contextPath: PaloAltoNetworksXDR.Incident.file_artifacts.file_name
      description: Name of the file.
      type: String
    - contextPath: PaloAltoNetworksXDR.Incident.file_artifacts.file_wildfire_verdict
      description: 'The file verdict, calculated by Wildfire. Valid values are: "BENIGN" "MALWARE" "GRAYWARE" "PHISHING" "UNKNOWN".'
      type: String
    - contextPath: PaloAltoNetworksXDR.Incident.file_artifacts.alert_count
      description: Number of alerts related to the artifact.
      type: number
    - contextPath: PaloAltoNetworksXDR.Incident.file_artifacts.is_malicious
      description: Whether the artifact is malicious, as decided by the Wildfire verdict.
      type: boolean
    - contextPath: PaloAltoNetworksXDR.Incident.file_artifacts.is_manual
      description: Whether the artifact was created by the user (manually).
      type: boolean
    - contextPath: PaloAltoNetworksXDR.Incident.file_artifacts.type
      description: 'The artifact type. Valid values are: "META" "GID" "CID" "HASH" "IP" "DOMAIN" "REGISTRY" "HOSTNAME".'
      type: String
    - contextPath: PaloAltoNetworksXDR.Incident.file_artifacts.file_sha256
      description: SHA256 hash of the file.
      type: String
    - contextPath: PaloAltoNetworksXDR.Incident.file_artifacts.file_signature_vendor_name
      description: File signature vendor name.
      type: String
    - contextPath: Account.Username
      description: The username in the relevant system.
      type: String
    - contextPath: Endpoint.Hostname
      description: The hostname that is mapped to this endpoint.
      type: String
    - contextPath: Endpoint.ID
      description: The agent ID of the endpoint.
      type: String
    - contextPath: File.Path
      description: The path where the file is located.
      type: String
    - contextPath: File.MD5
      description: The MD5 hash of the file.
      type: String
    - contextPath: File.SHA256
      description: The SHA256 hash of the file.
      type: String
    - contextPath: File.Name
      description: The full file name (including the file extension).
      type: String
    - contextPath: Process.Name
      description: The name of the process.
      type: String
    - contextPath: Process.MD5
      description: The MD5 hash of the process.
      type: String
    - contextPath: Process.SHA256
      description: The SHA256 hash of the process.
      type: String
    - contextPath: Process.PID
      description: The PID of the process.
      type: String
    - contextPath: Process.Path
      description: The file system path to the binary file.
      type: String
    - contextPath: Process.Start Time
      description: The timestamp of the process start time.
      type: String
    - contextPath: Process.CommandLine
      description: The full command line (including arguments).
      type: String
    - contextPath: Process.is_malicious
      description: Whether the artifact is malicious, as decided by the Wildfire verdict.
      type: boolean
    - contextPath: IP.Address
      description: IP address.
      type: String
    - contextPath: IP.Geo.Country
      description: The country in which the IP address is located.
      type: String
    - contextPath: Domain.Name
      description: 'The domain name, for example: "google.com".'
      type: String
  - arguments:
    - description: XDR incident ID. You can get the incident ID from the output of the 'xdr-get-incidents' command or the 'xdr-get-incident-extra-details' command.
      name: incident_id
      required: true
    - auto: PREDEFINED
      description: Severity to assign to the incident.
      name: manual_severity
      predefined:
      - HIGH
      - MEDIUM
      - LOW
    - description: Email address of the user to assign to the incident.
      name: assigned_user_mail
    - description: Full name of the user assigned to the incident. To supply a new value in this field, you must also provide a value for the 'assigned_user_mail' argument.
      name: assigned_user_pretty_name
    - auto: PREDEFINED
      description: Status of the incident.
      name: status
      predefined:
      - NEW
      - UNDER_INVESTIGATION
      - RESOLVED_KNOWN_ISSUE
      - RESOLVED_DUPLICATE
      - RESOLVED_FALSE_POSITIVE
      - RESOLVED_TRUE_POSITIVE
      - RESOLVED_SECURITY_TESTING
      - RESOLVED_OTHER
    - description: Comment explaining why the incident was resolved. This should be set when the incident is resolved.
      name: resolve_comment
    - auto: PREDEFINED
      description: If true, will remove all assigned users from the incident.
      name: unassign_user
      predefined:
      - 'true'
      - 'false'
    - description: Add a comment to the incident.
      name: add_comment
    - auto: PREDEFINED
      description: Whether to resolve alerts related to a resolved incident. The incident is considered resolved when the status argument includes the "RESOLVED" or "resolve_comment" value.
      name: resolve_alerts
      predefined:
      - 'true'
      - 'false'
      defaultValue: 'false'
    description: Updates one or more fields of a specified incident. Missing fields will be ignored. To remove the assignment for an incident, pass a null value in the assignee email argument.
    name: xdr-update-incident
  - arguments:
    - description: Product name.
      name: product
      required: true
    - description: Vendor name.
      name: vendor
      required: true
    - description: Source IP address.
      name: local_ip
    - description: Source port.
      name: local_port
      required: true
    - description: Destination IP address.
      name: remote_ip
      required: true
    - description: Destination port.
      name: remote_port
      required: true
    - description: The time the alert occurred in milliseconds, or a date in the format 2019-10-23T10:00:00. If not set, the event time will be defined as now.
      name: event_timestamp
    - auto: PREDEFINED
      defaultValue: Medium
      description: 'The alert severity. '
      name: severity
      predefined:
      - Informational
      - Low
      - Medium
      - High
    - description: The alert name.
      name: alert_name
      required: true
    - description: The alert description.
      name: alert_description
    description: "Uploads an alert from external alert sources in Cortex XDR format. Cortex XDR displays alerts that are parsed\nsuccessfully in related incidents and views. You can send 600 alerts per minute. Each request can contain a\nmaximum of 60 alerts."
    name: xdr-insert-parsed-alert
  - arguments:
    - description: List of alerts in CEF format.
      isArray: true
      name: cef_alerts
      required: true
    description: Upload alerts in CEF format from external alert sources. After you map CEF alert fields to Cortex XDR fields, Cortex XDR displays the alerts in related incidents and views. You can send 600 requests per minute. Each request can contain a maximum of 60 alerts.
    name: xdr-insert-cef-alerts
  - arguments:
    - description: The incident ID. Allows linking the response action to the incident that triggered it.
      name: incident_id
    - description: The endpoint ID to isolate. You can retrieve the string from the xdr-get-endpoints command.
      name: endpoint_id
      required: true
    - auto: PREDEFINED
      defaultValue: 'false'
      description: Whether to suppress an error when trying to isolate a disconnected endpoint. When set to false, an error will be returned.
      name: suppress_disconnected_endpoint_error
      predefined:
      - 'true'
      - 'false'
    - description: Interval in seconds between each poll.
      name: interval_in_seconds
    - description: Polling timeout in seconds.
      name: timeout_in_seconds
    - description: The action IDs for polling use.
      isArray: true
      name: action_id
      deprecated: true
    description: Isolates the specified endpoint.
    execution: true
    name: xdr-endpoint-isolate
    outputs:
    - contextPath: PaloAltoNetworksXDR.Isolation.endpoint_id
      description: The endpoint ID.
      type: String
    polling: true
  - arguments:
    - description: The incident ID. Allows linking the response action to the incident that triggered it.
      name: incident_id
    - description: The endpoint ID to isolate. You can retrieve the string from the xdr-get-endpoints command.
      name: endpoint_id
      required: true
    - auto: PREDEFINED
      defaultValue: 'false'
      description: Whether to suppress an error when trying to isolate a disconnected endpoint. When set to false, an error will be returned.
      name: suppress_disconnected_endpoint_error
      predefined:
      - 'true'
      - 'false'
    deprecated: true
    description: Deprecated. Use `xdr-endpoint-isolate` instead.
    execution: true
    name: xdr-isolate-endpoint
    outputs:
    - contextPath: PaloAltoNetworksXDR.Isolation.endpoint_id
      description: The endpoint ID.
      type: String
  - arguments:
    - description: The incident ID. Allows linking the response action to the incident that triggered it.
      name: incident_id
    - description: The endpoint ID for which to reverse the isolation. You can retrieve it from the xdr-get-endpoints command.
      name: endpoint_id
      required: true
    - description: Whether to suppress an error when trying to unisolate a disconnected endpoint. When set to false, an error will be returned.
      name: suppress_disconnected_endpoint_error
      auto: PREDEFINED
      defaultValue: 'false'
      predefined:
      - 'true'
      - 'false'
    - description: Interval in seconds between each poll.
      name: interval_in_seconds
    - description: Polling timeout in seconds.
      name: timeout_in_seconds
    - description: The action IDs for polling use.
      isArray: true
      name: action_id
      deprecated: true
    description: Reverses the isolation of an endpoint.
    execution: true
    name: xdr-endpoint-unisolate
    outputs:
    - contextPath: PaloAltoNetworksXDR.UnIsolation.endpoint_id
      description: Isolates the specified endpoint.
      type: String
    polling: true
  - deprecated: true
    description: Deprecated. Use `xdr-endpoint-unisolate` instead.
    execution: true
    name: xdr-unisolate-endpoint
    outputs:
    - contextPath: PaloAltoNetworksXDR.UnIsolation.endpoint_id
      description: Isolates the specified endpoint.
      type: String
    arguments:
    - description: The incident ID. Allows linking the response action to the incident that triggered it.
      name: incident_id
    - description: The endpoint ID for which to reverse the isolation. You can retrieve it from the xdr-get-endpoints command.
      name: endpoint_id
      required: true
    - auto: PREDEFINED
      defaultValue: 'false'
      description: Whether to suppress an error when trying to unisolate a disconnected endpoint. When set to false, an error will be returned.
      name: suppress_disconnected_endpoint_error
      predefined:
      - 'true'
      - 'false'
  - arguments:
    - description: 'A comma-separated list of endpoints statuses to filter. Valid values are: connected, disconnected, lost, uninstalled, windows, linux, macos, android, isolated, unisolated.'
      name: status
      isArray: true
    - description: A comma-separated list of endpoint IDs.
      isArray: true
      name: endpoint_id_list
    - description: "A comma-separated list of distribution package names or installation package names.\nExample: dist_name1,dist_name2."
      isArray: true
      name: dist_name
    - description: "A comma-separated list of private IP addresses.\nExample: 10.1.1.1,192.168.1.1."
      isArray: true
      name: ip_list
    - description: "A comma-separated list of public IP addresses that correlate to the last IPv4 address from which the Cortex XDR agent connected (know as `Last Origin IP`).\nExample: 8.8.8.8,1.1.1.1."
      isArray: true
      name: public_ip_list
    - description: "The group name to which the agent belongs.\nExample: group_name1,group_name2."
      isArray: true
      name: group_name
    - description: The endpoint platform.
      isArray: true
      name: platform
      auto: PREDEFINED
      predefined:
      - windows
      - linux
      - macos
      - android
    - description: "A comma-separated list of alias names.\nExamples: alias_name1,alias_name2."
      name: alias_name
      isArray: true
    - description: Specifies whether the endpoint was isolated or unisolated.
      name: isolate
      auto: PREDEFINED
      predefined:
      - isolated
      - unisolated
    - description: "Hostname\nExample: hostname1,hostname2."
      name: hostname
      isArray: true
    - description: "Include agents that were first seen on and after this date.\nSupported values:\n1579039377301 (time in milliseconds)\n\"3 days\" (relative date)\n\"2019-10-21T23:45:00\" (date)."
      name: first_seen_gte
    - description: "Include agents that were first seen on and before this date.\nSupported values:\n1579039377301 (time in milliseconds)\n\"3 days\" (relative date)\n\"2019-10-21T23:45:00\" (date)."
      name: first_seen_lte
    - description: "Include agents that were last seen on and after this date.\nSupported values:\n1579039377301 (time in milliseconds)\n\"3 days\" (relative date)\n\"2019-10-21T23:45:00\" (date)."
      name: last_seen_gte
    - description: "All the agents that were last seen before {last_seen_lte}.\nSupported values:\n1579039377301 (time in milliseconds)\n\"3 days\" (relative date)\n\"2019-10-21T23:45:00\" (date)."
      name: last_seen_lte
    - defaultValue: '0'
      description: Page number (for pagination). 0 is the first page.
      name: page
    - description: Maximum number of endpoints to return per page. The default and maximum is 30.
      name: limit
      defaultValue: '30'
    - auto: PREDEFINED
      description: Specifies whether to sort endpoints by the first time or last time they were seen.
      name: sort_by
      predefined:
      - first_seen
      - last_seen
    - name: sort_order
      description: The order by which to sort results. Can be "asc" (ascending) or "desc" (descending).
      auto: PREDEFINED
      defaultValue: asc
      predefined:
      - asc
      - desc
    - name: username
      description: The usernames to query for. Accepts a single user, or comma-separated list of usernames.
      isArray: true
    description: Gets a list of endpoints, according to the passed filters. If there are no filters, all endpoints are returned. Filtering by multiple fields will be concatenated using AND condition (OR is not supported). Maximum result set size is 100. Offset is the zero-based number of endpoint from the start of the result set. (Start by counting from 0).
    name: xdr-get-endpoints
    outputs:
    - contextPath: PaloAltoNetworksXDR.Endpoint.endpoint_id
      description: The endpoint ID.
      type: String
    - contextPath: PaloAltoNetworksXDR.Endpoint.endpoint_name
      description: The endpoint name.
      type: String
    - contextPath: PaloAltoNetworksXDR.Endpoint.endpoint_type
      description: The endpoint type.
      type: String
    - contextPath: PaloAltoNetworksXDR.Endpoint.endpoint_status
      description: The status of the endpoint.
      type: String
    - contextPath: PaloAltoNetworksXDR.Endpoint.os_type
      description: The endpoint operating type.
      type: String
    - contextPath: PaloAltoNetworksXDR.Endpoint.ip
      description: A list of IP addresses.
      type: Unknown
    - contextPath: PaloAltoNetworksXDR.Endpoint.users
      description: A list of users.
      type: Unknown
    - contextPath: PaloAltoNetworksXDR.Endpoint.domain
      description: The endpoint domain.
      type: String
    - contextPath: PaloAltoNetworksXDR.Endpoint.alias
      description: The endpoint aliases.
      type: String
    - contextPath: PaloAltoNetworksXDR.Endpoint.first_seen
      description: First seen date/time in epoch (milliseconds).
      type: Unknown
    - contextPath: PaloAltoNetworksXDR.Endpoint.last_seen
      description: Last seen date/time in epoch (milliseconds).
      type: Date
    - contextPath: PaloAltoNetworksXDR.Endpoint.content_version
      description: Content version.
      type: String
    - contextPath: PaloAltoNetworksXDR.Endpoint.installation_package
      description: Installation package.
      type: String
    - contextPath: PaloAltoNetworksXDR.Endpoint.active_directory
      description: Active directory.
      type: String
    - contextPath: PaloAltoNetworksXDR.Endpoint.install_date
      description: Install date in epoch (milliseconds).
      type: Date
    - contextPath: PaloAltoNetworksXDR.Endpoint.endpoint_version
      description: Endpoint version.
      type: String
    - contextPath: PaloAltoNetworksXDR.Endpoint.is_isolated
      description: Whether the endpoint is isolated.
      type: String
    - contextPath: PaloAltoNetworksXDR.Endpoint.group_name
      description: The name of the group to which the endpoint belongs.
      type: String
    - contextPath: PaloAltoNetworksXDR.Endpoint.count
      description: Number of endpoints returned.
      type: String
    - contextPath: Endpoint.Hostname
      description: The hostname that is mapped to this endpoint.
      type: String
    - contextPath: Endpoint.ID
      description: The unique ID within the tool retrieving the endpoint.
      type: String
    - contextPath: Endpoint.IPAddress
      description: The IP address of the endpoint.
      type: String
    - contextPath: Endpoint.Domain
      description: The domain of the endpoint.
      type: String
    - contextPath: Endpoint.OS
      description: The endpoint's operating system.
      type: String
    - contextPath: Account.Username
      description: The username in the relevant system.
      type: String
    - contextPath: Account.Domain
      description: The domain of the account.
      type: String
    - contextPath: Endpoint.Status
      description: The endpoint's status.
      type: String
    - contextPath: Endpoint.IsIsolated
      description: The endpoint's isolation status.
      type: String
    - contextPath: Endpoint.MACAddress
      description: The endpoint's MAC address.
      type: String
    - contextPath: Endpoint.Vendor
      description: The integration name of the endpoint vendor.
      type: String
  - arguments:
    - description: The status of the endpoint to use as a filter.
      name: status
      auto: PREDEFINED
      predefined:
      - connected
      - disconnected
    - description: A comma-separated list of endpoint IDs to use as a filter.
      isArray: true
      name: endpoint_id_list
    - description: "A comma-separated list of distribution package names or installation package names to use as a filter.\nExample: dist_name1,dist_name2."
      isArray: true
      name: dist_name
    - description: "A comma-separated list of IP addresses to use as a filter.\nExample: 8.8.8.8,1.1.1.1."
      isArray: true
      name: ip_list
    - description: A comma-separated list of group names to which the agent belongs to use as a filter.
      isArray: true
      name: group_name
    - description: The endpoint platform to use as a filter.
      isArray: true
      name: platform
      auto: PREDEFINED
      predefined:
      - windows
      - linux
      - macos
      - android
    - description: "A comma-separated list of alias names to use as a filter.\nExamples: alias_name1,alias_name2."
      isArray: true
      name: alias_name
    - auto: PREDEFINED
      description: Specifies whether the endpoint was isolated or unisolated to use as a filter.
      name: isolate
      predefined:
      - isolated
      - unisolated
    - description: A comma-separated list of hostnames to use as a filter.
      isArray: true
      name: hostname
    - description: "Include agents that were first seen on and after this date.\nSupported values:\n1579039377301 (time in milliseconds)\n\"3 days\" (relative date)\n\"2019-10-21T23:45:00\" (date)."
      name: first_seen_gte
    - description: "Include agents that were first seen on and before this date.\nSupported values:\n1579039377301 (time in milliseconds)\n\"3 days\" (relative date)\n\"2019-10-21T23:45:00\" (date)."
      name: first_seen_lte
    - description: "Include agents that were last seen on and after this date.\nSupported values:\n1579039377301 (time in milliseconds)\n\"3 days\" (relative date)\n\"2019-10-21T23:45:00\" (date)."
      name: last_seen_gte
    - description: "Include agents that were last seen on and before this date.\nSupported values:\n1579039377301 (time in milliseconds)\n\"3 days\" (relative date)\n\"2019-10-21T23:45:00\" (date)."
      name: last_seen_lte
    - name: username
      description: The usernames to use as a filter. Accepts a single user, or comma-separated list of usernames.
      isArray: true
    - name: new_alias_name
      required: true
      description: "The alias name to change to.\nNote: If you send an empty field, (e.g., new_alias_name=\\\"\\\") the current alias name is deleted."
    - name: scan_status
      description: The scan status of the endpoint to use as a filter.
      auto: PREDEFINED
      predefined:
      - none
      - pending
      - in_progress
      - canceled
      - aborted
      - pending_cancellation
      - success
      - error
    description: Gets a list of endpoints according to the passed filters, and changes their alias name. Filtering by multiple fields will be concatenated using the AND condition (OR is not supported).
    name: xdr-endpoint-alias-change
  - description: Gets a list of all the agent versions to use for creating a distribution list.
    name: xdr-get-distribution-versions
    outputs:
    - contextPath: PaloAltoNetworksXDR.DistributionVersions.windows
      description: A list of Windows agent versions.
      type: Unknown
    - contextPath: PaloAltoNetworksXDR.DistributionVersions.linux
      description: A list of Linux agent versions.
      type: Unknown
    - contextPath: PaloAltoNetworksXDR.DistributionVersions.macos
      description: A list of Mac agent versions.
      type: Unknown
    arguments: []
  - arguments:
    - description: The name of the installation package.
      name: name
      required: true
    - auto: PREDEFINED
      description: The platform type.
      name: platform
      predefined:
      - windows
      - linux
      - macos
      - android
      required: true
    - auto: PREDEFINED
      description: "The type of package to create.\nstandalone - An installation for a new agent.\nupgrade - An upgrade of an agent from ESM."
      name: package_type
      predefined:
      - standalone
      - upgrade
      required: true
    - description: Agent version returned from xdr-get-distribution-versions. Not required for an Android platform.
      name: agent_version
      required: true
    - description: Information about the package.
      name: description
    description: Creates an installation package. This is an asynchronous call that returns the distribution ID. This does not mean that the creation succeeded. To confirm that the package has been created, check the status of the distribution by running the Get Distribution Status API.
    name: xdr-create-distribution
    outputs:
    - contextPath: PaloAltoNetworksXDR.Distribution.id
      description: The installation package ID.
      type: String
    - contextPath: PaloAltoNetworksXDR.Distribution.name
      description: The name of the installation package.
      type: String
    - contextPath: PaloAltoNetworksXDR.Distribution.platform
      description: The installation operating system.
      type: String
    - contextPath: PaloAltoNetworksXDR.Distribution.agent_version
      description: Agent version.
      type: String
    - contextPath: PaloAltoNetworksXDR.Distribution.description
      description: Description of the package.
      type: String
  - arguments:
    - description: "The ID of the installation package.\nCopy the distribution ID from the \"id\" field on the Endpoints > Agent Installation page."
      name: distribution_id
      required: true
    - auto: PREDEFINED
      description: "The installation package type. Valid\nvalues are:\n• upgrade\n• sh - For Linux\n• rpm - For Linux\n• deb - For Linux\n• pkg - For Mac\n• x86 - For Windows\n• x64 - For Windows."
      name: package_type
      predefined:
      - upgrade
      - sh
      - rpm
      - deb
      - pkg
      - x86
      - x64
      required: true
    description: Gets the distribution URL for downloading the installation package.
    name: xdr-get-distribution-url
    outputs:
    - contextPath: PaloAltoNetworksXDR.Distribution.id
      description: Distribution ID.
      type: String
    - contextPath: PaloAltoNetworksXDR.Distribution.url
      description: URL for downloading the installation package.
      type: String
  - arguments:
    - description: A comma-separated list of distribution IDs to get the status for.
      isArray: true
      name: distribution_ids
      required: true
    description: Gets the status of the installation package.
    name: xdr-get-create-distribution-status
    outputs:
    - contextPath: PaloAltoNetworksXDR.Distribution.id
      description: Distribution ID.
      type: String
    - contextPath: PaloAltoNetworksXDR.Distribution.status
      description: The status of the installation package.
      type: String
  - arguments:
    - description: User's email address.
      name: email
    - description: The audit log type.
      name: type
      auto: PREDEFINED
      predefined:
      - LIVE_TERMINAL
      - RULES
      - AUTH
      - RESPONSE
      - INCIDENT_MANAGEMENT
      - ENDPOINT_MANAGEMENT
      - ALERT_WHITELIST
      - PUBLIC_API
      - DISTRIBUTIONS
      - STARRED_INCIDENTS
      - POLICY_PROFILES
      - DEVICE_CONTROL_PROFILE
      - HOST_FIREWALL_PROFILE
      - POLICY_RULES
      - PROTECTION_POLICY
      - DEVICE_CONTROL_TEMP_EXCEPTIONS
      - DEVICE_CONTROL_GLOBAL_EXCEPTIONS
      - GLOBAL_EXCEPTIONS
      - MSSP
      - REPORTING
      - DASHBOARD
      - BROKER_VM
    - description: The audit log subtype.
      name: sub_type
    - auto: PREDEFINED
      description: Result type.
      name: result
      predefined:
      - SUCCESS
      - FAIL
      - PARTIAL
    - description: "Return logs for which the timestamp is after 'log_time_after'.\nSupported values:\n1579039377301 (time in milliseconds)\n\"3 days\" (relative date)\n\"2019-10-21T23:45:00\" (date)."
      name: timestamp_gte
    - description: "Return logs for which the timestamp is before the 'log_time_after'.\nSupported values:\n1579039377301 (time in milliseconds)\n\"3 days\" (relative date)\n\"2019-10-21T23:45:00\" (date)."
      name: timestamp_lte
    - defaultValue: '0'
      description: Page number (for pagination). 0 is the first page.
      name: page
    - defaultValue: '30'
      description: Maximum number of audit logs to return per page. The default and maximum is 30.
      name: limit
    - auto: PREDEFINED
      description: Specifies the field by which to sort the results. By default the sort is defined as creation-time and DESC.
      name: sort_by
      predefined:
      - type
      - sub_type
      - result
      - timestamp
    - auto: PREDEFINED
      defaultValue: desc
      description: The sort order. Can be "asc" (ascending) or "desc" (descending).
      name: sort_order
      predefined:
      - asc
      - desc
    description: Gets management logs. You can filter by multiple fields, which will be concatenated using the AND condition (OR is not supported). Maximum result set size is 100. Offset is the zero-based number of management logs from the start of the result set (start by counting from 0).
    name: xdr-get-audit-management-logs
    outputs:
    - contextPath: PaloAltoNetworksXDR.AuditManagementLogs.AUDIT_ID
      description: Audit log ID.
      type: Number
    - contextPath: PaloAltoNetworksXDR.AuditManagementLogs.AUDIT_OWNER_NAME
      description: Audit owner name.
      type: String
    - contextPath: PaloAltoNetworksXDR.AuditManagementLogs.AUDIT_OWNER_EMAIL
      description: Audit owner email address.
      type: String
    - contextPath: PaloAltoNetworksXDR.AuditManagementLogs.AUDIT_ASSET_JSON
      description: Asset JSON.
      type: String
    - contextPath: PaloAltoNetworksXDR.AuditManagementLogs.AUDIT_ASSET_NAMES
      description: Audit asset names.
      type: String
    - contextPath: PaloAltoNetworksXDR.AuditManagementLogs.AUDIT_HOSTNAME
      description: Hostname.
      type: String
    - contextPath: PaloAltoNetworksXDR.AuditManagementLogs.AUDIT_RESULT
      description: Audit result.
      type: String
    - contextPath: PaloAltoNetworksXDR.AuditManagementLogs.AUDIT_REASON
      description: Audit reason.
      type: String
    - contextPath: PaloAltoNetworksXDR.AuditManagementLogs.AUDIT_DESCRIPTION
      description: Description of the audit.
      type: String
    - contextPath: PaloAltoNetworksXDR.AuditManagementLogs.AUDIT_ENTITY
      description: Audit entity (e.g., AUTH, DISTRIBUTIONS).
      type: String
    - contextPath: PaloAltoNetworksXDR.AuditManagementLogs.AUDIT_ENTITY_SUBTYPE
      description: Entity subtype (e.g., Login, Create).
      type: String
    - contextPath: PaloAltoNetworksXDR.AuditManagementLogs.AUDIT_CASE_ID
      description: Audit case ID.
      type: Number
    - contextPath: PaloAltoNetworksXDR.AuditManagementLogs.AUDIT_INSERT_TIME
      description: Log's insert time.
      type: Date
  - arguments:
    - description: A comma-separated list of endpoint IDs.
      isArray: true
      name: endpoint_ids
    - description: A comma-separated list of endpoint names.
      isArray: true
      name: endpoint_names
    - description: The report type.
      isArray: true
      name: type
      auto: PREDEFINED
      predefined:
      - Installation
      - Policy
      - Action
      - Agent Service
      - Agent Modules
      - Agent Status
    - auto: PREDEFINED
      description: The report subtype.
      isArray: true
      name: sub_type
      predefined:
      - Install
      - Uninstall
      - Upgrade
      - Local Configuration
      - Content Update
      - Policy Update
      - Process Exception
      - Hash Exception
      - Scan
      - File Retrieval
      - File Scan
      - Terminate Process
      - Isolate
      - Cancel Isolation
      - Payload Execution
      - Quarantine
      - Restore
      - Stop
      - Start
      - Module Initialization
      - Local Analysis Model
      - Local Analysis Feature Extraction
      - Fully Protected
      - OS Incompatible
      - Software Incompatible
      - Kernel Driver Initialization
      - Kernel Extension Initialization
      - Proxy Communication
      - Quota Exceeded
      - Minimal Content
      - Reboot Required
      - Missing Disc Access
    - auto: PREDEFINED
      description: The result type. Can be "Success" or "Fail". If not passed, returns all event reports.
      isArray: true
      name: result
      predefined:
      - Success
      - Fail
    - description: "Return logs for which the timestamp is greater than 'log_time_after'.\nSupported values:\n1579039377301 (time in milliseconds)\n\"3 days\" (relative date)\n\"2019-10-21T23:45:00\" (date)."
      name: timestamp_gte
    - description: "Return logs for which the timestamp is before the 'timestamp_lte'.\n\nSupported values:\n1579039377301 (time in milliseconds)\n\"3 days\" (relative date)\n\"2019-10-21T23:45:00\" (date)."
      name: timestamp_lte
    - defaultValue: '0'
      description: Page number (for pagination). 0 is the first page.
      name: page
    - defaultValue: '30'
      description: The maximum number of reports to return. Default and maximum is 30.
      name: limit
    - auto: PREDEFINED
      description: The field by which to sort results.
      name: sort_by
      predefined:
      - type
      - category
      - trapsversion
      - timestamp
      - domain
    - auto: PREDEFINED
      defaultValue: asc
      description: The sort order. Can be "asc" (ascending) or "desc" (descending).
      name: sort_order
      predefined:
      - asc
      - desc
    description: Gets agent event reports. You can filter by multiple fields, which will be concatenated using the AND condition (OR is not supported). Maximum result set size is 100. Offset is the zero-based number of reports from the start of the result set (start by counting from 0).
    name: xdr-get-audit-agent-reports
    outputs:
    - contextPath: PaloAltoNetworksXDR.AuditAgentReports.ENDPOINTID
      description: Endpoint ID.
      type: String
    - contextPath: PaloAltoNetworksXDR.AuditAgentReports.ENDPOINTNAME
      description: Endpoint name.
      type: String
    - contextPath: PaloAltoNetworksXDR.AuditAgentReports.DOMAIN
      description: Agent domain.
      type: String
    - contextPath: PaloAltoNetworksXDR.AuditAgentReports.TRAPSVERSION
      description: Traps version.
      type: String
    - contextPath: PaloAltoNetworksXDR.AuditAgentReports.RECEIVEDTIME
      description: Received time in epoch time.
      type: Date
    - contextPath: PaloAltoNetworksXDR.AuditAgentReports.TIMESTAMP
      description: Timestamp in epoch time.
      type: Date
    - contextPath: PaloAltoNetworksXDR.AuditAgentReports.CATEGORY
      description: Report category (e.g., Audit).
      type: String
    - contextPath: PaloAltoNetworksXDR.AuditAgentReports.TYPE
      description: Report type (e.g., Action, Policy).
      type: String
    - contextPath: PaloAltoNetworksXDR.AuditAgentReports.SUBTYPE
      description: Report subtype (e.g., Fully Protected,Policy Update,Cancel Isolation).
      type: String
    - contextPath: PaloAltoNetworksXDR.AuditAgentReports.RESULT
      description: Report result.
      type: String
    - contextPath: PaloAltoNetworksXDR.AuditAgentReports.REASON
      description: Report reason.
      type: String
    - contextPath: PaloAltoNetworksXDR.AuditAgentReports.DESCRIPTION
      description: Description of the agent report.
      type: String
    - contextPath: Endpoint.ID
      description: The unique ID within the tool retrieving the endpoint.
      type: String
    - contextPath: Endpoint.Hostname
      description: The hostname that is mapped to this endpoint.
      type: String
    - contextPath: Endpoint.Domain
      description: The domain of the endpoint.
      type: String
  - arguments:
    - description: Links the response action to the triggered incident.
      name: incident_id
    - description: String that represents a list of hashed files you want to add to the block list. Must be a valid SHA256 hash.
      isArray: true
      name: hash_list
      required: true
    - description: String that represents additional information regarding the action.
      name: comment
    - description: Whether to retrieve a regular response or detailed response. False = regular response. True = detailed response.
      name: detailed_response
      auto: PREDEFINED
      defaultValue: 'false'
      predefined:
      - 'true'
      - 'false'
    description: Block lists requested files which have not already been block listed or added to allow lists.
    name: xdr-blocklist-files
    outputs:
    - contextPath: PaloAltoNetworksXDR.blocklist.added_hashes
      description: Number of file hashes added to the block list.
      type: Number
    - contextPath: PaloAltoNetworksXDR.blocklist.excluded_hashes
      description: Number of file hashes excluded from the block list.
      type: Number
  - arguments:
    - description: Allows linking the response action to the incident that triggered it.
      name: incident_id
    - description: String that represents a list of hashed files you want to add to the block list. Must be a valid SHA256 hash.
      isArray: true
      name: hash_list
      required: true
    - description: String that represents additional information regarding the action.
      name: comment
    deprecated: true
    description: Deprecated. Use `xdr-blocklist-files` instead.
    name: xdr-blacklist-files
  - arguments:
    - description: Links the response action to the triggered incident.
      name: incident_id
    - description: String that represents a list of hashed files you want to add to allow lists. Must be a valid SHA256 hash.
      isArray: true
      name: hash_list
      required: true
    - description: String that represents additional information regarding the action.
      name: comment
    - auto: PREDEFINED
      defaultValue: 'false'
      description: Whether to retrieve a regular response or detailed response. False = regular response. True = detailed response.
      name: detailed_response
      predefined:
      - 'true'
      - 'false'
    description: Adds requested files to the allow list if they are not already on the block list or allow list.
    name: xdr-allowlist-files
    outputs:
    - contextPath: PaloAltoNetworksXDR.allowlist.added_hashes
      description: Number of added file hashes to allow list.
      type: Number
    - contextPath: PaloAltoNetworksXDR.allowlist.excluded_hashes
      description: Number of excluded file hashes from allow list.
      type: Number
  - arguments:
    - description: Allows linking the response action to the incident that triggered it.
      name: incident_id
    - description: String that represents a list of hashed files you want to add to the allow list. Must be a valid SHA256 hash.
      isArray: true
      name: hash_list
      required: true
    - description: String that represents additional information regarding the action.
      name: comment
    deprecated: true
    description: Deprecated. Use `xdr-allowlist-files` instead.
    name: xdr-whitelist-files
  - arguments:
    - description: Allows linking the response action to the incident that triggered it.
      name: incident_id
    - description: List of endpoint IDs.
      isArray: true
      name: endpoint_id_list
      required: true
    - description: String that represents the path of the file you want to quarantine.
      name: file_path
      required: true
    - description: String that represents the file's hash. Must be a valid SHA256 hash.
      name: file_hash
      required: true
    - description: Interval in seconds between each poll.
      name: interval_in_seconds
    - description: Polling timeout in seconds.
      name: timeout_in_seconds
    - description: The action IDs for polling use.
      isArray: true
      name: action_id
      deprecated: true
    description: Quarantines a file on selected endpoints. You can select up to 1000 endpoints.
    name: xdr-file-quarantine
    polling: true
  - deprecated: true
    description: Deprecated. Use `xdr-file-quarantine` instead.
    name: xdr-quarantine-files
    arguments:
    - description: Allows linking the response action to the incident that triggered it.
      name: incident_id
    - description: List of endpoint IDs.
      isArray: true
      name: endpoint_id_list
      required: true
    - description: String that represents the path of the file you want to quarantine.
      name: file_path
      required: true
    - description: String that represents the file's hash. Must be a valid SHA256 hash.
      name: file_hash
      required: true
  - arguments:
    - description: String that represents the endpoint ID.
      name: endpoint_id
      required: true
    - description: String that represents the file hash. Must be a valid SHA256 hash.
      name: file_hash
      required: true
    - description: String that represents the file path.
      name: file_path
      required: true
    description: Retrieves the quarantine status for a selected file.
    name: xdr-get-quarantine-status
  - arguments:
    - description: Allows linking the response action to the incident that triggered it.
      name: incident_id
    - description: The hash code of the file. Must be a valid SHA256 hash.
      name: file_hash
      required: true
    - description: String that represents the endpoint ID. If you do not enter a specific endpoint ID, the request will run restore on all endpoints that relate to the quarantined file you defined.
      name: endpoint_id
    - description: Interval in seconds between each poll.
      name: interval_in_seconds
    - description: Polling timeout in seconds.
      name: timeout_in_seconds
    - description: The action IDs for polling use.
      isArray: true
      name: action_id
      deprecated: true
    description: Restores a quarantined file on requested endpoints.
    name: xdr-file-restore
    polling: true
  - arguments:
    - description: Allows to link the response action to the incident that triggered it.
      name: incident_id
    - description: The hash code of the file. Must be a valid SHA256 hash.
      name: file_hash
      required: true
    - description: The endpoint ID. If you do not enter a specific endpoint ID, the request will run restore on all endpoints that relate to the quarantined file you defined.
      name: endpoint_id
    deprecated: true
    description: Deprecated. Use `xdr-file-restore` instead.
    name: xdr-restore-file
  - arguments:
    - description: Allows linking the response action to the incident that triggered it.
      name: incident_id
    - description: List of endpoint IDs.
      isArray: true
      name: endpoint_id_list
    - description: Name of the distribution list.
      isArray: true
      name: dist_name
    - description: Greater than or equal to first seen timestamp in milliseconds.
      name: gte_first_seen
    - description: Greater than or equal to last seen timestamp in milliseconds.
      name: gte_last_seen
    - description: Less than or equal to first seen timestamp in milliseconds.
      name: lte_first_seen
    - description: Less than or equal to last seen timestamp in milliseconds.
      name: lte_last_seen
    - description: List of IP addresses.
      isArray: true
      name: ip_list
    - description: Name of the endpoint group.
      isArray: true
      name: group_name
    - auto: PREDEFINED
      description: Type of operating system.
      isArray: true
      name: platform
      predefined:
      - windows
      - linux
      - macos
      - android
    - description: Endpoint alias name.
      isArray: true
      name: alias
    - auto: PREDEFINED
      description: Whether an endpoint has been isolated.
      name: isolate
      predefined:
      - isolated
      - unisolated
    - description: Name of the host.
      isArray: true
      name: hostname
    - auto: PREDEFINED
      defaultValue: 'false'
      description: Whether to scan all of the endpoints. Scanning all of the endpoints may cause performance issues and latency.
      name: all
      predefined:
      - 'true'
      - 'false'
    - description: The action IDs for polling use.
      isArray: true
      name: action_id
      deprecated: true
    - description: Interval in seconds between each poll.
      name: interval_in_seconds
    - description: Polling timeout in seconds.
      name: timeout_in_seconds
    description: 'Runs a scan on a selected endpoint. To scan all endpoints, run this command with argument all=true. Note: Scanning all the endpoints may cause performance issues and latency.'
    execution: true
    name: xdr-endpoint-scan-execute
    outputs:
    - contextPath: PaloAltoNetworksXDR.endpointScan.actionId
      description: The action ID of the scan request.
      type: Number
    - contextPath: PaloAltoNetworksXDR.endpointScan.aborted
      description: Was the scan aborted?
      type: Boolean
    polling: true
  - arguments:
    - description: Allows linking the response action to the incident that triggered it.
      name: incident_id
    - description: List of endpoint IDs.
      isArray: true
      name: endpoint_id_list
    - description: Name of the distribution list.
      isArray: true
      name: dist_name
    - description: Greater than or equal to first seen timestamp in milliseconds.
      name: gte_first_seen
    - description: Greater than or equal to last seen timestamp in milliseconds.
      name: gte_last_seen
    - description: Less than or equal to first seen timestamp in milliseconds.
      name: lte_first_seen
    - description: Less than or equal to last seen timestamp in milliseconds.
      name: lte_last_seen
    - description: List of IP addresses.
      isArray: true
      name: ip_list
    - description: Name of the endpoint group.
      isArray: true
      name: group_name
    - auto: PREDEFINED
      description: Type of operating system.
      isArray: true
      name: platform
      predefined:
      - windows
      - linux
      - macos
      - android
    - description: Endpoint alias name.
      isArray: true
      name: alias
    - auto: PREDEFINED
      description: Whether an endpoint has been isolated.
      name: isolate
      predefined:
      - isolated
      - unisolated
    - description: Name of the host.
      isArray: true
      name: hostname
    - auto: PREDEFINED
      defaultValue: 'false'
      description: 'Whether to scan all of the endpoints. Note: Scanning all of the endpoints may cause performance issues and latency.'
      name: all
      predefined:
      - 'true'
      - 'false'
    deprecated: true
    description: Deprecated. Use `xdr-endpoint-scan-execute` instead.
    execution: true
    name: xdr-endpoint-scan
    outputs:
    - contextPath: PaloAltoNetworksXDR.endpointScan.actionId
      description: The action ID of the scan request.
      type: Number
    - contextPath: PaloAltoNetworksXDR.endpointScan.aborted
      description: Was the scan aborted?
      type: Boolean
  - arguments:
    - description: Allows linking the response action to the incident that triggered it.
      name: incident_id
    - description: List of endpoint IDs.
      isArray: true
      name: endpoint_id_list
    - description: Name of the distribution list.
      isArray: true
      name: dist_name
    - description: Greater than or equal to first seen timestamp in milliseconds.
      name: gte_first_seen
    - description: Greater than or equal to last seen timestamp in milliseconds.
      name: gte_last_seen
    - description: Less than or equal to first seen timestamp in milliseconds.
      name: lte_first_seen
    - description: Less than or equal to last seen timestamp in milliseconds.
      name: lte_last_seen
    - description: List of IP addresses.
      isArray: true
      name: ip_list
    - description: Name of the endpoint group.
      isArray: true
      name: group_name
    - description: Type of operating system.
      isArray: true
      name: platform
      auto: PREDEFINED
      predefined:
      - windows
      - linux
      - macos
      - android
    - description: Endpoint alias name.
      isArray: true
      name: alias
    - description: Whether an endpoint has been isolated.
      name: isolate
      auto: PREDEFINED
      predefined:
      - isolated
      - unisolated
    - description: Name of the host.
      isArray: true
      name: hostname
    - auto: PREDEFINED
      defaultValue: 'false'
      description: 'Whether to scan all of the endpoints. Note: Scanning all of the endpoints may cause performance issues and latency.'
      name: all
      predefined:
      - 'true'
      - 'false'
    description: Cancels the scan of selected endpoints. A scan can only be aborted if the selected endpoints are Pending or In Progress. To scan all endpoints, run the command with the argument all=true. Note that scanning all of the endpoints may cause performance issues and latency.
    execution: true
    name: xdr-endpoint-scan-abort
    outputs:
    - contextPath: PaloAltoNetworksXDR.endpointScan.actionId
      description: The action ID of the abort scan request.
      type: Unknown
    - contextPath: PaloAltoNetworksXDR.endpointScan.aborted
      description: Was the scan aborted?
      type: Boolean
  - description: "Gets mapping fields from remote incident. Note: This method will not update the current incident. It's here for debugging purposes."
    name: get-mapping-fields
    arguments: []
  - arguments:
    - description: The remote incident ID.
      name: id
      required: true
    - defaultValue: '0'
      description: UTC timestamp in seconds. The incident is only updated if it was modified after the last update time.
      name: lastUpdate
    description: "Gets remote data from a remote incident. Note: This method will not update the current incident. It's here for debugging purposes."
    name: get-remote-data
  - arguments:
    - description: 'Date string representing the local date time in the ISO 8601 format (for example: 2019-10-23T10:00:00). The incident is only returned if it was modified after the last update time.'
      name: lastUpdate
    description: 'Gets the list of incidents that were modified since the last update. Note: This method is here for debugging purposes. get-modified-remote-data is used as part of a Mirroring feature, which is available since version 6.1.'
    name: get-modified-remote-data
  - arguments:
    - description: The endpoint ID. Can be retrieved by running the xdr-get-endpoints command.
      name: endpoint_id
      required: true
    description: Gets the policy name for a specific endpoint.
    name: xdr-get-policy
    outputs:
    - contextPath: PaloAltoNetworksXDR.Policy
      description: The policy allocated with the endpoint.
      type: string
    - contextPath: PaloAltoNetworksXDR.Policy.policy_name
      description: Name of the policy allocated with the endpoint.
      type: string
    - contextPath: PaloAltoNetworksXDR.Policy.endpoint_id
      description: Endpoint ID.
      type: string
  - arguments:
    - description: A comma-separated list of the script names.
      isArray: true
      name: script_name
    - description: A comma-separated list of the script descriptions.
      isArray: true
      name: description
    - description: A comma-separated list of the users who created the script.
      isArray: true
      name: created_by
    - description: The maximum number of scripts returned to the War Room.
      name: limit
    - description: (Int) Offset in the data set.
      name: offset
    - auto: PREDEFINED
      description: Whether the script can be executed on a Windows operating system.
      name: windows_supported
      predefined:
      - 'true'
      - 'false'
    - auto: PREDEFINED
      description: Whether the script can be executed on a Linux operating system.
      name: linux_supported
      predefined:
      - 'true'
      - 'false'
    - auto: PREDEFINED
      description: Whether the script can be executed on a Mac operating system.
      name: macos_supported
      predefined:
      - 'true'
      - 'false'
    - auto: PREDEFINED
      description: Whether the script has a high-risk outcome.
      name: is_high_risk
      predefined:
      - 'true'
      - 'false'
    description: Gets a list of scripts available in the scripts library.
    name: xdr-get-scripts
    outputs:
    - contextPath: PaloAltoNetworksXDR.Scripts
      description: The scripts command results.
      type: Unknown
    - contextPath: PaloAltoNetworksXDR.Scripts.script_id
      description: Script ID.
      type: Unknown
    - contextPath: PaloAltoNetworksXDR.Scripts.name
      description: Name of the script.
      type: string
    - contextPath: PaloAltoNetworksXDR.Scripts.description
      description: Description of the script.
      type: string
    - contextPath: PaloAltoNetworksXDR.Scripts.modification_date
      description: Timestamp of when the script was last modified.
      type: Unknown
    - contextPath: PaloAltoNetworksXDR.Scripts.created_by
      description: Name of the user who created the script.
      type: string
    - contextPath: PaloAltoNetworksXDR.Scripts.windows_supported
      description: Whether the script can be executed on a Windows operating system.
      type: boolean
    - contextPath: PaloAltoNetworksXDR.Scripts.linux_supported
      description: Whether the script can be executed on a Linux operating system.
      type: boolean
    - contextPath: PaloAltoNetworksXDR.Scripts.macos_supported
      description: Whether the script can be executed on Mac operating system.
      type: boolean
    - contextPath: PaloAltoNetworksXDR.Scripts.is_high_risk
      description: Whether the script has a high-risk outcome.
      type: boolean
    - contextPath: PaloAltoNetworksXDR.Scripts.script_uid
      description: Globally Unique Identifier of the script, used to identify the script when executing.
      type: string
  - arguments:
    - description: A comma-separated list of endpoint IDs. You can retrieve the endpoint IDs from the xdr-get-endpoints command.
      name: endpoint_ids
      required: true
    description: Deletes selected endpoints in the Cortex XDR app. You can delete up to 1000 endpoints.
    name: xdr-delete-endpoints
  - arguments:
    - description: A comma-separated list of endpoint IDs. You can retrieve the endpoint IDs from the xdr-get-endpoints command.
      isArray: true
      name: endpoint_ids
    - description: Type of violation.
      name: type
      auto: PREDEFINED
      predefined:
      - cd-rom
      - disk drive
      - floppy disk
      - portable device
    - description: 'Timestamp of the violation. Violations that are greater than or equal to this timestamp will be returned. Values can be in either ISO date format, relative time, or epoch timestamp. For example:  "2019-10-21T23:45:00" (ISO date format), "3 days ago" (relative time) 1579039377301 (epoch time).'
      name: timestamp_gte
    - description: 'Timestamp of the violation. Violations that are less than or equal to this timestamp will be returned. Values can be in either ISO date format, relative time, or epoch timestamp. For example:  "2019-10-21T23:45:00" (ISO date format), "3 days ago" (relative time) 1579039377301 (epoch time).'
      name: timestamp_lte
    - description: A comma-separated list of IP addresses.
      isArray: true
      name: ip_list
    - description: Name of the vendor.
      isArray: true
      name: vendor
    - description: Vendor ID.
      isArray: true
      name: vendor_id
    - description: Name of the product.
      isArray: true
      name: product
    - description: Product ID.
      isArray: true
      name: product_id
    - description: Serial number.
      isArray: true
      name: serial
    - description: Hostname.
      isArray: true
      name: hostname
    - description: A comma-separated list of violation IDs.
      isArray: true
      name: violation_id_list
    - description: Username.
      isArray: true
      name: username
    description: Gets a list of device control violations filtered by selected fields. You can retrieve up to 100 violations.
    name: xdr-get-endpoint-device-control-violations
    outputs:
    - contextPath: PaloAltoNetworksXDR.EndpointViolations
      description: Endpoint violations command results.
      type: Unknown
    - contextPath: PaloAltoNetworksXDR.EndpointViolations.violations
      description: A list of violations.
      type: Unknown
    - contextPath: PaloAltoNetworksXDR.EndpointViolations.violations.os_type
      description: Type of the operating system.
      type: string
    - contextPath: PaloAltoNetworksXDR.EndpointViolations.violations.hostname
      description: Hostname of the violation.
      type: string
    - contextPath: PaloAltoNetworksXDR.EndpointViolations.violations.username
      description: Username of the violation.
      type: string
    - contextPath: PaloAltoNetworksXDR.EndpointViolations.violations.ip
      description: IP address of the violation.
      type: string
    - contextPath: PaloAltoNetworksXDR.EndpointViolations.violations.timestamp
      description: Timestamp of the violation.
      type: number
    - contextPath: PaloAltoNetworksXDR.EndpointViolations.violations.violation_id
      description: Violation ID.
      type: number
    - contextPath: PaloAltoNetworksXDR.EndpointViolations.violations.type
      description: Type of violation.
      type: string
    - contextPath: PaloAltoNetworksXDR.EndpointViolations.violations.vendor_id
      description: Vendor ID of the violation.
      type: string
    - contextPath: PaloAltoNetworksXDR.EndpointViolations.violations.vendor
      description: Name of the vendor of the violation.
      type: string
    - contextPath: PaloAltoNetworksXDR.EndpointViolations.violations.product_id
      description: Product ID of the violation.
      type: string
    - contextPath: PaloAltoNetworksXDR.EndpointViolations.violations.product
      description: Name of the product of the violation.
      type: string
    - contextPath: PaloAltoNetworksXDR.EndpointViolations.violations.serial
      description: Serial number of the violation.
      type: string
    - contextPath: PaloAltoNetworksXDR.EndpointViolations.violations.endpoint_id
      description: Endpoint ID of the violation.
      type: string
  - arguments:
    - description: Allows to link the response action to the incident that triggered it.
      name: incident_id
    - description: A comma-separated list of endpoint IDs.
      isArray: true
      name: endpoint_ids
      required: true
    - description: A comma-separated list of file paths on the Windows platform.
      isArray: true
      name: windows_file_paths
    - description: A comma-separated list of file paths on the Linux platform.
      isArray: true
      name: linux_file_paths
    - description: A comma-separated list of file paths on the Mac platform.
      isArray: true
      name: mac_file_paths
    - description: A comma-separated list of file paths in any platform. Can be used instead of the mac/windows/linux file paths. The order of the files path list must be parallel to the endpoints list order, so the first file path in the list is related to the first endpoint and so on.
      isArray: true
      name: generic_file_path
    - description: Interval in seconds between each poll.
      name: interval_in_seconds
    - description: Polling timeout in seconds.
      name: timeout_in_seconds
    - description: The action IDs for polling use.
      isArray: true
      name: action_id
      deprecated: true
    description: Retrieves files from selected endpoints. You can retrieve up to 20 files, from no more than 10 endpoints. At least one endpoint ID and one file path are necessary in order to run the command. After running this command, you can use the xdr-action-status-get command with returned action_id, to check the action status.
    name: xdr-file-retrieve
    outputs:
    - contextPath: PaloAltoNetworksXDR.RetrievedFiles.action_id
      description: ID of the action to retrieve files from selected endpoints.
      type: string
    - contextPath: PaloAltoNetworksXDR.RetrievedFiles.endpoint_id
      description: Endpoint ID. Added only when the operation is successful.
      type: string
    - contextPath: PaloAltoNetworksXDR.RetrievedFiles.file_link
      description: Link to the file. Added only when the operation is successful.
      type: string
    - contextPath: PaloAltoNetworksXDR.RetrievedFiles.status
      description: The action status. Added only when the operation is unsuccessful.
      type: string
    polling: true
  - arguments:
    - description: Allows linking the response action to the incident that triggered it.
      name: incident_id
    - description: A comma-separated list of endpoint IDs.
      isArray: true
      name: endpoint_ids
      required: true
    - description: A comma-separated list of file paths on the Windows platform.
      isArray: true
      name: windows_file_paths
    - description: A comma-separated list of file paths on the Linux platform.
      isArray: true
      name: linux_file_paths
    - description: A comma-separated list of file paths on the Mac platform.
      isArray: true
      name: mac_file_paths
    - description: A comma-separated list of file paths in any platform. Can be used instead of the mac/windows/linux file paths. The order of the files path list must be parallel to the endpoints list order, so the first file path in the list is related to the first endpoint and so on.
      isArray: true
      name: generic_file_path
    deprecated: true
    description: Deprecated. Use `xdr-file-retrieve` instead.
    name: xdr-retrieve-files
    outputs:
    - contextPath: PaloAltoNetworksXDR.RetrievedFiles.action_id
      description: ID of the action to retrieve files from selected endpoints.
      type: string
  - arguments:
    - description: Action IDs retrieved from the xdr-retrieve-files command.
      isArray: true
      name: action_id
      required: true
    description: View the file retrieved by the xdr-retrieve-files command according to the action ID. Before running this command, you can use the xdr-action-status-get command to check if this action completed successfully.
    name: xdr-retrieve-file-details
    outputs:
    - contextPath: File
      description: The file details command results.
      type: Unknown
    - contextPath: File.Name
      description: The full file name (including the file extension).
      type: String
    - contextPath: File.EntryID
      description: The ID for locating the file in the War Room.
      type: String
    - contextPath: File.Size
      description: The size of the file in bytes.
      type: Number
    - contextPath: File.MD5
      description: The MD5 hash of the file.
      type: String
    - contextPath: File.SHA1
      description: The SHA1 hash of the file.
      type: String
    - contextPath: File.SHA256
      description: The SHA256 hash of the file.
      type: String
    - contextPath: File.SHA512
      description: The SHA512 hash of the file.
      type: String
    - contextPath: File.Extension
      description: 'The file extension. For example: "xls".'
      type: String
    - contextPath: File.Type
      description: The file type, as determined by libmagic (same as displayed in file entries).
      type: String
  - arguments:
    - description: Unique identifier of the script, returned by the xdr-get-scripts command.
      name: script_uid
      required: true
    description: Gets the full definition of a specific script in the scripts library.
    name: xdr-get-script-metadata
    outputs:
    - contextPath: PaloAltoNetworksXDR.ScriptMetadata
      description: The script metadata command results.
      type: Unknown
    - contextPath: PaloAltoNetworksXDR.ScriptMetadata.script_id
      description: Script ID.
      type: number
    - contextPath: PaloAltoNetworksXDR.ScriptMetadata.name
      description: Script name.
      type: string
    - contextPath: PaloAltoNetworksXDR.ScriptMetadata.description
      description: Description of the script.
      type: string
    - contextPath: PaloAltoNetworksXDR.ScriptMetadata.modification_date
      description: Timestamp of when the script was last modified.
      type: unknown
    - contextPath: PaloAltoNetworksXDR.ScriptMetadata.created_by
      description: Name of the user who created the script.
      type: string
    - contextPath: PaloAltoNetworksXDR.ScriptMetadata.is_high_risk
      description: Whether the script has a high-risk outcome.
      type: boolean
    - contextPath: PaloAltoNetworksXDR.ScriptMetadata.windows_supported
      description: Whether the script can be executed on a Windows operating system.
      type: boolean
    - contextPath: PaloAltoNetworksXDR.ScriptMetadata.linux_supported
      description: Whether the script can be executed on a Linux operating system.
      type: boolean
    - contextPath: PaloAltoNetworksXDR.ScriptMetadata.macos_supported
      description: Whether the script can be executed on a Mac operating system.
      type: boolean
    - contextPath: PaloAltoNetworksXDR.ScriptMetadata.entry_point
      description: Name of the entry point selected for the script. An empty string indicates the script was defined as just run.
      type: string
    - contextPath: PaloAltoNetworksXDR.ScriptMetadata.script_input
      description: Name and type for the specified entry point.
      type: string
    - contextPath: PaloAltoNetworksXDR.ScriptMetadata.script_output_type
      description: Type of the output.
      type: string
    - contextPath: PaloAltoNetworksXDR.ScriptMetadata.script_output_dictionary_definitions
      description: If the script_output_type is a dictionary, an array with friendly name, name, and type for each output.
      type: Unknown
  - arguments:
    - description: Unique identifier of the script, returned by the xdr-get-scripts command.
      name: script_uid
      required: true
    description: Gets the code of a specific script in the script library.
    name: xdr-get-script-code
    outputs:
    - contextPath: PaloAltoNetworksXDR.ScriptCode
      description: The script code command results.
      type: Unknown
    - contextPath: PaloAltoNetworksXDR.ScriptCode.code
      description: The code of a specific script in the script library.
      type: string
    - contextPath: PaloAltoNetworksXDR.ScriptCode.script_uid
      description: Unique identifier of the script.
      type: string
  - arguments:
    - description: The action IDs of the selected request. After performing an action, you will receive an action ID.
      isArray: true
      name: action_id
      required: true
    description: Retrieves the status of the requested actions according to the action ID.
    name: xdr-action-status-get
    outputs:
    - contextPath: PaloAltoNetworksXDR.GetActionStatus
      description: The action status command results.
      type: Unknown
    - contextPath: PaloAltoNetworksXDR.GetActionStatus.endpoint_id
      description: Endpoint ID.
      type: string
    - contextPath: PaloAltoNetworksXDR.GetActionStatus.status
      description: The status of the specific endpoint ID.
      type: string
    - contextPath: PaloAltoNetworksXDR.GetActionStatus.action_id
      description: The specified action ID.
      type: number
  - arguments:
    - description: Allows linking the response action to the incident that triggered it.
      name: incident_id
    - description: A comma-separated list of endpoint IDs. Can be retrieved by running the xdr-get-endpoints command.
      name: endpoint_ids
      required: true
    - description: Unique identifier of the script. Can be retrieved by running the xdr-get-scripts command.
      name: script_uid
      required: true
    - description: Dictionary containing the parameter name as key and its value for this execution as the value. For example, {"param1":"param1_value","param2":"param2_value"}.
      name: parameters
    - defaultValue: '600'
      description: The timeout in seconds for this execution.
      name: timeout
    description: This command will soon be deprecated; run xdr-script-run instead. Initiates a new endpoint script execution action using a script from the script library.
    name: xdr-run-script
    outputs:
    - contextPath: PaloAltoNetworksXDR.ScriptRun.action_id
      description: ID of the action initiated.
      type: Number
    - contextPath: PaloAltoNetworksXDR.ScriptRun.endpoints_count
      description: Number of endpoints the action was initiated on.
      type: Number
  - arguments:
    - description: Allows linking the response action to the incident that triggered it.
      name: incident_id
    - description: A comma-separated list of endpoint IDs. Can be retrieved by running the xdr-get-endpoints command.
      name: endpoint_ids
      required: true
    - description: Unique identifier of the script. Can be retrieved by running the xdr-get-scripts command.
      name: script_uid
      required: true
    - description: Dictionary containing the parameter name as key and its value for this execution as the value. For example, {"param1":"param1_value","param2":"param2_value"}.
      name: parameters
    - defaultValue: '600'
      description: The timeout in seconds for this execution.
      name: timeout
    - description: Interval in seconds between each poll.
      defaultValue: '10'
      name: polling_interval_in_seconds
    - description: Polling timeout in seconds.
      name: polling_timeout_in_seconds
      defaultValue: '600'
    - description: The action ID for polling use.
      name: action_id
      deprecated: true
    - name: hide_polling_output
      deprecated: true
      description: Whether to hide the polling result (automatically filled by polling).
    description: Initiates a new endpoint script execution action using a script from the script library and returns the results.
    name: xdr-script-run
    polling: true
    outputs:
    - contextPath: PaloAltoNetworksXDR.ScriptResult.action_id
      description: ID of the action initiated.
      type: Number
    - contextPath: PaloAltoNetworksXDR.ScriptResult.results.retrieved_files
      description: Number of successfully retrieved files.
      type: Number
    - contextPath: PaloAltoNetworksXDR.ScriptResult.results.endpoint_ip_address
      description: Endpoint IP address.
      type: String
    - contextPath: PaloAltoNetworksXDR.ScriptResult.results.endpoint_name
      description: Name of successfully retrieved files.
      type: String
    - contextPath: PaloAltoNetworksXDR.ScriptResult.results.failed_files
      description: Number of files failed to be retrieved.
      type: Number
    - contextPath: PaloAltoNetworksXDR.ScriptResult.results.endpoint_status
      description: Endpoint status.
      type: String
    - contextPath: PaloAltoNetworksXDR.ScriptResult.results.domain
      description: Domain to which the endpoint belongs.
      type: String
    - contextPath: PaloAltoNetworksXDR.ScriptResult.results.endpoint_id
      description: Endpoint ID.
      type: String
    - contextPath: PaloAltoNetworksXDR.ScriptResult.results.execution_status
      description: Execution status of this endpoint.
      type: String
    - contextPath: PaloAltoNetworksXDR.ScriptResult.results.return_value
      description: Value returned by the script in case the type is not a dictionary.
      type: String
    - contextPath: PaloAltoNetworksXDR.ScriptResult.results.standard_output
      description: The STDOUT and the STDERR logged by the script during the execution.
      type: String
    - contextPath: PaloAltoNetworksXDR.ScriptResult.results.retention_date
      description: Timestamp in which the retrieved files will be deleted from the server.
      type: Date
  - arguments:
    - description: Allows linking the response action to the incident that triggered it.
      name: incident_id
    - description: A comma-separated list of endpoint IDs. Can be retrieved by running the xdr-get-endpoints command.
      name: endpoint_ids
      required: true
    - description: Section of a script to initiate on an endpoint (e.g., print("7")).
      name: snippet_code
      required: true
    - description: Interval in seconds between each poll.
      name: interval_in_seconds
    - description: Polling timeout in seconds.
      name: timeout_in_seconds
    - description: Action IDs for polling use.
      isArray: true
      name: action_id
      deprecated: true
    description: Initiates a new endpoint script execution action using the provided snippet code.
    name: xdr-snippet-code-script-execute
    outputs:
    - contextPath: PaloAltoNetworksXDR.ScriptRun.action_id
      description: ID of the action initiated.
      type: Number
    - contextPath: PaloAltoNetworksXDR.ScriptRun.endpoints_count
      description: Number of endpoints the action was initiated on.
      type: Number
    polling: true
  - arguments:
    - description: Allows linking the response action to the incident that triggered it.
      name: incident_id
    - description: A comma-separated list of endpoint IDs. Can be retrieved by running the xdr-get-endpoints command.
      name: endpoint_ids
      required: true
    - description: Section of a script you want to initiate on an endpoint (e.g., print("7")).
      name: snippet_code
      required: true
    deprecated: true
    description: Deprecated. Use `xdr-snippet-code-script-execute` instead.
    name: xdr-run-snippet-code-script
    outputs:
    - contextPath: PaloAltoNetworksXDR.ScriptRun.action_id
      description: ID of the action initiated.
      type: Number
    - contextPath: PaloAltoNetworksXDR.ScriptRun.endpoints_count
      description: Number of endpoints the action was initiated on.
      type: Number
  - arguments:
    - description: Action IDs retrieved from the xdr-run-script command.
      isArray: true
      name: action_id
      required: true
    description: Retrieves the status of a script execution action.
    name: xdr-get-script-execution-status
    outputs:
    - contextPath: PaloAltoNetworksXDR.ScriptStatus.general_status
      description: General status of the action, considering the status of all the endpoints.
      type: String
    - contextPath: PaloAltoNetworksXDR.ScriptStatus.error_message
      description: Error message regarding permissions for running APIs or the action doesn't exist.
      type: String
    - contextPath: PaloAltoNetworksXDR.ScriptStatus.endpoints_timeout
      description: Number of endpoints in the "timeout" status.
      type: Number
    - contextPath: PaloAltoNetworksXDR.ScriptStatus.action_id
      description: ID of the action initiated.
      type: Number
    - contextPath: PaloAltoNetworksXDR.ScriptStatus.endpoints_pending_abort
      description: Number of endpoints in the "pending abort" status.
      type: Number
    - contextPath: PaloAltoNetworksXDR.ScriptStatus.endpoints_pending
      description: Number of endpoints in the "pending" status.
      type: Number
    - contextPath: PaloAltoNetworksXDR.ScriptStatus.endpoints_in_progress
      description: Number of endpoints in the "in progress" status.
      type: Number
    - contextPath: PaloAltoNetworksXDR.ScriptStatus.endpoints_failed
      description: Number of endpoints in the "failed" status.
      type: Number
    - contextPath: PaloAltoNetworksXDR.ScriptStatus.endpoints_expired
      description: Number of endpoints in the "expired" status.
      type: Number
    - contextPath: PaloAltoNetworksXDR.ScriptStatus.endpoints_completed_successfully
      description: Number of endpoints in the "completed successfully" status.
      type: Number
    - contextPath: PaloAltoNetworksXDR.ScriptStatus.endpoints_canceled
      description: Number of endpoints in the "canceled" status.
      type: Number
    - contextPath: PaloAltoNetworksXDR.ScriptStatus.endpoints_aborted
      description: Number of endpoints in the "aborted" status.
      type: Number
  - arguments:
    - description: Action IDs retrieved from the xdr-run-script command.
      isArray: true
      name: action_id
      required: true
    description: Retrieve the results of a script execution action.
    name: xdr-get-script-execution-results
    outputs:
    - contextPath: PaloAltoNetworksXDR.ScriptResult.action_id
      description: ID of the action initiated.
      type: Number
    - contextPath: PaloAltoNetworksXDR.ScriptResult.results.retrieved_files
      description: Number of successfully retrieved files.
      type: Number
    - contextPath: PaloAltoNetworksXDR.ScriptResult.results.endpoint_ip_address
      description: Endpoint IP address.
      type: String
    - contextPath: PaloAltoNetworksXDR.ScriptResult.results.endpoint_name
      description: Name of successfully retrieved files.
      type: String
    - contextPath: PaloAltoNetworksXDR.ScriptResult.results.failed_files
      description: Number of files failed to be retrieved.
      type: Number
    - contextPath: PaloAltoNetworksXDR.ScriptResult.results.endpoint_status
      description: Endpoint status.
      type: String
    - contextPath: PaloAltoNetworksXDR.ScriptResult.results.domain
      description: Domain to which the endpoint belongs.
      type: String
    - contextPath: PaloAltoNetworksXDR.ScriptResult.results.endpoint_id
      description: Endpoint ID.
      type: String
    - contextPath: PaloAltoNetworksXDR.ScriptResult.results.execution_status
      description: Execution status of this endpoint.
      type: String
    - contextPath: PaloAltoNetworksXDR.ScriptResult.results.return_value
      description: Value returned by the script in case the type is not a dictionary.
      type: String
    - contextPath: PaloAltoNetworksXDR.ScriptResult.results.standard_output
      description: The STDOUT and the STDERR logged by the script during the execution.
      type: String
    - contextPath: PaloAltoNetworksXDR.ScriptResult.results.retention_date
      description: Timestamp in which the retrieved files will be deleted from the server.
      type: Date
  - arguments:
    - description: Action IDs retrieved from the xdr-run-script command.
      isArray: true
      name: action_id
      required: true
    - description: Endpoint ID. Can be retrieved by running the xdr-get-endpoints command.
      isArray: true
      name: endpoint_id
      required: true
    description: Gets the files retrieved from a specific endpoint during a script execution.
    name: xdr-get-script-execution-result-files
    outputs:
    - contextPath: File.Size
      description: The size of the file.
      type: String
    - contextPath: File.SHA1
      description: The SHA1 hash of the file.
      type: String
    - contextPath: File.SHA256
      description: The SHA256 hash of the file.
      type: String
    - contextPath: File.SHA512
      description: The SHA512 hash of the file.
      type: String
    - contextPath: File.Name
      description: The name of the file.
      type: String
    - contextPath: File.SSDeep
      description: The SSDeep hash of the file.
      type: String
    - contextPath: File.EntryID
      description: EntryID of the file.
      type: String
    - contextPath: File.Info
      description: Information about the file.
      type: String
    - contextPath: File.Type
      description: The file type.
      type: String
    - contextPath: File.MD5
      description: The MD5 hash of the file.
      type: String
    - contextPath: File.Extension
      description: The extension of the file.
      type: String
  - arguments:
    - description: Allows linking the response action to the incident that triggered it.
      name: incident_id
    - description: A comma-separated list of endpoint IDs. Can be retrieved by running the xdr-get-endpoints command.
      name: endpoint_ids
      required: true
    - description: A comma-separated list of shell commands to execute.
      name: commands
      required: true
    - defaultValue: '600'
      description: The timeout in seconds for this execution.
      name: timeout
    - description: Interval in seconds between each poll.
      name: interval_in_seconds
    - description: Polling timeout in seconds.
      name: timeout_in_seconds
    - description: The action IDs for polling use.
      isArray: true
      name: action_id
      deprecated: true
    description: Initiates a new endpoint script execution of shell commands.
    name: xdr-script-commands-execute
    polling: true
    outputs:
    - contextPath: PaloAltoNetworksXDR.ScriptRun.action_id
      description: ID of the action initiated.
      type: Number
    - contextPath: PaloAltoNetworksXDR.ScriptRun.endpoints_count
      description: Number of endpoints the action was initiated on.
      type: Number
  - arguments:
    - description: Allows linking the response action to the incident that triggered it.
      name: incident_id
    - description: A comma-separated list of endpoint IDs. Can be retrieved by running the xdr-get-endpoints command.
      name: endpoint_ids
      required: true
    - description: A comma-separated list of shell commands to execute.
      name: commands
      required: true
    - defaultValue: '600'
      description: The timeout in seconds for this execution.
      name: timeout
    deprecated: true
    description: Deprecated. Use `xdr-script-commands-execute` instead.
    name: xdr-run-script-execute-commands
    outputs:
    - contextPath: PaloAltoNetworksXDR.ScriptRun.action_id
      description: ID of the action initiated.
      type: Number
    - contextPath: PaloAltoNetworksXDR.ScriptRun.endpoints_count
      description: Number of endpoints the action was initiated on.
      type: Number
  - arguments:
    - description: Allows linking the response action to the incident that triggered it.
      name: incident_id
    - description: A comma-separated list of endpoint IDs. Can be retrieved by running the xdr-get-endpoints command.
      isArray: true
      name: endpoint_ids
      required: true
    - description: A comma-separated list of paths of the files to delete. All of the given file paths will run on all of the endpoints.
      isArray: true
      name: file_path
      required: true
    - defaultValue: '600'
      description: The timeout in seconds for this execution.
      name: timeout
    - description: Interval in seconds between each poll.
      name: interval_in_seconds
    - description: Polling timeout in seconds.
      name: timeout_in_seconds
    - description: The acton IDs for polling use.
      isArray: true
      name: action_id
      deprecated: true
    description: Initiates a new endpoint script execution to delete the specified file.
    name: xdr-file-delete-script-execute
    polling: true
    outputs:
    - contextPath: PaloAltoNetworksXDR.ScriptRun.action_id
      description: ID of the action initiated.
      type: Number
    - contextPath: PaloAltoNetworksXDR.ScriptRun.endpoints_count
      description: Number of endpoints the action was initiated on.
      type: Number
  - arguments:
    - description: Allows linking the response action to the incident that triggered it.
      name: incident_id
    - description: A comma-separated list of endpoint IDs. Can be retrieved by running the xdr-get-endpoints command.
      isArray: true
      name: endpoint_ids
      required: true
    - description: A comma-separated list of paths of the files to delete. All of the given file paths will run on all of the endpoints.
      isArray: true
      name: file_path
      required: true
    - defaultValue: '600'
      description: The timeout in seconds for this execution.
      name: timeout
    deprecated: true
    description: Deprecated. Use `xdr-file-delete-script-execute` instead.
    name: xdr-run-script-delete-file
    outputs:
    - contextPath: PaloAltoNetworksXDR.ScriptRun.action_id
      description: ID of the action initiated.
      type: Number
    - contextPath: PaloAltoNetworksXDR.ScriptRun.endpoints_count
      description: Number of endpoints the action was initiated on.
      type: Number
  - arguments:
    - description: Allows linking the response action to the incident that triggered it.
      name: incident_id
    - description: A comma-separated list of endpoint IDs. Can be retrieved by running the xdr-get-endpoints command.
      isArray: true
      name: endpoint_ids
      required: true
    - description: A comma-separated list of paths of the files to check for existence. All of the given file paths will run on all of the endpoints.
      isArray: true
      name: file_path
      required: true
    - defaultValue: '600'
      description: The timeout in seconds for this execution.
      name: timeout
    - description: Interval in seconds between each poll.
      name: interval_in_seconds
    - description: Polling timeout in seconds.
      name: timeout_in_seconds
    - description: The action IDs for polling use.
      isArray: true
      name: action_id
      deprecated: true
    description: Initiates a new endpoint script execution to check if the file exists.
    name: xdr-file-exist-script-execute
    polling: true
    outputs:
    - contextPath: PaloAltoNetworksXDR.ScriptRun.action_id
      description: ID of the action initiated.
      type: Number
    - contextPath: PaloAltoNetworksXDR.ScriptRun.endpoints_count
      description: Number of endpoints the action was initiated on.
      type: Number
  - arguments:
    - description: Allows linking the response action to the incident that triggered it.
      name: incident_id
    - description: A comma-separated list of endpoint IDs. Can be retrieved by running the xdr-get-endpoints command.
      isArray: true
      name: endpoint_ids
      required: true
    - description: A comma-separated list of paths of the files to check for existence. All of the given file paths will run on all of the endpoints.
      isArray: true
      name: file_path
      required: true
    - defaultValue: '600'
      description: The timeout in seconds for this execution.
      name: timeout
    deprecated: true
    description: Deprecated. Use `xdr-file-exist-script-execute` instead.
    name: xdr-run-script-file-exists
    outputs:
    - contextPath: PaloAltoNetworksXDR.ScriptRun.action_id
      description: ID of the action initiated.
      type: Number
    - contextPath: PaloAltoNetworksXDR.ScriptRun.endpoints_count
      description: Number of endpoints the action was initiated on.
      type: Number
  - arguments:
    - description: Allows to link the response action to the incident that triggered it.
      name: incident_id
    - description: A comma-separated list of endpoint IDs. Can be retrieved by running the xdr-get-endpoints command.
      isArray: true
      name: endpoint_ids
      required: true
    - description: Names of processes to kill. Will kill all of the given processes on all of the endpoints.
      isArray: true
      name: process_name
      required: true
    - defaultValue: '600'
      description: The timeout in seconds for this execution.
      name: timeout
    - description: Interval in seconds between each poll.
      name: interval_in_seconds
    - description: Polling timeout in seconds.
      name: timeout_in_seconds
    - description: The action IDs for polling use.
      isArray: true
      name: action_id
      deprecated: true
    description: Initiates a new endpoint script execution kill process.
    name: xdr-kill-process-script-execute
    polling: true
    outputs:
    - contextPath: PaloAltoNetworksXDR.ScriptRun.action_id
      description: ID of the action initiated.
      type: Number
    - contextPath: PaloAltoNetworksXDR.ScriptRun.endpoints_count
      description: Number of endpoints the action was initiated on.
      type: Number
  - arguments:
    - description: Allows linking the response action to the incident that triggered it.
      name: incident_id
    - description: A comma-separated list of endpoint IDs. Can be retrieved by running the xdr-get-endpoints command.
      isArray: true
      name: endpoint_ids
      required: true
    - description: Names of processes to kill. Will kill all of the given processes on all of the endpoints.
      isArray: true
      name: process_name
      required: true
    - defaultValue: '600'
      description: The timeout in seconds for this execution.
      name: timeout
    deprecated: true
    description: Deprecated. Use `xdr-kill-process-script-execute` instead.
    name: xdr-run-script-kill-process
    outputs:
    - contextPath: PaloAltoNetworksXDR.ScriptRun.action_id
      description: ID of the action initiated.
      type: Number
    - contextPath: PaloAltoNetworksXDR.ScriptRun.endpoints_count
      description: Number of endpoints the action was initiated on.
      type: Number
  - arguments:
    - description: The endpoint ID.
      isArray: true
      name: id
    - default: true
      description: The endpoint IP address.
      isArray: true
      name: ip
    - description: The endpoint hostname.
      isArray: true
      name: hostname
    description: Returns information about an endpoint.
    name: endpoint
    outputs:
    - contextPath: Endpoint.Hostname
      description: The endpoint hostname.
      type: String
    - contextPath: Endpoint.OS
      description: The endpoint operation system.
      type: String
    - contextPath: Endpoint.IPAddress
      description: The endpoint IP address.
      type: String
    - contextPath: Endpoint.ID
      description: The endpoint ID.
      type: String
    - contextPath: Endpoint.Status
      description: The endpoint status.
      type: String
    - contextPath: Endpoint.IsIsolated
      description: The endpoint isolation status.
      type: String
    - contextPath: Endpoint.MACAddress
      description: The endpoint MAC address.
      type: String
    - contextPath: Endpoint.Vendor
      description: The integration name of the endpoint vendor.
      type: String
  - arguments:
    - description: 'A comma-separated list of endpoint statuses to filter. Valid values are: connected, disconnected, lost, uninstalled, windows, linux, macos, android, isolated, unisolated.'
      name: status
      required: true
      isArray: true
    - description: "All the agents that were last seen after {last_seen_gte}. Supported\n        values: 1579039377301 (time in milliseconds) \"3 days\" (relative date) \"2019-10-21T23:45:00\"\n        (date)."
      name: last_seen_gte
    - description: "All the agents that were last seen before {last_seen_lte}. Supported\n        values: 1579039377301 (time in milliseconds) \"3 days\" (relative date) \"2019-10-21T23:45:00\"\n        (date)."
      name: last_seen_lte
    description: Returns the number of the connected\disconnected endpoints.
    name: xdr-get-endpoints-by-status
    outputs:
    - contextPath: PaloAltoNetworksXDR.EndpointsStatus.status
      description: The endpoint status.
      type: String
    - contextPath: PaloAltoNetworksXDR.EndpointsStatus.count
      description: The number of endpoints with this status.
      type: Number
  - arguments:
    - description: A comma-separated list of alert IDs.
      isArray: true
      name: alert_ids
      required: true
    - description: Whether to return only a subset of the alert fields. Filtering the fields can reduce response size for large alerts.
      name: filter_alert_fields
      auto: PREDEFINED
      defaultValue: 'true'
      predefined:
      - 'true'
      - 'false'
    description: Returns information about each alert ID.
    name: xdr-get-cloud-original-alerts
    outputs:
    - contextPath: PaloAltoNetworksXDR.OriginalAlert.event._time
      description: The timestamp of the occurrence of the event.
      type: String
    - contextPath: PaloAltoNetworksXDR.OriginalAlert.event.vendor
      description: Vendor name.
      type: String
    - contextPath: PaloAltoNetworksXDR.OriginalAlert.event.event_timestamp
      description: Event timestamp.
      type: Number
    - contextPath: PaloAltoNetworksXDR.OriginalAlert.event.event_type
      description: Event type (static 500).
      type: Number
    - contextPath: PaloAltoNetworksXDR.OriginalAlert.event.cloud_provider
      description: The cloud provider - GCP, AZURE, or AWS.
      type: String
    - contextPath: PaloAltoNetworksXDR.OriginalAlert.event.project
      description: The project in which the event occurred.
      type: String
    - contextPath: PaloAltoNetworksXDR.OriginalAlert.event.cloud_provider_event_id
      description: The ID given to the event by the cloud provider, if the ID exists.
      type: String
    - contextPath: PaloAltoNetworksXDR.OriginalAlert.event.cloud_correlation_id
      description: The ID the cloud provider is using to aggregate events that are part of the same general event.
      type: String
    - contextPath: PaloAltoNetworksXDR.OriginalAlert.event.operation_name_orig
      description: The name of the operation that occurred, as supplied by the cloud provider.
      type: String
    - contextPath: PaloAltoNetworksXDR.OriginalAlert.event.operation_name
      description: The normalized name of the operation performed by the event.
      type: String
    - contextPath: PaloAltoNetworksXDR.OriginalAlert.event.identity_orig
      description: Contains the original identity related fields as provided by the cloud provider.
      type: String
    - contextPath: PaloAltoNetworksXDR.OriginalAlert.event.identity_name
      description: The name of the identity that initiated the action.
      type: String
    - contextPath: PaloAltoNetworksXDR.OriginalAlert.event.identity_uuid
      description: Same as identity_name but also contains the UUID of the identity if it exists.
      type: String
    - contextPath: PaloAltoNetworksXDR.OriginalAlert.event.identity_type
      description: An enum representing the type of the identity.
      type: String
    - contextPath: PaloAltoNetworksXDR.OriginalAlert.event.identity_sub_type
      description: An enum representing the sub-type of the identity, respective to its identity_type.
      type: String
    - contextPath: PaloAltoNetworksXDR.OriginalAlert.event.identity_invoked_by_name
      description: The name of the identity that invoked the action as it appears in the log.
      type: String
    - contextPath: PaloAltoNetworksXDR.OriginalAlert.event.identity_invoked_by_uuid
      description: The UUID of the identity that invoked the action as it appears in the log.
      type: String
    - contextPath: PaloAltoNetworksXDR.OriginalAlert.event.identity_invoked_by_type
      description: An enum that represents the type of identity event that invoked the action.
      type: String
    - contextPath: PaloAltoNetworksXDR.OriginalAlert.event.identity_invoked_by_sub_type
      description: An enum that represents the respective sub_type of the type of identity (identity_type) that has invoked the action.
      type: String
    - contextPath: PaloAltoNetworksXDR.OriginalAlert.event.operation_status
      description: Status of whether the operation has succeed or failed, if provided.
      type: String
    - contextPath: PaloAltoNetworksXDR.OriginalAlert.event.operation_status_orig
      description: The operation status code as it appears in the log, including the lookup from the code number to code name.
      type: String
    - contextPath: PaloAltoNetworksXDR.OriginalAlert.event.operation_status_orig_code
      description: The operation status code as it appears in the log.
      type: String
    - contextPath: PaloAltoNetworksXDR.OriginalAlert.event.operation_status_reason_provided
      description: Description of the error, if the log record indicates an error and the cloud provider supplied the reason.
      type: String
    - contextPath: PaloAltoNetworksXDR.OriginalAlert.event.resource_type
      description: The normalized type of the service that emitted the log row.
      type: String
    - contextPath: PaloAltoNetworksXDR.OriginalAlert.event.resource_type_orig
      description: The type of the service that emitted the log as provided by the cloud provider.
      type: String
    - contextPath: PaloAltoNetworksXDR.OriginalAlert.event.resource_sub_type
      description: The sub-type respective to the resource_type field, normalized across all cloud providers.
      type: String
    - contextPath: PaloAltoNetworksXDR.OriginalAlert.event.resource_sub_type_orig
      description: The sub-type of the service that emitted this log row as provided by the cloud provider.
      type: String
    - contextPath: PaloAltoNetworksXDR.OriginalAlert.event.region
      description: The cloud region of the resource that emitted the log.
      type: String
    - contextPath: PaloAltoNetworksXDR.OriginalAlert.event.zone
      description: The availability zone of the resource that emitted the log.
      type: String
    - contextPath: PaloAltoNetworksXDR.OriginalAlert.event.referenced_resource
      description: The cloud resource referenced in the audit log.
      type: String
    - contextPath: PaloAltoNetworksXDR.OriginalAlert.event.referenced_resource_name
      description: Same as referenced_resource but provides only the substring that represents the resource name instead of the full asset ID.
      type: String
    - contextPath: PaloAltoNetworksXDR.OriginalAlert.event.referenced_resources_count
      description: The number of extracted resources referenced in this audit log.
      type: Number
    - contextPath: PaloAltoNetworksXDR.OriginalAlert.event.user_agent
      description: The user agent provided in the call to the API of the cloud provider.
      type: String
    - contextPath: PaloAltoNetworksXDR.OriginalAlert.event.caller_ip
      description: The IP of the caller that performed the action in the log.
      type: String
    - contextPath: PaloAltoNetworksXDR.OriginalAlert.event.caller_ip_geolocation
      description: The geolocation associated with the caller_ip's value.
      type: String
    - contextPath: PaloAltoNetworksXDR.OriginalAlert.event.caller_ip_asn
      description: The ASN of the caller_ip's value.
      type: Number
    - contextPath: PaloAltoNetworksXDR.OriginalAlert.event.caller_project
      description: The project of the caller entity.
      type: String
    - contextPath: PaloAltoNetworksXDR.OriginalAlert.event.raw_log
      description: The raw log that is being normalized.
      type: Unknown
    - contextPath: PaloAltoNetworksXDR.OriginalAlert.event.log_name
      description: The name of the log that contains the log row.
      type: String
    - contextPath: PaloAltoNetworksXDR.OriginalAlert.event.caller_ip_asn_org
      description: The organization associated with the ASN of the caller_ip's value.
      type: String
    - contextPath: PaloAltoNetworksXDR.OriginalAlert.event.event_base_id
      description: Event base ID.
      type: String
    - contextPath: PaloAltoNetworksXDR.OriginalAlert.event.ingestion_time
      description: Ingestion time.
      type: String
  - arguments:
    - description: The unique ID of the alert.
      isArray: true
      name: alert_id
    - auto: PREDEFINED
      description: The severity of the alert.
      isArray: true
      name: severity
      predefined:
      - low
      - medium
      - high
    - description: "A custom filter. When using this argument, other filter arguments are not relevant. example: \n`{\n                \"OR\": [\n                    {\n                        \"SEARCH_FIELD\": \"actor_process_command_line\",\n                        \"SEARCH_TYPE\": \"EQ\",\n                        \"SEARCH_VALUE\": \"path_to_file\"\n                    }\n                ]\n            }`."
      name: custom_filter
    - auto: PREDEFINED
      description: Account type.
      isArray: true
      name: Identity_type
      predefined:
      - ANONYMOUS
      - APPLICATION
      - COMPUTE
      - FEDERATED_IDENTITY
      - SERVICE
      - SERVICE_ACCOUNT
      - TEMPORARY_CREDENTIALS
      - TOKEN
      - UNKNOWN
      - USER
    - description: A unique identifier per agent.
      isArray: true
      name: agent_id
    - description: The hostname to connect to. In case of a proxy connection, this value will differ from action_remote_ip.
      isArray: true
      name: action_external_hostname
    - description: A string identifying the user rule.
      isArray: true
      name: rule_id
    - description: The name of the user rule.
      isArray: true
      name: rule_name
    - description: The alert name.
      isArray: true
      name: alert_name
    - description: The alert source.
      isArray: true
      name: alert_source
    - auto: PREDEFINED
      description: Supports relative times or “custom” time option. If you choose the "custom" option, you should use start_time and end_time arguments.
      name: time_frame
      predefined:
      - 60 minutes
      - 3 hours
      - 12 hours
      - 24 hours
      - 2 days
      - 7 days
      - 14 days
      - 30 days
      - custom
    - description: The name assigned to the user_id during agent runtime.
      isArray: true
      name: user_name
    - description: The file name of the binary file.
      isArray: true
      name: actor_process_image_name
    - description: CGO CMD.
      isArray: true
      name: causality_actor_process_image_command_line
    - description: "Trimmed to 128 unicode chars during event serialization.\nFull value reported as part of the original process event."
      isArray: true
      name: actor_process_image_command_line
    - description: The command line of the process created.
      isArray: true
      name: action_process_image_command_line
    - description: SHA256 hash of the binary file.
      isArray: true
      name: actor_process_image_sha256
    - description: SHA256 hash of the binary file.
      isArray: true
      name: causality_actor_process_image_sha256
    - description: SHA256 of the binary file.
      isArray: true
      name: action_process_image_sha256
    - description: SHA256 of the file related to the event.
      isArray: true
      name: action_file_image_sha256
    - description: The name of the registry.
      isArray: true
      name: action_registry_name
    - description: The key data of the registry.
      isArray: true
      name: action_registry_key_data
    - description: The host IP address.
      isArray: true
      name: host_ip
    - description: The local IP address for the connection.
      isArray: true
      name: action_local_ip
    - description: Remote IP address for the connection.
      isArray: true
      name: action_remote_ip
    - auto: PREDEFINED
      description: Alert action status.
      name: alert_action_status
      predefined:
      - detected
      - detected (allowed the session)
      - detected (download)
      - detected (forward)
      - detected (post detected)
      - detected (prompt allow)
      - detected (raised an alert)
      - detected (reported)
      - detected (on write)
      - detected (scanned)
      - detected (sinkhole)
      - detected (syncookie sent)
      - detected (wildfire upload failure)
      - detected (wildfire upload success)
      - detected (wildfire upload skip)
      - detected (xdr managed threat hunting)
      - prevented (block)
      - prevented (blocked)
      - prevented (block-override)
      - prevented (blocked the url)
      - prevented (blocked the ip)
      - prevented (continue)
      - prevented (denied the session)
      - prevented (dropped all packets)
      - prevented (dropped the session)
      - prevented (dropped the session and sent a tcp reset)
      - prevented (dropped the packet)
      - prevented (override)
      - prevented (override-lockout)
      - prevented (post detected)
      - prevented (prompt block)
      - prevented (random-drop)
      - prevented (silently dropped the session with an icmp unreachable message to the host or application)
      - prevented (terminated the session and sent a tcp reset to both sides of the connection)
      - prevented (terminated the session and sent a tcp reset to the client)
      - prevented (terminated the session and sent a tcp reset to the server)
      - prevented (on write)
    - description: The local IP address for the connection.
      isArray: true
      name: action_local_port
    - description: The remote port for the connection.
      isArray: true
      name: action_remote_port
    - description: The hostname connected to. In case of a proxy connection, this value will differ from action_remote_ip.
      isArray: true
      name: dst_action_external_hostname
    - defaultValue: source_insert_ts
      description: The field by which to sort the results.
      isArray: true
      name: sort_field
    - auto: PREDEFINED
      description: The order in which to sort the results.
      name: sort_order
      predefined:
      - DESC
      - ASC
    - defaultValue: '0'
      description: The first page from which we bring the alerts.
      isArray: true
      name: offset
    - defaultValue: '50'
      description: The last page from which we bring the alerts.
      isArray: true
      name: limit
    - description: Relevant when "time_frame" argument is "custom". Supports epoch timestamp and simplified extended ISO format (YYYY-MM-DDThh:mm:ss.000Z).
      name: start_time
    - description: Relevant when "time_frame" argument is "custom". Supports epoch timestamp and simplified extended ISO format (YYYY-MM-DDThh:mm:ss.000Z).
      name: end_time
    - auto: PREDEFINED
      description: Whether the alert is starred or not.
      name: starred
      predefined:
      - 'true'
      - 'false'
    - description: The MITRE attack technique.
      isArray: true
      name: mitre_technique_id_and_name
    description: "Returns a list of alerts and their metadata, which you can filter by built-in arguments or use the custom_filter to input a JSON filter object. \nMultiple filter arguments will be concatenated using the AND operator, while arguments that support a comma-separated list of values will use an OR operator between each value."
    name: xdr-get-alerts
    outputs:
    - contextPath: PaloAltoNetworksXDR.Alert.internal_id
      description: The unique ID of the alert.
      type: String
    - contextPath: PaloAltoNetworksXDR.Alert.source_insert_ts
      description: The detection timestamp.
      type: Number
    - contextPath: PaloAltoNetworksXDR.Alert.alert_name
      description: The name of the alert.
      type: String
    - contextPath: PaloAltoNetworksXDR.Alert.severity
      description: The severity of the alert.
      type: String
    - contextPath: PaloAltoNetworksXDR.Alert.alert_category
      description: The category of the alert.
      type: String
    - contextPath: PaloAltoNetworksXDR.Alert.alert_action_status
      description: "The alert action. Possible values.\n\nDETECTED: detected\nDETECTED_0: detected (allowed the session)\nDOWNLOAD: detected (download)\nDETECTED_19: detected (forward)\nPOST_DETECTED: detected (post detected)\nPROMPT_ALLOW: detected (prompt allow)\nDETECTED_4: detected (raised an alert)\nREPORTED: detected (reported)\nREPORTED_TRIGGER_4: detected (on write)\nSCANNED: detected (scanned)\nDETECTED_23: detected (sinkhole)\nDETECTED_18: detected (syncookie sent)\nDETECTED_21: detected (wildfire upload failure)\nDETECTED_20: detected (wildfire upload success)\nDETECTED_22: detected (wildfire upload skip)\nDETECTED_MTH: detected (xdr managed threat hunting)\nBLOCKED_25: prevented (block)\nBLOCKED: prevented (blocked)\nBLOCKED_14: prevented (block-override)\nBLOCKED_5: prevented (blocked the url)\nBLOCKED_6: prevented (blocked the ip)\nBLOCKED_13: prevented (continue)\nBLOCKED_1: prevented (denied the session)\nBLOCKED_8: prevented (dropped all packets)\nBLOCKED_2: prevented (dropped the session)\nBLOCKED_3: prevented (dropped the session and sent a tcp reset)\nBLOCKED_7: prevented (dropped the packet)\nBLOCKED_16: prevented (override)\nBLOCKED_15: prevented (override-lockout)\nBLOCKED_26: prevented (post detected)\nPROMPT_BLOCK: prevented (prompt block)\nBLOCKED_17: prevented (random-drop)\nBLOCKED_24: prevented (silently dropped the session with an icmp unreachable message to the host or application)\nBLOCKED_9: prevented (terminated the session and sent a tcp reset to both sides of the connection)\nBLOCKED_10: prevented (terminated the session and sent a tcp reset to the client)\nBLOCKED_11: prevented (terminated the session and sent a tcp reset to the server)\nBLOCKED_TRIGGER_4: prevented (on write)."
      type: String
    - contextPath: PaloAltoNetworksXDR.Alert.alert_action_status_readable
      description: The alert action.
      type: String
    - contextPath: PaloAltoNetworksXDR.Alert.alert_name
      description: The alert name.
      type: String
    - contextPath: PaloAltoNetworksXDR.Alert.alert_description
      description: The alert description.
      type: String
    - contextPath: PaloAltoNetworksXDR.Alert.agent_ip_addresses
      description: The host IP address.
      type: String
    - contextPath: PaloAltoNetworksXDR.Alert.agent_hostname
      description: The hostname.
      type: String
    - contextPath: PaloAltoNetworksXDR.Alert.mitre_tactic_id_and_name
      description: The MITRE attack tactic.
      type: String
    - contextPath: PaloAltoNetworksXDR.Alert.mitre_technique_id_and_name
      description: The MITRE attack technique.
      type: String
    - contextPath: PaloAltoNetworksXDR.Alert.starred
      description: Whether the alert is starred or not.
      type: Boolean
  - arguments:
    - description: Links the response action to the incident that triggered it.
      name: incident_id
    - description: String that represents a list of hashed files to add to the allow list. Must be a valid SHA256 hash.
      isArray: true
      name: hash_list
      required: true
    - description: String that represents additional information regarding the action.
      name: comment
    description: Removes requested files from allow list.
    name: xdr-remove-allowlist-files
    outputs:
    - contextPath: PaloAltoNetworksXDR.allowlist.removed_hashes
      description: Removed file hash.
      type: Number
  - arguments:
    - description: Links the response action to the incident that triggered it.
      name: incident_id
    - description: String that represents a list of hashed files to add to the allow list. Must be a valid SHA256 hash.
      isArray: true
      name: hash_list
      required: true
    - description: String that represents additional information regarding the action.
      name: comment
    description: Removes requested files from the block list.
    name: xdr-remove-blocklist-files
    outputs:
    - contextPath: PaloAltoNetworksXDR.blocklist.removed_hashes
      description: Removed file hash from block list.
      type: Number
  - arguments:
    - description: The alert ID's from where to retrieve the contributing events.
      isArray: true
      name: alert_ids
      required: true
    - defaultValue: '50'
      description: The maximum number of contributing events to retrieve.
      name: limit
    - defaultValue: '1'
      description: The page number to retrieve. Minimum is 1.
      name: page_number
    - defaultValue: '50'
      description: The page size.
      name: page_size
    description: Retrieves contributing events for a specific correlation alert.
    name: xdr-get-contributing-event
    outputs:
    - contextPath: PaloAltoNetworksXDR.ContributingEvent.alertID
      description: The alert ID.
      type: String
    - contextPath: PaloAltoNetworksXDR.ContributingEvent.events
      description: The contributing events.
      type: Unknown
  - arguments:
    - auto: PREDEFINED
      description: The field type to change.
      name: field_type
      predefined:
      - hosts
      - users
      - ip_addresses
      - ad_groups
      required: true
    - description: The string value, which defines the new field. Maximum length is 256 characters.
      isArray: true
      name: values
      required: true
    - description: The string value, which represents additional information regarding the featured alert field.
      name: comments
    - auto: PREDEFINED
      defaultValue: group
      description: The string value to replace an active directory group or organizational unit.
      name: ad_type
      predefined:
      - group
      - ou
    description: Replace the featured hosts\users\IP addresses\active directory groups listed in your environment.
    name: xdr-replace-featured-field
    outputs:
    - contextPath: PaloAltoNetworksXDR.FeaturedField.fieldType
      description: The field type that changed.
      type: String
    - contextPath: PaloAltoNetworksXDR.FeaturedField.fields
      description: String value that defines the new field.
      type: String
  - arguments:
    - description: A comma-separated list of endpoint IDs.
      isArray: true
      name: endpoint_ids
      required: true
    - description: Tag to add.
      name: tag
      required: true
    description: Adds a tag to specified endpoint_ids.
    name: xdr-endpoint-tag-add
  - arguments:
    - description: A comma-separated list of endpoint IDs.
      isArray: true
      required: true
      name: endpoint_ids
    - description: Tag to remove from specified endpoint_ids.
      name: tag
      required: true
    description: Removes a tag from specified endpoint_ids.
    name: xdr-endpoint-tag-remove
  - name: xdr-get-tenant-info
    outputs:
    - contextPath: PaloAltoNetworksXDR.TenantInformation.pro_per_endpoint_expiration
      description: Expiration time pro per endpoint.
      type: Date
    - contextPath: PaloAltoNetworksXDR.TenantInformation.purchased_pro_per_endpoint.agents
      description: Number of endpoint agents purchased.
      type: Number
    - contextPath: PaloAltoNetworksXDR.TenantInformation.data_enabled_pro_per_endpoint
      description: Enabled data per pro endpoint.
      type: Number
    - contextPath: PaloAltoNetworksXDR.TenantInformation.prevent_expiration
      description: Number of prevent expirations.
      type: Number
    - contextPath: PaloAltoNetworksXDR.TenantInformation.purchased_prevent
      description: Number of purchased prevents.
      type: Number
    - contextPath: PaloAltoNetworksXDR.TenantInformation.installed_prevent
      description: Number of installed prevents.
      type: Number
    - contextPath: PaloAltoNetworksXDR.TenantInformation.pro_tb_expiration
      description: pro_tb license expiration time.
      type: Date
    - contextPath: PaloAltoNetworksXDR.TenantInformation.purchased_pro_tb.tb
      description: Number of pro_tbs purchased.
      type: Number
    - contextPath: PaloAltoNetworksXDR.TenantInformation.installed_pro_tb
      description: Number of pro_tbs installed.
      type: Number
    - contextPath: PaloAltoNetworksXDR.TenantInformation.compute_unit_expiration
      description: Compute unit expiration time.
      type: Date
    - contextPath: PaloAltoNetworksXDR.TenantInformation.purchased_compute_unit
      description: Number of compute units purchased.
      type: Number
    - contextPath: PaloAltoNetworksXDR.TenantInformation.compute_unit_is_trial
      description: Whether the compute unit is a trial.
      type: Boolean
    - contextPath: PaloAltoNetworksXDR.TenantInformation.host_insights_expiration
      description: Host insight expiration date.
      type: Date
    - contextPath: PaloAltoNetworksXDR.TenantInformation.enabled_host_insights
      description: Number of host insights enabled.
      type: Number
    - contextPath: PaloAltoNetworksXDR.TenantInformation.purchased_host_insights
      description: Number of purchased host insights.
      type: Number
    - contextPath: PaloAltoNetworksXDR.TenantInformation.forensics_expiration
      description: Forensic expiration date.
      type: Date
    - contextPath: PaloAltoNetworksXDR.TenantInformation.purchased_forensics
      description: Number of forensics purchased.
      type: Number
    arguments: []
    description: Provides information about the tenant.
  - name: xdr-list-users
    description: Retrieve a list of the current users in the environment.
    arguments: []
    outputs:
    - contextPath: PaloAltoNetworksXDR.User.user_email
      description: Email address of the user.
      type: string
    - contextPath: PaloAltoNetworksXDR.User.user_first_name
      description: First name of the user.
      type: string
    - contextPath: PaloAltoNetworksXDR.User.user_last_name
      description: Last name of the user.
      type: string
    - contextPath: PaloAltoNetworksXDR.User.role_name
      description: Role name associated with the user.
      type: string
    - contextPath: PaloAltoNetworksXDR.User.last_logged_in
      description: Timestamp of when the user last logged in.
      type: Number
    - contextPath: PaloAltoNetworksXDR.User.user_type
      description: Type of user.
      type: string
    - contextPath: PaloAltoNetworksXDR.User.groups
      description: Name of user groups associated with the user, if applicable.
      type: array
    - contextPath: PaloAltoNetworksXDR.User.scope
      description: Name of scope associated with the user, if applicable.
      type: array
  - arguments:
    - description: "Unique ID of a specific user.\nUser ID could be either of the `foo/dummy` format, or just `dummy`.\n"
      name: user_id
    - description: Limit the number of users that will appear in the list. (Use limit when no specific host is requested.)
      name: limit
      defaultValue: '50'
    name: xdr-list-risky-users
    description: Retrieve the risk score of a specific user or list of users with the highest risk score in the environment along with the reason affecting each score.
    outputs:
    - contextPath: PaloAltoNetworksXDR.RiskyUser.type
      description: Form of identification element.
      type: String
    - contextPath: PaloAltoNetworksXDR.RiskyUser.id
      description: Identification value of the type field.
      type: String
    - contextPath: PaloAltoNetworksXDR.RiskyUser.score
      description: The score assigned to the user.
      type: Number
    - contextPath: PaloAltoNetworksXDR.RiskyUser.reasons.date created
      description: Date when the incident was created.
      type: String
    - contextPath: PaloAltoNetworksXDR.RiskyUser.reasons.description
      description: Description of the incident.
      type: String
    - contextPath: PaloAltoNetworksXDR.RiskyUser.reasons.severity
      description: The severity of the incident.
      type: String
    - contextPath: PaloAltoNetworksXDR.RiskyUser.reasons.status
      description: The incident status.
      type: String
    - contextPath: PaloAltoNetworksXDR.RiskyUser.reasons.points
      description: The score.
      type: Number
  - arguments:
    - description: The name of the host.
      name: host_id
    - description: Limit the number of hosts that will appear in the list. By default, the limit is 50 hosts.(Use limit when no specific host is requested.)
      name: limit
      defaultValue: '50'
    name: xdr-list-risky-hosts
    description: Retrieve the risk score of a specific host or list of hosts with the highest risk score in the environment along with the reason affecting each score.
    outputs:
    - contextPath: PaloAltoNetworksXDR.RiskyHost.type
      description: Form of identification element.
      type: String
    - contextPath: PaloAltoNetworksXDR.RiskyHost.id
      description: Identification value of the type field.
      type: String
    - contextPath: PaloAltoNetworksXDR.RiskyHost.score
      description: The score assigned to the host.
      type: Number
    - contextPath: PaloAltoNetworksXDR.RiskyHost.reasons.date created
      description: Date when the incident was created.
      type: String
    - contextPath: PaloAltoNetworksXDR.RiskyHost.reasons.description
      description: Description of the incident.
      type: String
    - contextPath: PaloAltoNetworksXDR.RiskyHost.reasons.severity
      description: The severity of the incident.
      type: String
    - contextPath: PaloAltoNetworksXDR.RiskyHost.reasons.status
      description: The incident status.
      type: String
    - contextPath: PaloAltoNetworksXDR.RiskyHost.reasons.points
      description: The score.
      type: Number
  - arguments:
    - description: A comma-separated list of one or more user group names for the associated users.
      name: group_names
      isArray: true
      required: true
    name: xdr-list-user-groups
    description: Retrieve a list of the current user emails associated with one or more user groups in the environment.
    outputs:
    - contextPath: PaloAltoNetworksXDR.UserGroup.group_name
      description: Name of the user group.
      type: String
    - contextPath: PaloAltoNetworksXDR.UserGroup.description
      description: Description of the user group, if available.
      type: String
    - contextPath: PaloAltoNetworksXDR.UserGroup.pretty_name
      description: Name of the user group as it appears in the management console.
      type: String
    - contextPath: PaloAltoNetworksXDR.UserGroup.insert_time
      description: Timestamp of when the user group was created.
      type: Number
    - contextPath: PaloAltoNetworksXDR.UserGroup.update_time
      description: Timestamp of when the user group was last updated.
      type: Number
    - contextPath: PaloAltoNetworksXDR.UserGroup.user_email
      description: List of email addresses belonging to the users associated with the user group.
      type: array
    - contextPath: PaloAltoNetworksXDR.UserGroup.source
      description: Type of user group.
      type: String
  - arguments:
    - description: A comma-separated list of one or more role names in your environment for which to retrieve detailed information.
      name: role_names
      required: true
    name: xdr-list-roles
    description: Retrieve information about one or more roles created in the environment.
    outputs:
    - contextPath: PaloAltoNetworksXDR.Role.pretty_name
      description: Name of the role as it appears in the management console.
      type: String
    - contextPath: PaloAltoNetworksXDR.Role.permissions
      description: List of permissions associated with this role.
      type: array
    - contextPath: PaloAltoNetworksXDR.Role.insert_time
      description: Timestamp of when the role was created.
      type: Number
    - contextPath: PaloAltoNetworksXDR.Role.update_time
      description: Timestamp of when the role was last updated.
      type: Number
    - contextPath: PaloAltoNetworksXDR.Role.created_by
      description: Email of the user who created the role.
      type: String
    - contextPath: PaloAltoNetworksXDR.Role.description
      description: Description of the role, if available.
      type: String
    - contextPath: PaloAltoNetworksXDR.Role.groups
      description: Group names associated with the role.
      type: array
    - contextPath: PaloAltoNetworksXDR.Role.users
      description: Email address of users associated with the role.
      type: array
  - arguments:
    - description: A comma-separated list of one or more user emails of users you want to add to a role.
      name: user_emails
      required: true
      isArray: true
    - description: Name of the role to add a user to.
      name: role_name
      required: true
    name: xdr-set-user-role
    description: Add one or more users to a role.
  - arguments:
    - description: A comma-separate list of one or more user emails of users to remove from a role.
      name: user_emails
      required: true
      isArray: true
    name: xdr-remove-user-role
    description: Remove one or more users from a role.
  - arguments:
    - description: A comma-separated list of alert IDs.
      name: alert_ids
      required: true
      isArray: true
    - auto: PREDEFINED
      description: Required severity to update alerts to.
      name: severity
      required: false
      predefined:
      - critical
      - high
      - medium
      - low
    - auto: PREDEFINED
      description: New status for updated alerts.
      name: status
      required: false
      predefined:
      - new
      - resolved_threat_handled
      - under_investigation
      - resolved_security_testing
      - resolved_auto
      - resolved_known_issue
      - resolved_duplicate
      - resolved_other
      - resolved_false_positive
      - resolved_true_positive
    - description: Comment to append to updated alerts.
      name: comment
      required: false
    description: "Update one or more alerts with the provided arguments.\nRequired license: Cortex XDR Prevent, Cortex XDR Pro per Endpoint, or Cortex XDR Pro per GB."
    name: xdr-update-alert
  dockerimage: demisto/python3:3.11.9.107902
  isfetch: true
  script: >
    register_module_line('Cortex XDR - IR', 'start', __line__())

    ### pack version: 6.1.63



    import hashlib

    import secrets

    import string

    from itertools import zip_longest

    from datetime import datetime, timedelta

    import pytz



    ### GENERATED CODE ###: from CoreIRApiModule import *

    # This code was inserted in place of an API module.

    register_module_line('CoreIRApiModule', 'start', __line__(), wrapper=-3)



    import urllib3

    import copy

    import re

    from operator import itemgetter

    import json

    from typing import Tuple, Callable

    import base64


    # Disable insecure warnings

    urllib3.disable_warnings()

    TIME_FORMAT = "%Y-%m-%dT%H:%M:%S"


    XSOAR_RESOLVED_STATUS_TO_XDR = {
        'Other': 'resolved_other',
        'Duplicate': 'resolved_duplicate',
        'False Positive': 'resolved_false_positive',
        'Resolved': 'resolved_true_positive',
        'Security Testing': 'resolved_security_testing',
    }


    XDR_RESOLVED_STATUS_TO_XSOAR = {
        'resolved_known_issue': 'Other',
        'resolved_duplicate_incident': 'Duplicate',
        'resolved_duplicate': 'Duplicate',
        'resolved_false_positive': 'False Positive',
        'resolved_true_positive': 'Resolved',
        'resolved_security_testing': 'Security Testing',
        'resolved_other': 'Other',
        'resolved_auto': 'Resolved'
    }


    ALERT_GENERAL_FIELDS = {
        'detection_modules',
        'alert_full_description',
        'matching_service_rule_id',
        'variation_rule_id',
        'content_version',
        'detector_id',
        'mitre_technique_id_and_name',
        'silent',
        'mitre_technique_ids',
        'activity_first_seet_at',
        '_type',
        'dst_association_strength',
        'alert_description',
    }


    ALERT_EVENT_GENERAL_FIELDS = {
        "_time",
        "vendor",
        "event_timestamp",
        "event_type",
        "event_id",
        "cloud_provider",
        "project",
        "cloud_provider_event_id",
        "cloud_correlation_id",
        "operation_name_orig",
        "operation_name",
        "identity_orig",
        "identity_name",
        "identity_uuid",
        "identity_type",
        "identity_sub_type",
        "identity_invoked_by_name",
        "identity_invoked_by_uuid",
        "identity_invoked_by_type",
        "identity_invoked_by_sub_type",
        "operation_status",
        "operation_status_orig",
        "operation_status_orig_code",
        "operation_status_reason_provided",
        "resource_type",
        "resource_type_orig",
        "resource_sub_type",
        "resource_sub_type_orig",
        "region",
        "zone",
        "referenced_resource",
        "referenced_resource_name",
        "referenced_resources_count",
        "user_agent",
        "caller_ip",
        'caller_ip_geolocation',
        "caller_ip_asn",
        'caller_project',
        'raw_log',
        "log_name",
        "caller_ip_asn_org",
        "event_base_id",
        "ingestion_time",
    }


    ALERT_EVENT_AWS_FIELDS = {
        "eventVersion",
        "userIdentity",
        "eventTime",
        "eventSource",
        "eventName",
        "awsRegion",
        "sourceIPAddress",
        "userAgent",
        "requestID",
        "eventID",
        "readOnly",
        "eventType",
        "apiVersion",
        "managementEvent",
        "recipientAccountId",
        "eventCategory",
        "errorCode",
        "errorMessage",
        "resources",
    }


    ALERT_EVENT_GCP_FIELDS = {
        "labels",
        "operation",
        "protoPayload",
        "resource",
        "severity",
        "timestamp",
    }


    ALERT_EVENT_AZURE_FIELDS = {
        "time",
        "resourceId",
        "category",
        "operationName",
        "operationVersion",
        "schemaVersion",
        "statusCode",
        "statusText",
        "callerIpAddress",
        "correlationId",
        "identity",
        "level",
        "properties",
        "uri",
        "protocol",
        "resourceType",
        "tenantId",
    }


    RBAC_VALIDATIONS_VERSION = '8.6.0'

    RBAC_VALIDATIONS_BUILD_NUMBER = '992980'

    FORWARD_USER_RUN_RBAC = is_xsiam() and is_demisto_version_ge(version=RBAC_VALIDATIONS_VERSION,
                                                                 build_number=RBAC_VALIDATIONS_BUILD_NUMBER) and not is_using_engine()

    ALLOW_BIN_CONTENT_RESPONSE_BUILD_NUM = '1230614'

    ALLOW_BIN_CONTENT_RESPONSE_SERVER_VERSION = '8.7.0'

    ALLOW_RESPONSE_AS_BINARY = is_demisto_version_ge(version=ALLOW_BIN_CONTENT_RESPONSE_SERVER_VERSION,
                                                     build_number=ALLOW_BIN_CONTENT_RESPONSE_BUILD_NUM)


    class CoreClient(BaseClient):

        def __init__(self, base_url: str, headers: dict, timeout: int = 120, proxy: bool = False, verify: bool = False):
            super().__init__(base_url=base_url, headers=headers, proxy=proxy, verify=verify)
            self.timeout = timeout
            # For Xpanse tenants requiring direct use of the base client HTTP request instead of the _apiCall,

        def _http_request(self, method, url_suffix='', full_url=None, headers=None, json_data=None,
                          params=None, data=None, timeout=None, raise_on_status=False, ok_codes=None,
                          error_handler=None, with_metrics=False, resp_type='json'):
            '''
            """A wrapper for requests lib to send our requests and handle requests and responses better.

                :type method: ``str``
                :param method: The HTTP method, for example: GET, POST, and so on.


                :type url_suffix: ``str``
                :param url_suffix: The API endpoint.


                :type full_url: ``str``
                :param full_url:
                    Bypasses the use of self._base_url + url_suffix. This is useful if you need to
                    make a request to an address outside of the scope of the integration
                    API.


                :type headers: ``dict``
                :param headers: Headers to send in the request. If None, will use self._headers.


                :type params: ``dict``
                :param params: URL parameters to specify the query.


                :type data: ``dict``
                :param data: The data to send in a 'POST' request.


                :type raise_on_status ``bool``
                    :param raise_on_status: Similar meaning to ``raise_on_redirect``:
                        whether we should raise an exception, or return a response,
                        if status falls in ``status_forcelist`` range and retries have
                        been exhausted.


                :type timeout: ``float`` or ``tuple``
                :param timeout:
                    The amount of time (in seconds) that a request will wait for a client to
                    establish a connection to a remote machine before a timeout occurs.
                    can be only float (Connection Timeout) or a tuple (Connection Timeout, Read Timeout).
            '''
            if not FORWARD_USER_RUN_RBAC:
                return BaseClient._http_request(self,  # we use the standard base_client http_request without overriding it
                                                method=method,
                                                url_suffix=url_suffix,
                                                full_url=full_url,
                                                headers=headers,
                                                json_data=json_data, params=params, data=data,
                                                timeout=timeout,
                                                raise_on_status=raise_on_status,
                                                ok_codes=ok_codes,
                                                error_handler=error_handler,
                                                with_metrics=with_metrics,
                                                resp_type=resp_type)
            headers = headers if headers else self._headers
            data = json.dumps(json_data) if json_data else data
            address = full_url if full_url else urljoin(self._base_url, url_suffix)
            response_data_type = "bin" if resp_type == 'content' and ALLOW_RESPONSE_AS_BINARY else None
            if resp_type == 'content' and not ALLOW_RESPONSE_AS_BINARY:
                allowed_version = f'{ALLOW_BIN_CONTENT_RESPONSE_SERVER_VERSION}-{ALLOW_BIN_CONTENT_RESPONSE_BUILD_NUM}'
                raise DemistoException('getting binary data from server is allowed from '
                                       f'version: {allowed_version} and above')
            params = assign_params(
                method=method,
                path=address,
                data=data,
                headers=headers,
                timeout=timeout,
                response_data_type=response_data_type
            )
            response = demisto._apiCall(**params)
            if ok_codes and response.get('status') not in ok_codes:
                self._handle_error(error_handler, response, with_metrics)
            try:
                decoder = base64.b64decode if response_data_type == "bin" else json.loads
                demisto.debug(f'{response_data_type=}, {decoder.__name__=}')
                return decoder(response['data'])   # type: ignore[operator]
            except json.JSONDecodeError:
                demisto.debug(f"Converting data to json was failed. Return it as is. The data's type is {type(response['data'])}")
                return response['data']

        def get_incidents(self, incident_id_list=None, lte_modification_time=None, gte_modification_time=None,
                          lte_creation_time=None, gte_creation_time=None, status=None, starred=None,
                          starred_incidents_fetch_window=None, sort_by_modification_time=None, sort_by_creation_time=None,
                          page_number=0, limit=100, gte_creation_time_milliseconds=0,
                          gte_modification_time_milliseconds=None, lte_modification_time_milliseconds=None):
            """
            Filters and returns incidents

            :param incident_id_list: List of incident ids - must be list
            :param lte_modification_time: string of time format "2019-12-31T23:59:00"
            :param gte_modification_time: string of time format "2019-12-31T23:59:00"
            :param lte_creation_time: string of time format "2019-12-31T23:59:00"
            :param gte_creation_time: string of time format "2019-12-31T23:59:00"
            :param starred_incidents_fetch_window: string of time format "2019-12-31T23:59:00"
            :param starred: True if the incident is starred, else False
            :param status: string of status
            :param sort_by_modification_time: optional - enum (asc,desc)
            :param sort_by_creation_time: optional - enum (asc,desc)
            :param page_number: page number
            :param limit: maximum number of incidents to return per page
            :param gte_creation_time_milliseconds: greater than time in milliseconds
            :param gte_modification_time_milliseconds: greater than modification time in milliseconds
            :param lte_modification_time_milliseconds: greater than modification time in milliseconds
            :return:
            """
            search_from = page_number * limit
            search_to = search_from + limit

            request_data = {
                'search_from': search_from,
                'search_to': search_to,
            }

            if sort_by_creation_time and sort_by_modification_time:
                raise ValueError('Should be provide either sort_by_creation_time or '
                                 'sort_by_modification_time. Can\'t provide both')
            if sort_by_creation_time:
                request_data['sort'] = {
                    'field': 'creation_time',
                    'keyword': sort_by_creation_time
                }
            elif sort_by_modification_time:
                request_data['sort'] = {
                    'field': 'modification_time',
                    'keyword': sort_by_modification_time
                }

            filters = []
            if incident_id_list is not None and len(incident_id_list) > 0:
                filters.append({
                    'field': 'incident_id_list',
                    'operator': 'in',
                    'value': incident_id_list
                })

            if status:
                filters.append({
                    'field': 'status',
                    'operator': 'eq',
                    'value': status
                })

            if starred and starred_incidents_fetch_window and demisto.command() == 'fetch-incidents':
                filters.append({
                    'field': 'starred',
                    'operator': 'eq',
                    'value': True
                })
                filters.append({
                    'field': 'creation_time',
                    'operator': 'gte',
                    'value': starred_incidents_fetch_window
                })

                if len(filters) > 0:
                    request_data['filters'] = filters
                incidents = self.handle_fetch_starred_incidents(limit, page_number, request_data)
                return incidents

            if starred is not None and demisto.command() != 'fetch-incidents':
                filters.append({
                    'field': 'starred',
                    'operator': 'eq',
                    'value': starred
                })

            if lte_creation_time:
                filters.append({
                    'field': 'creation_time',
                    'operator': 'lte',
                    'value': date_to_timestamp(lte_creation_time, TIME_FORMAT)
                })

            if gte_creation_time:
                filters.append({
                    'field': 'creation_time',
                    'operator': 'gte',
                    'value': date_to_timestamp(gte_creation_time, TIME_FORMAT)
                })
            elif starred and starred_incidents_fetch_window and demisto.command() != 'fetch-incidents':
                # backwards compatibility of starred_incidents_fetch_window
                filters.append({
                    'field': 'creation_time',
                    'operator': 'gte',
                    'value': starred_incidents_fetch_window
                })

            if lte_modification_time and lte_modification_time_milliseconds:
                raise ValueError('Either lte_modification_time or '
                                 'lte_modification_time_milliseconds should be provided . Can\'t provide both')

            if gte_modification_time and gte_modification_time_milliseconds:
                raise ValueError('Either gte_modification_time or '
                                 'gte_modification_time_milliseconds should be provide. Can\'t provide both')

            if lte_modification_time:
                filters.append({
                    'field': 'modification_time',
                    'operator': 'lte',
                    'value': date_to_timestamp(lte_modification_time, TIME_FORMAT)
                })

            if gte_modification_time:
                filters.append({
                    'field': 'modification_time',
                    'operator': 'gte',
                    'value': date_to_timestamp(gte_modification_time, TIME_FORMAT)
                })

            if gte_creation_time_milliseconds:
                filters.append({
                    'field': 'creation_time',
                    'operator': 'gte',
                    'value': date_to_timestamp(gte_creation_time_milliseconds)
                })

            if gte_modification_time_milliseconds:
                filters.append({
                    'field': 'modification_time',
                    'operator': 'gte',
                    'value': date_to_timestamp(gte_modification_time_milliseconds)
                })

            if lte_modification_time_milliseconds:
                filters.append({
                    'field': 'modification_time',
                    'operator': 'lte',
                    'value': date_to_timestamp(lte_modification_time_milliseconds)
                })

            if len(filters) > 0:
                request_data['filters'] = filters
            res = self._http_request(
                method='POST',
                url_suffix='/incidents/get_incidents/',
                json_data={'request_data': request_data},
                headers=self._headers,
                timeout=self.timeout
            )
            incidents = res.get('reply', {}).get('incidents', [])

            return incidents

        def handle_fetch_starred_incidents(self, limit: int, page_number: int, request_data: Dict[Any, Any]) -> List[Any]:
            """Called from get_incidents if the command is fetch-incidents. Implement in child classes."""
            return []

        def get_endpoints(self,
                          endpoint_id_list=None,
                          dist_name=None,
                          ip_list=None,
                          public_ip_list=None,
                          group_name=None,
                          platform=None,
                          alias_name=None,
                          isolate=None,
                          hostname=None,
                          page_number=0,
                          limit=30,
                          first_seen_gte=None,
                          first_seen_lte=None,
                          last_seen_gte=None,
                          last_seen_lte=None,
                          sort_by_first_seen=None,
                          sort_by_last_seen=None,
                          status=None,
                          username=None
                          ):

            search_from = page_number * limit
            search_to = search_from + limit

            request_data = {
                'search_from': search_from,
                'search_to': search_to,
            }

            filters = create_request_filters(
                status=status, username=username, endpoint_id_list=endpoint_id_list, dist_name=dist_name,
                ip_list=ip_list, group_name=group_name, platform=platform, alias_name=alias_name, isolate=isolate,
                hostname=hostname, first_seen_gte=first_seen_gte, first_seen_lte=first_seen_lte,
                last_seen_gte=last_seen_gte, last_seen_lte=last_seen_lte, public_ip_list=public_ip_list
            )

            if search_from:
                request_data['search_from'] = search_from

            if search_to:
                request_data['search_to'] = search_to

            if sort_by_first_seen:
                request_data['sort'] = {
                    'field': 'first_seen',
                    'keyword': sort_by_first_seen
                }
            elif sort_by_last_seen:
                request_data['sort'] = {
                    'field': 'last_seen',
                    'keyword': sort_by_last_seen
                }

            request_data['filters'] = filters

            response = self._http_request(
                method='POST',
                url_suffix='/endpoints/get_endpoint/',
                json_data={'request_data': request_data},
                timeout=self.timeout
            )
            endpoints = response.get('reply', {}).get('endpoints', [])
            return endpoints

        def set_endpoints_alias(self, filters: list[dict[str, str]], new_alias_name: str | None) -> dict:  # pragma: no cover
            """
            This func is used to set the alias name of an endpoint.

            args:
                filters: list of filters to get the endpoints
                new_alias_name: the new alias name to set

            returns: dict of the response(True if success else error message)
            """

            request_data = {'filters': filters, 'alias': new_alias_name}

            return self._http_request(
                method='POST',
                url_suffix='/endpoints/update_agent_name/',
                json_data={'request_data': request_data},
                timeout=self.timeout,
            )

        def isolate_endpoint(self, endpoint_id, incident_id=None):
            request_data = {
                'endpoint_id': endpoint_id,
            }
            if incident_id:
                request_data['incident_id'] = incident_id

            reply = self._http_request(
                method='POST',
                url_suffix='/endpoints/isolate',
                json_data={'request_data': request_data},
                timeout=self.timeout
            )
            return reply.get('reply')

        def unisolate_endpoint(self, endpoint_id, incident_id=None):
            request_data = {
                'endpoint_id': endpoint_id,
            }
            if incident_id:
                request_data['incident_id'] = incident_id

            reply = self._http_request(
                method='POST',
                url_suffix='/endpoints/unisolate',
                json_data={'request_data': request_data},
                timeout=self.timeout
            )
            return reply.get('reply')

        def insert_alerts(self, alerts):
            self._http_request(
                method='POST',
                url_suffix='/alerts/insert_parsed_alerts/',
                json_data={
                    'request_data': {
                        'alerts': alerts
                    }
                },
                timeout=self.timeout
            )

        def insert_cef_alerts(self, alerts):
            self._http_request(
                method='POST',
                url_suffix='/alerts/insert_cef_alerts/',
                json_data={
                    'request_data': {
                        'alerts': alerts
                    }
                },
                timeout=self.timeout
            )

        def get_distribution_url(self, distribution_id, package_type):
            reply = self._http_request(
                method='POST',
                url_suffix='/distributions/get_dist_url/',
                json_data={
                    'request_data': {
                        'distribution_id': distribution_id,
                        'package_type': package_type
                    }
                },
                timeout=self.timeout
            )

            return reply.get('reply').get('distribution_url')

        def get_distribution_status(self, distribution_id):
            reply = self._http_request(
                method='POST',
                url_suffix='/distributions/get_status/',
                json_data={
                    'request_data': {
                        'distribution_id': distribution_id
                    }
                },
                timeout=self.timeout
            )

            return reply.get('reply').get('status')

        def get_distribution_versions(self):
            reply = self._http_request(
                method='POST',
                url_suffix='/distributions/get_versions/',
                json_data={},
                timeout=self.timeout
            )
            return reply.get('reply')

        def create_distribution(self, name, platform, package_type, agent_version, description):
            request_data = {}
            if package_type == 'standalone':
                request_data = {
                    'name': name,
                    'platform': platform,
                    'package_type': package_type,
                    'agent_version': agent_version,
                    'description': description,
                }
            elif package_type == 'upgrade':
                request_data = {
                    'name': name,
                    'package_type': package_type,
                    'description': description,
                }

                if platform == 'windows':
                    request_data['windows_version'] = agent_version
                elif platform == 'linux':
                    request_data['linux_version'] = agent_version
                elif platform == 'macos':
                    request_data['macos_version'] = agent_version

            reply = self._http_request(
                method='POST',
                url_suffix='/distributions/create/',
                json_data={
                    'request_data': request_data
                },
                timeout=self.timeout
            )

            return reply.get('reply').get('distribution_id')

        def audit_management_logs(self, email, result, _type, sub_type, search_from, search_to, timestamp_gte,
                                  timestamp_lte, sort_by, sort_order):

            request_data: Dict[str, Any] = {}
            filters = []
            if email:
                filters.append({
                    'field': 'email',
                    'operator': 'in',
                    'value': email
                })
            if result:
                filters.append({
                    'field': 'result',
                    'operator': 'in',
                    'value': result
                })
            if _type:
                filters.append({
                    'field': 'type',
                    'operator': 'in',
                    'value': _type
                })
            if sub_type:
                filters.append({
                    'field': 'sub_type',
                    'operator': 'in',
                    'value': sub_type
                })
            if timestamp_gte:
                filters.append({
                    'field': 'timestamp',
                    'operator': 'gte',
                    'value': timestamp_gte
                })
            if timestamp_lte:
                filters.append({
                    'field': 'timestamp',
                    'operator': 'lte',
                    'value': timestamp_lte
                })

            if filters:
                request_data['filters'] = filters

            if search_from > 0:
                request_data['search_from'] = search_from

            if search_to:
                request_data['search_to'] = search_to

            if sort_by:
                request_data['sort'] = {
                    'field': sort_by,
                    'keyword': sort_order
                }

            reply = self._http_request(
                method='POST',
                url_suffix='/audits/management_logs/',
                json_data={'request_data': request_data},
                timeout=self.timeout
            )

            return reply.get('reply').get('data', [])

        def get_audit_agent_reports(self, endpoint_ids, endpoint_names, result, _type, sub_type, search_from, search_to,
                                    timestamp_gte, timestamp_lte, sort_by, sort_order):
            request_data: Dict[str, Any] = {}
            filters = []
            if endpoint_ids:
                filters.append({
                    'field': 'endpoint_id',
                    'operator': 'in',
                    'value': endpoint_ids
                })
            if endpoint_names:
                filters.append({
                    'field': 'endpoint_name',
                    'operator': 'in',
                    'value': endpoint_names
                })
            if result:
                filters.append({
                    'field': 'result',
                    'operator': 'in',
                    'value': result
                })
            if _type:
                filters.append({
                    'field': 'type',
                    'operator': 'in',
                    'value': _type
                })
            if sub_type:
                filters.append({
                    'field': 'sub_type',
                    'operator': 'in',
                    'value': sub_type
                })
            if timestamp_gte:
                filters.append({
                    'field': 'timestamp',
                    'operator': 'gte',
                    'value': timestamp_gte
                })
            if timestamp_lte:
                filters.append({
                    'field': 'timestamp',
                    'operator': 'lte',
                    'value': timestamp_lte
                })

            if filters:
                request_data['filters'] = filters

            if search_from > 0:
                request_data['search_from'] = search_from

            if search_to:
                request_data['search_to'] = search_to

            if sort_by:
                request_data['sort'] = {
                    'field': sort_by,
                    'keyword': sort_order
                }

            reply = self._http_request(
                method='POST',
                url_suffix='/audits/agents_reports/',
                json_data={'request_data': request_data},
                timeout=self.timeout
            )

            return reply.get('reply').get('data', [])

        def blocklist_files(self, hash_list, comment=None, incident_id=None, detailed_response=False):
            request_data: Dict[str, Any] = {"hash_list": hash_list}
            if comment:
                request_data["comment"] = comment
            if incident_id:
                request_data['incident_id'] = incident_id
            if detailed_response:
                request_data['detailed_response'] = detailed_response

            self._headers['content-type'] = 'application/json'
            reply = self._http_request(
                method='POST',
                url_suffix='/hash_exceptions/blocklist/',
                json_data={'request_data': request_data},
                ok_codes=(200, 201, 500),
                timeout=self.timeout
            )
            return reply.get('reply')

        def remove_blocklist_files(self, hash_list, comment=None, incident_id=None):
            request_data: Dict[str, Any] = {"hash_list": hash_list}
            if comment:
                request_data["comment"] = comment
            if incident_id:
                request_data['incident_id'] = incident_id

            self._headers['content-type'] = 'application/json'
            reply = self._http_request(
                method='POST',
                url_suffix='/hash_exceptions/blocklist/remove/',
                json_data={'request_data': request_data},
                ok_codes=(200, 201, 500),
                timeout=self.timeout
            )
            res = reply.get('reply')
            if isinstance(res, dict) and res.get('err_code') == 500:
                raise DemistoException(f"{res.get('err_msg')}\nThe requested hash might not be in the blocklist.")
            return res

        def allowlist_files(self, hash_list, comment=None, incident_id=None, detailed_response=False):
            request_data: Dict[str, Any] = {"hash_list": hash_list}
            if comment:
                request_data["comment"] = comment
            if incident_id:
                request_data['incident_id'] = incident_id
            if detailed_response:
                request_data['detailed_response'] = detailed_response

            self._headers['content-type'] = 'application/json'
            reply = self._http_request(
                method='POST',
                url_suffix='/hash_exceptions/allowlist/',
                json_data={'request_data': request_data},
                ok_codes=(201, 200),
                timeout=self.timeout
            )
            return reply.get('reply')

        def remove_allowlist_files(self, hash_list, comment=None, incident_id=None):
            request_data: Dict[str, Any] = {"hash_list": hash_list}
            if comment:
                request_data["comment"] = comment
            if incident_id:
                request_data['incident_id'] = incident_id

            self._headers['content-type'] = 'application/json'
            reply = self._http_request(
                method='POST',
                url_suffix='/hash_exceptions/allowlist/remove/',
                json_data={'request_data': request_data},
                timeout=self.timeout
            )
            return reply.get('reply')

        def quarantine_files(self, endpoint_id_list, file_path, file_hash, incident_id):
            request_data: Dict[str, Any] = {}
            filters = []
            if endpoint_id_list:
                filters.append({
                    'field': 'endpoint_id_list',
                    'operator': 'in',
                    'value': endpoint_id_list
                })

            if filters:
                request_data['filters'] = filters

            request_data['file_path'] = file_path
            request_data['file_hash'] = file_hash
            if incident_id:
                request_data['incident_id'] = incident_id

            self._headers['content-type'] = 'application/json'
            reply = self._http_request(
                method='POST',
                url_suffix='/endpoints/quarantine/',
                json_data={'request_data': request_data},
                ok_codes=(200, 201),
                timeout=self.timeout
            )

            return reply.get('reply')

        def restore_file(self, file_hash, endpoint_id=None, incident_id=None):
            request_data: Dict[str, Any] = {'file_hash': file_hash}
            if incident_id:
                request_data['incident_id'] = incident_id
            if endpoint_id:
                request_data['endpoint_id'] = endpoint_id

            self._headers['content-type'] = 'application/json'
            reply = self._http_request(
                method='POST',
                url_suffix='/endpoints/restore/',
                json_data={'request_data': request_data},
                ok_codes=(200, 201),
                timeout=self.timeout
            )
            return reply.get('reply')

        def endpoint_scan(self, url_suffix, endpoint_id_list=None, dist_name=None, gte_first_seen=None, gte_last_seen=None,
                          lte_first_seen=None,
                          lte_last_seen=None, ip_list=None, group_name=None, platform=None, alias=None, isolate=None,
                          hostname: list = None, incident_id=None):
            request_data: Dict[str, Any] = {}
            filters = []

            if endpoint_id_list:
                filters.append({
                    'field': 'endpoint_id_list',
                    'operator': 'in',
                    'value': endpoint_id_list
                })

            if dist_name:
                filters.append({
                    'field': 'dist_name',
                    'operator': 'in',
                    'value': dist_name
                })

            if ip_list:
                filters.append({
                    'field': 'ip_list',
                    'operator': 'in',
                    'value': ip_list
                })

            if group_name:
                filters.append({
                    'field': 'group_name',
                    'operator': 'in',
                    'value': group_name
                })

            if platform:
                filters.append({
                    'field': 'platform',
                    'operator': 'in',
                    'value': platform
                })

            if alias:
                filters.append({
                    'field': 'alias',
                    'operator': 'in',
                    'value': alias
                })

            if isolate:
                filters.append({
                    'field': 'isolate',
                    'operator': 'in',
                    'value': [isolate]
                })

            if hostname:
                filters.append({
                    'field': 'hostname',
                    'operator': 'in',
                    'value': hostname
                })

            if gte_first_seen:
                filters.append({
                    'field': 'first_seen',
                    'operator': 'gte',
                    'value': gte_first_seen
                })

            if lte_first_seen:
                filters.append({
                    'field': 'first_seen',
                    'operator': 'lte',
                    'value': lte_first_seen
                })

            if gte_last_seen:
                filters.append({
                    'field': 'last_seen',
                    'operator': 'gte',
                    'value': gte_last_seen
                })

            if lte_last_seen:
                filters.append({
                    'field': 'last_seen',
                    'operator': 'lte',
                    'value': lte_last_seen
                })

            if filters:
                request_data['filters'] = filters
            else:
                request_data['filters'] = 'all'
            if incident_id:
                request_data['incident_id'] = incident_id

            self._headers['content-type'] = 'application/json'
            reply = self._http_request(
                method='POST',
                url_suffix=url_suffix,
                json_data={'request_data': request_data},
                ok_codes=(200, 201),
                timeout=self.timeout
            )
            return reply.get('reply')

        def get_quarantine_status(self, file_path, file_hash, endpoint_id):
            request_data: Dict[str, Any] = {'files': [{
                'endpoint_id': endpoint_id,
                'file_path': file_path,
                'file_hash': file_hash
            }]}
            self._headers['content-type'] = 'application/json'
            reply = self._http_request(
                method='POST',
                url_suffix='/quarantine/status/',
                json_data={'request_data': request_data},
                timeout=self.timeout
            )

            reply_content = reply.get('reply')
            if isinstance(reply_content, list):
                return reply_content[0]
            else:
                raise TypeError(f'got unexpected response from api: {reply_content}\n')

        def delete_endpoints(self, endpoint_ids: list):
            request_data: Dict[str, Any] = {
                'filters': [
                    {
                        'field': 'endpoint_id_list',
                        'operator': 'in',
                        'value': endpoint_ids
                    }
                ]
            }

            self._http_request(
                method='POST',
                url_suffix='/endpoints/delete/',
                json_data={'request_data': request_data},
                timeout=self.timeout
            )

        def get_policy(self, endpoint_id) -> Dict[str, Any]:
            request_data: Dict[str, Any] = {
                'endpoint_id': endpoint_id
            }

            reply = self._http_request(
                method='POST',
                url_suffix='/endpoints/get_policy/',
                json_data={'request_data': request_data},
                timeout=self.timeout
            )

            return reply.get('reply')

        def get_original_alerts(self, alert_id_list):
            res = self._http_request(
                method='POST',
                url_suffix='/alerts/get_original_alerts/',
                json_data={
                    'request_data': {
                        'alert_id_list': alert_id_list,
                    }
                },
            )
            return res.get('reply', {})

        def get_alerts_by_filter_data(self, request_data: dict):
            res = self._http_request(
                method='POST',
                url_suffix='/alerts/get_alerts_by_filter_data/',
                json_data={
                    'request_data': request_data
                },
            )
            return res.get('reply', {})

        def get_endpoint_device_control_violations(self, endpoint_ids: list, type_of_violation, timestamp_gte: int,
                                                   timestamp_lte: int,
                                                   ip_list: list, vendor: list, vendor_id: list, product: list,
                                                   product_id: list,
                                                   serial: list,
                                                   hostname: list, violation_ids: list, username: list) -> Dict[str, Any]:
            arg_list = {'type': type_of_violation,
                        'endpoint_id_list': endpoint_ids,
                        'ip_list': ip_list,
                        'vendor': vendor,
                        'vendor_id': vendor_id,
                        'product': product,
                        'product_id': product_id,
                        'serial': serial,
                        'hostname': hostname,
                        'violation_id_list': violation_ids,
                        'username': username
                        }

            filters: list = [{
                'field': arg_key,
                'operator': 'in',
                'value': arg_val
            } for arg_key, arg_val in arg_list.items() if arg_val and arg_val[0]]

            if timestamp_lte:
                filters.append({
                    'field': 'timestamp',
                    'operator': 'lte',
                    'value': timestamp_lte
                })
            if timestamp_gte:
                filters.append({
                    'field': 'timestamp',
                    'operator': 'gte',
                    'value': timestamp_gte})

            request_data: Dict[str, Any] = {
                'filters': filters
            }

            reply = self._http_request(
                method='POST',
                url_suffix='/device_control/get_violations/',
                json_data={'request_data': request_data},
                timeout=self.timeout
            )

            return reply.get('reply')

        def generate_files_dict_with_specific_os(self, windows: list, linux: list, macos: list) -> Dict[str, list]:
            if not windows and not linux and not macos:
                raise ValueError('You should enter at least one path.')

            files = {}
            if windows:
                files['windows'] = windows
            if linux:
                files['linux'] = linux
            if macos:
                files['macos'] = macos

            return files

        def retrieve_file(self, endpoint_id_list: list, windows: list, linux: list, macos: list, file_path_list: list,
                          incident_id: Optional[int]) -> Dict[str, Any]:
            # there are 2 options, either the paths are given with separation to a specific os or without
            # it using generic_file_path
            if file_path_list:
                files = self.generate_files_dict(
                    endpoint_id_list=endpoint_id_list,
                    file_path_list=file_path_list
                )
            else:
                files = self.generate_files_dict_with_specific_os(windows=windows, linux=linux, macos=macos)

            request_data: Dict[str, Any] = {
                'filters': [
                    {
                        'field': 'endpoint_id_list',
                        'operator': 'in',
                        'value': endpoint_id_list
                    }
                ],
                'files': files,
            }
            if incident_id:
                request_data['incident_id'] = incident_id

            reply = self._http_request(
                method='POST',
                url_suffix='/endpoints/file_retrieval/',
                json_data={'request_data': request_data},
                timeout=self.timeout
            )
            demisto.debug(f"retrieve_file = {reply}")

            return reply.get('reply')

        def generate_files_dict(self, endpoint_id_list: list, file_path_list: list) -> Dict[str, Any]:
            files: dict = {"windows": [], "linux": [], "macos": []}

            if len(endpoint_id_list) != len(file_path_list):
                raise ValueError("The endpoint_ids list must be in the same length as the generic_file_path")

            for endpoint_id, file_path in zip(endpoint_id_list, file_path_list):
                endpoints = self.get_endpoints(endpoint_id_list=[endpoint_id])

                if len(endpoints) == 0 or not isinstance(endpoints, list):
                    raise ValueError(f'Error: Endpoint {endpoint_id} was not found')

                endpoint = endpoints[0]
                endpoint_os_type = endpoint.get('os_type')

                if 'windows' in endpoint_os_type.lower():
                    files['windows'].append(file_path)
                elif 'linux' in endpoint_os_type.lower():
                    files['linux'].append(file_path)
                elif 'mac' in endpoint_os_type.lower():
                    files['macos'].append(file_path)

            # remove keys with no value
            files = {k: v for k, v in files.items() if v}

            return files

        def retrieve_file_details(self, action_id: int) -> Dict[str, Any]:
            request_data: Dict[str, Any] = {
                'group_action_id': action_id
            }

            reply = self._http_request(
                method='POST',
                url_suffix='/actions/file_retrieval_details/',
                json_data={'request_data': request_data},
                timeout=self.timeout
            )
            demisto.debug(f"retrieve_file_details = {reply}")

            return reply.get('reply').get('data')

        @logger
        def get_scripts(self, name: list, description: list, created_by: list, windows_supported,
                        linux_supported, macos_supported, is_high_risk) -> Dict[str, Any]:

            arg_list = {'name': name,
                        'description': description,
                        'created_by': created_by,
                        'windows_supported': windows_supported,
                        'linux_supported': linux_supported,
                        'macos_supported': macos_supported,
                        'is_high_risk': is_high_risk
                        }

            filters: list = [{
                'field': arg_key,
                'operator': 'in',
                'value': arg_val
            } for arg_key, arg_val in arg_list.items() if arg_val and arg_val[0]]

            request_data: Dict[str, Any] = {
                'filters': filters
            }

            reply = self._http_request(
                method='POST',
                url_suffix='/scripts/get_scripts/',
                json_data={'request_data': request_data},
                timeout=self.timeout
            )

            return reply.get('reply')

        def get_script_metadata(self, script_uid) -> Dict[str, Any]:
            request_data: Dict[str, Any] = {
                'script_uid': script_uid
            }

            reply = self._http_request(
                method='POST',
                url_suffix='/scripts/get_script_metadata/',
                json_data={'request_data': request_data},
                timeout=self.timeout
            )

            return reply.get('reply')

        def get_script_code(self, script_uid) -> Dict[str, Any]:
            request_data: Dict[str, Any] = {
                'script_uid': script_uid
            }

            reply = self._http_request(
                method='POST',
                url_suffix='/scripts/get_script_code/',
                json_data={'request_data': request_data},
                timeout=self.timeout
            )

            return reply.get('reply')

        @logger
        def run_script(self,
                       script_uid: str, endpoint_ids: list, parameters: Dict[str, Any], timeout: int, incident_id: Optional[int],
                       ) -> Dict[str, Any]:
            filters: list = [{
                'field': 'endpoint_id_list',
                'operator': 'in',
                'value': endpoint_ids
            }]
            request_data: Dict[str, Any] = {'script_uid': script_uid, 'timeout': timeout, 'filters': filters,
                                            'parameters_values': parameters}
            if incident_id:
                request_data['incident_id'] = incident_id

            return self._http_request(
                method='POST',
                url_suffix='/scripts/run_script/',
                json_data={'request_data': request_data},
                timeout=self.timeout
            )

        @logger
        def run_snippet_code_script(self, snippet_code: str, endpoint_ids: list,
                                    incident_id: Optional[int] = None) -> Dict[str, Any]:
            request_data: Dict[str, Any] = {
                'filters': [{
                    'field': 'endpoint_id_list',
                    'operator': 'in',
                    'value': endpoint_ids
                }],
                'snippet_code': snippet_code,
            }

            if incident_id:
                request_data['incident_id'] = incident_id

            return self._http_request(
                method='POST',
                url_suffix='/scripts/run_snippet_code_script',
                json_data={
                    'request_data': request_data
                },
                timeout=self.timeout,
            )

        @logger
        def get_script_execution_status(self, action_id: str) -> Dict[str, Any]:
            request_data: Dict[str, Any] = {
                'action_id': action_id
            }

            return self._http_request(
                method='POST',
                url_suffix='/scripts/get_script_execution_status/',
                json_data={'request_data': request_data},
                timeout=self.timeout
            )

        @logger
        def get_script_execution_results(self, action_id: str) -> Dict[str, Any]:
            return self._http_request(
                method='POST',
                url_suffix='/scripts/get_script_execution_results',
                json_data={
                    'request_data': {
                        'action_id': action_id
                    }
                },
                timeout=self.timeout,
            )

        @logger
        def get_script_execution_result_files(self, action_id: str, endpoint_id: str) -> Dict[str, Any]:
            response = self._http_request(
                method='POST',
                url_suffix='/scripts/get_script_execution_results_files',
                json_data={
                    'request_data': {
                        'action_id': action_id,
                        'endpoint_id': endpoint_id,
                    }
                },
                timeout=self.timeout,
            )
            link = response.get('reply', {}).get('DATA')
            demisto.debug(f"From the previous API call, this link was returned {link=}")
            # If the link is None, the API call will result in a 'Connection Timeout Error', so we raise an exception
            if not link:
                raise DemistoException(f'Failed getting response files for {action_id=}, {endpoint_id=}')
            return self._http_request(
                method='GET',
                url_suffix=re.findall('download.*', link)[0],
                resp_type='response',
            )

        def action_status_get(self, action_id) -> Dict[str, Any]:
            request_data: Dict[str, Any] = {
                'group_action_id': action_id,
            }

            reply = self._http_request(
                method='POST',
                url_suffix='/actions/get_action_status/',
                json_data={'request_data': request_data},
                timeout=self.timeout
            )
            demisto.debug(f"action_status_get = {reply}")

            return reply.get('reply').get('data')

        @logger
        def get_file(self, file_link):
            reply = self._http_request(
                method='GET',
                full_url=file_link,
                timeout=self.timeout,
                resp_type='content'
            )
            return reply

        def get_file_by_url_suffix(self, url_suffix):
            reply = self._http_request(
                method='GET',
                url_suffix=url_suffix,
                timeout=self.timeout,
                resp_type='content'
            )
            return reply

        @logger
        def get_endpoints_by_status(self, status, last_seen_gte=None, last_seen_lte=None):
            filters = []

            if not isinstance(status, list):
                status = [status]

            filters.append({
                'field': 'endpoint_status',
                'operator': 'IN',
                'value': status
            })

            if last_seen_gte:
                filters.append({
                    'field': 'last_seen',
                    'operator': 'gte',
                    'value': last_seen_gte
                })

            if last_seen_lte:
                filters.append({
                    'field': 'last_seen',
                    'operator': 'lte',
                    'value': last_seen_lte
                })

            reply = self._http_request(
                method='POST',
                url_suffix='/endpoints/get_endpoint/',
                json_data={'request_data': {'filters': filters}},
                timeout=self.timeout
            )

            endpoints_count = reply.get('reply').get('total_count', 0)
            return endpoints_count, reply

        def add_exclusion(self, indicator, name, status="ENABLED", comment=None):
            request_data: Dict[str, Any] = {
                'indicator': indicator,
                'status': status,
                'name': name
            }

            res = self._http_request(
                method='POST',
                url_suffix='/alerts_exclusion/add/',
                json_data={'request_data': request_data},
                timeout=self.timeout
            )
            return res.get("reply")

        def delete_exclusion(self, alert_exclusion_id: int):
            request_data: Dict[str, Any] = {
                'alert_exclusion_id': alert_exclusion_id,
            }

            res = self._http_request(
                method='POST',
                url_suffix='/alerts_exclusion/delete/',
                json_data={'request_data': request_data},
                timeout=self.timeout
            )
            return res.get("reply")

        def get_exclusion(self, limit, tenant_id=None, filter=None):
            request_data: Dict[str, Any] = {}
            if tenant_id:
                request_data['tenant_id'] = tenant_id
            if filter:
                request_data['filter_data'] = filter
            res = self._http_request(
                method='POST',
                url_suffix='/alerts_exclusion/',
                json_data={'request_data': request_data},
                timeout=self.timeout
            )
            reply = res.get("reply")
            return reply[:limit]

        def add_tag_endpoint(self, endpoint_ids, tag, args):
            """
            Add tag to an endpoint
            """
            return self.call_tag_endpoint(endpoint_ids=endpoint_ids, tag=tag, args=args, url_suffix='/tags/agents/assign/')

        def remove_tag_endpoint(self, endpoint_ids, tag, args):
            """
            Remove tag from an endpoint.
            """
            return self.call_tag_endpoint(endpoint_ids=endpoint_ids, tag=tag, args=args, url_suffix='/tags/agents/remove/')

        def call_tag_endpoint(self, endpoint_ids, tag, args, url_suffix):
            """
            Add or remove a tag from an endpoint.
            """
            filters = args_to_request_filters(args)

            body_request = {
                'context': {
                    'lcaas_id': endpoint_ids,
                },
                'request_data': {
                    'filters': filters,
                    'tag': tag
                },
            }

            return self._http_request(
                method='POST',
                url_suffix=url_suffix,
                json_data=body_request,
                timeout=self.timeout
            )

        def list_users(self) -> dict[str, list[dict[str, Any]]]:
            return self._http_request(
                method='POST',
                url_suffix='/rbac/get_users/',
                json_data={"request_data": {}},
            )

        def risk_score_user_or_host(self, user_or_host_id: str) -> dict[str, dict[str, Any]]:
            return self._http_request(
                method='POST',
                url_suffix='/get_risk_score/',
                json_data={"request_data": {"id": user_or_host_id}},
            )

        def list_risky_users(self) -> dict[str, list[dict[str, Any]]]:
            return self._http_request(
                method='POST',
                url_suffix='/get_risky_users/',
            )

        def list_risky_hosts(self) -> dict[str, list[dict[str, Any]]]:
            return self._http_request(
                method='POST',
                url_suffix='/get_risky_hosts/',
            )

        def list_user_groups(self, group_names: list[str]) -> dict[str, list[dict[str, Any]]]:
            return self._http_request(
                method='POST',
                url_suffix='/rbac/get_user_group/',
                json_data={"request_data": {"group_names": group_names}},
            )

        def list_roles(self, role_names: list[str]) -> dict[str, list[list[dict[str, Any]]]]:
            return self._http_request(
                method='POST',
                url_suffix='/rbac/get_roles/',
                json_data={"request_data": {"role_names": role_names}},
            )

        def set_user_role(self, user_emails: list[str], role_name: str) -> dict[str, dict[str, str]]:
            return self._http_request(
                method='POST',
                url_suffix='/rbac/set_user_role/',
                json_data={"request_data": {
                    "user_emails": user_emails,
                    "role_name": role_name
                }},
            )

        def remove_user_role(self, user_emails: list[str]) -> dict[str, dict[str, str]]:
            return self._http_request(
                method='POST',
                url_suffix='/rbac/set_user_role/',
                json_data={"request_data": {
                    "user_emails": user_emails,
                    "role_name": ""
                }},
            )


    class AlertFilterArg:
        def __init__(self, search_field: str, search_type: Optional[str], arg_type: str, option_mapper: dict = None):
            self.search_field = search_field
            self.search_type = search_type
            self.arg_type = arg_type
            self.option_mapper = option_mapper


    def catch_and_exit_gracefully(e):
        """

        Args:
            e: DemistoException caught while running a command.

        Returns:
            CommandResult if the error is internal XDR error, else, the exception.
        """
        if e.res.status_code == 500 and 'no endpoint was found for creating the requested action' in str(e).lower():
            return CommandResults(readable_output="The operation executed is not supported on the given machine.")
        else:
            raise e


    def init_filter_args_options():
        array = 'array'
        dropdown = 'dropdown'
        time_frame = 'time_frame'

        return {
            'alert_id': AlertFilterArg('internal_id', 'EQ', array),
            'severity': AlertFilterArg('severity', 'EQ', dropdown, {
                'low': 'SEV_020_LOW',
                'medium': 'SEV_030_MEDIUM',
                'high': 'SEV_040_HIGH'
            }),
            'starred': AlertFilterArg('starred', 'EQ', dropdown, {
                'true': True,
                'False': False,
            }),
            'Identity_type': AlertFilterArg('Identity_type', 'EQ', dropdown),
            'alert_action_status': AlertFilterArg('alert_action_status', 'EQ', dropdown, ALERT_STATUS_TYPES_REVERSE_DICT),
            'agent_id': AlertFilterArg('agent_id', 'EQ', array),
            'action_external_hostname': AlertFilterArg('action_external_hostname', 'CONTAINS', array),
            'rule_id': AlertFilterArg('matching_service_rule_id', 'EQ', array),
            'rule_name': AlertFilterArg('fw_rule', 'EQ', array),
            'alert_name': AlertFilterArg('alert_name', 'CONTAINS', array),
            'alert_source': AlertFilterArg('alert_source', 'CONTAINS', array),
            'time_frame': AlertFilterArg('source_insert_ts', None, time_frame),
            'user_name': AlertFilterArg('actor_effective_username', 'CONTAINS', array),
            'actor_process_image_name': AlertFilterArg('actor_process_image_name', 'CONTAINS', array),
            'causality_actor_process_image_command_line': AlertFilterArg('causality_actor_process_command_line', 'EQ',
                                                                         array),
            'actor_process_image_command_line': AlertFilterArg('actor_process_command_line', 'EQ', array),
            'action_process_image_command_line': AlertFilterArg('action_process_image_command_line', 'EQ', array),
            'actor_process_image_sha256': AlertFilterArg('actor_process_image_sha256', 'EQ', array),
            'causality_actor_process_image_sha256': AlertFilterArg('causality_actor_process_image_sha256', 'EQ', array),
            'action_process_image_sha256': AlertFilterArg('action_process_image_sha256', 'EQ', array),
            'action_file_image_sha256': AlertFilterArg('action_file_sha256', 'EQ', array),
            'action_registry_name': AlertFilterArg('action_registry_key_name', 'EQ', array),
            'action_registry_key_data': AlertFilterArg('action_registry_data', 'CONTAINS', array),
            'host_ip': AlertFilterArg('agent_ip_addresses', 'IPLIST_MATCH', array),
            'action_local_ip': AlertFilterArg('action_local_ip', 'IP_MATCH', array),
            'action_remote_ip': AlertFilterArg('action_remote_ip', 'IP_MATCH', array),
            'action_local_port': AlertFilterArg('action_local_port', 'EQ', array),
            'action_remote_port': AlertFilterArg('action_remote_port', 'EQ', array),
            'dst_action_external_hostname': AlertFilterArg('dst_action_external_hostname', 'CONTAINS', array),
            'mitre_technique_id_and_name': AlertFilterArg('mitre_technique_id_and_name', 'CONTAINS', array),
        }


    def run_polling_command(client: CoreClient,
                            args: dict,
                            cmd: str,
                            command_function: Callable,
                            command_decision_field: str,
                            results_function: Callable,
                            polling_field: str,
                            polling_value: List,
                            stop_polling: bool = False) -> CommandResults:
        """
        Arguments:
        args: args
        cmd: the scheduled command's name (as appears in the yml file) to run in the following polling.
        command_function: the pythonic function that executes the command.
        command_decision_field: the field that is retrieved from the command_function's response that indicates
        the command_function status.
        results_function: the pythonic result function which we want to poll on.
        polling_field: the field that is retrieved from the results_function's response and indicates the polling status.
        polling_value: list of values of the polling_field we want to check. The list can contain values to stop or
        continue polling on, not both.
        stop_polling: True - polling_value stops the polling. False - polling_value does not stop the polling.

        Return:
        command_results(CommandResults)
        """

        ScheduledCommand.raise_error_if_not_supported()
        interval_in_secs = int(args.get('interval_in_seconds', 60))
        timeout_in_seconds = int(args.get('timeout_in_seconds', 600))
        if command_decision_field not in args:
            # create new command run
            command_results = command_function(client, args)
            outputs = command_results.raw_response
            if outputs and not isinstance(outputs, list):
                outputs = [outputs]
            command_decision_values = [o.get(command_decision_field) for o in outputs] if outputs else []  # type: ignore
            if outputs and command_decision_values:
                polling_args = {
                    command_decision_field: command_decision_values,
                    'interval_in_seconds': interval_in_secs,
                    **args
                }
                scheduled_command = ScheduledCommand(
                    command=cmd,
                    next_run_in_seconds=interval_in_secs,
                    args=polling_args,
                    timeout_in_seconds=timeout_in_seconds)
                if isinstance(command_results, list):
                    command_results = command_results[0]
                command_results.scheduled_command = scheduled_command
                return command_results
            else:
                if command_results.readable_output:
                    demisto.error(f"{command_results.readable_output}")
                else:
                    demisto.error(f"Command {command_function} didn't succeeded, returned {outputs}")
                return command_results
        # get polling result
        command_results = results_function(client, args)
        outputs_result_func = command_results.raw_response
        if not outputs_result_func:
            return_error(f"Command {cmd} didn't succeeded, received empty response.")
        result = outputs_result_func.get(polling_field) if isinstance(outputs_result_func, dict) else \
            outputs_result_func[0].get(polling_field)
        cond = result not in polling_value if stop_polling else result in polling_value
        if cond:
            # schedule next poll
            polling_args = {
                'interval_in_seconds': interval_in_secs,
                **args
            }
            scheduled_command = ScheduledCommand(
                command=cmd,
                next_run_in_seconds=interval_in_secs,
                args=polling_args,
                timeout_in_seconds=timeout_in_seconds)

            # result with scheduled_command only - no update to the war room
            command_results = CommandResults(scheduled_command=scheduled_command, raw_response=outputs_result_func)
        return command_results


    def convert_time_to_epoch(time_to_convert: str) -> int:
        """
        Converts time in epoch UNIX timestamp format or date in '%Y-%m-%dT%H:%M:%S' format to timestamp format.
        :param time_to_convert:
        :return: converted_timestamp
        """
        try:
            timestamp = int(time_to_convert)
            return timestamp
        except Exception:
            try:
                return date_to_timestamp(time_to_convert)
            except Exception:
                raise DemistoException('the time_frame format is invalid. Valid formats: %Y-%m-%dT%H:%M:%S or '
                                       'epoch UNIX timestamp (example: 1651505482)')


    def create_filter_from_args(args: dict) -> dict:
        """
        Builds an XDR format filter dict for the xdr-get-alert command.
        :param args: The arguments provided by the user
        :return: The filter format built from args
        """
        valid_args = init_filter_args_options()
        and_operator_list = []
        start_time = args.pop('start_time', None)
        end_time = args.pop('end_time', None)

        if (start_time or end_time) and ('time_frame' not in args):
            raise DemistoException('Please choose "custom" under time_frame argument when using start_time and end_time '
                                   'arguments')

        for arg_name, arg_value in args.items():
            if arg_name not in valid_args:
                raise DemistoException(f'Argument {arg_name} is not valid.')
            arg_properties = valid_args.get(arg_name)

            # handle time frame
            if arg_name == 'time_frame':
                # custom time frame
                if arg_value == 'custom':
                    if not start_time or not end_time:
                        raise DemistoException(
                            'Please provide start_time and end_time arguments when using time_frame as custom.')
                    start_time = convert_time_to_epoch(start_time)
                    end_time = convert_time_to_epoch(end_time)
                    search_type = 'RANGE'
                    search_value: Union[dict, Optional[str]] = {
                        'from': start_time,
                        'to': end_time
                    }

                # relative time frame
                else:
                    search_value = None
                    search_type = 'RELATIVE_TIMESTAMP'
                    relative_date = dateparser.parse(arg_value)
                    if relative_date:
                        delta_in_milliseconds = int((datetime.now() - relative_date).total_seconds() * 1000)
                        search_value = str(delta_in_milliseconds)

                and_operator_list.append({
                    'SEARCH_FIELD': arg_properties.search_field,
                    'SEARCH_TYPE': search_type,
                    'SEARCH_VALUE': search_value
                })

            # handle array args, array elements should be seperated with 'or' op
            elif arg_properties.arg_type == 'array':
                or_operator_list = []
                arg_list = argToList(arg_value)
                for arg_item in arg_list:
                    or_operator_list.append({
                        'SEARCH_FIELD': arg_properties.search_field,
                        'SEARCH_TYPE': arg_properties.search_type,
                        'SEARCH_VALUE': arg_item
                    })
                and_operator_list.append({'OR': or_operator_list})
            else:
                and_operator_list.append({
                    'SEARCH_FIELD': arg_properties.search_field,
                    'SEARCH_TYPE': arg_properties.search_type,
                    'SEARCH_VALUE': arg_properties.option_mapper.get(arg_value) if arg_properties.option_mapper else arg_value
                })

        return {'AND': and_operator_list}


    def arg_to_int(arg, arg_name: str, required: bool = False):
        if arg is None:
            if required is True:
                raise ValueError(f'Missing "{arg_name}"')
            return None
        if isinstance(arg, str):
            if arg.isdigit():
                return int(arg)
            raise ValueError(f'Invalid number: "{arg_name}"="{arg}"')
        if isinstance(arg, int):
            return arg
        return ValueError(f'Invalid number: "{arg_name}"')


    def validate_args_scan_commands(args):
        endpoint_id_list = argToList(args.get('endpoint_id_list'))
        dist_name = argToList(args.get('dist_name'))
        gte_first_seen = args.get('gte_first_seen')
        gte_last_seen = args.get('gte_last_seen')
        lte_first_seen = args.get('lte_first_seen')
        lte_last_seen = args.get('lte_last_seen')
        ip_list = argToList(args.get('ip_list'))
        group_name = argToList(args.get('group_name'))
        platform = argToList(args.get('platform'))
        alias = argToList(args.get('alias'))
        hostname = argToList(args.get('hostname'))
        all_ = argToBoolean(args.get('all', 'false'))

        # to prevent the case where an empty filtered command will trigger by default a scan on all the endpoints.
        err_msg = 'To scan/abort scan all the endpoints run this command with the \'all\' argument as True ' \
                  'and without any other filters. This may cause performance issues.\n' \
                  'To scan/abort scan some of the endpoints, please use the filter arguments.'
        if all_:
            if (endpoint_id_list or dist_name or gte_first_seen or gte_last_seen or lte_first_seen or lte_last_seen
                    or ip_list or group_name or platform or alias or hostname):
                raise Exception(err_msg)
        elif not endpoint_id_list and not dist_name and not gte_first_seen and not gte_last_seen \
                and not lte_first_seen and not lte_last_seen and not ip_list and not group_name and not platform \
                and not alias and not hostname:
            raise Exception(err_msg)


    def endpoint_scan_command(client: CoreClient, args) -> CommandResults:
        endpoint_id_list = argToList(args.get('endpoint_id_list'))
        dist_name = argToList(args.get('dist_name'))
        gte_first_seen = args.get('gte_first_seen')
        gte_last_seen = args.get('gte_last_seen')
        lte_first_seen = args.get('lte_first_seen')
        lte_last_seen = args.get('lte_last_seen')
        ip_list = argToList(args.get('ip_list'))
        group_name = argToList(args.get('group_name'))
        platform = argToList(args.get('platform'))
        alias = argToList(args.get('alias'))
        isolate = args.get('isolate')
        hostname = argToList(args.get('hostname'))
        incident_id = arg_to_number(args.get('incident_id'))

        validate_args_scan_commands(args)

        reply = client.endpoint_scan(
            url_suffix='/endpoints/scan/',
            endpoint_id_list=argToList(endpoint_id_list),
            dist_name=dist_name,
            gte_first_seen=gte_first_seen,
            gte_last_seen=gte_last_seen,
            lte_first_seen=lte_first_seen,
            lte_last_seen=lte_last_seen,
            ip_list=ip_list,
            group_name=group_name,
            platform=platform,
            alias=alias,
            isolate=isolate,
            hostname=hostname,
            incident_id=incident_id
        )

        action_id = reply.get("action_id")

        context = {
            "actionId": action_id,
            "aborted": False
        }

        return CommandResults(
            readable_output=tableToMarkdown('Endpoint scan', {'Action Id': action_id}, ['Action Id']),
            outputs={f'{args.get("integration_context_brand", "CoreApiModule")}.endpointScan(val.actionId == obj.actionId)': context},
            raw_response=reply
        )


    def action_status_get_command(client: CoreClient, args) -> CommandResults:
        action_id_list = argToList(args.get('action_id', ''))
        action_id_list = [arg_to_int(arg=item, arg_name=str(item)) for item in action_id_list]

        result = []
        for action_id in action_id_list:
            data = client.action_status_get(action_id)

            for endpoint_id, status in data.items():
                result.append({
                    'action_id': action_id,
                    'endpoint_id': endpoint_id,
                    'status': status
                })

        return CommandResults(
            readable_output=tableToMarkdown(name='Get Action Status', t=result, removeNull=True),
            outputs_prefix=f'{args.get("integration_context_brand", "CoreApiModule")}.'
                           f'GetActionStatus(val.action_id == obj.action_id)',
            outputs=result,
            raw_response=result
        )


    def isolate_endpoint_command(client: CoreClient, args) -> CommandResults:
        endpoint_id = args.get('endpoint_id')
        disconnected_should_return_error = not argToBoolean(args.get('suppress_disconnected_endpoint_error', False))
        incident_id = arg_to_number(args.get('incident_id'))
        endpoint = client.get_endpoints(endpoint_id_list=[endpoint_id])
        if len(endpoint) == 0:
            raise ValueError(f'Error: Endpoint {endpoint_id} was not found')

        endpoint = endpoint[0]
        endpoint_status = endpoint.get('endpoint_status')
        is_isolated = endpoint.get('is_isolated')
        if is_isolated == 'AGENT_ISOLATED':
            return CommandResults(
                readable_output=f'Endpoint {endpoint_id} already isolated.'
            )
        if is_isolated == 'AGENT_PENDING_ISOLATION':
            return CommandResults(
                readable_output=f'Endpoint {endpoint_id} pending isolation.'
            )
        if endpoint_status == 'UNINSTALLED':
            raise ValueError(f'Error: Endpoint {endpoint_id}\'s Agent is uninstalled and therefore can not be isolated.')
        if endpoint_status == 'DISCONNECTED':
            if disconnected_should_return_error:
                raise ValueError(f'Error: Endpoint {endpoint_id} is disconnected and therefore can not be isolated.')
            else:
                return CommandResults(
                    readable_output=f'Warning: isolation action is pending for the following disconnected endpoint: {endpoint_id}.',
                    outputs={f'{args.get("integration_context_brand", "CoreApiModule")}.'
                             f'Isolation.endpoint_id(val.endpoint_id == obj.endpoint_id)': endpoint_id}
                )
        if is_isolated == 'AGENT_PENDING_ISOLATION_CANCELLATION':
            raise ValueError(
                f'Error: Endpoint {endpoint_id} is pending isolation cancellation and therefore can not be isolated.'
            )
        try:
            result = client.isolate_endpoint(endpoint_id=endpoint_id, incident_id=incident_id)

            return CommandResults(
                readable_output=f'The isolation request has been submitted successfully on Endpoint {endpoint_id}.\n',
                outputs={f'{args.get("integration_context_brand", "CoreApiModule")}.'
                         f'Isolation.endpoint_id(val.endpoint_id == obj.endpoint_id)': endpoint_id},
                raw_response=result
            )
        except Exception as e:
            return catch_and_exit_gracefully(e)


    def arg_to_timestamp(arg, arg_name: str, required: bool = False):
        if arg is None:
            if required is True:
                raise ValueError(f'Missing "{arg_name}"')
            return None

        if isinstance(arg, str) and arg.isdigit():
            # timestamp that str - we just convert it to int
            return int(arg)
        if isinstance(arg, str):
            # if the arg is string of date format 2019-10-23T00:00:00 or "3 days", etc
            date = dateparser.parse(arg, settings={'TIMEZONE': 'UTC'})
            if date is None:
                # if d is None it means dateparser failed to parse it
                raise ValueError(f'Invalid date: {arg_name}')

            return int(date.timestamp() * 1000)
        if isinstance(arg, (int, float)):
            return arg
        return None


    def create_account_context(endpoints):
        account_context = []
        for endpoint in endpoints:
            domain = endpoint.get('domain')
            if domain:
                users = endpoint.get('users', [])  # in case the value of 'users' is None
                if users and isinstance(users, list):
                    for user in users:
                        account_context.append({
                            'Username': user,
                            'Domain': domain,
                        })

        return account_context


    def get_endpoint_properties(single_endpoint):
        status = 'Online' if single_endpoint.get('endpoint_status', '').lower() == 'connected' else 'Offline'
        is_isolated = 'No' if 'unisolated' in single_endpoint.get('is_isolated', '').lower() else 'Yes'
        hostname = single_endpoint['host_name'] if single_endpoint.get('host_name') else single_endpoint.get(
            'endpoint_name')
        ip = single_endpoint.get('ip')
        return status, is_isolated, hostname, ip


    def convert_os_to_standard(endpoint_os):
        os_type = ''
        endpoint_os = endpoint_os.lower()
        if 'windows' in endpoint_os:
            os_type = "Windows"
        elif 'linux' in endpoint_os:
            os_type = "Linux"
        elif 'mac' in endpoint_os:
            os_type = "Macos"
        elif 'android' in endpoint_os:
            os_type = "Android"
        return os_type


    def generate_endpoint_by_contex_standard(endpoints, ip_as_string, integration_name="CoreApiModule"):
        standard_endpoints = []
        for single_endpoint in endpoints:
            status, is_isolated, hostname, ip = get_endpoint_properties(single_endpoint)
            # in the `-get-endpoints` command the ip is returned as list, in order not to break bc we will keep it
            # in the `endpoint` command we use the standard
            if ip_as_string and isinstance(ip, list):
                ip = ip[0]
            os_type = convert_os_to_standard(single_endpoint.get('os_type', ''))
            endpoint = Common.Endpoint(
                id=single_endpoint.get('endpoint_id'),
                hostname=hostname,
                ip_address=ip,
                os=os_type,
                status=status,
                is_isolated=is_isolated,
                mac_address=single_endpoint.get('mac_address'),
                domain=single_endpoint.get('domain'),
                vendor=integration_name)

            standard_endpoints.append(endpoint)
        return standard_endpoints


    def get_endpoints_command(client, args):
        integration_context_brand = args.pop('integration_context_brand', 'CoreApiModule')
        integration_name = args.pop("integration_name", "CoreApiModule")
        page_number = arg_to_int(
            arg=args.get('page', '0'),
            arg_name='Failed to parse "page". Must be a number.',
            required=True
        )

        limit = arg_to_int(
            arg=args.get('limit', '30'),
            arg_name='Failed to parse "limit". Must be a number.',
            required=True
        )

        endpoint_id_list = argToList(args.get('endpoint_id_list'))
        dist_name = argToList(args.get('dist_name'))
        ip_list = argToList(args.get('ip_list'))
        public_ip_list = argToList(args.get('public_ip_list'))
        group_name = argToList(args.get('group_name'))
        platform = argToList(args.get('platform'))
        alias_name = argToList(args.get('alias_name'))
        isolate = args.get('isolate')
        hostname = argToList(args.get('hostname'))
        status = argToList(args.get('status'))

        first_seen_gte = arg_to_timestamp(
            arg=args.get('first_seen_gte'),
            arg_name='first_seen_gte'
        )

        first_seen_lte = arg_to_timestamp(
            arg=args.get('first_seen_lte'),
            arg_name='first_seen_lte'
        )

        last_seen_gte = arg_to_timestamp(
            arg=args.get('last_seen_gte'),
            arg_name='last_seen_gte'
        )

        last_seen_lte = arg_to_timestamp(
            arg=args.get('last_seen_lte'),
            arg_name='last_seen_lte'
        )

        sort_by_first_seen = args.get('sort_by_first_seen')
        sort_by_last_seen = args.get('sort_by_last_seen')

        username = argToList(args.get('username'))

        endpoints = client.get_endpoints(
            endpoint_id_list=endpoint_id_list,
            dist_name=dist_name,
            ip_list=ip_list,
            public_ip_list=public_ip_list,
            group_name=group_name,
            platform=platform,
            alias_name=alias_name,
            isolate=isolate,
            hostname=hostname,
            page_number=page_number,
            limit=limit,
            first_seen_gte=first_seen_gte,
            first_seen_lte=first_seen_lte,
            last_seen_gte=last_seen_gte,
            last_seen_lte=last_seen_lte,
            sort_by_first_seen=sort_by_first_seen,
            sort_by_last_seen=sort_by_last_seen,
            status=status,
            username=username
        )

        standard_endpoints = generate_endpoint_by_contex_standard(endpoints, False, integration_name)
        endpoint_context_list = []
        for endpoint in standard_endpoints:
            endpoint_context = endpoint.to_context().get(Common.Endpoint.CONTEXT_PATH)
            endpoint_context_list.append(endpoint_context)

        context = {
            f'{integration_context_brand}.Endpoint(val.endpoint_id == obj.endpoint_id)': endpoints,
            Common.Endpoint.CONTEXT_PATH: endpoint_context_list,
            f'{integration_context_brand}.Endpoint.count': len(standard_endpoints)
        }
        account_context = create_account_context(endpoints)
        if account_context:
            context[Common.Account.CONTEXT_PATH] = account_context

        return CommandResults(
            readable_output=tableToMarkdown('Endpoints', endpoints),
            outputs=context,
            raw_response=endpoints
        )


    def endpoint_alias_change_command(client: CoreClient, **args) -> CommandResults:
        # get arguments
        endpoint_id_list = argToList(args.get('endpoint_id_list'))
        dist_name_list = argToList(args.get('dist_name'))
        ip_list = argToList(args.get('ip_list'))
        group_name_list = argToList(args.get('group_name'))
        platform_list = argToList(args.get('platform'))
        alias_name_list = argToList(args.get('alias_name'))
        isolate = args.get('isolate')
        hostname_list = argToList(args.get('hostname'))
        status = args.get('status')
        scan_status = args.get('scan_status')
        username_list = argToList(args.get('username'))
        new_alias_name = args.get('new_alias_name')

        # This is a workaround that is needed because of a specific behaviour of the system
        # that converts an empty string to a string with double quotes.
        if new_alias_name == '""':
            new_alias_name = ""

        first_seen_gte = arg_to_timestamp(
            arg=args.get('first_seen_gte'),
            arg_name='first_seen_gte'
        )

        first_seen_lte = arg_to_timestamp(
            arg=args.get('first_seen_lte'),
            arg_name='first_seen_lte'
        )

        last_seen_gte = arg_to_timestamp(
            arg=args.get('last_seen_gte'),
            arg_name='last_seen_gte'
        )

        last_seen_lte = arg_to_timestamp(
            arg=args.get('last_seen_lte'),
            arg_name='last_seen_lte'
        )

        # create filters
        filters: list[dict[str, str]] = create_request_filters(
            status=status, username=username_list, endpoint_id_list=endpoint_id_list, dist_name=dist_name_list,
            ip_list=ip_list, group_name=group_name_list, platform=platform_list, alias_name=alias_name_list, isolate=isolate,
            hostname=hostname_list, first_seen_gte=first_seen_gte, first_seen_lte=first_seen_lte,
            last_seen_gte=last_seen_gte, last_seen_lte=last_seen_lte, scan_status=scan_status
        )
        if not filters:
            raise DemistoException('Please provide at least one filter.')
        # importent: the API will return True even if the endpoint does not exist, so its a good idea to check
        # the results by a get_endpoints command
        client.set_endpoints_alias(filters=filters, new_alias_name=new_alias_name)

        return CommandResults(
            readable_output="The endpoint alias was changed successfully.")


    def unisolate_endpoint_command(client, args):
        endpoint_id = args.get('endpoint_id')
        incident_id = arg_to_number(args.get('incident_id'))

        disconnected_should_return_error = not argToBoolean(args.get('suppress_disconnected_endpoint_error', False))
        endpoint = client.get_endpoints(endpoint_id_list=[endpoint_id])
        if len(endpoint) == 0:
            raise ValueError(f'Error: Endpoint {endpoint_id} was not found')

        endpoint = endpoint[0]
        endpoint_status = endpoint.get('endpoint_status')
        is_isolated = endpoint.get('is_isolated')
        if is_isolated == 'AGENT_UNISOLATED':
            return CommandResults(
                readable_output=f'Endpoint {endpoint_id} already unisolated.'
            )
        if is_isolated == 'AGENT_PENDING_ISOLATION_CANCELLATION':
            return CommandResults(
                readable_output=f'Endpoint {endpoint_id} pending isolation cancellation.'
            )
        if endpoint_status == 'UNINSTALLED':
            raise ValueError(f'Error: Endpoint {endpoint_id}\'s Agent is uninstalled and therefore can not be un-isolated.')
        if endpoint_status == 'DISCONNECTED':
            if disconnected_should_return_error:
                raise ValueError(f'Error: Endpoint {endpoint_id} is disconnected and therefore can not be un-isolated.')
            else:
                return CommandResults(
                    readable_output=f'Warning: un-isolation action is pending for the following disconnected '
                                    f'endpoint: {endpoint_id}.',
                    outputs={
                        f'{args.get("integration_context_brand", "CoreApiModule")}.'
                        f'UnIsolation.endpoint_id(val.endpoint_id == obj.endpoint_id)'
                        f'': endpoint_id}
                )
        if is_isolated == 'AGENT_PENDING_ISOLATION':
            raise ValueError(
                f'Error: Endpoint {endpoint_id} is pending isolation and therefore can not be un-isolated.'
            )
        result = client.unisolate_endpoint(endpoint_id=endpoint_id, incident_id=incident_id)

        return CommandResults(
            readable_output=f'The un-isolation request has been submitted successfully on Endpoint {endpoint_id}.\n',
            outputs={f'{args.get("integration_context_brand", "CoreApiModule")}.'
                     f'UnIsolation.endpoint_id(val.endpoint_id == obj.endpoint_id)': endpoint_id},
            raw_response=result
        )


    def retrieve_files_command(client: CoreClient, args: Dict[str, str]) -> CommandResults:
        endpoint_id_list: list = argToList(args.get('endpoint_ids'))
        windows: list = argToList(args.get('windows_file_paths'))
        linux: list = argToList(args.get('linux_file_paths'))
        macos: list = argToList(args.get('mac_file_paths'))
        file_path_list: list = argToList(args.get('generic_file_path'))
        incident_id: Optional[int] = arg_to_number(args.get('incident_id'))

        reply = client.retrieve_file(
            endpoint_id_list=endpoint_id_list,
            windows=windows,
            linux=linux,
            macos=macos,
            file_path_list=file_path_list,
            incident_id=incident_id
        )
        result = {'action_id': reply.get('action_id')}

        return CommandResults(
            readable_output=tableToMarkdown(name='Retrieve files', t=result, headerTransform=string_to_table_header),
            outputs_prefix=f'{args.get("integration_context_brand", "CoreApiModule")}'
                           f'.RetrievedFiles(val.action_id == obj.action_id)',
            outputs=result,
            raw_response=reply
        )


    def run_snippet_code_script_command(client: CoreClient, args: Dict) -> CommandResults:
        snippet_code = args.get('snippet_code')
        endpoint_ids = argToList(args.get('endpoint_ids'))
        incident_id = arg_to_number(args.get('incident_id'))
        response = client.run_snippet_code_script(snippet_code=snippet_code, endpoint_ids=endpoint_ids, incident_id=incident_id)
        reply = response.get('reply')
        return CommandResults(
            readable_output=tableToMarkdown('Run Snippet Code Script', reply),
            outputs_prefix=f'{args.get("integration_context_brand", "CoreApiModule")}.ScriptRun',
            outputs_key_field='action_id',
            outputs=reply,
            raw_response=reply,
        )


    def run_script_execute_commands_command(client: CoreClient, args: Dict) -> CommandResults:
        endpoint_ids = argToList(args.get('endpoint_ids'))
        incident_id = arg_to_number(args.get('incident_id'))
        timeout = arg_to_number(args.get('timeout', 600)) or 600
        parameters = {'commands_list': argToList(args.get('commands'))}
        response = client.run_script('a6f7683c8e217d85bd3c398f0d3fb6bf', endpoint_ids, parameters, timeout, incident_id)
        reply = response.get('reply')
        return CommandResults(
            readable_output=tableToMarkdown('Run Script Execute Commands', reply),
            outputs_prefix=f'{args.get("integration_context_brand", "CoreApiModule")}.ScriptRun',
            outputs_key_field='action_id',
            outputs=reply,
            raw_response=reply,
        )


    def run_script_kill_process_command(client: CoreClient, args: Dict) -> CommandResults:
        endpoint_ids = argToList(args.get('endpoint_ids'))
        incident_id = arg_to_number(args.get('incident_id'))
        timeout = arg_to_number(args.get('timeout', 600)) or 600
        processes_names = argToList(args.get('process_name'))
        replies = []

        for process_name in processes_names:
            parameters = {'process_name': process_name}
            response = client.run_script('fd0a544a99a9421222b4f57a11839481', endpoint_ids, parameters, timeout, incident_id)
            reply = response.get('reply')
            replies.append(reply)

        command_result = CommandResults(
            readable_output=tableToMarkdown("Run Script Kill Process Results", replies),
            outputs_prefix=f'{args.get("integration_context_brand", "CoreApiModule")}.ScriptRun',
            outputs_key_field='action_id',
            outputs=replies,
            raw_response=replies,
        )

        return command_result


    def run_script_file_exists_command(client: CoreClient, args: Dict) -> CommandResults:
        endpoint_ids = argToList(args.get('endpoint_ids'))
        incident_id = arg_to_number(args.get('incident_id'))
        timeout = arg_to_number(args.get('timeout', 600)) or 600
        file_paths = argToList(args.get('file_path'))
        replies = []
        for file_path in file_paths:
            parameters = {'path': file_path}
            response = client.run_script('414763381b5bfb7b05796c9fe690df46', endpoint_ids, parameters, timeout, incident_id)
            reply = response.get('reply')
            replies.append(reply)

        command_result = CommandResults(
            readable_output=tableToMarkdown(f'Run Script File Exists on {",".join(file_paths)}', replies),
            outputs_prefix=f'{args.get("integration_context_brand", "CoreApiModule")}.ScriptRun',
            outputs_key_field='action_id',
            outputs=replies,
            raw_response=replies,
        )
        return command_result


    def run_script_delete_file_command(client: CoreClient, args: Dict) -> CommandResults:
        endpoint_ids = argToList(args.get('endpoint_ids'))
        incident_id = arg_to_number(args.get('incident_id'))
        timeout = arg_to_number(args.get('timeout', 600)) or 600
        file_paths = argToList(args.get('file_path'))
        replies = []
        for file_path in file_paths:
            parameters = {'file_path': file_path}
            response = client.run_script('548023b6e4a01ec51a495ba6e5d2a15d', endpoint_ids, parameters, timeout, incident_id)
            reply = response.get('reply')
            replies.append(reply)

        command_result = CommandResults(
            readable_output=tableToMarkdown(f'Run Script Delete File on {",".join(file_paths)}', replies),
            outputs_prefix=f'{args.get("integration_context_brand", "CoreApiModule")}.ScriptRun',
            outputs_key_field='action_id',
            outputs=replies,
            raw_response=replies,
        )
        return command_result


    def quarantine_files_command(client, args):
        endpoint_id_list = argToList(args.get("endpoint_id_list"))
        file_path = args.get("file_path")
        file_hash = args.get("file_hash")
        incident_id = arg_to_number(args.get('incident_id'))

        try:
            reply = client.quarantine_files(
                endpoint_id_list=endpoint_id_list,
                file_path=file_path,
                file_hash=file_hash,
                incident_id=incident_id
            )
            output = {
                'endpointIdList': endpoint_id_list,
                'filePath': file_path,
                'fileHash': file_hash,
                'actionId': reply.get("action_id")
            }

            return CommandResults(
                readable_output=tableToMarkdown('Quarantine files', output, headers=[*output],
                                                headerTransform=pascalToSpace),
                outputs={f'{args.get("integration_context_brand", "CoreApiModule")}.'
                         f'quarantineFiles.actionIds(val.actionId === obj.actionId)': output},
                raw_response=reply
            )
        except Exception as e:
            return catch_and_exit_gracefully(e)


    def restore_file_command(client, args):
        file_hash = args.get('file_hash')
        endpoint_id = args.get('endpoint_id')
        incident_id = arg_to_number(args.get('incident_id'))

        reply = client.restore_file(
            file_hash=file_hash,
            endpoint_id=endpoint_id,
            incident_id=incident_id
        )
        action_id = reply.get("action_id")

        return CommandResults(
            readable_output=tableToMarkdown('Restore files', {'Action Id': action_id}, ['Action Id']),
            outputs={f'{args.get("integration_context_brand", "CoreApiModule")}.'
                     f'restoredFiles.actionId(val.actionId == obj.actionId)': action_id},
            raw_response=reply
        )


    def validate_sha256_hashes(hash_list):
        for hash_value in hash_list:
            if detect_file_indicator_type(hash_value) != 'sha256':
                raise DemistoException(f'The provided hash {hash_value} is not a valid sha256.')


    def blocklist_files_command(client, args):
        hash_list = argToList(args.get('hash_list'))
        validate_sha256_hashes(hash_list)
        comment = args.get('comment')
        incident_id = arg_to_number(args.get('incident_id'))
        detailed_response = argToBoolean(args.get('detailed_response', False))
        try:
            res = client.blocklist_files(hash_list=hash_list,
                                         comment=comment,
                                         incident_id=incident_id,
                                         detailed_response=detailed_response)
        except Exception as e:
            if 'All hashes have already been added to the allow or block list' in str(e):
                return CommandResults(
                    readable_output='All hashes have already been added to the block list.'
                )
            raise e

        if detailed_response:
            return CommandResults(
                readable_output=tableToMarkdown('Blocklist Files', res),
                outputs_prefix=f'{args.get("integration_context_brand", "CoreApiModule")}.blocklist',
                outputs=res,
                raw_response=res
            )

        markdown_data = [{'added_hashes': file_hash} for file_hash in hash_list]

        return CommandResults(
            readable_output=tableToMarkdown('Blocklist Files',
                                            markdown_data,
                                            headers=['added_hashes'],
                                            headerTransform=pascalToSpace),
            outputs={f'{args.get("integration_context_brand", "CoreApiModule")}.'
                     f'{args.get("prefix", "blocklist")}.added_hashes.fileHash(val.fileHash == obj.fileHash)': hash_list},
            raw_response=res
        )


    def remove_blocklist_files_command(client: CoreClient, args: Dict) -> CommandResults:
        hash_list = argToList(args.get('hash_list'))
        validate_sha256_hashes(hash_list)
        comment = args.get('comment')
        incident_id = arg_to_number(args.get('incident_id'))

        res = client.remove_blocklist_files(hash_list=hash_list, comment=comment, incident_id=incident_id)
        markdown_data = [{'removed_hashes': file_hash} for file_hash in hash_list]

        return CommandResults(
            readable_output=tableToMarkdown('Blocklist Files Removed',
                                            markdown_data,
                                            headers=['removed_hashes'],
                                            headerTransform=pascalToSpace),
            outputs_prefix=f'{args.get("integration_context_brand", "CoreApiModule")}.blocklist',
            outputs=markdown_data,
            raw_response=res
        )


    def allowlist_files_command(client, args):
        hash_list = argToList(args.get('hash_list'))
        comment = args.get('comment')
        incident_id = arg_to_number(args.get('incident_id'))
        detailed_response = argToBoolean(args.get('detailed_response', False))
        try:
            res = client.allowlist_files(hash_list=hash_list,
                                         comment=comment,
                                         incident_id=incident_id,
                                         detailed_response=detailed_response)
        except Exception as e:
            if 'All hashes have already been added to the allow or block list' in str(e):
                return CommandResults(
                    readable_output='All hashes have already been added to the allow list.'
                )
            raise e

        if detailed_response:
            return CommandResults(
                readable_output=tableToMarkdown('Allowlist Files', res),
                outputs_prefix=f'{args.get("integration_context_brand", "CoreApiModule")}.allowlist',
                outputs=res,
                raw_response=res
            )

        markdown_data = [{'added_hashes': file_hash} for file_hash in hash_list]

        return CommandResults(
            readable_output=tableToMarkdown('Allowlist Files',
                                            markdown_data,
                                            headers=['added_hashes'],
                                            headerTransform=pascalToSpace),
            outputs={f'{args.get("integration_context_brand", "CoreApiModule")}.'
                     f'{args.get("prefix", "allowlist")}.added_hashes.fileHash(val.fileHash == obj.fileHash)': hash_list},
            raw_response=res
        )


    def remove_allowlist_files_command(client, args):
        hash_list = argToList(args.get('hash_list'))
        comment = args.get('comment')
        incident_id = arg_to_number(args.get('incident_id'))
        res = client.remove_allowlist_files(hash_list=hash_list, comment=comment, incident_id=incident_id)
        markdown_data = [{'removed_hashes': file_hash} for file_hash in hash_list]
        return CommandResults(
            readable_output=tableToMarkdown('Allowlist Files Removed',
                                            markdown_data,
                                            headers=['removed_hashes'],
                                            headerTransform=pascalToSpace),
            outputs_prefix=f'{args.get("integration_context_brand", "CoreApiModule")}.allowlist',
            outputs=markdown_data,
            raw_response=res
        )


    def create_endpoint_context(audit_logs):
        endpoints = []
        for log in audit_logs:
            endpoint_details = {
                'ID': log.get('ENDPOINTID'),
                'Hostname': log.get('ENDPOINTNAME'),
                'Domain': log.get('DOMAIN'),
            }
            remove_nulls_from_dictionary(endpoint_details)
            if endpoint_details:
                endpoints.append(endpoint_details)

        return endpoints


    def get_audit_agent_reports_command(client, args):
        endpoint_ids = argToList(args.get('endpoint_ids'))
        endpoint_names = argToList(args.get('endpoint_names'))
        result = argToList(args.get('result'))
        _type = argToList(args.get('type'))
        sub_type = argToList(args.get('sub_type'))

        timestamp_gte = arg_to_timestamp(
            arg=args.get('timestamp_gte'),
            arg_name='timestamp_gte'
        )

        timestamp_lte = arg_to_timestamp(
            arg=args.get('timestamp_lte'),
            arg_name='timestamp_lte'
        )

        page_number = arg_to_int(
            arg=args.get('page', 0),
            arg_name='Failed to parse "page". Must be a number.',
            required=True
        )
        limit = arg_to_int(
            arg=args.get('limit', 20),
            arg_name='Failed to parse "limit". Must be a number.',
            required=True
        )
        search_from = page_number * limit
        search_to = search_from + limit

        sort_by = args.get('sort_by')
        sort_order = args.get('sort_order', 'asc')

        audit_logs = client.get_audit_agent_reports(
            endpoint_ids=endpoint_ids,
            endpoint_names=endpoint_names,
            result=result,
            _type=_type,
            sub_type=sub_type,
            timestamp_gte=timestamp_gte,
            timestamp_lte=timestamp_lte,

            search_from=search_from,
            search_to=search_to,
            sort_by=sort_by,
            sort_order=sort_order
        )
        integration_context = {
            f'{args.get("integration_context_brand", "CoreApiModule")}.AuditAgentReports': audit_logs}
        endpoint_context = create_endpoint_context(audit_logs)
        if endpoint_context:
            integration_context[Common.Endpoint.CONTEXT_PATH] = endpoint_context
        return (
            tableToMarkdown('Audit Agent Reports', audit_logs),
            integration_context,
            audit_logs
        )


    def get_distribution_url_command(client, args):
        distribution_id = args.get('distribution_id')
        package_type = args.get('package_type')

        url = client.get_distribution_url(distribution_id, package_type)

        return (
            f'[Distribution URL]({url})',
            {
                f'{args.get("integration_context_brand", "CoreApiModule")}.Distribution(val.id == obj.id)': {
                    'id': distribution_id,
                    'url': url
                }
            },
            url
        )


    def get_distribution_status_command(client, args):
        distribution_ids = argToList(args.get('distribution_ids'))

        distribution_list = []
        for distribution_id in distribution_ids:
            status = client.get_distribution_status(distribution_id)

            distribution_list.append({
                'id': distribution_id,
                'status': status
            })

        return (
            tableToMarkdown('Distribution Status', distribution_list, ['id', 'status']),
            {
                f'{args.get("integration_context_brand", "CoreApiModule")}.Distribution(val.id == obj.id)': distribution_list
            },
            distribution_list
        )


    def get_process_context(alert, process_type):
        process_context = {
            'Name': alert.get(f'{process_type}_process_image_name'),
            'MD5': alert.get(f'{process_type}_process_image_md5'),
            'SHA256': alert.get(f'{process_type}_process_image_sha256'),
            'PID': alert.get(f'{process_type}_process_os_pid'),
            'CommandLine': alert.get(f'{process_type}_process_command_line'),
            'Path': alert.get(f'{process_type}_process_image_path'),
            'Start Time': alert.get(f'{process_type}_process_execution_time'),
            'Hostname': alert.get('host_name'),
        }

        remove_nulls_from_dictionary(process_context)

        # If the process contains only 'HostName' , don't create an indicator
        if len(process_context.keys()) == 1 and 'Hostname' in process_context:
            return {}
        return process_context


    def add_to_ip_context(alert, ip_context):
        action_local_ip = alert.get('action_local_ip')
        action_remote_ip = alert.get('action_remote_ip')
        if action_local_ip:
            ip_context.append({
                'Address': action_local_ip,
            })

        if action_remote_ip:
            ip_context.append({
                'Address': action_remote_ip,
            })


    def create_context_from_network_artifacts(network_artifacts, ip_context):
        domain_context = []

        if network_artifacts:
            for artifact in network_artifacts:
                domain = artifact.get('network_domain')
                if domain:
                    domain_context.append({
                        'Name': domain,
                    })

                network_ip_details = {
                    'Address': artifact.get('network_remote_ip'),
                    'GEO': {
                        'Country': artifact.get('network_country')},
                }

                remove_nulls_from_dictionary(network_ip_details)

                if network_ip_details:
                    ip_context.append(network_ip_details)

        return domain_context


    def get_indicators_context(incident):
        file_context: List[Any] = []
        process_context: List[Any] = []
        ip_context: List[Any] = []
        for alert in incident.get('alerts', []):
            # file context
            file_details = {
                'Name': alert.get('action_file_name'),
                'Path': alert.get('action_file_path'),
                'SHA265': alert.get('action_file_sha256'),  # Here for backward compatibility
                'SHA256': alert.get('action_file_sha256'),
                'MD5': alert.get('action_file_md5'),
            }
            remove_nulls_from_dictionary(file_details)

            if file_details:
                file_context.append(file_details)

            # process context
            process_types = ['actor', 'os_actor', 'causality_actor', 'action']
            for process_type in process_types:
                single_process_context = get_process_context(alert, process_type)
                if single_process_context:
                    process_context.append(single_process_context)

            # ip context
            add_to_ip_context(alert, ip_context)

        network_artifacts = incident.get('network_artifacts', [])

        domain_context = create_context_from_network_artifacts(network_artifacts, ip_context)

        file_artifacts = incident.get('file_artifacts', [])
        for file in file_artifacts:
            file_sha = file.get('file_sha256')
            file_details = {
                'Name': file.get('file_name'),
                'SHA256': file_sha,
            }
            remove_nulls_from_dictionary(file_details)
            is_malicious = file.get("is_malicious")

            if file_details:
                file_context.append(file_details)
                if file_sha:
                    relevant_processes = filter(lambda p: p.get("SHA256") == file_sha, process_context)
                    for process in relevant_processes:
                        process["is_malicious"] = is_malicious

        return file_context, process_context, domain_context, ip_context


    def endpoint_command(client, args):
        endpoint_id_list = argToList(args.get('id'))
        endpoint_ip_list = argToList(args.get('ip'))
        endpoint_hostname_list = argToList(args.get('hostname'))

        if not any((endpoint_id_list, endpoint_ip_list, endpoint_hostname_list)):
            raise DemistoException(f'{args.get("integration_name", "CoreApiModule")} -'
                                   f' In order to run this command, please provide a valid id, ip or hostname')

        endpoints = client.get_endpoints(
            endpoint_id_list=endpoint_id_list,
            ip_list=endpoint_ip_list,
            hostname=endpoint_hostname_list,
        )
        standard_endpoints = generate_endpoint_by_contex_standard(endpoints, True, args.get("integration_name", "CoreApiModule"))
        command_results = []
        if standard_endpoints:
            for endpoint in standard_endpoints:
                endpoint_context = endpoint.to_context().get(Common.Endpoint.CONTEXT_PATH)
                hr = tableToMarkdown('Cortex Endpoint', endpoint_context)

                command_results.append(CommandResults(
                    readable_output=hr,
                    raw_response=endpoints,
                    indicator=endpoint
                ))

        else:
            command_results.append(CommandResults(
                readable_output="No endpoints were found",
                raw_response=endpoints,
            ))
        return command_results


    def get_audit_management_logs_command(client, args):
        email = argToList(args.get('email'))
        result = argToList(args.get('result'))
        _type = argToList(args.get('type'))
        sub_type = argToList(args.get('sub_type'))

        timestamp_gte = arg_to_timestamp(
            arg=args.get('timestamp_gte'),
            arg_name='timestamp_gte'
        )

        timestamp_lte = arg_to_timestamp(
            arg=args.get('timestamp_lte'),
            arg_name='timestamp_lte'
        )

        page_number = arg_to_int(
            arg=args.get('page', 0),
            arg_name='Failed to parse "page". Must be a number.',
            required=True
        )
        limit = arg_to_int(
            arg=args.get('limit', 20),
            arg_name='Failed to parse "limit". Must be a number.',
            required=True
        )
        search_from = page_number * limit
        search_to = search_from + limit

        sort_by = args.get('sort_by')
        sort_order = args.get('sort_order', 'asc')

        audit_logs = client.audit_management_logs(
            email=email,
            result=result,
            _type=_type,
            sub_type=sub_type,
            timestamp_gte=timestamp_gte,
            timestamp_lte=timestamp_lte,
            search_from=search_from,
            search_to=search_to,
            sort_by=sort_by,
            sort_order=sort_order
        )

        return (
            tableToMarkdown('Audit Management Logs', audit_logs, [
                'AUDIT_ID',
                'AUDIT_RESULT',
                'AUDIT_DESCRIPTION',
                'AUDIT_OWNER_NAME',
                'AUDIT_OWNER_EMAIL',
                'AUDIT_ASSET_JSON',
                'AUDIT_ASSET_NAMES',
                'AUDIT_HOSTNAME',
                'AUDIT_REASON',
                'AUDIT_ENTITY',
                'AUDIT_ENTITY_SUBTYPE',
                'AUDIT_SESSION_ID',
                'AUDIT_CASE_ID',
                'AUDIT_INSERT_TIME'
            ]),
            {
                f'{args.get("integration_context_brand", "CoreApiModule")}.'
                f'AuditManagementLogs(val.AUDIT_ID == obj.AUDIT_ID)': audit_logs
            },
            audit_logs
        )


    def get_quarantine_status_command(client, args):
        file_path = args.get('file_path')
        file_hash = args.get('file_hash')
        endpoint_id = args.get('endpoint_id')

        reply = client.get_quarantine_status(
            file_path=file_path,
            file_hash=file_hash,
            endpoint_id=endpoint_id
        )
        output = {
            'status': reply['status'],
            'endpointId': reply['endpoint_id'],
            'filePath': reply['file_path'],
            'fileHash': reply['file_hash']
        }

        return CommandResults(
            readable_output=tableToMarkdown('Quarantine files status', output, headers=[*output], headerTransform=pascalToSpace),
            outputs={f'{args.get("integration_context_brand", "CoreApiModule")}.'
                     f'quarantineFiles.status(val.fileHash === obj.fileHash &&'
                     f'val.endpointId === obj.endpointId && val.filePath === obj.filePath)': output},
            raw_response=reply
        )


    def endpoint_scan_abort_command(client, args):
        endpoint_id_list = argToList(args.get('endpoint_id_list'))
        dist_name = argToList(args.get('dist_name'))
        gte_first_seen = args.get('gte_first_seen')
        gte_last_seen = args.get('gte_last_seen')
        lte_first_seen = args.get('lte_first_seen')
        lte_last_seen = args.get('lte_last_seen')
        ip_list = argToList(args.get('ip_list'))
        group_name = argToList(args.get('group_name'))
        platform = argToList(args.get('platform'))
        alias = argToList(args.get('alias'))
        isolate = args.get('isolate')
        hostname = argToList(args.get('hostname'))
        incident_id = arg_to_number(args.get('incident_id'))

        validate_args_scan_commands(args)

        reply = client.endpoint_scan(
            url_suffix='endpoints/abort_scan/',
            endpoint_id_list=argToList(endpoint_id_list),
            dist_name=dist_name,
            gte_first_seen=gte_first_seen,
            gte_last_seen=gte_last_seen,
            lte_first_seen=lte_first_seen,
            lte_last_seen=lte_last_seen,
            ip_list=ip_list,
            group_name=group_name,
            platform=platform,
            alias=alias,
            isolate=isolate,
            hostname=hostname,
            incident_id=incident_id
        )

        action_id = reply.get("action_id")

        context = {
            "actionId": action_id,
            "aborted": True
        }

        return CommandResults(
            readable_output=tableToMarkdown('Endpoint abort scan', {'Action Id': action_id}, ['Action Id']),
            outputs={f'{args.get("integration_context_brand", "CoreApiModule")}.'
                     f'endpointScan(val.actionId == obj.actionId)': context},
            raw_response=reply
        )


    def sort_by_key(list_to_sort, main_key, fallback_key):
        """Sorts a given list elements by main_key for all elements with the key,
        uses sorting by fallback_key on all elements that dont have the main_key"""
        list_elements_with_main_key = [element for element in list_to_sort if element.get(main_key)]
        sorted_list = sorted(list_elements_with_main_key, key=itemgetter(main_key))
        if len(list_to_sort) == len(sorted_list):
            return sorted_list

        list_elements_with_fallback_without_main = [element for element in list_to_sort
                                                    if element.get(fallback_key) and not element.get(main_key)]
        sorted_list.extend(sorted(list_elements_with_fallback_without_main, key=itemgetter(fallback_key)))

        if len(sorted_list) == len(list_to_sort):
            return sorted_list

        list_elements_without_fallback_and_main = [element for element in list_to_sort
                                                   if not element.get(fallback_key) and not element.get(main_key)]

        sorted_list.extend(list_elements_without_fallback_and_main)
        return sorted_list


    def drop_field_underscore(section):
        section_copy = section.copy()
        for field in section_copy:
            if '_' in field:
                section[field.replace('_', '')] = section.get(field)


    def reformat_sublist_fields(sublist):
        for section in sublist:
            drop_field_underscore(section)


    def handle_outgoing_incident_owner_sync(update_args):
        if 'owner' in update_args and demisto.params().get('sync_owners'):
            if update_args.get('owner'):
                user_info = demisto.findUser(username=update_args.get('owner'))
                if user_info:
                    update_args['assigned_user_mail'] = user_info.get('email')
            else:
                # handle synced unassignment
                update_args['assigned_user_mail'] = None


    def handle_user_unassignment(update_args):
        if ('assigned_user_mail' in update_args and update_args.get('assigned_user_mail') in ['None', 'null', '', None]) \
            or ('assigned_user_pretty_name' in update_args
                and update_args.get('assigned_user_pretty_name') in ['None', 'null', '', None]):
            update_args['unassign_user'] = 'true'
            update_args['assigned_user_mail'] = None
            update_args['assigned_user_pretty_name'] = None


    def resolve_xdr_close_reason(xsoar_close_reason: str) -> str:
        """
        Resolving XDR close reason from possible custom XSOAR->XDR close-reason mapping or default mapping.
        :param xsoar_close_reason: XSOAR raw status/close reason e.g. 'False Positive'.
        :return: XDR close-reason in snake_case format e.g. 'resolved_false_positive'.
        """
        # Initially setting the close reason according to the default mapping.
        xdr_close_reason = XSOAR_RESOLVED_STATUS_TO_XDR.get(xsoar_close_reason, 'resolved_other')

        # Reading custom XSOAR->XDR close-reason mapping.
        custom_xsoar_to_xdr_close_reason_mapping = comma_separated_mapping_to_dict(
            demisto.params().get("custom_xsoar_to_xdr_close_reason_mapping")
        )

        # Overriding default close-reason mapping if there exists a custom one.
        if xsoar_close_reason in custom_xsoar_to_xdr_close_reason_mapping:
            xdr_close_reason_candidate = custom_xsoar_to_xdr_close_reason_mapping.get(xsoar_close_reason)
            # Transforming resolved close-reason into snake_case format with known prefix to match XDR status format.
            xdr_close_reason_candidate = "resolved_" + "_".join(xdr_close_reason_candidate.lower().split(" "))
            if xdr_close_reason_candidate not in XDR_RESOLVED_STATUS_TO_XSOAR:
                demisto.debug("Warning: Provided XDR close-reason does not exist. Using default XDR close-reason mapping. ")
            else:
                xdr_close_reason = xdr_close_reason_candidate
                demisto.debug(
                    f"resolve_xdr_close_reason XSOAR->XDR custom close-reason exists, using {xsoar_close_reason}={xdr_close_reason}")
        else:
            demisto.debug(f"resolve_xdr_close_reason using default mapping {xsoar_close_reason}={xdr_close_reason}")

        return xdr_close_reason


    def handle_outgoing_issue_closure(remote_args):
        incident_id = remote_args.remote_incident_id
        demisto.debug(f"handle_outgoing_issue_closure {incident_id=}")
        update_args = remote_args.delta
        current_remote_status = remote_args.data.get('status') if remote_args.data else None
        close_reason = update_args.get('close_reason') or update_args.get('closeReason')
        demisto.debug(f'{current_remote_status=} {remote_args.data=} {remote_args.inc_status=} {close_reason=}')
        # force closing remote incident only if:
        #   The XSOAR incident is closed
        #   and the remote incident isn't already closed
        if remote_args.inc_status == 2 and current_remote_status not in XDR_RESOLVED_STATUS_TO_XSOAR and close_reason:
            if close_notes := update_args.get('closeNotes'):
                demisto.debug(f"handle_outgoing_issue_closure {incident_id=} {close_notes=}")
                update_args['resolve_comment'] = close_notes

            xdr_close_reason = resolve_xdr_close_reason(close_reason)
            update_args['status'] = xdr_close_reason
            demisto.debug(f"handle_outgoing_issue_closure Closing Remote incident {incident_id=} with status {update_args['status']}")


    def get_update_args(remote_args):
        """Change the updated field names to fit the update command"""

        handle_outgoing_issue_closure(remote_args)
        handle_outgoing_incident_owner_sync(remote_args.delta)
        handle_user_unassignment(remote_args.delta)
        return remote_args.delta


    def get_distribution_versions_command(client, args):
        versions = client.get_distribution_versions()

        readable_output = []
        for operation_system in versions:
            os_versions = versions[operation_system]

            readable_output.append(
                tableToMarkdown(operation_system, os_versions or [], ['versions'])
            )

        return (
            '\n\n'.join(readable_output),
            {
                f'{args.get("integration_context_brand", "CoreApiModule")}.DistributionVersions': versions
            },
            versions
        )


    def create_distribution_command(client, args):
        name = args.get('name')
        platform = args.get('platform')
        package_type = args.get('package_type')
        description = args.get('description')
        agent_version = args.get('agent_version')
        if not platform == 'android' and not agent_version:
            # agent_version must be provided for all the platforms except android
            raise ValueError(f'Missing argument "agent_version" for platform "{platform}"')

        distribution_id = client.create_distribution(
            name=name,
            platform=platform,
            package_type=package_type,
            agent_version=agent_version,
            description=description
        )

        distribution = {
            'id': distribution_id,
            'name': name,
            'platform': platform,
            'package_type': package_type,
            'agent_version': agent_version,
            'description': description
        }

        return (
            f'Distribution {distribution_id} created successfully',
            {
                f'{args.get("integration_context_brand", "CoreApiModule")}.Distribution(val.id == obj.id)': distribution
            },
            distribution
        )


    def delete_endpoints_command(client: CoreClient, args: Dict[str, str]) -> Tuple[str, Any, Any]:
        endpoint_id_list: list = argToList(args.get('endpoint_ids'))

        client.delete_endpoints(endpoint_id_list)

        return f'Successfully deleted the following endpoints: {args.get("endpoint_ids")}', None, None


    def get_policy_command(client: CoreClient, args: Dict[str, str]) -> Tuple[str, dict, Any]:
        endpoint_id = args.get('endpoint_id')

        reply = client.get_policy(endpoint_id)
        context = {'endpoint_id': endpoint_id,
                   'policy_name': reply.get('policy_name')}

        return (
            f'The policy name of endpoint: {endpoint_id} is: {reply.get("policy_name")}.',
            {
                f'{args.get("integration_context_brand", "CoreApiModule")}.Policy(val.endpoint_id == obj.endpoint_id)': context
            },
            reply
        )


    def get_endpoint_device_control_violations_command(client: CoreClient, args: Dict[str, str]) -> Tuple[str, dict, Any]:
        endpoint_ids: list = argToList(args.get('endpoint_ids'))
        type_of_violation = args.get('type')
        timestamp_gte: int = arg_to_timestamp(
            arg=args.get('timestamp_gte'),
            arg_name='timestamp_gte'
        )
        timestamp_lte: int = arg_to_timestamp(
            arg=args.get('timestamp_lte'),
            arg_name='timestamp_lte'
        )
        ip_list: list = argToList(args.get('ip_list'))
        vendor: list = argToList(args.get('vendor'))
        vendor_id: list = argToList(args.get('vendor_id'))
        product: list = argToList(args.get('product'))
        product_id: list = argToList(args.get('product_id'))
        serial: list = argToList(args.get('serial'))
        hostname: list = argToList(args.get('hostname'))
        violation_id_list: list = argToList(args.get('violation_id_list', ''))
        username: list = argToList(args.get('username'))

        violation_ids = [arg_to_int(arg=item, arg_name=str(item)) for item in violation_id_list]

        reply = client.get_endpoint_device_control_violations(
            endpoint_ids=endpoint_ids,
            type_of_violation=[type_of_violation],
            timestamp_gte=timestamp_gte,
            timestamp_lte=timestamp_lte,
            ip_list=ip_list,
            vendor=vendor,
            vendor_id=vendor_id,
            product=product,
            product_id=product_id,
            serial=serial,
            hostname=hostname,
            violation_ids=violation_ids,
            username=username
        )

        headers = ['date', 'hostname', 'platform', 'username', 'ip', 'type', 'violation_id', 'vendor', 'product',
                   'serial']
        violations: list = copy.deepcopy(reply.get('violations'))  # type: ignore
        for violation in violations:
            timestamp: str = violation.get('timestamp')
            violation['date'] = timestamp_to_datestring(timestamp, TIME_FORMAT)

        return (
            tableToMarkdown(name='Endpoint Device Control Violation', t=violations, headers=headers,
                            headerTransform=string_to_table_header, removeNull=True),
            {
                f'{args.get("integration_context_brand", "CoreApiModule")}.'
                f'EndpointViolations(val.violation_id==obj.violation_id)': violations
            },
            reply
        )


    def retrieve_file_details_command(client: CoreClient, args, add_to_context):
        action_id_list = argToList(args.get('action_id', ''))
        action_id_list = [arg_to_int(arg=item, arg_name=str(item)) for item in action_id_list]

        result = []
        raw_result = []
        file_results = []
        endpoints_count = 0
        retrived_files_count = 0

        for action_id in action_id_list:
            data = client.retrieve_file_details(action_id)
            raw_result.append(data)

            for endpoint, link in data.items():
                endpoints_count += 1
                obj = {
                    'action_id': action_id,
                    'endpoint_id': endpoint
                }
                if link:
                    retrived_files_count += 1
                    obj['file_link'] = link
                    file_link = "download" + link.split("download")[1]
                    file = client.get_file_by_url_suffix(url_suffix=file_link)
                    file_results.append(fileResult(filename=f'{endpoint}_{retrived_files_count}.zip', data=file))
                result.append(obj)

        hr = f'### Action id : {args.get("action_id", "")} \n Retrieved {retrived_files_count} files from ' \
             f'{endpoints_count} endpoints. \n To get the exact action status run the core-action-status-get command'
        context = {f'{args.get("integration_context_brand", "CoreApiModule")}'
                   f'.RetrievedFiles(val.action_id == obj.action_id)': result}
        return_entry = {'Type': entryTypes['note'],
                        'ContentsFormat': formats['json'],
                        'Contents': raw_result,
                        'HumanReadable': hr,
                        'ReadableContentsFormat': formats['markdown'],
                        'EntryContext': context if add_to_context else {}
                        }
        return return_entry, file_results


    def get_scripts_command(client: CoreClient, args: Dict[str, str]) -> Tuple[str, dict, Any]:
        script_name: list = argToList(args.get('script_name'))
        description: list = argToList(args.get('description'))
        created_by: list = argToList(args.get('created_by'))
        windows_supported = args.get('windows_supported')
        linux_supported = args.get('linux_supported')
        macos_supported = args.get('macos_supported')
        is_high_risk = args.get('is_high_risk')
        offset = arg_to_int(arg=args.get('offset', 0), arg_name='offset')
        limit = arg_to_int(arg=args.get('limit', 50), arg_name='limit')

        result = client.get_scripts(
            name=script_name,
            description=description,
            created_by=created_by,
            windows_supported=[windows_supported],
            linux_supported=[linux_supported],
            macos_supported=[macos_supported],
            is_high_risk=[is_high_risk]
        )
        scripts = copy.deepcopy(result.get('scripts')[offset:(offset + limit)])  # type: ignore
        for script in scripts:
            timestamp = script.get('modification_date')
            script['modification_date_timestamp'] = timestamp
            script['modification_date'] = timestamp_to_datestring(timestamp, TIME_FORMAT)
        headers: list = ['name', 'description', 'script_uid', 'modification_date', 'created_by',
                         'windows_supported', 'linux_supported', 'macos_supported', 'is_high_risk']

        return (
            tableToMarkdown(name='Scripts', t=scripts, headers=headers, removeNull=True,
                            headerTransform=string_to_table_header),
            {
                f'{args.get("integration_context_brand", "CoreApiModule")}.Scripts(val.script_uid == obj.script_uid)': scripts
            },
            result
        )


    def get_script_metadata_command(client: CoreClient, args: Dict[str, str]) -> Tuple[str, dict, Any]:
        script_uid = args.get('script_uid')

        reply = client.get_script_metadata(script_uid)
        script_metadata = copy.deepcopy(reply)

        timestamp = script_metadata.get('modification_date')
        script_metadata['modification_date_timestamp'] = timestamp
        script_metadata['modification_date'] = timestamp_to_datestring(timestamp, TIME_FORMAT)

        return (
            tableToMarkdown(name='Script Metadata', t=script_metadata, removeNull=True,
                            headerTransform=string_to_table_header),
            {
                f'{args.get("integration_context_brand", "CoreApiModule")}.ScriptMetadata(val.script_uid == obj.script_uid)': reply
            },
            reply
        )


    def get_script_code_command(client: CoreClient, args: Dict[str, str]) -> Tuple[str, dict, Any]:
        script_uid = args.get('script_uid')

        reply = client.get_script_code(script_uid)
        context = {
            'script_uid': script_uid,
            'code': reply
        }

        return (
            f'### Script code: \n ``` {str(reply)} ```',
            {
                f'{args.get("integration_context_brand", "CoreApiModule")}.ScriptCode(val.script_uid == obj.script_uid)': context
            },
            reply
        )


    @polling_function(
        name=demisto.command(),
        interval=arg_to_number(demisto.args().get('polling_interval_in_seconds', 10)),
        # Check for both 'polling_timeout_in_seconds' and 'polling_timeout' to avoid breaking BC:
        timeout=arg_to_number(demisto.args().get('polling_timeout_in_seconds', demisto.args().get('polling_timeout', 600))),
        requires_polling_arg=False  # means it will always be default to poll, poll=true
    )

    def script_run_polling_command(args: dict, client: CoreClient) -> PollResult:
        if action_id := args.get('action_id'):
            response = client.get_script_execution_status(action_id)
            general_status = response.get('reply', {}).get('general_status') or ''

            return PollResult(
                response=get_script_execution_results_command(
                    client, {'action_id': action_id, 'integration_context_brand': 'PaloAltoNetworksXDR'}
                ),
                continue_to_poll=general_status.upper() in ('PENDING', 'IN_PROGRESS')
            )

        else:
            endpoint_ids = argToList(args.get('endpoint_ids'))
            response = get_run_script_execution_response(client, args)
            reply = response.get('reply')
            action_id = reply.get('action_id')

            args['action_id'] = action_id

            return PollResult(
                response=None,  # since polling defaults to true, no need to deliver response here
                continue_to_poll=True,  # if an error is raised from the api, an exception will be raised
                partial_result=CommandResults(
                    outputs_prefix=f'{args.get("integration_context_brand", "CoreApiModule")}.ScriptRun',
                    outputs_key_field='action_id',
                    outputs=reply,
                    raw_response=response,
                    readable_output=f'Waiting for the script to finish running '
                                    f'on the following endpoints: {endpoint_ids}...'
                ),
                args_for_next_run=args
            )


    def get_run_script_execution_response(client: CoreClient, args: Dict):
        script_uid = args.get('script_uid')
        endpoint_ids = argToList(args.get('endpoint_ids'))
        timeout = arg_to_number(args.get('timeout', 600)) or 600
        incident_id = arg_to_number(args.get('incident_id'))
        if parameters := args.get('parameters'):
            try:
                parameters = json.loads(parameters)
            except json.decoder.JSONDecodeError as e:
                raise ValueError(f'The parameters argument is not in a valid JSON structure:\n{e}')
        else:
            parameters = {}
        return client.run_script(script_uid, endpoint_ids, parameters, timeout, incident_id=incident_id)


    def run_script_command(client: CoreClient, args: Dict) -> CommandResults:
        response = get_run_script_execution_response(client, args)
        reply = response.get('reply')
        return CommandResults(
            readable_output=tableToMarkdown('Run Script', reply),
            outputs_prefix=f'{args.get("integration_context_brand", "CoreApiModule")}.ScriptRun',
            outputs_key_field='action_id',
            outputs=reply,
            raw_response=response,
        )


    def get_script_execution_status_command(client: CoreClient, args: Dict) -> CommandResults:
        action_ids = argToList(args.get('action_id', ''))
        replies = []
        raw_responses = []
        for action_id in action_ids:
            response = client.get_script_execution_status(action_id)
            reply = response.get('reply')
            reply['action_id'] = int(action_id)
            replies.append(reply)
            raw_responses.append(response)

        command_result = CommandResults(
            readable_output=tableToMarkdown(f'Script Execution Status - {",".join(str(i) for i in action_ids)}', replies),
            outputs_prefix=f'{args.get("integration_context_brand", "CoreApiModule")}.ScriptStatus',
            outputs_key_field='action_id',
            outputs=replies,
            raw_response=raw_responses,
        )
        return command_result


    def parse_get_script_execution_results(results: List[Dict]) -> List[Dict]:
        parsed_results = []
        api_keys = ['endpoint_name',
                    'endpoint_ip_address',
                    'endpoint_status',
                    'domain',
                    'endpoint_id',
                    'execution_status',
                    'return_value',
                    'standard_output',
                    'retrieved_files',
                    'failed_files',
                    'retention_date']
        for result in results:
            result_keys = result.keys()
            difference_keys = list(set(result_keys) - set(api_keys))
            if difference_keys:
                for key in difference_keys:
                    parsed_res = result.copy()
                    parsed_res['command'] = key
                    parsed_res['command_output'] = result[key]
                    parsed_results.append(parsed_res)
            else:
                parsed_results.append(result.copy())
        return parsed_results


    def get_script_execution_results_command(client: CoreClient, args: Dict) -> List[CommandResults]:
        action_ids = argToList(args.get('action_id', ''))
        command_results = []
        for action_id in action_ids:
            response = client.get_script_execution_results(action_id)
            results = response.get('reply', {}).get('results')
            context = {
                'action_id': int(action_id),
                'results': parse_get_script_execution_results(results),
            }
            command_results.append(CommandResults(
                readable_output=tableToMarkdown(f'Script Execution Results - {action_id}', results),
                outputs_prefix=f'{args.get("integration_context_brand", "CoreApiModule")}.ScriptResult',
                outputs_key_field='action_id',
                outputs=context,
                raw_response=response,
            ))
        return command_results


    def get_script_execution_result_files_command(client: CoreClient, args: Dict) -> Dict:
        action_id = args.get('action_id', '')
        endpoint_id = args.get('endpoint_id')
        file_response = client.get_script_execution_result_files(action_id, endpoint_id)
        try:
            filename = file_response.headers.get('Content-Disposition').split('attachment; filename=')[1]
        except Exception as e:
            demisto.debug(f'Failed extracting filename from response headers - [{str(e)}]')
            filename = action_id + '.zip'
        return fileResult(filename, file_response.content)


    def add_exclusion_command(client: CoreClient, args: Dict) -> CommandResults:
        name = args.get('name')
        indicator = args.get('filterObject')
        if not indicator:
            raise DemistoException("Didn't get filterObject arg. This arg is required.")
        status = args.get('status', "ENABLED")
        comment = args.get('comment')

        res = client.add_exclusion(name=name,
                                   status=status,
                                   indicator=json.loads(indicator),
                                   comment=comment)

        return CommandResults(
            readable_output=tableToMarkdown('Add Exclusion', res),
            outputs={
                f'{args.get("integration_context_brand", "CoreApiModule")}.exclusion.rule_id(val.rule_id == obj.rule_id)': res.get(
                    "rule_id")},
            raw_response=res
        )


    def delete_exclusion_command(client: CoreClient, args: Dict) -> CommandResults:
        alert_exclusion_id = arg_to_number(args.get('alert_exclusion_id'))
        if not alert_exclusion_id:
            raise DemistoException("Didn't get alert_exclusion_id arg. This arg is required.")
        res = client.delete_exclusion(alert_exclusion_id=alert_exclusion_id)
        return CommandResults(
            readable_output=f"Successfully deleted the following exclusion: {alert_exclusion_id}",
            outputs={
                f'{args.get("integration_context_brand", "CoreApiModule")}.'
                f'deletedExclusion.rule_id(val.rule_id == obj.rule_id)': res.get(
                    "rule_id")},
            raw_response=res
        )


    def get_exclusion_command(client: CoreClient, args: Dict) -> CommandResults:
        res = client.get_exclusion(tenant_id=args.get('tenant_ID'),
                                   filter=args.get('filterObject'),
                                   limit=arg_to_number(args.get('limit', 20)))

        return CommandResults(
            outputs_prefix=f'{args.get("integration_context_brand", "CoreApiModule")}.exclusion',
            outputs=res,
            readable_output=tableToMarkdown('Exclusion', res),
            raw_response=res
        )


    def decode_dict_values(dict_to_decode: dict):
        """Decode JSON str values of a given dict.

        Args:
          dict_to_decode (dict): The dict to decode.

        """
        for key, value in dict_to_decode.items():
            # if value is a dictionary, we want to recursively decode it's values
            if isinstance(value, dict):
                decode_dict_values(value)
            # if value is a string, we want to try to decode it, if it cannot be decoded, we will move on.
            elif isinstance(value, str):
                try:
                    dict_to_decode[key] = json.loads(value)
                except ValueError:
                    continue


    def filter_general_fields(alert: dict, filter_fields: bool = True) -> dict:
        """filter only relevant general fields from a given alert.

        Args:
          alert (dict): The alert to filter
          filter_fields (bool): Whether to return a subset of the fields.

        Returns:
          dict: The filtered alert
        """

        if filter_fields:
            result = {k: v for k, v in alert.items() if k in ALERT_GENERAL_FIELDS}
        else:
            result = alert

        if not (event := alert.get('raw_abioc', {}).get('event', {})):
            return_warning('No XDR cloud analytics event.')
            return result

        if filter_fields:
            updated_event = {k: v for k, v in event.items() if k in ALERT_EVENT_GENERAL_FIELDS}
        else:
            updated_event = event

        result['event'] = updated_event
        return result


    def filter_vendor_fields(alert: dict):
        """Remove non relevant fields from the alert event (filter by vendor: Amazon/google/Microsoft)

        Args:
          alert (dict): The alert to filter

        Returns:
          dict: The filtered alert
        """
        vendor_mapper = {
            'Amazon': ALERT_EVENT_AWS_FIELDS,
            'Google': ALERT_EVENT_GCP_FIELDS,
            'MSFT': ALERT_EVENT_AZURE_FIELDS,
        }
        event = alert.get('event', {})
        vendor = event.get('vendor')
        if vendor and vendor in vendor_mapper:
            raw_log = event.get('raw_log', {})
            if raw_log and isinstance(raw_log, dict):
                for key in list(raw_log):
                    if key not in vendor_mapper[vendor]:
                        raw_log.pop(key)


    def get_original_alerts_command(client: CoreClient, args: Dict) -> CommandResults:
        alert_id_list = argToList(args.get('alert_ids', []))
        raw_response = client.get_original_alerts(alert_id_list)
        reply = copy.deepcopy(raw_response)
        alerts = reply.get('alerts', [])
        processed_alerts = []
        filtered_alerts = []

        filter_fields_argument = argToBoolean(args.get('filter_alert_fields', True))  # default, for BC, is True.

        for alert in alerts:
            # decode raw_response
            try:
                alert['original_alert_json'] = safe_load_json(alert.get('original_alert_json', ''))
                # some of the returned JSON fields are double encoded, so it needs to be double-decoded.
                # example: {"x": "someValue", "y": "{\"z\":\"anotherValue\"}"}
                decode_dict_values(alert)
            except Exception as e:
                demisto.debug("encountered the following while decoding dictionary values, skipping")
                demisto.debug(e)
                continue

            # Remove original_alert_json field and add its content to the alert body.
            alert.update(alert.pop('original_alert_json', {}))

            # Process the alert (with without filetring fields)
            processed_alerts.append(filter_general_fields(alert, filter_fields=False))

            # Create a filtered version (used either for output when filter_fields is False, or for readable output)
            filtered_alert = filter_general_fields(alert, filter_fields=True)
            filter_vendor_fields(filtered_alert)  # changes in-place

            filtered_alerts.append(filtered_alert)

        return CommandResults(
            outputs_prefix=f'{args.get("integration_context_brand", "CoreApiModule")}.OriginalAlert',
            outputs_key_field='internal_id',
            outputs=filtered_alerts if filter_fields_argument else processed_alerts,
            readable_output=tableToMarkdown("Alerts", t=filtered_alerts),  # Filtered are always used for readable output
            raw_response=raw_response,
        )


    ALERT_STATUS_TYPES = {
        'DETECTED': 'detected',
        'DETECTED_0': 'detected (allowed the session)',
        'DOWNLOAD': 'detected (download)',
        'DETECTED_19': 'detected (forward)',
        'POST_DETECTED': 'detected (post detected)',
        'PROMPT_ALLOW': 'detected (prompt allow)',
        'DETECTED_4': 'detected (raised an alert)',
        'REPORTED': 'detected (reported)',
        'REPORTED_TRIGGER_4': 'detected (on write)',
        'SCANNED': 'detected (scanned)',
        'DETECTED_23': 'detected (sinkhole)',
        'DETECTED_18': 'detected (syncookie sent)',
        'DETECTED_21': 'detected (wildfire upload failure)',
        'DETECTED_20': 'detected (wildfire upload success)',
        'DETECTED_22': 'detected (wildfire upload skip)',
        'DETECTED_MTH': 'detected (xdr managed threat hunting)',
        'BLOCKED_25': 'prevented (block)',
        'BLOCKED': 'prevented (blocked)',
        'BLOCKED_14': 'prevented (block-override)',
        'BLOCKED_5': 'prevented (blocked the url)',
        'BLOCKED_6': 'prevented (blocked the ip)',
        'BLOCKED_13': 'prevented (continue)',
        'BLOCKED_1': 'prevented (denied the session)',
        'BLOCKED_8': 'prevented (dropped all packets)',
        'BLOCKED_2': 'prevented (dropped the session)',
        'BLOCKED_3': 'prevented (dropped the session and sent a tcp reset)',
        'BLOCKED_7': 'prevented (dropped the packet)',
        'BLOCKED_16': 'prevented (override)',
        'BLOCKED_15': 'prevented (override-lockout)',
        'BLOCKED_26': 'prevented (post detected)',
        'PROMPT_BLOCK': 'prevented (prompt block)',
        'BLOCKED_17': 'prevented (random-drop)',
        'BLOCKED_24': 'prevented (silently dropped the session with an icmp unreachable message to the host or application)',
        'BLOCKED_9': 'prevented (terminated the session and sent a tcp reset to both sides of the connection)',
        'BLOCKED_10': 'prevented (terminated the session and sent a tcp reset to the client)',
        'BLOCKED_11': 'prevented (terminated the session and sent a tcp reset to the server)',
        'BLOCKED_TRIGGER_4': 'prevented (on write)',
    }


    ALERT_STATUS_TYPES_REVERSE_DICT = {v: k for k, v in ALERT_STATUS_TYPES.items()}



    def get_alerts_by_filter_command(client: CoreClient, args: Dict) -> CommandResults:
        # get arguments
        request_data: dict = {'filter_data': {}}
        filter_data = request_data['filter_data']
        sort_field = args.pop('sort_field', 'source_insert_ts')
        sort_order = args.pop('sort_order', 'DESC')
        prefix = args.pop("integration_context_brand", "CoreApiModule")
        args.pop("integration_name", None)
        custom_filter = {}
        filter_data['sort'] = [{
            'FIELD': sort_field,
            'ORDER': sort_order
        }]
        offset = args.pop('offset', 0)
        limit = args.pop('limit', 50)
        filter_data['paging'] = {
            'from': int(offset),
            'to': int(limit)
        }
        if not args:
            raise DemistoException('Please provide at least one filter argument.')

        # handle custom filter
        custom_filter_str = args.pop('custom_filter', None)

        if custom_filter_str:
            for arg in args:
                if arg not in ['time_frame', 'start_time', 'end_time']:
                    raise DemistoException(
                        'Please provide either "custom_filter" argument or other filter arguments but not both.')
            try:
                custom_filter = json.loads(custom_filter_str)
            except Exception as e:
                raise DemistoException('custom_filter format is not valid.') from e

        filter_res = create_filter_from_args(args)
        if custom_filter:  # if exists, add custom filter to the built filter
            if 'AND' in custom_filter:
                filter_obj = custom_filter['AND']
                filter_res['AND'].extend(filter_obj)
            else:
                filter_res['AND'].append(custom_filter)

        filter_data['filter'] = filter_res
        demisto.debug(f'sending the following request data: {request_data}')
        raw_response = client.get_alerts_by_filter_data(request_data)

        context = []
        for alert in raw_response.get('alerts', []):
            alert = alert.get('alert_fields')
            if 'alert_action_status' in alert:
                # convert the status, if failed take the original status
                action_status = alert.get('alert_action_status')
                alert['alert_action_status_readable'] = ALERT_STATUS_TYPES.get(action_status, action_status)

            context.append(alert)

        human_readable = [{
            'Alert ID': alert.get('internal_id'),
            'Detection Timestamp': timestamp_to_datestring(alert.get('source_insert_ts')),
            'Name': alert.get('alert_name'),
            'Severity': alert.get('severity'),
            'Category': alert.get('alert_category'),
            'Action': alert.get('alert_action_status_readable'),
            'Description': alert.get('alert_description'),
            'Host IP': alert.get('agent_ip_addresses'),
            'Host Name': alert.get('agent_hostname'),
        } for alert in context]

        return CommandResults(
            outputs_prefix=f'{prefix}.Alert',
            outputs_key_field='internal_id',
            outputs=context,
            readable_output=tableToMarkdown('Alerts', human_readable),
            raw_response=raw_response,
        )


    def get_dynamic_analysis_command(client: CoreClient, args: Dict) -> CommandResults:
        alert_id_list = argToList(args.get('alert_ids', []))
        raw_response = client.get_original_alerts(alert_id_list)
        reply = copy.deepcopy(raw_response)
        alerts = reply.get('alerts', [])
        filtered_alerts = []
        for alert in alerts:
            # decode raw_response
            try:
                alert['original_alert_json'] = safe_load_json(alert.get('original_alert_json', ''))
                # some of the returned JSON fields are double encoded, so it needs to be double-decoded.
                # example: {"x": "someValue", "y": "{\"z\":\"anotherValue\"}"}
                decode_dict_values(alert)
            except Exception as e:
                demisto.debug("encountered the following while decoding dictionary values, skipping")
                demisto.debug(e)
            # remove original_alert_json field and add its content to alert.
            alert.update(alert.pop('original_alert_json', {}))
            if demisto.get(alert, 'messageData.dynamicAnalysis'):
                filtered_alerts.append(demisto.get(alert, 'messageData.dynamicAnalysis'))
        if not filtered_alerts:
            return CommandResults(
                readable_output="There is no dynamicAnalysis for these alert ids.",
                raw_response=raw_response
            )
        return CommandResults(
            outputs_prefix=f'{args.get("integration_context_brand", "CoreApiModule")}.DynamicAnalysis',
            outputs=filtered_alerts,
            raw_response=raw_response,
        )


    def create_request_filters(
        status: Optional[str] = None,
        username: Optional[List] = None,
        endpoint_id_list: Optional[List] = None,
        dist_name: Optional[List] = None,
        ip_list: Optional[List] = None,
        public_ip_list: Optional[List] = None,
        group_name: Optional[List] = None,
        platform: Optional[List] = None,
        alias_name: Optional[List] = None,
        isolate: Optional[str] = None,
        hostname: Optional[List] = None,
        first_seen_gte=None,
        first_seen_lte=None,
        last_seen_gte=None,
        last_seen_lte=None,
        scan_status=None,
    ):
        filters = []

        if status:
            filters.append({
                'field': 'endpoint_status',
                'operator': 'IN',
                'value': status if isinstance(status, list) else [status]
            })

        if username:
            filters.append({
                'field': 'username',
                'operator': 'IN',
                'value': username
            })

        if endpoint_id_list:
            filters.append({
                'field': 'endpoint_id_list',
                'operator': 'in',
                'value': endpoint_id_list
            })

        if dist_name:
            filters.append({
                'field': 'dist_name',
                'operator': 'in',
                'value': dist_name
            })

        if ip_list:
            filters.append({
                'field': 'ip_list',
                'operator': 'in',
                'value': ip_list
            })

        if public_ip_list:
            filters.append({
                'field': 'public_ip_list',
                'operator': 'in',
                'value': public_ip_list
            })

        if group_name:
            filters.append({
                'field': 'group_name',
                'operator': 'in',
                'value': group_name
            })

        if platform:
            filters.append({
                'field': 'platform',
                'operator': 'in',
                'value': platform
            })

        if alias_name:
            filters.append({
                'field': 'alias',
                'operator': 'in',
                'value': alias_name
            })

        if isolate:
            filters.append({
                'field': 'isolate',
                'operator': 'in',
                'value': [isolate]
            })

        if hostname:
            filters.append({
                'field': 'hostname',
                'operator': 'in',
                'value': hostname
            })

        if first_seen_gte:
            filters.append({
                'field': 'first_seen',
                'operator': 'gte',
                'value': first_seen_gte
            })

        if first_seen_lte:
            filters.append({
                'field': 'first_seen',
                'operator': 'lte',
                'value': first_seen_lte
            })

        if last_seen_gte:
            filters.append({
                'field': 'last_seen',
                'operator': 'gte',
                'value': last_seen_gte
            })

        if last_seen_lte:
            filters.append({
                'field': 'last_seen',
                'operator': 'lte',
                'value': last_seen_lte
            })

        if scan_status:
            filters.append({
                'field': 'scan_status',
                'operator': 'IN',
                'value': [scan_status]
            })

        return filters


    def args_to_request_filters(args):
        if set(args.keys()) & {  # check if any filter argument was provided
            'endpoint_id_list', 'dist_name', 'ip_list', 'group_name', 'platform', 'alias_name',
            'isolate', 'hostname', 'status', 'first_seen_gte', 'first_seen_lte', 'last_seen_gte', 'last_seen_lte'
        }:
            endpoint_id_list = argToList(args.get('endpoint_id_list'))
            dist_name = argToList(args.get('dist_name'))
            ip_list = argToList(args.get('ip_list'))
            group_name = argToList(args.get('group_name'))
            platform = argToList(args.get('platform'))
            alias_name = argToList(args.get('alias_name'))
            isolate = args.get('isolate')
            hostname = argToList(args.get('hostname'))
            status = args.get('status')

            first_seen_gte = arg_to_timestamp(
                arg=args.get('first_seen_gte'),
                arg_name='first_seen_gte'
            )

            first_seen_lte = arg_to_timestamp(
                arg=args.get('first_seen_lte'),
                arg_name='first_seen_lte'
            )

            last_seen_gte = arg_to_timestamp(
                arg=args.get('last_seen_gte'),
                arg_name='last_seen_gte'
            )

            last_seen_lte = arg_to_timestamp(
                arg=args.get('last_seen_lte'),
                arg_name='last_seen_lte'
            )

            return create_request_filters(
                endpoint_id_list=endpoint_id_list, dist_name=dist_name, ip_list=ip_list,
                group_name=group_name, platform=platform, alias_name=alias_name, isolate=isolate, hostname=hostname,
                first_seen_lte=first_seen_lte, first_seen_gte=first_seen_gte,
                last_seen_lte=last_seen_lte, last_seen_gte=last_seen_gte, status=status
            )
        # a request must be sent with at least one filter parameter, so by default we will send the endpoint_id_list filter
        return create_request_filters(endpoint_id_list=argToList(args.get('endpoint_ids')))


    def add_tag_to_endpoints_command(client: CoreClient, args: Dict):
        endpoint_ids = argToList(args.get('endpoint_ids', []))
        tag = args.get('tag')
        raw_response = {}
        for b in batch(endpoint_ids, 1000):
            raw_response.update(client.add_tag_endpoint(endpoint_ids=b, tag=tag, args=args))

        return CommandResults(
            readable_output=f'Successfully added tag {tag} to endpoint(s) {endpoint_ids}', raw_response=raw_response
        )


    def remove_tag_from_endpoints_command(client: CoreClient, args: Dict):
        endpoint_ids = argToList(args.get('endpoint_ids', []))
        tag = args.get('tag')
        raw_response = {}
        for b in batch(endpoint_ids, 1000):
            raw_response.update(client.remove_tag_endpoint(endpoint_ids=b, tag=tag, args=args))

        return CommandResults(
            readable_output=f'Successfully removed tag {tag} from endpoint(s) {endpoint_ids}', raw_response=raw_response
        )


    def parse_risky_users_or_hosts(user_or_host_data: dict[str, Any],
                                   id_header: str,
                                   score_header: str,
                                   description_header: str
                                   ) -> dict[str, Any]:
        reasons = user_or_host_data.get('reasons', [])
        return {
            id_header: user_or_host_data.get('id'),
            score_header: user_or_host_data.get('score'),
            description_header: reasons[0].get('description') if reasons else None,
        }


    def parse_user_groups(group: dict[str, Any]) -> list[dict[str, Any]]:
        return [
            {
                'User email': user,
                'Group Name': group.get('group_name'),
                'Group Description': group.get('description'),
            }
            for user in group.get("user_email", [])
        ]


    def parse_role_names(role_data: dict[str, Any]) -> dict[str, Any]:
        return {
            "Role Name": role_data.get("pretty_name"),
            "Description": role_data.get("description"),
            "Permissions": role_data.get("permissions", []),
            "Users": role_data.get("users", []),
            "Groups": role_data.get("groups", []),
        }


    def enrich_error_message_id_group_role(e: DemistoException, type_: str | None, custom_message: str | None) -> str | None:
        """
        Attempts to parse additional info from an exception and return it as string. Returns `None` if it can't do that.

        Args:
            e (Exception): The error that occurred.
            type (str | None): The type of resource associated with the error(Role id or Group), if applicable.
            custom_message (str | None): A custom error message to be included in the raised ValueError, if desired.

        Raises:
            ValueError: If the error message indicates that the resource was not found, a more detailed error message
                is constructed using the `find_the_cause_error` function and raised with the original error as the cause.
        """
        if (
            e.res is not None
            and e.res.status_code == 500
            and 'was not found' in str(e)
        ):
            error_message: str = ''
            pattern = r"(id|Group|Role) \\?'([/A-Za-z 0-9_]+)\\?'"
            if match := re.search(pattern, str(e)):
                error_message = f'Error: {match[1]} {match[2]} was not found. '

            return (f'{error_message}{custom_message if custom_message and type_ in ("Group", "Role") else ""}'
                    f'Full error message: {e}')
        return None


    def list_users_command(client: CoreClient, args: dict[str, str]) -> CommandResults:
        """
        Returns a list of all users using the Core API client.

        Args:
            client: A CoreClient instance used for connecting to the Core API.
            args: A dictionary containing additional arguments. Possible keys include:
                - integration_context_brand (str): The name of the integration context brand.

        Returns:
            A CommandResults object containing the readable_output and outputs fields.

        Raises:
            ValueError: If the API connection failed.
        """

        def parse_user(user: dict[str, Any]) -> dict[str, Any]:
            return {
                'User email': user.get('user_email'),
                'First Name': user.get('user_first_name'),
                'Last Name': user.get('user_last_name'),
                'Role': user.get('role_name'),
                'Type': user.get('user_type'),
                'Groups': user.get('groups'),
            }

        listed_users: list[dict[str, Any]] = client.list_users().get('reply', [])
        table_for_markdown = [parse_user(user) for user in listed_users]
        readable_output = tableToMarkdown(name='Users', t=table_for_markdown)

        return CommandResults(
            readable_output=readable_output,
            outputs_prefix=f'{args.get("integration_context_brand", "CoreApiModule")}.User',
            outputs_key_field='user_email',
            outputs=listed_users,
        )


    def list_user_groups_command(client: CoreClient, args: dict[str, str]) -> CommandResults:
        """
         Retrieves a list of user groups from the Core API module based on the specified group names.

        Args:
            client: A CoreClient object used to communicate with the Core API module.
            args: A dictionary of arguments passed to the function. The following keys may be present:
                - group_names (required): A list of group names to retrieve details for.

        Returns:
            A CommandResults object containing the table of user groups.

        Raises:
            ValueError: If the API connection fails or the specified group name(s) is not found.
        """

        group_names = argToList(args['group_names'])
        try:
            outputs = client.list_user_groups(group_names).get("reply", [])
        except DemistoException as e:
            custom_message = None
            if len(group_names) > 1:
                custom_message = "Note: If you sent more than one group name, they may not exist either. "

            if error_message := enrich_error_message_id_group_role(e=e, type_="Group", custom_message=custom_message):
                raise DemistoException(error_message)
            raise

        table_for_markdown: list[dict[str, str | None]] = []
        for group in outputs:
            table_for_markdown.extend(parse_user_groups(group))

        headers = ["Group Name", "Group Description", "User email"]
        readable_output = tableToMarkdown(name='Groups', t=table_for_markdown, headers=headers)
        return CommandResults(
            readable_output=readable_output,
            outputs_prefix=f'{args.get("integration_context_brand", "CoreApiModule")}.UserGroup',
            outputs_key_field='group_name',
            outputs=outputs,
        )


    def list_roles_command(client: CoreClient, args: dict[str, str]) -> CommandResults:
        """
        Retrieves a list of roles with the provided role names from the Core API.

        Args:
            client: A CoreClient object used to communicate with the Core API module.
            args: A dictionary of arguments. The 'role_names' key should be present and contain a
                  comma-separated string of role names to retrieve.

        Returns:
             A CommandResults object containing the table of roles.

        Raises:
            DemistoException: If an error occurs while retrieving the data from the Core API.
            ValueError: If the input argument is not valid.

        """
        role_names = argToList(args["role_names"])
        try:
            outputs = client.list_roles(role_names).get("reply", [])
        except DemistoException as e:
            custom_message = None
            if len(role_names) > 1:
                custom_message = "Note: If you sent more than one Role name, they may not exist either. "

            if error_message := enrich_error_message_id_group_role(e=e, type_="Role", custom_message=custom_message):
                raise DemistoException(error_message)
            raise

        headers = ["Role Name", "Description", "Permissions", "Users", "Groups"]
        table_for_markdown = [parse_role_names(role[0]) for role in outputs if len(role) == 1]
        readable_output = tableToMarkdown(
            name='Roles',
            t=table_for_markdown,
            headers=headers
        )
        return CommandResults(
            readable_output=readable_output,
            outputs_prefix=f'{args.get("integration_context_brand", "CoreApiModule")}.Role',
            outputs_key_field='pretty_name',
            outputs=outputs,
        )


    def change_user_role_command(client: CoreClient, args: dict[str, str]) -> CommandResults:
        """
         Changes or removes the role of user(s) in the system.

        Args:
            client (CoreClient): An instance of the CoreClient class used to interact with the system.
            args (dict[str, str]): A dictionary containing the command arguments.
                - 'user_emails' (str): A comma-separated string of user emails.
                - 'role_name' (str, optional): The name of the role to assign to the user(s).
                  If not provided, the role for the user(s) will be removed.

        Returns:
            CommandResults: An object containing the result of the command execution.
        """
        user_emails = argToList(args['user_emails'])

        if role_name := args.get('role_name'):
            res = client.set_user_role(user_emails, role_name)["reply"]
            action_message = "updated"
        else:
            res = client.remove_user_role(user_emails)["reply"]
            action_message = "removed"

        if not (count := int(res["update_count"])):
            raise DemistoException(f"No user role has been {action_message}.")

        plural_suffix = 's' if count > 1 else ''

        return CommandResults(
            readable_output=f"Role was {action_message} successfully for {count} user{plural_suffix}."
        )


    def list_risky_users_or_host_command(client: CoreClient, command: str, args: dict[str, str]) -> CommandResults:
        """
        Retrieves a list of risky users or details about a specific user's risk score.

        Args:
            client: A CoreClient object used to communicate with the API.
            args: A dictionary containing the following headers (optional):
                - user_id [str]: ID of the user to retrieve risk score details for.
                - limit [str]: Specifying the maximum number of risky users to return.

        Returns:
            A CommandResults object, in case the user was not found, an appropriate message will be returend.

        Raises:
            ValueError: If the API connection fails.

        """

        def _warn_if_module_is_disabled(e: DemistoException) -> None:
            if (
                e is not None
                and e.res is not None
                and e.res.status_code == 500
                and 'No identity threat' in str(e)
                and "An error occurred while processing XDR public API" in e.message
            ):
                return_warning(f'Please confirm the XDR Identity Threat Module is enabled.\nFull error message: {e}', exit=True)

        match command:
            case "user":
                id_key = "user_id"
                table_title = "Risky Users"
                outputs_prefix = "RiskyUser"
                get_func = client.list_risky_users
                table_headers = ["User ID", "Score", "Description"]
            case 'host':
                id_key = "host_id"
                table_title = "Risky Hosts"
                outputs_prefix = "RiskyHost"
                get_func = client.list_risky_hosts
                table_headers = ["Host ID", "Score", "Description"]

        outputs: list[dict] | dict
        if id_ := args.get(id_key):
            try:
                outputs = client.risk_score_user_or_host(id_).get('reply', {})
            except DemistoException as e:
                _warn_if_module_is_disabled(e)
                if error_message := enrich_error_message_id_group_role(e=e, type_="id", custom_message=""):
                    not_found_message = 'was not found'
                    if not_found_message in error_message:
                        return CommandResults(readable_output=f'The {command} {id_} {not_found_message}')
                    else:
                        raise DemistoException(error_message)
                else:
                    raise

            table_for_markdown = [parse_risky_users_or_hosts(outputs, *table_headers)]  # type: ignore[arg-type]

        else:
            list_limit = int(args.get('limit', 50))

            try:
                outputs = get_func().get('reply', [])[:list_limit]
            except DemistoException as e:
                _warn_if_module_is_disabled(e)
                raise
            table_for_markdown = [parse_risky_users_or_hosts(user, *table_headers) for user in outputs]

        readable_output = tableToMarkdown(name=table_title, t=table_for_markdown, headers=table_headers)

        return CommandResults(
            readable_output=readable_output,
            outputs_prefix=f'{args.get("integration_context_brand", "CoreApiModule")}.{outputs_prefix}',
            outputs_key_field='id',
            outputs=outputs,
        )


    def get_incidents_command(client, args):
        """
        Retrieve a list of incidents from XDR, filtered by some filters.
        """

        # sometimes incident id can be passed as integer from the playbook
        incident_id_list = args.get('incident_id_list')
        if isinstance(incident_id_list, int):
            incident_id_list = str(incident_id_list)

        incident_id_list = argToList(incident_id_list)
        # make sure all the ids passed are strings and not integers
        for index, id_ in enumerate(incident_id_list):
            if isinstance(id_, int | float):
                incident_id_list[index] = str(id_)

        lte_modification_time = args.get('lte_modification_time')
        gte_modification_time = args.get('gte_modification_time')
        since_modification_time = args.get('since_modification_time')

        if since_modification_time and gte_modification_time:
            raise ValueError('Can\'t set both since_modification_time and lte_modification_time')
        if since_modification_time:
            gte_modification_time, _ = parse_date_range(since_modification_time, TIME_FORMAT)

        lte_creation_time = args.get('lte_creation_time')
        gte_creation_time = args.get('gte_creation_time')
        since_creation_time = args.get('since_creation_time')

        if since_creation_time and gte_creation_time:
            raise ValueError('Can\'t set both since_creation_time and lte_creation_time')
        if since_creation_time:
            gte_creation_time, _ = parse_date_range(since_creation_time, TIME_FORMAT)

        statuses = argToList(args.get('status', ''))

        starred = argToBoolean(args.get('starred')) if args.get('starred', None) not in ('', None) else None
        starred_incidents_fetch_window = args.get('starred_incidents_fetch_window', '3 days')
        starred_incidents_fetch_window, _ = parse_date_range(starred_incidents_fetch_window, to_timestamp=True)

        sort_by_modification_time = args.get('sort_by_modification_time')
        sort_by_creation_time = args.get('sort_by_creation_time')

        page = int(args.get('page', 0))
        limit = int(args.get('limit', 100))

        # If no filters were given, return a meaningful error message
        if not incident_id_list and (not lte_modification_time and not gte_modification_time and not since_modification_time
                                     and not lte_creation_time and not gte_creation_time and not since_creation_time
                                     and not statuses and not starred):
            raise ValueError("Specify a query for the incidents.\nFor example:"
                             " since_creation_time=\"1 year\" sort_by_creation_time=\"desc\" limit=10")

        if statuses:
            raw_incidents = []

            for status in statuses:
                raw_incidents += client.get_incidents(
                    incident_id_list=incident_id_list,
                    lte_modification_time=lte_modification_time,
                    gte_modification_time=gte_modification_time,
                    lte_creation_time=lte_creation_time,
                    gte_creation_time=gte_creation_time,
                    sort_by_creation_time=sort_by_creation_time,
                    sort_by_modification_time=sort_by_modification_time,
                    page_number=page,
                    limit=limit,
                    status=status,
                    starred=starred,
                    starred_incidents_fetch_window=starred_incidents_fetch_window,
                )

            if len(raw_incidents) > limit:
                raw_incidents = raw_incidents[:limit]
        else:
            raw_incidents = client.get_incidents(
                incident_id_list=incident_id_list,
                lte_modification_time=lte_modification_time,
                gte_modification_time=gte_modification_time,
                lte_creation_time=lte_creation_time,
                gte_creation_time=gte_creation_time,
                sort_by_creation_time=sort_by_creation_time,
                sort_by_modification_time=sort_by_modification_time,
                page_number=page,
                limit=limit,
                starred=starred,
                starred_incidents_fetch_window=starred_incidents_fetch_window,
            )

        return (
            tableToMarkdown('Incidents', raw_incidents),
            {
                f'{args.get("integration_context_brand", "CoreApiModule")}.Incident(val.incident_id==obj.incident_id)': raw_incidents
            },
            raw_incidents
        )

    register_module_line('CoreIRApiModule', 'end', __line__(), wrapper=1)

    ### END GENERATED CODE ###


    # Disable insecure warnings

    urllib3.disable_warnings()


    TIME_FORMAT = "%Y-%m-%dT%H:%M:%S"

    NONCE_LENGTH = 64

    API_KEY_LENGTH = 128


    INTEGRATION_CONTEXT_BRAND = 'PaloAltoNetworksXDR'

    XDR_INCIDENT_TYPE_NAME = 'Cortex XDR Incident Schema'

    INTEGRATION_NAME = 'Cortex XDR - IR'

    ALERTS_LIMIT_PER_INCIDENTS: int = -1

    FIELDS_TO_EXCLUDE = [
        'network_artifacts',
        'file_artifacts'
    ]



    XDR_INCIDENT_FIELDS = {
        "status": {"description": "Current status of the incident: \"new\",\"under_"
                                  "investigation\",\"resolved_known_issue\","
                                  "\"resolved_duplicate\",\"resolved_false_positive\","
                                  "\"resolved_true_positive\",\"resolved_security_testing\",\"resolved_other\"",
                   "xsoar_field_name": 'xdrstatusv2'},
        "assigned_user_mail": {"description": "Email address of the assigned user.",
                               'xsoar_field_name': "xdrassigneduseremail"},
        "assigned_user_pretty_name": {"description": "Full name of the user assigned to the incident.",
                                      "xsoar_field_name": "xdrassigneduserprettyname"},
        "resolve_comment": {"description": "Comments entered by the user when the incident was resolved.",
                            "xsoar_field_name": "xdrresolvecomment"},
        "manual_severity": {"description": "Incident severity assigned by the user. "
                                           "This does not affect the calculated severity low medium high",
                            "xsoar_field_name": "severity"},
        "close_reason": {"description": "The close reason of the XSOAR incident",
                         "xsoar_field_name": "closeReason"}
    }


    MIRROR_DIRECTION = {
        'None': None,
        'Incoming': 'In',
        'Outgoing': 'Out',
        'Both': 'Both'
    }


    XSOAR_TO_XDR = "XSOAR -> XDR"

    XDR_TO_XSOAR = "XDR -> XSOAR"



    def convert_epoch_to_milli(timestamp):
        if timestamp is None:
            return None
        if 9 < len(str(timestamp)) < 13:
            timestamp = int(timestamp) * 1000
        return int(timestamp)


    def convert_datetime_to_epoch(the_time: (int | datetime) = 0):
        if the_time is None:
            return None
        try:
            if isinstance(the_time, datetime):
                return int(the_time.strftime('%s'))
        except Exception as err:
            demisto.debug(err)
            return 0


    def convert_datetime_to_epoch_millis(the_time: (int | datetime) = 0):
        return convert_epoch_to_milli(convert_datetime_to_epoch(the_time=the_time))


    def generate_current_epoch_utc():
        return convert_datetime_to_epoch_millis(datetime.now(timezone.utc))


    def generate_key():
        return "".join([secrets.choice(string.ascii_letters + string.digits) for _ in range(API_KEY_LENGTH)])


    def create_auth(api_key):
        nonce = "".join([secrets.choice(string.ascii_letters + string.digits) for _ in range(NONCE_LENGTH)])
        timestamp = str(generate_current_epoch_utc())  # Get epoch time utc millis
        hash_ = hashlib.sha256()
        hash_.update((api_key + nonce + timestamp).encode("utf-8"))
        return nonce, timestamp, hash_.hexdigest()


    def clear_trailing_whitespace(res):
        index = 0
        while index < len(res):
            for key, value in res[index].items():
                if isinstance(value, str):
                    res[index][key] = value.rstrip()
            index += 1
        return res


    def filter_and_save_unseen_incident(incidents: List, limit: int, number_of_already_filtered_incidents: int) -> List:
        """
        Filters incidents that were seen already and saves the unseen incidents to LastRun object.
        :param incidents: List of incident - must be list
        :param limit: the maximum number of incident per fetch
        :param number_of_already_filtered_incidents: number of incidents that were fetched already
        :return: the filtered incidents.
        """
        last_run_obj = demisto.getLastRun()
        fetched_starred_incidents = last_run_obj.pop('fetched_starred_incidents', {})
        filtered_incidents = []
        for incident in incidents:
            incident_id = incident.get('incident_id')
            if incident_id in fetched_starred_incidents:
                demisto.debug(f'incident (ID {incident_id}) was already fetched in the past.')
                continue
            fetched_starred_incidents[incident_id] = True
            filtered_incidents.append(incident)
            number_of_already_filtered_incidents += 1
            if number_of_already_filtered_incidents >= limit:
                break

        last_run_obj['fetched_starred_incidents'] = fetched_starred_incidents
        demisto.setLastRun(last_run_obj)
        return filtered_incidents


    def get_xsoar_close_reasons():
        """
         Get the default XSOAR close-reasons in addition to custom close-reasons from server configuration.
        """
        default_xsoar_close_reasons = list(XSOAR_RESOLVED_STATUS_TO_XDR.keys())
        custom_close_reasons: List[str] = []
        try:
            server_config = get_server_config()
            demisto.debug(f'get_xsoar_close_reasons server-config: {str(server_config)}')
            if server_config:
                custom_close_reasons = argToList(server_config.get('incident.closereasons', ''))
        except Exception as e:
            demisto.error(f"Could not get server configuration: {e}")
        return default_xsoar_close_reasons + custom_close_reasons


    def validate_custom_close_reasons_mapping(mapping: str, direction: str):
        """ Check validity of provided custom close-reason mappings. """

        xdr_statuses = [status.replace("resolved_", "").replace("_", " ").title() for status in XDR_RESOLVED_STATUS_TO_XSOAR]
        xsoar_statuses = get_xsoar_close_reasons()

        exception_message = ('Improper custom mapping ({direction}) provided: "{key_or_value}" is not a valid Cortex '
                             '{xsoar_or_xdr} close-reason. Valid Cortex {xsoar_or_xdr} close-reasons are: {statuses}')

        def to_xdr_status(status):
            return "resolved_" + "_".join(status.lower().split(" "))

        custom_mapping = comma_separated_mapping_to_dict(mapping)

        valid_key = valid_value = True  # If no mapping was provided.

        for key, value in custom_mapping.items():
            if direction == XSOAR_TO_XDR:
                xdr_close_reason = to_xdr_status(value)
                valid_key = key in xsoar_statuses
                valid_value = xdr_close_reason in XDR_RESOLVED_STATUS_TO_XSOAR
            elif direction == XDR_TO_XSOAR:
                xdr_close_reason = to_xdr_status(key)
                valid_key = xdr_close_reason in XDR_RESOLVED_STATUS_TO_XSOAR
                valid_value = value in xsoar_statuses

            if not valid_key:
                raise DemistoException(
                    exception_message.format(direction=direction,
                                             key_or_value=key,
                                             xsoar_or_xdr="XSOAR" if direction == XSOAR_TO_XDR else "XDR",
                                             statuses=xsoar_statuses
                                             if direction == XSOAR_TO_XDR else xdr_statuses))
            elif not valid_value:
                raise DemistoException(
                    exception_message.format(direction=direction,
                                             key_or_value=value,
                                             xsoar_or_xdr="XDR" if direction == XSOAR_TO_XDR else "XSOAR",
                                             statuses=xdr_statuses
                                             if direction == XSOAR_TO_XDR else xsoar_statuses))


    class Client(CoreClient):
        def __init__(self, base_url, proxy, verify, timeout, params=None):
            if not params:
                params = {}
            self._params = params
            super().__init__(base_url=base_url, proxy=proxy, verify=verify, headers=self.headers, timeout=timeout)

        @property
        def headers(self):
            return get_headers(self._params)

        def test_module(self, first_fetch_time):
            """
                Performs basic get request to get item samples
            """
            last_one_day, _ = parse_date_range(first_fetch_time, TIME_FORMAT)
            try:
                self.get_incidents(lte_creation_time=last_one_day, limit=1)
            except Exception as err:
                if 'API request Unauthorized' in str(err):
                    # this error is received from the XDR server when the client clock is not in sync to the server
                    raise DemistoException(f'{str(err)} please validate that your both '
                                           f'XSOAR and XDR server clocks are in sync')
                else:
                    raise

            # XSOAR -> XDR
            validate_custom_close_reasons_mapping(mapping=self._params.get("custom_xsoar_to_xdr_close_reason_mapping"),
                                                  direction=XSOAR_TO_XDR)

            # XDR -> XSOAR
            validate_custom_close_reasons_mapping(mapping=self._params.get("custom_xdr_to_xsoar_close_reason_mapping"),
                                                  direction=XDR_TO_XSOAR)

        def handle_fetch_starred_incidents(self, limit: int, page_number: int, request_data: dict) -> List:
            """
            handles pagination and filter of starred incidents that were fetched.
            :param limit: the maximum number of incident per fetch
            :param page_number: page number
            :param request_data: the api call request data
            :return: the filtered starred incidents.
            """
            res = self._http_request(
                method='POST',
                url_suffix='/incidents/get_incidents/',
                json_data={'request_data': request_data},
                headers=self.headers,
                timeout=self.timeout
            )
            raw_incidents = res.get('reply', {}).get('incidents', [])

            # we want to avoid duplications of starred incidents in the fetch-incident command (we fetch all incidents
            # in the fetch window).
            filtered_incidents = filter_and_save_unseen_incident(raw_incidents, limit, 0)

            # we want to support pagination on starred incidents.
            while len(filtered_incidents) < limit:
                page_number += 1
                search_from = page_number * limit
                search_to = search_from + limit
                request_data['search_from'] = search_from
                request_data['search_to'] = search_to

                res = self._http_request(
                    method='POST',
                    url_suffix='/incidents/get_incidents/',
                    json_data={'request_data': request_data},
                    headers=self.headers,
                    timeout=self.timeout
                )
                raw_incidents = res.get('reply', {}).get('incidents', [])
                if not raw_incidents:
                    break
                filtered_incidents += filter_and_save_unseen_incident(raw_incidents, limit, len(filtered_incidents))

            return filtered_incidents

        def update_incident(self, incident_id, status=None, assigned_user_mail=None, assigned_user_pretty_name=None, severity=None,
                            resolve_comment=None, unassign_user=None, add_comment=None):
            update_data: dict[str, Any] = {}

            if unassign_user and (assigned_user_mail or assigned_user_pretty_name):
                raise ValueError("Can't provide both assignee_email/assignee_name and unassign_user")
            if unassign_user:
                update_data['assigned_user_mail'] = 'none'

            if assigned_user_mail:
                update_data['assigned_user_mail'] = assigned_user_mail

            if assigned_user_pretty_name:
                update_data['assigned_user_pretty_name'] = assigned_user_pretty_name

            if status:
                update_data['status'] = status

            if severity:
                update_data['manual_severity'] = severity

            if resolve_comment:
                update_data['resolve_comment'] = resolve_comment

            if add_comment:
                update_data['comment'] = {'comment_action': 'add', 'value': add_comment}

            request_data = {
                'incident_id': incident_id,
                'update_data': update_data,
            }

            self._http_request(
                method='POST',
                url_suffix='/incidents/update_incident/',
                json_data={'request_data': request_data},
                headers=self.headers,
                timeout=self.timeout
            )

        def get_incident_extra_data(self, incident_id, alerts_limit=1000):
            """
            Returns incident by id

            :param incident_id: The id of incident
            :param alerts_limit: Maximum number alerts to get
            :return:
            """
            request_data = {
                'incident_id': incident_id,
                'alerts_limit': alerts_limit,
            }

            reply = self._http_request(
                method='POST',
                url_suffix='/incidents/get_incident_extra_data/',
                json_data={'request_data': request_data},
                headers=self.headers,
                timeout=self.timeout
            )

            incident = reply.get('reply')

            return incident

        def save_modified_incidents_to_integration_context(self):
            last_modified_incidents = self.get_incidents(limit=100, sort_by_modification_time='desc')
            modified_incidents_context = {}
            for incident in last_modified_incidents:
                incident_id = incident.get('incident_id')
                modified_incidents_context[incident_id] = incident.get('modification_time')

            set_integration_context({'modified_incidents': modified_incidents_context})

        def get_contributing_event_by_alert_id(self, alert_id: int) -> dict:
            request_data = {
                "request_data": {
                    "alert_id": alert_id,
                }
            }

            reply = self._http_request(
                method='POST',
                url_suffix='/alerts/get_correlation_alert_data/',
                json_data=request_data,
                headers=self.headers,
                timeout=self.timeout,
            )

            return reply.get('reply', {})

        def replace_featured_field(self, field_type: str, fields: list[dict]) -> dict:
            request_data = {
                'request_data': {
                    'fields': fields
                }
            }

            reply = self._http_request(
                method='POST',
                url_suffix=f'/featured_fields/replace_{field_type}',
                json_data=request_data,
                timeout=self.timeout,
                headers=self.headers,
                raise_on_status=True
            )

            return reply.get('reply')

        def get_tenant_info(self):
            reply = self._http_request(
                method='POST',
                url_suffix='/system/get_tenant_info/',
                json_data={'request_data': {}},
                headers=self.headers,
                timeout=self.timeout
            )
            return reply.get('reply', {})

        def get_multiple_incidents_extra_data(self, exclude_artifacts, incident_id_list=[], gte_creation_time_milliseconds=0,
                                              status=None, starred=None, starred_incidents_fetch_window=None,
                                              page_number=0, limit=100):
            """
            Returns incident by id
            :param incident_id_list: The list ids of incidents
            :return:
            Maximum number alerts to get in Maximum number alerts to get in "get_multiple_incidents_extra_data" is 50, not sorted
            """
            global ALERTS_LIMIT_PER_INCIDENTS
            request_data = {}
            filters: List[Any] = []
            if incident_id_list:
                incident_id_list = argToList(incident_id_list, transform=lambda x: str(x))
                filters.append({"field": "incident_id_list", "operator": "in", "value": incident_id_list})
            if status:
                filters.append({
                    'field': 'status',
                    'operator': 'eq',
                    'value': status
                })
            if exclude_artifacts:
                request_data['fields_to_exclude'] = FIELDS_TO_EXCLUDE  # type: ignore

            if starred and starred_incidents_fetch_window:
                filters.append({
                    'field': 'starred',
                    'operator': 'eq',
                    'value': True
                })
                filters.append({
                    'field': 'creation_time',
                    'operator': 'gte',
                    'value': starred_incidents_fetch_window
                })
                if demisto.command() == 'fetch-incidents':
                    if len(filters) > 0:
                        request_data['filters'] = filters
                    incidents = self.handle_fetch_starred_incidents(limit, page_number, request_data)
                    return incidents
            elif gte_creation_time_milliseconds:
                filters.append({
                    'field': 'creation_time',
                    'operator': 'gte',
                    'value': gte_creation_time_milliseconds
                })
            if len(filters) > 0:
                request_data['filters'] = filters

            reply = self._http_request(
                method='POST',
                url_suffix='/incidents/get_multiple_incidents_extra_data/',
                json_data={'request_data': request_data},
                headers=self.headers,
                timeout=self.timeout,
            )
            if ALERTS_LIMIT_PER_INCIDENTS < 0:
                ALERTS_LIMIT_PER_INCIDENTS = arg_to_number(reply.get('reply', {}).get('alerts_limit_per_incident')) or 50
                demisto.debug(f'Setting alerts limit per incident to {ALERTS_LIMIT_PER_INCIDENTS}')
            incidents = reply.get('reply')
            return incidents.get('incidents', {}) if isinstance(incidents, dict) else incidents  # type: ignore

        def update_alerts_in_xdr_request(self, alerts_ids, severity, status, comment) -> List[Any]:
            request_data = {"request_data": {
                "alert_id_list": alerts_ids,
            }}
            update_data = assign_params(severity=severity, status=status, comment=comment)
            request_data['request_data']['update_data'] = update_data
            response = self._http_request(
                method='POST',
                url_suffix='/alerts/update_alerts',
                json_data=request_data,
                headers=self.headers,
                timeout=self.timeout,
            )
            if "reply" not in response or "alerts_ids" not in response["reply"]:
                raise DemistoException(f"Parse Error. Response not in format, can't find reply key. The response {response}.")
            return response['reply']['alerts_ids']


    def get_headers(params: dict) -> dict:
        api_key = params.get('apikey_creds', {}).get('password', '') or params.get('apikey', '')
        api_key_id = params.get('apikey_id_creds', {}).get('password', '') or params.get('apikey_id')
        nonce: str = "".join([secrets.choice(string.ascii_letters + string.digits) for _ in range(64)])
        timestamp: str = str(int(datetime.now(timezone.utc).timestamp()) * 1000)
        auth_key = f"{api_key}{nonce}{timestamp}"
        auth_key = auth_key.encode("utf-8")
        api_key_hash: str = hashlib.sha256(auth_key).hexdigest()

        if argToBoolean(params.get("prevent_only", False)):
            api_key_hash = api_key

        headers: dict = {
            "x-xdr-timestamp": timestamp,
            "x-xdr-nonce": nonce,
            "x-xdr-auth-id": str(api_key_id),
            "Authorization": api_key_hash,
        }

        return headers


    def get_tenant_info_command(client: Client):
        tenant_info = client.get_tenant_info()
        readable_output = tableToMarkdown(
            'Tenant Information', tenant_info, headerTransform=pascalToSpace, removeNull=True, is_auto_json_transform=True
        )
        return CommandResults(
            readable_output=readable_output,
            outputs_prefix=f'{INTEGRATION_CONTEXT_BRAND}.TenantInformation',
            outputs=tenant_info,
            raw_response=tenant_info
        )


    def update_incident_command(client, args):
        incident_id = args.get('incident_id')
        assigned_user_mail = args.get('assigned_user_mail')
        assigned_user_pretty_name = args.get('assigned_user_pretty_name')
        status = args.get('status')
        demisto.debug(f"this_is_the_status {status}")
        severity = args.get('manual_severity')
        unassign_user = args.get('unassign_user') == 'true'
        resolve_comment = args.get('resolve_comment')
        add_comment = args.get('add_comment')
        resolve_alerts = argToBoolean(args.get('resolve_alerts', False))

        if assigned_user_pretty_name and not assigned_user_mail:
            raise DemistoException('To set a new assigned_user_pretty_name, '
                                   'you must also provide a value for the "assigned_user_mail" argument.')

        client.update_incident(
            incident_id=incident_id,
            assigned_user_mail=assigned_user_mail,
            assigned_user_pretty_name=assigned_user_pretty_name,
            unassign_user=unassign_user,
            status=status,
            severity=severity,
            resolve_comment=resolve_comment,
            add_comment=add_comment,
        )
        is_closed = resolve_comment or (status and argToList(status, '_')[0] == 'RESOLVED')
        if resolve_alerts and is_closed:
            args['status'] = args['status'].lower()
            update_related_alerts(client, args)

        return f'Incident {incident_id} has been updated', None, None


    def check_if_incident_was_modified_in_xdr(incident_id, last_mirrored_in_time_timestamp, last_modified_incidents_dict):
        if incident_id in last_modified_incidents_dict:  # search the incident in the dict of modified incidents
            incident_modification_time_in_xdr = int(str(last_modified_incidents_dict[incident_id]))

            demisto.debug(f"XDR incident {incident_id}\n"
                          f"modified time:         {incident_modification_time_in_xdr}\n"
                          f"last mirrored in time: {last_mirrored_in_time_timestamp}")

            if incident_modification_time_in_xdr > last_mirrored_in_time_timestamp:  # need to update this incident
                demisto.info(f"Incident '{incident_id}' was modified. performing extra-data request.")
                return True
            # the incident was not modified
        return False


    def get_last_mirrored_in_time(args):
        demisto_incidents = demisto.get_incidents()  # type: ignore

        if demisto_incidents:  # handling 5.5 version
            demisto_incident = demisto_incidents[0]
            last_mirrored_in_time = demisto_incident.get('CustomFields', {}).get('lastmirroredintime')
            if not last_mirrored_in_time:  # this is an old incident, update anyway
                return 0
            last_mirrored_in_timestamp = arg_to_timestamp(last_mirrored_in_time, 'last_mirrored_in_time')

        else:  # handling 6.0 version
            last_mirrored_in_time = arg_to_timestamp(args.get('last_update'), 'last_update')
            last_mirrored_in_timestamp = (last_mirrored_in_time - (120 * 1000))

        return last_mirrored_in_timestamp


    def sort_incident_data(raw_incident):
        """
        Sorts and processes the raw incident data into a cleaned incident dict.

        Parameters:
        -  raw_incident (dict): The raw incident data as provided by the API.

        Returns:
        - dict: A dictionary containing the processed incident data with:
                - organized alerts.
                - file artifact
                - network artifacts.
        """
        incident = raw_incident.get('incident', {})
        raw_alerts = raw_incident.get('alerts', {}).get('data', [])
        file_artifacts = raw_incident.get('file_artifacts', {}).get('data', [])
        network_artifacts = raw_incident.get('network_artifacts', {}).get('data', [])
        context_alerts = clear_trailing_whitespace(raw_alerts)
        if context_alerts:
            for alert in context_alerts:
                alert['host_ip_list'] = alert.get('host_ip').split(',') if alert.get('host_ip') else []
        incident.update({
            'alerts': context_alerts,
            'file_artifacts': file_artifacts,
            'network_artifacts': network_artifacts
        })
        return incident


    def get_incident_extra_data_command(client, args):
        global ALERTS_LIMIT_PER_INCIDENTS
        incident_id = args.get('incident_id')
        alerts_limit = int(args.get('alerts_limit', 1000))
        exclude_artifacts = argToBoolean(args.get('excluding_artifacts', 'False'))
        return_only_updated_incident = argToBoolean(args.get('return_only_updated_incident', 'False'))
        if return_only_updated_incident:
            last_mirrored_in_time = get_last_mirrored_in_time(args)
            last_modified_incidents_dict = get_integration_context().get('modified_incidents', {})

            if check_if_incident_was_modified_in_xdr(incident_id, last_mirrored_in_time, last_modified_incidents_dict):
                pass  # the incident was modified. continue to perform extra-data request

            else:  # the incident was not modified
                return "The incident was not modified in XDR since the last mirror in.", {}, {}
        raw_incident = client.get_multiple_incidents_extra_data(incident_id_list=[incident_id], exclude_artifacts=exclude_artifacts)
        if not raw_incident:
            raise DemistoException(f'Incident {incident_id} is not found')
        if isinstance(raw_incident, list):
            raw_incident = raw_incident[0]
        if raw_incident.get('incident', {}).get('alert_count') > ALERTS_LIMIT_PER_INCIDENTS:
            demisto.debug(f'for incident:{incident_id} using the old call since "\
                "alert_count:{raw_incident.get("incident", {}).get("alert_count")} >" \
                "limit:{ALERTS_LIMIT_PER_INCIDENTS}')
            raw_incident = client.get_incident_extra_data(incident_id, alerts_limit)
        readable_output = [tableToMarkdown(f'Incident {incident_id}', raw_incident.get('incident'), removeNull=True)]

        incident = sort_incident_data(raw_incident)

        if incident_alerts := incident.get('alerts'):
            readable_output.append(tableToMarkdown('Alerts', incident_alerts,
                                                   headers=[key for key in incident_alerts[0]
                                                            if key != 'host_ip'], removeNull=True))
        readable_output.append(tableToMarkdown('Network Artifacts', incident.get('network_artifacts'), removeNull=True))
        readable_output.append(tableToMarkdown('File Artifacts', incident.get('file_artifacts'), removeNull=True))

        account_context_output = assign_params(
            Username=incident.get('users', '')
        )
        endpoint_context_output = []

        for alert in incident.get('alerts') or []:
            alert_context = {}
            if hostname := alert.get('host_name'):
                alert_context['Hostname'] = hostname
            if endpoint_id := alert.get('endpoint_id'):
                alert_context['ID'] = endpoint_id
            if alert_context:
                endpoint_context_output.append(alert_context)
        context_output = {f'{INTEGRATION_CONTEXT_BRAND}.Incident(val.incident_id==obj.incident_id)': incident}
        if account_context_output:
            context_output['Account(val.Username==obj.Username)'] = account_context_output
        if endpoint_context_output:
            context_output['Endpoint(val.Hostname==obj.Hostname)'] = endpoint_context_output
        file_context, process_context, domain_context, ip_context = get_indicators_context(incident)
        if file_context:
            context_output[Common.File.CONTEXT_PATH] = file_context
        if domain_context:
            context_output[Common.Domain.CONTEXT_PATH] = domain_context
        if ip_context:
            context_output[Common.IP.CONTEXT_PATH] = ip_context
        if process_context:
            context_output['Process(val.Name && val.Name == obj.Name)'] = process_context

        return (
            '\n'.join(readable_output),
            context_output,
            raw_incident
        )


    def create_parsed_alert(product, vendor, local_ip, local_port, remote_ip, remote_port, event_timestamp, severity,
                            alert_name, alert_description):
        alert = {
            "product": product,
            "vendor": vendor,
            "local_ip": local_ip,
            "local_port": local_port,
            "remote_ip": remote_ip,
            "remote_port": remote_port,
            "event_timestamp": event_timestamp,
            "severity": severity,
            "alert_name": alert_name,
            "alert_description": alert_description
        }

        return alert


    def insert_parsed_alert_command(client, args):
        product = args.get('product')
        vendor = args.get('vendor')
        local_ip = args.get('local_ip')
        local_port = arg_to_int(
            arg=args.get('local_port'),
            arg_name='local_port'
        )
        remote_ip = args.get('remote_ip')
        remote_port = arg_to_int(
            arg=args.get('remote_port'),
            arg_name='remote_port'
        )

        severity = args.get('severity')
        alert_name = args.get('alert_name')
        alert_description = args.get('alert_description', '')

        event_timestamp = int(round(time.time() * 1000)) if args.get("event_timestamp") is None else int(args.get("event_timestamp"))

        alert = create_parsed_alert(
            product=product,
            vendor=vendor,
            local_ip=local_ip,
            local_port=local_port,
            remote_ip=remote_ip,
            remote_port=remote_port,
            event_timestamp=event_timestamp,
            severity=severity,
            alert_name=alert_name,
            alert_description=alert_description
        )

        client.insert_alerts([alert])

        return (
            'Alert inserted successfully',
            None,
            None
        )


    def insert_cef_alerts_command(client, args):
        # parsing alerts list. the reason we don't use argToList is because cef_alerts could contain comma (,) so
        # we shouldn't split them by comma
        alerts = args.get('cef_alerts')
        if isinstance(alerts, list):
            pass
        elif isinstance(alerts, str):
            alerts = json.loads(alerts) if alerts[0] == "[" and alerts[-1] == "]" else [alerts]
        else:
            raise ValueError('Invalid argument "cef_alerts". It should be either list of strings (cef alerts), '
                             'or single string')

        client.insert_cef_alerts(alerts)

        return (
            'Alerts inserted successfully',
            None,
            None
        )


    def sort_all_list_incident_fields(incident_data):
        """Sorting all lists fields in an incident - without this, elements may shift which results in false
        identification of changed fields"""
        if incident_data.get('hosts', []):
            incident_data['hosts'] = sorted(incident_data.get('hosts', []))
            incident_data['hosts'] = [host.upper() for host in incident_data.get('hosts', [])]

        if incident_data.get('users', []):
            incident_data['users'] = sorted(incident_data.get('users', []))
            incident_data['users'] = [user.upper() for user in incident_data.get('users', [])]

        if incident_data.get('incident_sources', []):
            incident_data['incident_sources'] = sorted(incident_data.get('incident_sources', []))
        format_sublists = not argToBoolean(demisto.params().get('dont_format_sublists', False))
        if incident_data.get('alerts', []):
            incident_data['alerts'] = sort_by_key(incident_data.get('alerts', []), main_key='alert_id', fallback_key='name')
            if format_sublists:
                reformat_sublist_fields(incident_data['alerts'])

        if incident_data.get('file_artifacts', []):
            incident_data['file_artifacts'] = sort_by_key(incident_data.get('file_artifacts', []), main_key='file_name',
                                                          fallback_key='file_sha256')
            if format_sublists:
                reformat_sublist_fields(incident_data['file_artifacts'])

        if incident_data.get('network_artifacts', []):
            incident_data['network_artifacts'] = sort_by_key(incident_data.get('network_artifacts', []),
                                                             main_key='network_domain', fallback_key='network_remote_ip')
            if format_sublists:
                reformat_sublist_fields(incident_data['network_artifacts'])


    def sync_incoming_incident_owners(incident_data):
        if incident_data.get('assigned_user_mail') and demisto.params().get('sync_owners'):
            user_info = demisto.findUser(email=incident_data.get('assigned_user_mail'))
            if user_info:
                demisto.debug(f"Syncing incident owners: XDR incident {incident_data.get('incident_id')}, "
                              f"owner {user_info.get('username')}")
                incident_data['owner'] = user_info.get('username')

            else:
                demisto.debug(f"The user assigned to XDR incident {incident_data.get('incident_id')} "
                              f"is not registered on XSOAR")


    def handle_incoming_user_unassignment(incident_data):
        incident_data['assigned_user_mail'] = ''
        incident_data['assigned_user_pretty_name'] = ''
        if demisto.params().get('sync_owners'):
            demisto.debug(f'Unassigning owner from XDR incident {incident_data.get("incident_id")}')
            incident_data['owner'] = ''


    def resolve_xsoar_close_reason(xdr_close_reason: str):
        """
        Resolving XSOAR close reason from possible custom XDR->XSOAR close-reason mapping or default mapping.
        :param xdr_close_reason: XDR raw status/close reason e.g. 'resolved_false_positive'.
        :return: XSOAR close reason.
        """
        possible_xsoar_close_reasons = get_xsoar_close_reasons()

        # Check if incoming XDR close-reason has a non-default mapping to XSOAR close-reason.
        if demisto.params().get("custom_xdr_to_xsoar_close_reason_mapping"):
            custom_xdr_to_xsoar_close_reason_mapping = comma_separated_mapping_to_dict(
                demisto.params().get("custom_xdr_to_xsoar_close_reason_mapping")
            )
            # XDR raw status/close-reason is prefixed with 'resolved_' and is given in snake_case format,
            # e.g. 'resolved_false_positive', whilst custom XDR->XSOAR close-reason mapping
            # is using title case format e.g. 'False Positive', therefore we need to adapt it accordingly.
            title_cased_xdr_close_reason = (
                xdr_close_reason.replace("resolved_", "").replace("_", " ").title()
            )
            xsoar_close_reason = custom_xdr_to_xsoar_close_reason_mapping.get(title_cased_xdr_close_reason)
            if xsoar_close_reason in possible_xsoar_close_reasons:
                demisto.debug(
                    f"XDR->XSOAR custom close-reason exists, using {xdr_close_reason}={xsoar_close_reason}"
                )
                return xsoar_close_reason

        # Otherwise, we use default mapping.
        xsoar_close_reason = XDR_RESOLVED_STATUS_TO_XSOAR.get(xdr_close_reason)
        demisto.debug(
            f"XDR->XSOAR custom close-reason does not exists, using default mapping {xdr_close_reason}={xsoar_close_reason}"
        )
        return xsoar_close_reason


    def handle_incoming_closing_incident(incident_data) -> dict:
        incident_id = incident_data.get("incident_id")
        demisto.debug(f"handle_incoming_closing_incident {incident_data=} {incident_id=}")
        closing_entry = {}  # type: Dict

        if incident_data.get("status") in XDR_RESOLVED_STATUS_TO_XSOAR:
            demisto.debug(
                f"handle_incoming_closing_incident {incident_data.get('status')=} {incident_id=}"
            )
            demisto.debug(f"Closing XDR issue {incident_id=}")
            xsoar_close_reason = resolve_xsoar_close_reason(incident_data.get("status"))
            closing_entry = {
                "Type": EntryType.NOTE,
                "Contents": {
                    "dbotIncidentClose": True,
                    "closeReason": xsoar_close_reason,
                    "closeNotes": incident_data.get("resolve_comment", ""),
                },
                "ContentsFormat": EntryFormat.JSON,
            }
            incident_data["closeReason"] = closing_entry["Contents"]["closeReason"]
            incident_data["closeNotes"] = closing_entry["Contents"]["closeNotes"]
            demisto.debug(
                f"handle_incoming_closing_incident {incident_id=} {incident_data['closeReason']=} "
                f"{incident_data['closeNotes']=}"
            )

            if incident_data.get("status") == "resolved_known_issue":
                close_notes = f'Known Issue.\n{incident_data.get("closeNotes", "")}'
                closing_entry["Contents"]["closeNotes"] = close_notes
                incident_data["closeNotes"] = close_notes
                demisto.debug(
                    f"handle_incoming_closing_incident {incident_id=} {close_notes=}"
                )

        return closing_entry


    def get_mapping_fields_command():
        xdr_incident_type_scheme = SchemeTypeMapping(type_name=XDR_INCIDENT_TYPE_NAME)
        for field in XDR_INCIDENT_FIELDS:
            xdr_incident_type_scheme.add_field(name=field, description=XDR_INCIDENT_FIELDS[field].get('description'))

        mapping_response = GetMappingFieldsResponse()
        mapping_response.add_scheme_type(xdr_incident_type_scheme)

        return mapping_response


    def get_modified_remote_data_command(client, args, mirroring_last_update: str = '', xdr_delay: int = 1):
        remote_args = GetModifiedRemoteDataArgs(args)
        last_update: str = mirroring_last_update or remote_args.last_update
        last_update_utc = dateparser.parse(last_update,
                                           settings={'TIMEZONE': 'UTC', 'RETURN_AS_TIMEZONE_AWARE': False})   # convert to utc format

        if last_update_utc:
            gte_modification_time_milliseconds = last_update_utc - timedelta(minutes=xdr_delay)
            lte_modification_time_milliseconds = gte_modification_time_milliseconds + timedelta(minutes=1)
        demisto.debug(
            f'Performing get-modified-remote-data command {last_update=} | {gte_modification_time_milliseconds=} |'
            f'{lte_modification_time_milliseconds=}'
        )
        raw_incidents = client.get_incidents(
            gte_modification_time_milliseconds=gte_modification_time_milliseconds,
            lte_modification_time_milliseconds=lte_modification_time_milliseconds,
            limit=100)
        last_run_mirroring = (lte_modification_time_milliseconds + timedelta(milliseconds=1))
        # Format with milliseconds as string, truncate microseconds
        last_run_mirroring_str = last_run_mirroring.replace(tzinfo=pytz.UTC).strftime(  # type: ignore
            '%Y-%m-%d %H:%M:%S.%f')[:-3] + '+02:00'  # type: ignore
        modified_incident_ids = []
        for raw_incident in raw_incidents:
            incident_id = raw_incident.get('incident_id')
            modified_incident_ids.append(incident_id)
        return GetModifiedRemoteDataResponse(modified_incident_ids), last_run_mirroring_str


    def get_remote_data_command(client, args):
        remote_args = GetRemoteDataArgs(args)
        demisto.debug(f'Performing get-remote-data command with incident id: {remote_args.remote_incident_id}')

        incident_data = {}
        try:
            # when Demisto version is 6.1.0 and above, this command will only be automatically executed on incidents
            # returned from get_modified_remote_data_command so we want to perform extra-data request on those incidents.
            return_only_updated_incident = not is_demisto_version_ge('6.1.0')  # True if version is below 6.1 else False

            incident_data = get_incident_extra_data_command(client, {"incident_id": remote_args.remote_incident_id,
                                                                     "alerts_limit": 1000,
                                                                     "return_only_updated_incident": return_only_updated_incident,
                                                                     "last_update": remote_args.last_update})
            if 'The incident was not modified' not in incident_data[0]:
                demisto.debug(f"Updating XDR incident {remote_args.remote_incident_id}")

                incident_data = incident_data[2].get('incident')
                incident_data['id'] = incident_data.get('incident_id')

                sort_all_list_incident_fields(incident_data)

                # deleting creation time as it keeps updating in the system
                del incident_data['creation_time']

                # handle unasignment
                if incident_data.get('assigned_user_mail') is None:
                    handle_incoming_user_unassignment(incident_data)

                else:
                    # handle owner sync
                    sync_incoming_incident_owners(incident_data)

                # handle closed issue in XDR and handle outgoing error entry
                entries = [handle_incoming_closing_incident(incident_data)]

                reformatted_entries = []
                for entry in entries:
                    if entry:
                        reformatted_entries.append(entry)

                incident_data['in_mirror_error'] = ''

                return GetRemoteDataResponse(
                    mirrored_object=incident_data,
                    entries=reformatted_entries
                )

            else:  # no need to update this incident
                incident_data = {
                    'id': remote_args.remote_incident_id,
                    'in_mirror_error': ""
                }

                return GetRemoteDataResponse(
                    mirrored_object=incident_data,
                    entries=[]
                )

        except Exception as e:
            demisto.debug(f"Error in XDR incoming mirror for incident {remote_args.remote_incident_id} \n"
                          f"Error message: {str(e)}")

            if "Rate limit exceeded" in str(e):
                return_error("API rate limit")

            if incident_data:
                incident_data['in_mirror_error'] = str(e)
                sort_all_list_incident_fields(incident_data)

                # deleting creation time as it keeps updating in the system
                del incident_data['creation_time']

            else:
                incident_data = {
                    'id': remote_args.remote_incident_id,
                    'in_mirror_error': str(e)
                }

            return GetRemoteDataResponse(
                mirrored_object=incident_data,
                entries=[]
            )


    def update_remote_system_command(client, args):
        remote_args = UpdateRemoteSystemArgs(args)
        incident_id = remote_args.remote_incident_id
        remote_data = remote_args.data
        demisto.debug(f"update_remote_system_command {incident_id=} {remote_args=}")
        demisto.debug(f"update_remote_system_command {incident_id=} , {remote_data.get('closeReason')=}, "
                      f"{remote_data.get('closeNotes')=}")

        if remote_args.delta:
            demisto.debug(f'Got the following delta keys {str(list(remote_args.delta.keys()))} to update'
                          f'incident {remote_args.remote_incident_id}')
        try:
            if remote_args.incident_changed:
                demisto.debug(f"update_remote_system_command {incident_id=} {remote_args.incident_changed=}")
                update_args = get_update_args(remote_args)

                update_args['incident_id'] = remote_args.remote_incident_id
                demisto.debug(f'Sending incident with remote ID [{remote_args.remote_incident_id}]\n')
                demisto.debug(f"Before checking status {update_args=}")
                current_remote_status = remote_args.data.get('status') if remote_args.data else None
                is_closed_delta = (update_args.get('close_reason') or update_args.get('closeReason') or update_args.get('closeNotes')
                                   or update_args.get('resolve_comment') or update_args.get('closingUserId'))
                is_closed_data = (remote_data.get('closeReason') or remote_data.get('close_reason') or remote_data.get('closeNotes'))
                demisto.debug(f"update_remote_system_command {is_closed_delta=}, {is_closed_data=}")
                is_closed = is_closed_delta or is_closed_data
                closed_without_status = not update_args.get('close_reason') and not update_args.get('closeReason')
                remote_is_already_closed = current_remote_status in XDR_RESOLVED_STATUS_TO_XSOAR
                demisto.debug(f"{remote_is_already_closed=}")
                if is_closed and closed_without_status and not remote_is_already_closed:
                    update_args['status'] = XSOAR_RESOLVED_STATUS_TO_XDR.get('Other')
                demisto.debug(f"After checking status {update_args=}")
                update_incident_command(client, update_args)

                close_alerts_in_xdr = argToBoolean(client._params.get("close_alerts_in_xdr", False))
                # Check all relevant fields for an incident being closed in XSOAR UI
                demisto.debug(f"Defining whether to close related alerts by: {is_closed=} {close_alerts_in_xdr=}")
                if is_closed and closed_without_status and remote_is_already_closed:
                    update_args['status'] = current_remote_status
                if close_alerts_in_xdr and is_closed:
                    update_related_alerts(client, update_args)

            else:
                demisto.debug(f'Skipping updating remote incident fields [{remote_args.remote_incident_id}] '
                              f'as it is not new nor changed')

            return remote_args.remote_incident_id

        except Exception as e:
            demisto.debug(f"Error in outgoing mirror for incident {remote_args.remote_incident_id} \n"
                          f"Error message: {str(e)}")

            return remote_args.remote_incident_id


    def update_related_alerts(client: Client, args: dict):
        new_status = args.get('status')
        incident_id = args.get('incident_id')
        comment = f"Resolved by XSOAR, due to incident {incident_id} that has been resolved."
        demisto.debug(f"{new_status=}, {comment=}")
        if not new_status:
            raise DemistoException(f"Failed to update alerts related to incident {incident_id},"
                                   "no status found")
        incident_extra_data = client.get_incident_extra_data(incident_id)
        if 'alerts' in incident_extra_data and 'data' in incident_extra_data['alerts']:
            alerts_array = incident_extra_data['alerts']['data']
            related_alerts_ids_array = [str(alert['alert_id']) for alert in alerts_array if 'alert_id' in alert]
            demisto.debug(f"{related_alerts_ids_array=}")
            args_for_command = {'alert_ids': related_alerts_ids_array, 'status': new_status, 'comment': comment}
            return_results(update_alerts_in_xdr_command(client, args_for_command))


    def fetch_incidents(client: Client, first_fetch_time, integration_instance, exclude_artifacts: bool, last_run: dict,
                        max_fetch: int = 10, statuses: List = [], starred: Optional[bool] = None,
                        starred_incidents_fetch_window: str = None):
        global ALERTS_LIMIT_PER_INCIDENTS
        # Get the last fetch time, if exists
        last_fetch = last_run.get('time')
        incidents_from_previous_run = last_run.get('incidents_from_previous_run', [])

        incidents_at_last_timestamp = set(last_run.get('incidents_at_last_timestamp', []))
        new_incidents_at_last_timestamp = []

        # Handle first time fetch, fetch incidents retroactively
        if last_fetch is None:
            last_fetch, _ = parse_date_range(first_fetch_time, to_timestamp=True)

        if starred:
            starred_incidents_fetch_window, _ = parse_date_range(starred_incidents_fetch_window, to_timestamp=True)

        incidents = []
        if incidents_from_previous_run:
            raw_incidents = incidents_from_previous_run
            ALERTS_LIMIT_PER_INCIDENTS = last_run.get('alerts_limit_per_incident', -1)
        else:
            if statuses:
                raw_incidents = []
                for status in statuses:
                    raw_incident_status = client.get_multiple_incidents_extra_data(
                        gte_creation_time_milliseconds=last_fetch,
                        status=status,
                        limit=max_fetch, starred=starred,
                        starred_incidents_fetch_window=starred_incidents_fetch_window,
                        exclude_artifacts=exclude_artifacts)
                    raw_incidents.extend(raw_incident_status)
                raw_incidents = sorted(raw_incidents, key=lambda inc: inc.get('incident', {}).get('creation_time'))
            else:
                raw_incidents = client.get_multiple_incidents_extra_data(
                    gte_creation_time_milliseconds=last_fetch, limit=max_fetch,
                    starred=starred,
                    starred_incidents_fetch_window=starred_incidents_fetch_window,
                    exclude_artifacts=exclude_artifacts)

        # save the last 100 modified incidents to the integration context - for mirroring purposes
        client.save_modified_incidents_to_integration_context()

        # maintain a list of non created incidents in a case of a rate limit exception
        non_created_incidents: list = raw_incidents.copy()
        next_run = {}
        try:
            for raw_incident in raw_incidents[:max_fetch]:
                incident_data: dict[str, Any] = sort_incident_data(raw_incident) if raw_incident.get('incident') else raw_incident
                incident_id = incident_data.get('incident_id')
                if incident_id in incidents_at_last_timestamp:  # remove duplicates
                    demisto.debug(f'incident {incident_id!r} is a duplicate, skipping.')
                    non_created_incidents.remove(raw_incident)
                    continue
                alert_count = arg_to_number(incident_data.get('alert_count')) or 0
                if alert_count > ALERTS_LIMIT_PER_INCIDENTS:
                    demisto.debug(f'for incident:{incident_id} using the old call since alert_count:{alert_count} >" \
                                  "limit:{ALERTS_LIMIT_PER_INCIDENTS}')
                    raw_incident_ = client.get_incident_extra_data(incident_id=incident_id)
                    incident_data = sort_incident_data(raw_incident_)
                sort_all_list_incident_fields(incident_data)
                incident_data['mirror_direction'] = MIRROR_DIRECTION.get(demisto.params().get('mirror_direction', 'None'))
                incident_data['mirror_instance'] = integration_instance
                incident_data['last_mirrored_in'] = int(datetime.now().timestamp() * 1000)
                description = incident_data.get('description')
                occurred = timestamp_to_datestring(incident_data['creation_time'], TIME_FORMAT + 'Z')
                incident: dict[str, Any] = {
                    'name': f'XDR Incident {incident_id} - {description}',
                    'occurred': occurred,
                    'rawJSON': json.dumps(incident_data),
                }
                if demisto.params().get('sync_owners') and incident_data.get('assigned_user_mail'):
                    incident['owner'] = demisto.findUser(email=incident_data['assigned_user_mail']).get('username')
                # Update last run and add incident if the incident is newer than last fetch
                if incident_data.get('creation_time', 0) > last_fetch:
                    last_fetch = incident_data['creation_time']
                    new_incidents_at_last_timestamp = [incident_id]
                elif incident_data.get('creation_time') == last_fetch:
                    new_incidents_at_last_timestamp.append(incident_id)

                incidents.append(incident)
                non_created_incidents.remove(raw_incident)

        except Exception as e:
            if "Rate limit exceeded" in str(e):
                demisto.info(f"Cortex XDR - rate limit exceeded, number of non created incidents is: "
                             f"{len(non_created_incidents)!r}.\n The incidents will be created in the next fetch")
            else:
                raise

        if non_created_incidents:
            next_run['alerts_limit_per_incident'] = ALERTS_LIMIT_PER_INCIDENTS  # type: ignore[assignment]
        next_run['incidents_from_previous_run'] = non_created_incidents
        # stay on same timestamp if there are new incidents fetched because there might be more created in the same instant.
        next_run['time'] = last_fetch + (0 if new_incidents_at_last_timestamp else 1)
        next_run['incidents_at_last_timestamp'] = new_incidents_at_last_timestamp

        return next_run, incidents


    def get_endpoints_by_status_command(client: Client, args: Dict) -> CommandResults:
        status = args.get('status')

        status = argToList(status)
        last_seen_gte = arg_to_timestamp(
            arg=args.get('last_seen_gte'),
            arg_name='last_seen_gte'
        )

        last_seen_lte = arg_to_timestamp(
            arg=args.get('last_seen_lte'),
            arg_name='last_seen_lte'
        )

        endpoints_count, raw_res = client.get_endpoints_by_status(status, last_seen_gte=last_seen_gte,
                                                                  last_seen_lte=last_seen_lte)

        ec = {'status': status, 'count': endpoints_count}

        return CommandResults(
            readable_output=f'{status} endpoints count: {endpoints_count}',
            outputs_prefix=f'{INTEGRATION_CONTEXT_BRAND}.EndpointsStatus',
            outputs_key_field='status',
            outputs=ec,
            raw_response=raw_res)


    def file_details_results(client: Client, args: Dict, add_to_context: bool) -> None:
        return_entry, file_results = retrieve_file_details_command(client, args, add_to_context)
        demisto.results(return_entry)
        if file_results:
            demisto.results(file_results)


    def get_contributing_event_command(client: Client, args: Dict) -> CommandResults:
        if alert_ids := argToList(args.get('alert_ids')):
            alerts = []

            for alert_id in alert_ids:
                if alert := client.get_contributing_event_by_alert_id(int(alert_id)):
                    page_number = max(int(args.get('page_number', 1)), 1) - 1  # Min & default zero (First page)
                    page_size = max(int(args.get('page_size', 50)), 0)  # Min zero & default 50
                    offset = page_number * page_size
                    limit = max(int(args.get('limit', 0)), 0) or offset + page_size

                    alert_with_events = {
                        'alertID': str(alert_id),
                        'events': alert.get('events', [])[offset:limit],
                    }
                    alerts.append(alert_with_events)

            readable_output = tableToMarkdown(
                'Contributing events', alerts, headerTransform=pascalToSpace, removeNull=True, is_auto_json_transform=True
            )
            return CommandResults(
                readable_output=readable_output,
                outputs_prefix=f'{INTEGRATION_CONTEXT_BRAND}.ContributingEvent',
                outputs_key_field='alertID',
                outputs=alerts,
                raw_response=alerts
            )

        else:
            return CommandResults(readable_output='The alert_ids argument cannot be empty.')


    def replace_featured_field_command(client: Client, args: Dict) -> CommandResults:
        field_type = args.get('field_type', '')
        values = argToList(args.get('values'))
        len_values = len(values)
        comments = argToList(args.get('comments'))[:len_values]
        ad_type = argToList(args.get('ad_type', 'group'))[:len_values]

        if field_type == 'ad_groups':
            fields = [
                {
                    'value': field[0], 'comment': field[1], 'type': field[2]
                } for field in zip_longest(values, comments, ad_type, fillvalue='')
            ]
        else:
            fields = [
                {'value': field[0], 'comment': field[1]} for field in zip_longest(values, comments, fillvalue='')
            ]

        client.replace_featured_field(field_type, fields)

        result = {'fieldType': field_type, 'fields': fields}

        readable_output = tableToMarkdown(
            f'Replaced featured: {result.get("fieldType")}', result.get('fields'), headerTransform=pascalToSpace
        )

        return CommandResults(
            readable_output=readable_output,
            outputs_prefix=f'{INTEGRATION_CONTEXT_BRAND}.FeaturedField',
            outputs_key_field='fieldType',
            outputs=result,
            raw_response=result
        )


    def update_alerts_in_xdr_command(client: Client, args: Dict) -> CommandResults:
        alerts_list = argToList(args.get('alert_ids'))
        array_of_all_ids = []
        severity = args.get('severity')
        status = args.get('status')
        comment = args.get('comment')
        if not severity and not status and not comment:
            raise DemistoException(
                f"Can not find a field to update for alerts {alerts_list}, please fill in severity/status/comment.")
        # API is limited to 100 alerts per request, doing the request in batches of 100.
        for index in range(0, len(alerts_list), 100):
            alerts_sublist = alerts_list[index:index + 100]
            demisto.debug(f'{alerts_sublist=}, {severity=}, {status=}, {comment=}')
            array_of_sublist_ids = client.update_alerts_in_xdr_request(alerts_sublist, severity, status, comment)
            array_of_all_ids += array_of_sublist_ids
        if not array_of_all_ids:
            raise DemistoException("Could not find alerts to update, please make sure you used valid alert IDs.")
        return CommandResults(readable_output="Alerts with IDs {} have been updated successfully.".format(",".join(array_of_all_ids))
                              )


    def main():  # pragma: no cover
        """
        Executes an integration command
        """
        command = demisto.command()
        params = demisto.params()
        LOG(f'Command being called is {command}')
        # using two different credentials object as they both fields need to be encrypted
        first_fetch_time = params.get('fetch_time', '3 days')
        base_url = urljoin(params.get('url'), '/public_api/v1')
        proxy = params.get('proxy')
        verify_cert = not params.get('insecure', False)
        statuses = params.get('status')
        starred = True if params.get('starred') else None
        starred_incidents_fetch_window = params.get('starred_incidents_fetch_window', '3 days')
        exclude_artifacts = argToBoolean(params.get('exclude_fields', True))
        xdr_delay = arg_to_number(params.get('xdr_delay')) or 1
        try:
            timeout = int(params.get('timeout', 120))
        except ValueError as e:
            demisto.debug(f'Failed casting timeout parameter to int, falling back to 120 - {e}')
            timeout = 120
        try:
            max_fetch = int(params.get('max_fetch', 10))
        except ValueError as e:
            demisto.debug(f'Failed casting max fetch parameter to int, falling back to 10 - {e}')
            max_fetch = 10

        client = Client(
            base_url=base_url,
            proxy=proxy,
            verify=verify_cert,
            timeout=timeout,
            params=params
        )

        args = demisto.args()
        args["integration_context_brand"] = INTEGRATION_CONTEXT_BRAND
        args["integration_name"] = INTEGRATION_NAME
        try:
            if command == 'test-module':
                client.test_module(first_fetch_time)
                demisto.results('ok')

            elif command == 'fetch-incidents':
                integration_instance = demisto.integrationInstance()
                next_run, incidents = fetch_incidents(client=client,
                                                      first_fetch_time=first_fetch_time,
                                                      integration_instance=integration_instance,
                                                      exclude_artifacts=exclude_artifacts,
                                                      last_run=demisto.getLastRun().get('next_run') or {},
                                                      max_fetch=max_fetch,
                                                      statuses=statuses,
                                                      starred=starred,
                                                      starred_incidents_fetch_window=starred_incidents_fetch_window,
                                                      )
                last_run_obj = demisto.getLastRun()
                last_run_obj['next_run'] = next_run
                demisto.setLastRun(last_run_obj)
                demisto.incidents(incidents)

            elif command == 'xdr-get-incidents':
                return_outputs(*get_incidents_command(client, args))

            elif command == 'xdr-get-incident-extra-data':
                return_outputs(*get_incident_extra_data_command(client, args))

            elif command == 'xdr-update-incident':
                return_outputs(*update_incident_command(client, args))

            elif command == 'xdr-get-endpoints':
                return_results(get_endpoints_command(client, args))

            elif command == 'xdr-endpoint-alias-change':
                return_results(endpoint_alias_change_command(client, **args))

            elif command == 'xdr-insert-parsed-alert':
                return_outputs(*insert_parsed_alert_command(client, args))

            elif command == 'xdr-insert-cef-alerts':
                return_outputs(*insert_cef_alerts_command(client, args))

            elif command == 'xdr-isolate-endpoint':
                return_results(isolate_endpoint_command(client, args))

            elif command == 'xdr-endpoint-isolate':
                polling_args = {
                    **args,
                    "endpoint_id_list": args.get('endpoint_id')
                }
                return_results(run_polling_command(client=client,
                                                   args=polling_args,
                                                   cmd="xdr-endpoint-isolate",
                                                   command_function=isolate_endpoint_command,
                                                   command_decision_field="action_id",
                                                   results_function=get_endpoints_command,
                                                   polling_field="is_isolated",
                                                   polling_value=["AGENT_ISOLATED"],
                                                   stop_polling=True))

            elif command == 'xdr-unisolate-endpoint':
                return_results(unisolate_endpoint_command(client, args))

            elif command == 'xdr-endpoint-unisolate':
                polling_args = {
                    **args,
                    "endpoint_id_list": args.get('endpoint_id')
                }
                return_results(run_polling_command(client=client,
                                                   args=polling_args,
                                                   cmd="xdr-endpoint-unisolate",
                                                   command_function=unisolate_endpoint_command,
                                                   command_decision_field="action_id",
                                                   results_function=get_endpoints_command,
                                                   polling_field="is_isolated",
                                                   polling_value=["AGENT_UNISOLATED",
                                                                  "CANCELLED",
                                                                  "ֿPENDING_ABORT",
                                                                  "ABORTED",
                                                                  "EXPIRED",
                                                                  "COMPLETED_PARTIAL",
                                                                  "COMPLETED_SUCCESSFULLY",
                                                                  "FAILED",
                                                                  "TIMEOUT"],
                                                   stop_polling=True))

            elif command == 'xdr-get-distribution-url':
                return_outputs(*get_distribution_url_command(client, args))

            elif command == 'xdr-get-create-distribution-status':
                return_outputs(*get_distribution_status_command(client, args))

            elif command == 'xdr-get-distribution-versions':
                return_outputs(*get_distribution_versions_command(client, args))

            elif command == 'xdr-create-distribution':
                return_outputs(*create_distribution_command(client, args))

            elif command == 'xdr-get-audit-management-logs':
                return_outputs(*get_audit_management_logs_command(client, args))

            elif command == 'xdr-get-audit-agent-reports':
                return_outputs(*get_audit_agent_reports_command(client, args))

            elif command == 'xdr-quarantine-files':
                return_results(quarantine_files_command(client, args))

            elif command == 'xdr-file-quarantine':
                return_results(run_polling_command(client=client,
                                                   args=args,
                                                   cmd="xdr-file-quarantine",
                                                   command_function=quarantine_files_command,
                                                   command_decision_field="action_id",
                                                   results_function=action_status_get_command,
                                                   polling_field="status",
                                                   polling_value=["PENDING",
                                                                  "IN_PROGRESS",
                                                                  "PENDING_ABORT"]))

            elif command == 'core-quarantine-files':
                polling_args = {
                    **args,
                    "endpoint_id": argToList(args.get("endpoint_id_list"))[0]
                }
                return_results(run_polling_command(client=client,
                                                   args=polling_args,
                                                   cmd="core-quarantine-files",
                                                   command_function=quarantine_files_command,
                                                   command_decision_field="action_id",
                                                   results_function=action_status_get_command,
                                                   polling_field="status",
                                                   polling_value=["PENDING",
                                                                  "IN_PROGRESS",
                                                                  "PENDING_ABORT"]))

            elif command == 'xdr-get-quarantine-status':
                return_results(get_quarantine_status_command(client, args))

            elif command == 'xdr-restore-file':
                return_results(restore_file_command(client, args))

            elif command == 'xdr-file-restore':
                return_results(run_polling_command(client=client,
                                                   args=args,
                                                   cmd="xdr-file-restore",
                                                   command_function=restore_file_command,
                                                   command_decision_field="action_id",
                                                   results_function=action_status_get_command,
                                                   polling_field="status",
                                                   polling_value=["PENDING",
                                                                  "IN_PROGRESS",
                                                                  "PENDING_ABORT"]))

            elif command == 'xdr-endpoint-scan':
                return_results(endpoint_scan_command(client, args))

            elif command == 'xdr-endpoint-scan-execute':
                return_results(run_polling_command(client=client,
                                                   args=args,
                                                   cmd="xdr-endpoint-scan-execute",
                                                   command_function=endpoint_scan_command,
                                                   command_decision_field="action_id",
                                                   results_function=action_status_get_command,
                                                   polling_field="status",
                                                   polling_value=["PENDING",
                                                                  "IN_PROGRESS",
                                                                  "PENDING_ABORT"]))

            elif command == 'xdr-endpoint-scan-abort':
                return_results(endpoint_scan_abort_command(client, args))

            elif command == 'get-mapping-fields':
                return_results(get_mapping_fields_command())

            elif command == 'get-remote-data':
                return_results(get_remote_data_command(client, args))

            elif command == 'update-remote-system':
                return_results(update_remote_system_command(client, args))

            elif command == 'xdr-delete-endpoints':
                return_outputs(*delete_endpoints_command(client, args))

            elif command == 'xdr-get-policy':
                return_outputs(*get_policy_command(client, args))

            elif command == 'xdr-get-endpoint-device-control-violations':
                return_outputs(*get_endpoint_device_control_violations_command(client, args))

            elif command == 'xdr-retrieve-files':
                return_results(retrieve_files_command(client, args))

            elif command == 'xdr-file-retrieve':
                polling = run_polling_command(client=client,
                                              args=args,
                                              cmd="xdr-file-retrieve",
                                              command_function=retrieve_files_command,
                                              command_decision_field="action_id",
                                              results_function=action_status_get_command,
                                              polling_field="status",
                                              polling_value=["PENDING",
                                                             "IN_PROGRESS",
                                                             "PENDING_ABORT"])
                raw = polling.raw_response
                # raw is the response returned by the get-action-status
                if polling.scheduled_command:
                    return_results(polling)
                    return
                status = raw[0].get('status')  # type: ignore
                if status == 'COMPLETED_SUCCESSFULLY':
                    file_details_results(client, args, True)
                else:  # status is not in polling value and operation was not COMPLETED_SUCCESSFULLY
                    polling.outputs_prefix = f'{args.get("integration_context_brand", "CoreApiModule")}' \
                                             f'.RetrievedFiles(val.action_id == obj.action_id)'
                    return_results(polling)

            elif command == 'xdr-retrieve-file-details':
                file_details_results(client, args, False)

            elif command == 'xdr-get-scripts':
                return_outputs(*get_scripts_command(client, args))

            elif command == 'xdr-get-script-metadata':
                return_outputs(*get_script_metadata_command(client, args))

            elif command == 'xdr-get-script-code':
                return_outputs(*get_script_code_command(client, args))

            elif command == 'xdr-action-status-get':
                return_results(action_status_get_command(client, args))

            elif command == 'get-modified-remote-data':
                last_run_mirroring: Dict[str, Any] = demisto.getLastRun()

                modified_incidents, next_mirroring_time = get_modified_remote_data_command(
                    client=client,
                    args=demisto.args(),
                    mirroring_last_update=last_run_mirroring.get('mirroring_last_update', ''),
                    xdr_delay=xdr_delay,
                )
                last_run_mirroring['mirroring_last_update'] = next_mirroring_time
                demisto.setLastRun(last_run_mirroring)
                return_results(modified_incidents)

            elif command == 'xdr-script-run':  # used with polling = true always
                return_results(script_run_polling_command(args, client))

            elif command == 'xdr-run-script':
                return_results(run_script_command(client, args))

            elif command == 'xdr-run-snippet-code-script':
                return_results(run_snippet_code_script_command(client, args))

            elif command == 'xdr-snippet-code-script-execute':
                return_results(run_polling_command(client=client,
                                                   args=args,
                                                   cmd="xdr-snippet-code-script-execute",
                                                   command_function=run_snippet_code_script_command,
                                                   command_decision_field="action_id",
                                                   results_function=action_status_get_command,
                                                   polling_field="status",
                                                   polling_value=["PENDING",
                                                                  "IN_PROGRESS",
                                                                  "PENDING_ABORT"]))

            elif command == 'xdr-get-script-execution-status':
                return_results(get_script_execution_status_command(client, args))

            elif command == 'xdr-get-script-execution-results':
                return_results(get_script_execution_results_command(client, args))

            elif command == 'xdr-get-script-execution-result-files':
                return_results(get_script_execution_result_files_command(client, args))

            elif command == 'xdr-get-cloud-original-alerts':
                return_results(get_original_alerts_command(client, args))

            elif command == 'xdr-get-alerts':
                return_results(get_alerts_by_filter_command(client, args))

            elif command == 'xdr-run-script-execute-commands':
                return_results(run_script_execute_commands_command(client, args))

            elif command == 'xdr-script-commands-execute':
                return_results(run_polling_command(client=client,
                                                   args=args,
                                                   cmd="xdr-script-commands-execute",
                                                   command_function=run_script_execute_commands_command,
                                                   command_decision_field="action_id",
                                                   results_function=action_status_get_command,
                                                   polling_field="status",
                                                   polling_value=["PENDING",
                                                                  "IN_PROGRESS",
                                                                  "PENDING_ABORT"]))

            elif command == 'xdr-run-script-delete-file':
                return_results(run_script_delete_file_command(client, args))

            elif command == 'xdr-file-delete-script-execute':
                return_results(run_polling_command(client=client,
                                                   args=args,
                                                   cmd="xdr-file-delete-script-execute",
                                                   command_function=run_script_delete_file_command,
                                                   command_decision_field="action_id",
                                                   results_function=action_status_get_command,
                                                   polling_field="status",
                                                   polling_value=["PENDING",
                                                                  "IN_PROGRESS",
                                                                  "PENDING_ABORT"]))

            elif command == 'xdr-run-script-file-exists':
                return_results(run_script_file_exists_command(client, args))

            elif command == 'xdr-file-exist-script-execute':
                return_results(run_polling_command(client=client,
                                                   args=args,
                                                   cmd="xdr-file-exist-script-execute",
                                                   command_function=run_script_file_exists_command,
                                                   command_decision_field="action_id",
                                                   results_function=action_status_get_command,
                                                   polling_field="status",
                                                   polling_value=["PENDING",
                                                                  "IN_PROGRESS",
                                                                  "PENDING_ABORT"]))

            elif command == 'xdr-run-script-kill-process':
                return_results((client, args))

            elif command == 'xdr-kill-process-script-execute':
                return_results(run_polling_command(client=client,
                                                   args=args,
                                                   cmd="xdr-kill-process-script-execute",
                                                   command_function=run_script_kill_process_command,
                                                   command_decision_field="action_id",
                                                   results_function=action_status_get_command,
                                                   polling_field="status",
                                                   polling_value=["PENDING",
                                                                  "IN_PROGRESS",
                                                                  "PENDING_ABORT"]))

            elif command == 'endpoint':
                return_results(endpoint_command(client, args))

            elif command == 'xdr-get-endpoints-by-status':
                return_results(get_endpoints_by_status_command(client, args))

            elif command == 'xdr-blocklist-files':
                return_results(blocklist_files_command(client, args))

            elif command == 'xdr-blacklist-files':
                args['prefix'] = 'blacklist'
                return_results(blocklist_files_command(client, args))

            elif command == 'xdr-allowlist-files':
                return_results(allowlist_files_command(client, args))

            elif command == 'xdr-whitelist-files':
                args['prefix'] = 'whitelist'
                return_results(allowlist_files_command(client, args))

            elif command == 'xdr-remove-blocklist-files':
                return_results(remove_blocklist_files_command(client, args))

            elif command == 'xdr-remove-allowlist-files':
                return_results(remove_allowlist_files_command(client, args))

            elif command == 'xdr-get-contributing-event':
                return_results(get_contributing_event_command(client, args))

            elif command == 'xdr-replace-featured-field':
                return_results(replace_featured_field_command(client, args))

            elif command == 'xdr-endpoint-tag-add':
                return_results(add_tag_to_endpoints_command(client, args))

            elif command == 'xdr-endpoint-tag-remove':
                return_results(remove_tag_from_endpoints_command(client, args))

            elif command == 'xdr-get-tenant-info':
                return_results(get_tenant_info_command(client))

            elif command == 'xdr-list-users':
                return_results(list_users_command(client, args))

            elif command == 'xdr-list-risky-users':
                return_results(list_risky_users_or_host_command(client, "user", args))

            elif command == 'xdr-list-risky-hosts':
                return_results(list_risky_users_or_host_command(client, "host", args))

            elif command == 'xdr-list-user-groups':
                return_results(list_user_groups_command(client, args))

            elif command == 'xdr-list-roles':
                return_results(list_roles_command(client, args))

            elif command in ('xdr-set-user-role', 'xdr-remove-user-role'):
                return_results(change_user_role_command(client, args))

            elif command == 'xdr-update-alert':
                return_results(update_alerts_in_xdr_command(client, args))

        except Exception as err:
            return_error(str(err))


    if __name__ in ('__main__', '__builtin__', 'builtins'):
        main()

    register_module_line('Cortex XDR - IR', 'end', __line__())
  subtype: python3
  ismappable: true
  isremotesyncin: true
  isremotesyncout: true
  type: python
  nativeimage:
  - '8.7'
  - '8.6'
tests:
- Test XDR Playbook execute script commands
- Test XDR Playbook quarantine file command
- Test XDR Playbook general commands
- Test XDR Playbook retrieve file command
defaultmapperin: Cortex XDR - IR-mapper
defaultmapperout: Cortex XDR - IR-out-mapper
fromversion: 5.0.0
image: data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAHgAAAAyCAYAAACXpx/YAAAACXBIWXMAAAsSAAALEgHS3X78AAAD6klEQVR4nO2cS24bMQyGyaL75AbJCeo5QIH6BnVPkOkN3BPER8gN4tzA3XQbB+gBHHTbRbzq1kH3ZaGA4ygUNaPxxBOA4AcIqPWgHv9QosZOkYjAscs719Y2LrBxXGDjuMDGcYGN4wIbxwU2jgtsHBfYOC6wcVxg47jAxnGBjeMCG+f9W04PEacAENIDES2TCs7wNR77+2BEPAeABQBcRNl3RDRNKjuDGdWDEbEGgCsAOEkKnaPQW2BErHhbPY2ydwCwJqJN0uCluNdJQf/+Q79VUiAgonWS+WyjEuMvIRwjDwPs7OL14eMpJrGfm2+YGyLOAeAPAPwloh9Jb1HlogQAQaAwAGpJD5otfiC0dksuW/LnYH+u2SiwpaVg91SxsVbqdqXFQDtr0bYW5cFJKlEniLsR9eZc9hsA/gHAL22d9ja0TKWT4olkbMgHYxNPhs9kWZ4Ic4DAT7YUG28ucMm8owd/7xBR2UdOH7R1alLJFh06+STybnhyQbhz3kJmAHCmbDG1yH8MdbXtKGICACsWs4tvvDDNw1ixdzR9TsJ2KLbsJY8/5jL6951Snt3ymS3bzZHMl4gWHHQ2Aed+3ogoA9EbIqqjtj8z/SSdZBMvVvwEPQnaUn+m5MmnUPME+SQ3aarUlR5cUifpU2nTq77iwYmH9jj+5BrJneFg210ePBOf6zbPI6JVkpl64VVSI8+swHM0kgBGqfPanLPXSTrv+MEzOWCbcFa8Y94rOhTTK4pui0xbeLFtE9EuXzWhM1oODwwixjYrcQ175G3v2JyJbb7hrmPrbpjyUSOPs2nPNXtBL4FDyD6ksyMxaTE7eIFGRIthTnjHqw8dRte7aLkw86RGN9u4BgcVpWTv1RH37CVbkf+d44USG69BeBuHSuoMFDveEVxw+UF0CbxkL2i4DOcMX77jAZ6GQSCidtbJbb3PYEu21jkvYsViN3wecnaNBSLOhLhhvb+Idb8+WGQt8hIRnryQxxH1Wl7EC9vLC70WRa8y48lG0XxN2rX1lUuvEEUfcg+uxHj3LzuUMuIgNxlHW2otFCLJztSUaS9fdOyEMFLgdY8XHdPSRWtLYwusjDN5GBXnKJpLn2tS4+VLRFxxhzMlUt3yZHNRdmh3G30ObW8RsYkwm3M5bLFXHdeKHZ+58ed4rBt+zxtfxxYF23VsUztqNPqc77LuQuQtZbzA6w7iWAtHZF0aOI72dWFHIOFfFx6J0X7RwV75VQQPjhWB4Vnkit9lOyPwpn/h7z/ZOT7+XzgYx39VaRwX2DgusHFcYOO4wMZxgY3jAhvHBTaOC2wcF9g4LrBxXGDjuMDGcYEtAwD/AbjPSozwVJX9AAAAAElFTkSuQmCC
detaileddescription: "## Palo Alto Networks Cortex XDR - IR\n[Cortex XDR](https://www.paloaltonetworks.com/cortex/cortex-xdr) is the world's first detection and response app that natively integrates network, endpoint, and cloud data to stop sophisticated attacks.\n\n### Generate an API Key and API Key ID\n1. In your Cortex XDR platform, go to **Settings** > **Configurations** > **Integrations** >**API key** page..\n2. Click the **+New Key** button in the top right corner.\n3. Generate a key of *Security Level* type **Advanced**, and a *Role* according your Permissions.\n4. Copy and paste the key from Generated key.\n5. From the ID column, copy the Key ID.\n\n### URL\n1. In your Cortex XDR platform, go to **Settings** > **Configurations** > **Integrations** > **API key** page.\n2. Click the **Copy API URL** button in the top right corner.\n\n---\n\n### Mirroring\n\n**XDR mirroring delay in minutes**: In case of missing updates in mirroring incoming changes from XDR, use the xdr_delay parameter to extend the delay period. However, be aware that this may result in increased latency when updating incidents.\n\n**Close-reason default mapping XSOAR -> XDR**: _Other=Other, Duplicate=Duplicate Incident, False Positive=False Positive, Resolved=True Positive_\n\n**Close-reason default mapping XDR -> XSOAR**: _Known Issue=Other, Duplicate Incident=Duplicate, False Positive=False Positive, True Positive=Resolved, Other=Other, Auto=Resolved_\n\n[View Integration Documentation](https://xsoar.pan.dev/docs/reference/integrations/cortex-xdr---ir)\n"
